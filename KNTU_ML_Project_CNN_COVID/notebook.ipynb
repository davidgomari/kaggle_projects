{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 1 Prerequisites","metadata":{}},{"cell_type":"code","source":"import gdown\nfrom pickle import dump, load\nimport shutil\nimport os\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, Input\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\nimport seaborn as sns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T17:57:34.255357Z","iopub.execute_input":"2025-02-08T17:57:34.255720Z","iopub.status.idle":"2025-02-08T17:57:34.318264Z","shell.execute_reply.started":"2025-02-08T17:57:34.255689Z","shell.execute_reply":"2025-02-08T17:57:34.317594Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"np.random.seed(33)\ntf.random.set_seed(33)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T17:57:35.365712Z","iopub.execute_input":"2025-02-08T17:57:35.366046Z","iopub.status.idle":"2025-02-08T17:57:35.374473Z","shell.execute_reply.started":"2025-02-08T17:57:35.366019Z","shell.execute_reply":"2025-02-08T17:57:35.373533Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"## 1.1 Required global functions","metadata":{}},{"cell_type":"code","source":"def download_from_drive(filename, file_id):\n    url = f\"https://drive.google.com/uc?export=download&id={file_id}\"\n    gdown.download(url, filename, quiet=False)\n\ndef load_dataset(image_size=(150, 150)):\n\n    categories = [\"NORMAL\", \"COVID\"]\n    datasets_name_list = [\"test\", \"train\"]\n    X = [[], []] # 0 for test & 1 for train\n    y = [[], []] # 0 for test & 1 for train\n\n    for i, dataset_name in enumerate(datasets_name_list):\n        for label, category in enumerate(categories):\n            dir_path = \"/kaggle/working/dataset1/\" + dataset_name + '/' + category + '/'\n            for filename in os.listdir(dir_path):\n                img_path = os.path.join(dir_path, filename)\n                img = Image.open(img_path).convert(\"RGB\")\n                img = img.resize(image_size)\n                img_array = np.array(img)\n                X[i].append(img_array)\n                y[i].append(label) # NORMAL = 0, COVID = 1\n\n    X_train = np.array(X[1]) / 255.0\n    y_train = np.array(y[1])\n    X_test = np.array(X[0]) / 255.0\n    y_test = np.array(y[0])\n\n    indices = np.arange(X_train.shape[0])\n    np.random.shuffle(indices)\n    X_train = X_train[indices]\n    y_train = y_train[indices]\n\n    return X_train, y_train, X_test, y_test\n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T16:31:07.480800Z","iopub.execute_input":"2025-02-08T16:31:07.481388Z","iopub.status.idle":"2025-02-08T16:31:07.495990Z","shell.execute_reply.started":"2025-02-08T16:31:07.481343Z","shell.execute_reply":"2025-02-08T16:31:07.494812Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"## 1.2 Downloading & Loading the dataset","metadata":{}},{"cell_type":"code","source":"download_from_drive(\n    filename=\"Datasets.rar\",\n    file_id=\"1wM1NufVrRtbHuLmeBjiOls_e80Qrsoy-\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T09:59:56.327216Z","iopub.execute_input":"2025-02-07T09:59:56.327604Z","iopub.status.idle":"2025-02-07T10:00:02.919933Z","shell.execute_reply.started":"2025-02-07T09:59:56.327571Z","shell.execute_reply":"2025-02-07T10:00:02.918908Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Extract the Datasets.rar file in the current directory\n!unrar x \"Datasets.rar\" ./","metadata":{"trusted":true,"_kg_hide-output":true,"scrolled":true,"execution":{"iopub.status.busy":"2025-02-07T10:00:02.921204Z","iopub.execute_input":"2025-02-07T10:00:02.921494Z","iopub.status.idle":"2025-02-07T10:00:05.358943Z","shell.execute_reply.started":"2025-02-07T10:00:02.921468Z","shell.execute_reply":"2025-02-07T10:00:05.357315Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train, y_train, X_test, y_test = load_dataset()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T22:36:14.532968Z","iopub.execute_input":"2025-02-07T22:36:14.533261Z","iopub.status.idle":"2025-02-07T22:36:22.070931Z","shell.execute_reply.started":"2025-02-07T22:36:14.533239Z","shell.execute_reply":"2025-02-07T22:36:22.070165Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"num_train = X_train.shape[0]\nnum_test = X_test.shape[0]\nnum_covid = sum(y_train[y_train==1]) + sum(y_test[y_test==1])\nprint(f\"Number of Training Samples: {num_train}\\nNumber of Test Samples: {num_test}\\nNumber of COVID samples: {num_covid}\\nNumber of Normal samples: {num_train + num_test - num_covid}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T16:36:51.172953Z","iopub.execute_input":"2025-02-08T16:36:51.173307Z","iopub.status.idle":"2025-02-08T16:36:51.178054Z","shell.execute_reply.started":"2025-02-08T16:36:51.173278Z","shell.execute_reply":"2025-02-08T16:36:51.177030Z"}},"outputs":[{"name":"stdout","text":"Number of Training Samples: 148\nNumber of Test Samples: 40\nNumber of COVID samples: 94\nNumber of Normal samples: 94\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"## 1.3 CNN Architecture","metadata":{}},{"cell_type":"code","source":"def define_model(input_shape=(150,150,3), lr=0.001):\n    model = Sequential(\n        [\n            # Input\n            Input(shape=input_shape),\n            \n            # Conv1\n            Conv2D(64, kernel_size=(3,3), activation='relu', padding='same'),\n            BatchNormalization(axis=-1),\n            MaxPooling2D(pool_size=(2,2)),\n            Dropout(0.2),\n\n            # Conv2\n            Conv2D(64, kernel_size=(3,3), activation='relu', padding='same'),\n            BatchNormalization(axis=-1),\n            MaxPooling2D(pool_size=(2,2)),\n            Dropout(0.2),\n\n            # Conv3\n            Conv2D(128, kernel_size=(3,3), activation='relu', padding='same'),\n            BatchNormalization(axis=-1),\n            MaxPooling2D(pool_size=(2,2)),\n            Dropout(0.2),\n\n            # Conv4\n            Conv2D(128, kernel_size=(3,3), activation='relu', padding='same'),\n            BatchNormalization(axis=-1),\n            MaxPooling2D(pool_size=(2,2)),\n            Dropout(0.2),\n\n            # Conv5\n            Conv2D(256, kernel_size=(3,3), activation='relu', padding='same'),\n            BatchNormalization(axis=-1),\n            MaxPooling2D(pool_size=(2,2)),\n            Dropout(0.2),\n\n            # Conv6\n            Conv2D(256, kernel_size=(3,3), activation='relu', padding='same'),\n            BatchNormalization(axis=-1),\n            MaxPooling2D(pool_size=(2,2)),\n            Dropout(0.2),\n\n            # Flatten Layer\n            Flatten(),\n\n            # FCL\n            Dense(512, activation='relu'),\n            BatchNormalization(axis=-1),\n            Dense(256, activation='relu'),\n            BatchNormalization(axis=-1),\n\n            # Output\n            Dense(1, activation='sigmoid')\n        ]\n    )\n\n    model.compile(\n        optimizer=Adam(learning_rate=lr),\n        loss='binary_crossentropy',\n        metrics=['accuracy']\n    )\n\n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T16:36:53.982794Z","iopub.execute_input":"2025-02-08T16:36:53.983164Z","iopub.status.idle":"2025-02-08T16:36:53.991177Z","shell.execute_reply.started":"2025-02-08T16:36:53.983135Z","shell.execute_reply":"2025-02-08T16:36:53.990064Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"## 1.4 Train & Evaluation of model with k-fold cross-validation","metadata":{}},{"cell_type":"code","source":"def train_evaluate_model_with_k_fold(X_train, y_train, lr=0.01, epochs=50, batch_size=16, early_stopping_pat=5, red_lr_factor=0.1, red_lr_par=3):\n    \n    kf = KFold(n_splits=10, shuffle=True, random_state=33)\n\n    fold_no = 1\n    train_acc_scores = []\n    val_acc_scores = []\n    \n    for train_index, val_index in kf.split(X_train, y_train):\n        print(f\"\\nTraining on Fold {fold_no}...\")\n        \n        X_tr, X_val = X_train[train_index], X_train[val_index]\n        y_tr, y_val = y_train[train_index], y_train[val_index]\n        \n        # Recreate a fresh model for each fold\n        model = define_model(input_shape=(150,150,3), lr=lr)\n        \n        history = model.fit(\n            X_tr, y_tr,\n            validation_data=(X_val, y_val),\n            epochs=epochs,\n            batch_size=batch_size,\n            callbacks=[\n                EarlyStopping(monitor=\"val_loss\", patience=early_stopping_pat, restore_best_weights=True, verbose=1),\n                ReduceLROnPlateau(monitor='val_loss', factor=red_lr_factor, patience=red_lr_par, verbose=1)\n            ],\n            verbose=1,\n            shuffle=True\n        )\n        \n        # Evaluate the model on the fold's training and validation sets\n        train_loss, train_acc = model.evaluate(X_tr, y_tr, verbose=0)\n        val_loss, val_acc = model.evaluate(X_val, y_val, verbose=0)\n        \n        print(f\"Fold {fold_no} - Train Accuracy: {train_acc*100:.2f}%, Validation Accuracy: {val_acc*100:.2f}%\")\n        train_acc_scores.append(train_acc)\n        val_acc_scores.append(val_acc)\n        \n        fold_no += 1\n    \n    print(\"\\nAverage Training Accuracy: {:.2f}%\".format(np.mean(train_acc_scores)*100))\n    print(\"Average Validation Accuracy: {:.2f}%\".format(np.mean(val_acc_scores)*100))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T17:08:36.456224Z","iopub.execute_input":"2025-02-08T17:08:36.456558Z","iopub.status.idle":"2025-02-08T17:08:36.463857Z","shell.execute_reply.started":"2025-02-08T17:08:36.456535Z","shell.execute_reply":"2025-02-08T17:08:36.462869Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"# 2 Data Collection and Image Preprocessing","metadata":{}},{"cell_type":"markdown","source":"## 2.0 Evaluation before adding augmented dataset","metadata":{}},{"cell_type":"code","source":"train_evaluate_model_with_k_fold(X_train, y_train, lr=0.01, epochs=50, batch_size=16)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T16:38:25.408431Z","iopub.execute_input":"2025-02-08T16:38:25.408726Z","iopub.status.idle":"2025-02-08T16:42:36.273832Z","shell.execute_reply.started":"2025-02-08T16:38:25.408704Z","shell.execute_reply":"2025-02-08T16:42:36.272883Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"\nTraining on Fold 1...\nEpoch 1/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1s/step - accuracy: 0.7318 - loss: 0.7372 - val_accuracy: 0.6000 - val_loss: 15746.2070 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9110 - loss: 0.4959 - val_accuracy: 0.6000 - val_loss: 10519.9580 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9280 - loss: 0.1998 - val_accuracy: 0.6000 - val_loss: 1203.2817 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9653 - loss: 0.1200 - val_accuracy: 0.6000 - val_loss: 597.6396 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9598 - loss: 0.1310 - val_accuracy: 0.6000 - val_loss: 330.0821 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9745 - loss: 0.0895 - val_accuracy: 0.6000 - val_loss: 188.4097 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9784 - loss: 0.0535 - val_accuracy: 0.6000 - val_loss: 82.7942 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9930 - loss: 0.0365 - val_accuracy: 0.6667 - val_loss: 22.1471 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.8754 - loss: 0.4106 - val_accuracy: 0.6000 - val_loss: 3.8772 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9985 - loss: 0.0394 - val_accuracy: 0.7333 - val_loss: 1.8000 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9777 - loss: 0.1298 - val_accuracy: 0.8000 - val_loss: 2.0214 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9891 - loss: 0.0405 - val_accuracy: 0.8667 - val_loss: 2.9262 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m7/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.0116\nEpoch 13: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9977 - loss: 0.0264 - val_accuracy: 0.8667 - val_loss: 2.6471 - learning_rate: 0.0100\nEpoch 14/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9958 - loss: 0.0238 - val_accuracy: 0.8667 - val_loss: 2.3691 - learning_rate: 1.0000e-03\nEpoch 15/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9840 - loss: 0.0438 - val_accuracy: 0.8667 - val_loss: 2.2253 - learning_rate: 1.0000e-03\nEpoch 15: early stopping\nRestoring model weights from the end of the best epoch: 10.\nFold 1 - Train Accuracy: 85.71%, Validation Accuracy: 73.33%\n\nTraining on Fold 2...\nEpoch 1/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 887ms/step - accuracy: 0.7039 - loss: 1.0648 - val_accuracy: 0.0667 - val_loss: 1170.2561 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7975 - loss: 0.4977 - val_accuracy: 0.5333 - val_loss: 717.2070 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9561 - loss: 0.1590 - val_accuracy: 0.4667 - val_loss: 437.1776 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9261 - loss: 0.1522 - val_accuracy: 0.4667 - val_loss: 72.3634 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9669 - loss: 0.0732 - val_accuracy: 0.4667 - val_loss: 88.8668 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9050 - loss: 0.1943 - val_accuracy: 0.4667 - val_loss: 185.7953 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m7/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9713 - loss: 0.1615\nEpoch 7: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9731 - loss: 0.1491 - val_accuracy: 0.4667 - val_loss: 118.6488 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9909 - loss: 0.0246 - val_accuracy: 0.4667 - val_loss: 69.3277 - learning_rate: 1.0000e-03\nEpoch 9/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9855 - loss: 0.0399 - val_accuracy: 0.4667 - val_loss: 43.4547 - learning_rate: 1.0000e-03\nEpoch 10/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9894 - loss: 0.0326 - val_accuracy: 0.4667 - val_loss: 28.5326 - learning_rate: 1.0000e-03\nEpoch 11/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9828 - loss: 0.0483 - val_accuracy: 0.4667 - val_loss: 19.3022 - learning_rate: 1.0000e-03\nEpoch 12/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9807 - loss: 0.0555 - val_accuracy: 0.4667 - val_loss: 13.3182 - learning_rate: 1.0000e-03\nEpoch 13/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9878 - loss: 0.0258 - val_accuracy: 0.4667 - val_loss: 8.7429 - learning_rate: 1.0000e-03\nEpoch 14/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9900 - loss: 0.0589 - val_accuracy: 0.4667 - val_loss: 5.9046 - learning_rate: 1.0000e-03\nEpoch 15/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9708 - loss: 0.0748 - val_accuracy: 0.6000 - val_loss: 4.0653 - learning_rate: 1.0000e-03\nEpoch 16/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9578 - loss: 0.1044 - val_accuracy: 0.5333 - val_loss: 2.6922 - learning_rate: 1.0000e-03\nEpoch 17/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9398 - loss: 0.1817 - val_accuracy: 0.6000 - val_loss: 1.6729 - learning_rate: 1.0000e-03\nEpoch 18/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9453 - loss: 0.1286 - val_accuracy: 0.7333 - val_loss: 1.0691 - learning_rate: 1.0000e-03\nEpoch 19/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9700 - loss: 0.0581 - val_accuracy: 0.8000 - val_loss: 0.6636 - learning_rate: 1.0000e-03\nEpoch 20/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9853 - loss: 0.0423 - val_accuracy: 0.8667 - val_loss: 0.4727 - learning_rate: 1.0000e-03\nEpoch 21/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9328 - loss: 0.1864 - val_accuracy: 0.8667 - val_loss: 0.3546 - learning_rate: 1.0000e-03\nEpoch 22/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9800 - loss: 0.1031 - val_accuracy: 0.8667 - val_loss: 0.2467 - learning_rate: 1.0000e-03\nEpoch 23/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9758 - loss: 0.0742 - val_accuracy: 0.8667 - val_loss: 0.2070 - learning_rate: 1.0000e-03\nEpoch 24/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9859 - loss: 0.0444 - val_accuracy: 0.8667 - val_loss: 0.1525 - learning_rate: 1.0000e-03\nEpoch 25/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9958 - loss: 0.0163 - val_accuracy: 0.9333 - val_loss: 0.1301 - learning_rate: 1.0000e-03\nEpoch 26/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9837 - loss: 0.0605 - val_accuracy: 0.9333 - val_loss: 0.1212 - learning_rate: 1.0000e-03\nEpoch 27/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9945 - loss: 0.0206 - val_accuracy: 0.9333 - val_loss: 0.1177 - learning_rate: 1.0000e-03\nEpoch 28/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 0.0125 - val_accuracy: 1.0000 - val_loss: 0.1018 - learning_rate: 1.0000e-03\nEpoch 29/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9909 - loss: 0.0236 - val_accuracy: 1.0000 - val_loss: 0.0867 - learning_rate: 1.0000e-03\nEpoch 30/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9823 - loss: 0.0672 - val_accuracy: 1.0000 - val_loss: 0.0725 - learning_rate: 1.0000e-03\nEpoch 31/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9977 - loss: 0.0135 - val_accuracy: 1.0000 - val_loss: 0.0496 - learning_rate: 1.0000e-03\nEpoch 32/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9977 - loss: 0.0153 - val_accuracy: 1.0000 - val_loss: 0.0350 - learning_rate: 1.0000e-03\nEpoch 33/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0251 - val_accuracy: 1.0000 - val_loss: 0.0272 - learning_rate: 1.0000e-03\nEpoch 34/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9882 - loss: 0.0434 - val_accuracy: 1.0000 - val_loss: 0.0244 - learning_rate: 1.0000e-03\nEpoch 35/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9898 - loss: 0.0557 - val_accuracy: 1.0000 - val_loss: 0.0253 - learning_rate: 1.0000e-03\nEpoch 36/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9607 - loss: 0.0753 - val_accuracy: 1.0000 - val_loss: 0.0314 - learning_rate: 1.0000e-03\nEpoch 37/50\n\u001b[1m7/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9945 - loss: 0.0406\nEpoch 37: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9916 - loss: 0.0474 - val_accuracy: 1.0000 - val_loss: 0.0379 - learning_rate: 1.0000e-03\nEpoch 38/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9945 - loss: 0.0128 - val_accuracy: 1.0000 - val_loss: 0.0331 - learning_rate: 1.0000e-04\nEpoch 39/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9878 - loss: 0.0378 - val_accuracy: 1.0000 - val_loss: 0.0297 - learning_rate: 1.0000e-04\nEpoch 39: early stopping\nRestoring model weights from the end of the best epoch: 34.\nFold 2 - Train Accuracy: 99.25%, Validation Accuracy: 100.00%\n\nTraining on Fold 3...\nEpoch 1/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 904ms/step - accuracy: 0.6651 - loss: 1.0628 - val_accuracy: 0.2667 - val_loss: 22247.1465 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8743 - loss: 0.3533 - val_accuracy: 0.2667 - val_loss: 2444.4233 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9009 - loss: 0.2356 - val_accuracy: 0.2667 - val_loss: 268.4742 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9382 - loss: 0.1254 - val_accuracy: 0.2667 - val_loss: 1377.5765 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9562 - loss: 0.0931 - val_accuracy: 0.2667 - val_loss: 447.2863 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9798 - loss: 0.0411 - val_accuracy: 1.0000 - val_loss: 0.0077 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9755 - loss: 0.0799 - val_accuracy: 1.0000 - val_loss: 0.0754 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9605 - loss: 0.0844 - val_accuracy: 0.2667 - val_loss: 19.3252 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m7/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9905 - loss: 0.0602\nEpoch 9: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9850 - loss: 0.0723 - val_accuracy: 0.9333 - val_loss: 0.1000 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9492 - loss: 0.1787 - val_accuracy: 0.8667 - val_loss: 0.4512 - learning_rate: 1.0000e-03\nEpoch 11/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9815 - loss: 0.1079 - val_accuracy: 0.8667 - val_loss: 0.2207 - learning_rate: 1.0000e-03\nEpoch 11: early stopping\nRestoring model weights from the end of the best epoch: 6.\nFold 3 - Train Accuracy: 75.19%, Validation Accuracy: 100.00%\n\nTraining on Fold 4...\nEpoch 1/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 796ms/step - accuracy: 0.6059 - loss: 1.7069 - val_accuracy: 0.6000 - val_loss: 14994.3994 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8755 - loss: 0.2614 - val_accuracy: 0.6000 - val_loss: 1260.4886 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9530 - loss: 0.1317 - val_accuracy: 0.3333 - val_loss: 203.3345 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9930 - loss: 0.0399 - val_accuracy: 0.4000 - val_loss: 470.0001 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9166 - loss: 0.1378 - val_accuracy: 0.4000 - val_loss: 225.2306 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9169 - loss: 0.1403 - val_accuracy: 0.4000 - val_loss: 58.6032 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9580 - loss: 0.1194 - val_accuracy: 0.5333 - val_loss: 8.7659 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9511 - loss: 0.1165 - val_accuracy: 0.4000 - val_loss: 10.7536 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9863 - loss: 0.0622 - val_accuracy: 0.4000 - val_loss: 9.0707 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9861 - loss: 0.0464 - val_accuracy: 0.4667 - val_loss: 1.9017 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9675 - loss: 0.1075 - val_accuracy: 0.6667 - val_loss: 3.1262 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9691 - loss: 0.1067 - val_accuracy: 0.6000 - val_loss: 1.2827 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9945 - loss: 0.0472 - val_accuracy: 0.4000 - val_loss: 3.5965 - learning_rate: 0.0100\nEpoch 14/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9859 - loss: 0.0657 - val_accuracy: 0.6667 - val_loss: 4.1559 - learning_rate: 0.0100\nEpoch 15/50\n\u001b[1m7/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9905 - loss: 0.0235\nEpoch 15: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9842 - loss: 0.0352 - val_accuracy: 0.6667 - val_loss: 2.5546 - learning_rate: 0.0100\nEpoch 16/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9894 - loss: 0.0347 - val_accuracy: 0.6000 - val_loss: 1.7093 - learning_rate: 1.0000e-03\nEpoch 17/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9846 - loss: 0.0446 - val_accuracy: 0.6000 - val_loss: 1.1893 - learning_rate: 1.0000e-03\nEpoch 18/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9930 - loss: 0.0392 - val_accuracy: 0.6000 - val_loss: 0.7812 - learning_rate: 1.0000e-03\nEpoch 19/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9958 - loss: 0.0241 - val_accuracy: 0.7333 - val_loss: 0.4708 - learning_rate: 1.0000e-03\nEpoch 20/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9970 - loss: 0.0082 - val_accuracy: 0.8000 - val_loss: 0.3116 - learning_rate: 1.0000e-03\nEpoch 21/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0047 - val_accuracy: 0.8667 - val_loss: 0.2131 - learning_rate: 1.0000e-03\nEpoch 22/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9886 - loss: 0.0258 - val_accuracy: 0.9333 - val_loss: 0.1718 - learning_rate: 1.0000e-03\nEpoch 23/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0040 - val_accuracy: 0.9333 - val_loss: 0.1449 - learning_rate: 1.0000e-03\nEpoch 24/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9985 - loss: 0.0095 - val_accuracy: 0.9333 - val_loss: 0.1263 - learning_rate: 1.0000e-03\nEpoch 25/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0088 - val_accuracy: 0.9333 - val_loss: 0.1048 - learning_rate: 1.0000e-03\nEpoch 26/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9958 - loss: 0.0237 - val_accuracy: 1.0000 - val_loss: 0.0674 - learning_rate: 1.0000e-03\nEpoch 27/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9977 - loss: 0.0061 - val_accuracy: 1.0000 - val_loss: 0.0438 - learning_rate: 1.0000e-03\nEpoch 28/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9920 - loss: 0.0137 - val_accuracy: 1.0000 - val_loss: 0.0533 - learning_rate: 1.0000e-03\nEpoch 29/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9977 - loss: 0.0076 - val_accuracy: 0.9333 - val_loss: 0.0982 - learning_rate: 1.0000e-03\nEpoch 30/50\n\u001b[1m7/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9558 - loss: 0.1169\nEpoch 30: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9592 - loss: 0.1209 - val_accuracy: 0.8667 - val_loss: 0.1197 - learning_rate: 1.0000e-03\nEpoch 31/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0215 - val_accuracy: 1.0000 - val_loss: 0.0814 - learning_rate: 1.0000e-04\nEpoch 32/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0064 - val_accuracy: 1.0000 - val_loss: 0.0649 - learning_rate: 1.0000e-04\nEpoch 32: early stopping\nRestoring model weights from the end of the best epoch: 27.\nFold 4 - Train Accuracy: 98.50%, Validation Accuracy: 100.00%\n\nTraining on Fold 5...\nEpoch 1/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 791ms/step - accuracy: 0.7035 - loss: 0.8900 - val_accuracy: 0.4000 - val_loss: 18425.9473 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9205 - loss: 0.3084 - val_accuracy: 0.6000 - val_loss: 7335.9033 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8405 - loss: 0.3698 - val_accuracy: 0.6000 - val_loss: 530.3809 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9255 - loss: 0.1437 - val_accuracy: 0.6000 - val_loss: 619.3036 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9835 - loss: 0.0903 - val_accuracy: 0.6000 - val_loss: 368.7557 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9319 - loss: 0.1990 - val_accuracy: 0.6000 - val_loss: 100.4897 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9705 - loss: 0.0918 - val_accuracy: 0.6000 - val_loss: 78.1776 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9565 - loss: 0.1128 - val_accuracy: 0.6000 - val_loss: 28.8936 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9891 - loss: 0.0596 - val_accuracy: 0.6000 - val_loss: 9.4016 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9505 - loss: 0.1214 - val_accuracy: 0.6000 - val_loss: 7.6290 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9907 - loss: 0.0313 - val_accuracy: 0.6000 - val_loss: 6.1841 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9923 - loss: 0.0485 - val_accuracy: 1.0000 - val_loss: 0.0308 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9775 - loss: 0.0647 - val_accuracy: 0.9333 - val_loss: 0.1160 - learning_rate: 0.0100\nEpoch 14/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9463 - loss: 0.0836 - val_accuracy: 0.6000 - val_loss: 4.3153 - learning_rate: 0.0100\nEpoch 15/50\n\u001b[1m7/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9403 - loss: 0.1640\nEpoch 15: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9445 - loss: 0.1504 - val_accuracy: 0.6000 - val_loss: 4.8203 - learning_rate: 0.0100\nEpoch 16/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9890 - loss: 0.0701 - val_accuracy: 0.6000 - val_loss: 2.2351 - learning_rate: 1.0000e-03\nEpoch 17/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9760 - loss: 0.0435 - val_accuracy: 0.6667 - val_loss: 0.9196 - learning_rate: 1.0000e-03\nEpoch 17: early stopping\nRestoring model weights from the end of the best epoch: 12.\nFold 5 - Train Accuracy: 88.72%, Validation Accuracy: 100.00%\n\nTraining on Fold 6...\nEpoch 1/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 797ms/step - accuracy: 0.6048 - loss: 0.9253 - val_accuracy: 0.4667 - val_loss: 25114.3555 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9215 - loss: 0.2612 - val_accuracy: 0.4667 - val_loss: 5711.9565 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9678 - loss: 0.0901 - val_accuracy: 0.4667 - val_loss: 1532.5531 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9710 - loss: 0.0878 - val_accuracy: 0.4667 - val_loss: 214.7019 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9537 - loss: 0.1531 - val_accuracy: 0.2667 - val_loss: 33.7697 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9492 - loss: 0.1718 - val_accuracy: 0.2667 - val_loss: 14.5975 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9098 - loss: 0.2200 - val_accuracy: 0.5333 - val_loss: 4.2122 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9614 - loss: 0.0896 - val_accuracy: 0.5333 - val_loss: 1.7806 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9909 - loss: 0.0442 - val_accuracy: 0.4667 - val_loss: 7.0054 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9570 - loss: 0.0704 - val_accuracy: 0.5333 - val_loss: 1.4249 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9756 - loss: 0.0803 - val_accuracy: 0.4667 - val_loss: 2.8204 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9526 - loss: 0.0787 - val_accuracy: 0.4667 - val_loss: 6.4029 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9917 - loss: 0.0544\nEpoch 13: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9903 - loss: 0.0579 - val_accuracy: 0.4667 - val_loss: 5.6142 - learning_rate: 0.0100\nEpoch 14/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9839 - loss: 0.0628 - val_accuracy: 0.4667 - val_loss: 4.3531 - learning_rate: 1.0000e-03\nEpoch 15/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9900 - loss: 0.0347 - val_accuracy: 0.4667 - val_loss: 3.3421 - learning_rate: 1.0000e-03\nEpoch 15: early stopping\nRestoring model weights from the end of the best epoch: 10.\nFold 6 - Train Accuracy: 63.91%, Validation Accuracy: 53.33%\n\nTraining on Fold 7...\nEpoch 1/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 781ms/step - accuracy: 0.7261 - loss: 1.0359 - val_accuracy: 0.4000 - val_loss: 12028.0186 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8917 - loss: 0.3070 - val_accuracy: 0.6000 - val_loss: 1650.2177 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9233 - loss: 0.2003 - val_accuracy: 0.2000 - val_loss: 204.2756 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9606 - loss: 0.1356 - val_accuracy: 0.4000 - val_loss: 180.4439 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9708 - loss: 0.1039 - val_accuracy: 0.4000 - val_loss: 47.2430 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9195 - loss: 0.1438 - val_accuracy: 0.4000 - val_loss: 38.5035 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9467 - loss: 0.1400 - val_accuracy: 0.7333 - val_loss: 6.0120 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9666 - loss: 0.1199 - val_accuracy: 0.4667 - val_loss: 8.7294 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9911 - loss: 0.0803 - val_accuracy: 0.4000 - val_loss: 15.8227 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9771 - loss: 0.0486 - val_accuracy: 0.5333 - val_loss: 3.2525 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9831 - loss: 0.0866 - val_accuracy: 0.6667 - val_loss: 1.7563 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9505 - loss: 0.1134 - val_accuracy: 0.6000 - val_loss: 0.9400 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9760 - loss: 0.0906 - val_accuracy: 0.8000 - val_loss: 0.8377 - learning_rate: 0.0100\nEpoch 14/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9845 - loss: 0.0317 - val_accuracy: 0.6667 - val_loss: 2.1630 - learning_rate: 0.0100\nEpoch 15/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9654 - loss: 0.0904 - val_accuracy: 0.8667 - val_loss: 0.1268 - learning_rate: 0.0100\nEpoch 16/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9914 - loss: 0.0203 - val_accuracy: 0.4667 - val_loss: 4.3919 - learning_rate: 0.0100\nEpoch 17/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9789 - loss: 0.0491 - val_accuracy: 0.6000 - val_loss: 1.5288 - learning_rate: 0.0100\nEpoch 18/50\n\u001b[1m7/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9386 - loss: 0.0638\nEpoch 18: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9433 - loss: 0.0602 - val_accuracy: 0.8000 - val_loss: 0.9370 - learning_rate: 0.0100\nEpoch 19/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9922 - loss: 0.0352 - val_accuracy: 0.8667 - val_loss: 0.4002 - learning_rate: 1.0000e-03\nEpoch 20/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9835 - loss: 0.0347 - val_accuracy: 0.9333 - val_loss: 0.2300 - learning_rate: 1.0000e-03\nEpoch 20: early stopping\nRestoring model weights from the end of the best epoch: 15.\nFold 7 - Train Accuracy: 90.98%, Validation Accuracy: 86.67%\n\nTraining on Fold 8...\nEpoch 1/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 825ms/step - accuracy: 0.6753 - loss: 1.2199 - val_accuracy: 0.5333 - val_loss: 13032.5928 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8946 - loss: 0.2442 - val_accuracy: 0.4667 - val_loss: 4839.0728 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9330 - loss: 0.1983 - val_accuracy: 0.4667 - val_loss: 654.7759 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9193 - loss: 0.1845 - val_accuracy: 0.4667 - val_loss: 228.0698 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9758 - loss: 0.0970 - val_accuracy: 0.5333 - val_loss: 51.3346 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9907 - loss: 0.0387 - val_accuracy: 0.4667 - val_loss: 64.8423 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9701 - loss: 0.0635 - val_accuracy: 0.4667 - val_loss: 41.1487 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9815 - loss: 0.0576 - val_accuracy: 0.4667 - val_loss: 32.0033 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9707 - loss: 0.0798 - val_accuracy: 0.6000 - val_loss: 8.1928 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9857 - loss: 0.0634 - val_accuracy: 0.4667 - val_loss: 14.4519 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9376 - loss: 0.2243 - val_accuracy: 0.4667 - val_loss: 11.6725 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9730 - loss: 0.0995 - val_accuracy: 0.6000 - val_loss: 3.8519 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9877 - loss: 0.0481 - val_accuracy: 0.6000 - val_loss: 5.6738 - learning_rate: 0.0100\nEpoch 14/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9909 - loss: 0.0340 - val_accuracy: 0.6000 - val_loss: 5.3721 - learning_rate: 0.0100\nEpoch 15/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9985 - loss: 0.0164 - val_accuracy: 0.6000 - val_loss: 2.3479 - learning_rate: 0.0100\nEpoch 16/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9702 - loss: 0.1576 - val_accuracy: 0.6000 - val_loss: 2.9973 - learning_rate: 0.0100\nEpoch 17/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9914 - loss: 0.0390 - val_accuracy: 0.7333 - val_loss: 0.6745 - learning_rate: 0.0100\nEpoch 18/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9945 - loss: 0.0291 - val_accuracy: 1.0000 - val_loss: 0.0317 - learning_rate: 0.0100\nEpoch 19/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9542 - loss: 0.1404 - val_accuracy: 0.9333 - val_loss: 0.1090 - learning_rate: 0.0100\nEpoch 20/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9985 - loss: 0.0228 - val_accuracy: 0.8000 - val_loss: 0.4609 - learning_rate: 0.0100\nEpoch 21/50\n\u001b[1m7/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9902 - loss: 0.0421\nEpoch 21: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9909 - loss: 0.0411 - val_accuracy: 0.5333 - val_loss: 1.7794 - learning_rate: 0.0100\nEpoch 22/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9683 - loss: 0.1505 - val_accuracy: 0.6667 - val_loss: 1.1581 - learning_rate: 1.0000e-03\nEpoch 23/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9903 - loss: 0.0209 - val_accuracy: 0.7333 - val_loss: 0.4838 - learning_rate: 1.0000e-03\nEpoch 23: early stopping\nRestoring model weights from the end of the best epoch: 18.\nFold 8 - Train Accuracy: 91.73%, Validation Accuracy: 100.00%\n\nTraining on Fold 9...\nEpoch 1/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1s/step - accuracy: 0.6483 - loss: 1.1172 - val_accuracy: 0.4286 - val_loss: 11092.0713 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9070 - loss: 0.2353 - val_accuracy: 0.4286 - val_loss: 4198.2705 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9481 - loss: 0.1791 - val_accuracy: 0.4286 - val_loss: 1080.7571 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9347 - loss: 0.1704 - val_accuracy: 0.4286 - val_loss: 1113.0723 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9445 - loss: 0.1905 - val_accuracy: 0.4286 - val_loss: 72.2641 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9387 - loss: 0.1297 - val_accuracy: 0.4286 - val_loss: 54.2795 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9485 - loss: 0.1193 - val_accuracy: 0.4286 - val_loss: 40.3119 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9859 - loss: 0.0433 - val_accuracy: 0.5000 - val_loss: 15.8360 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9722 - loss: 0.0731 - val_accuracy: 0.5714 - val_loss: 8.6123 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9734 - loss: 0.0600 - val_accuracy: 0.5000 - val_loss: 9.9740 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9621 - loss: 0.1193 - val_accuracy: 0.5000 - val_loss: 3.2692 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9727 - loss: 0.1014 - val_accuracy: 0.5000 - val_loss: 5.7138 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9768 - loss: 0.0673 - val_accuracy: 0.5000 - val_loss: 8.6126 - learning_rate: 0.0100\nEpoch 14/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9909 - loss: 0.0315 - val_accuracy: 0.7857 - val_loss: 1.8439 - learning_rate: 0.0100\nEpoch 15/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9907 - loss: 0.0464 - val_accuracy: 0.6429 - val_loss: 1.8628 - learning_rate: 0.0100\nEpoch 16/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9823 - loss: 0.0347 - val_accuracy: 0.5000 - val_loss: 2.5098 - learning_rate: 0.0100\nEpoch 17/50\n\u001b[1m7/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9662 - loss: 0.0491\nEpoch 17: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9612 - loss: 0.0695 - val_accuracy: 0.5000 - val_loss: 2.7891 - learning_rate: 0.0100\nEpoch 18/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8647 - loss: 0.3209 - val_accuracy: 0.4286 - val_loss: 1.5827 - learning_rate: 1.0000e-03\nEpoch 19/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9195 - loss: 0.1427 - val_accuracy: 0.5714 - val_loss: 1.2201 - learning_rate: 1.0000e-03\nEpoch 20/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9601 - loss: 0.1266 - val_accuracy: 0.6429 - val_loss: 1.0674 - learning_rate: 1.0000e-03\nEpoch 21/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9778 - loss: 0.1366 - val_accuracy: 0.6429 - val_loss: 0.9224 - learning_rate: 1.0000e-03\nEpoch 22/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9693 - loss: 0.1188 - val_accuracy: 0.5714 - val_loss: 0.8154 - learning_rate: 1.0000e-03\nEpoch 23/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9985 - loss: 0.0284 - val_accuracy: 0.7143 - val_loss: 0.8343 - learning_rate: 1.0000e-03\nEpoch 24/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9930 - loss: 0.0162 - val_accuracy: 0.7857 - val_loss: 0.8781 - learning_rate: 1.0000e-03\nEpoch 25/50\n\u001b[1m7/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9955 - loss: 0.0331\nEpoch 25: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9945 - loss: 0.0349 - val_accuracy: 0.7857 - val_loss: 0.9188 - learning_rate: 1.0000e-03\nEpoch 26/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9943 - loss: 0.0316 - val_accuracy: 0.7857 - val_loss: 0.9424 - learning_rate: 1.0000e-04\nEpoch 27/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9977 - loss: 0.0305 - val_accuracy: 0.7143 - val_loss: 0.9505 - learning_rate: 1.0000e-04\nEpoch 27: early stopping\nRestoring model weights from the end of the best epoch: 22.\nFold 9 - Train Accuracy: 89.55%, Validation Accuracy: 57.14%\n\nTraining on Fold 10...\nEpoch 1/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 794ms/step - accuracy: 0.5958 - loss: 1.6866 - val_accuracy: 0.4286 - val_loss: 3899.7507 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8925 - loss: 0.2634 - val_accuracy: 0.5714 - val_loss: 815.0414 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9454 - loss: 0.1868 - val_accuracy: 0.5714 - val_loss: 403.5332 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9413 - loss: 0.1330 - val_accuracy: 0.5000 - val_loss: 48.3618 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9612 - loss: 0.1173 - val_accuracy: 0.5714 - val_loss: 33.1816 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9784 - loss: 0.0708 - val_accuracy: 0.7857 - val_loss: 4.6682 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9823 - loss: 0.0592 - val_accuracy: 0.6429 - val_loss: 4.3249 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0240 - val_accuracy: 0.8571 - val_loss: 2.3108 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9458 - loss: 0.1416 - val_accuracy: 0.7857 - val_loss: 1.5707 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9833 - loss: 0.0560 - val_accuracy: 0.7143 - val_loss: 4.4522 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9698 - loss: 0.1193 - val_accuracy: 0.9286 - val_loss: 0.5261 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9140 - loss: 0.1391 - val_accuracy: 0.8571 - val_loss: 0.6909 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9566 - loss: 0.0873 - val_accuracy: 1.0000 - val_loss: 0.0432 - learning_rate: 0.0100\nEpoch 14/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9536 - loss: 0.1385 - val_accuracy: 0.9286 - val_loss: 0.5474 - learning_rate: 0.0100\nEpoch 15/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9656 - loss: 0.1266 - val_accuracy: 0.7857 - val_loss: 0.5916 - learning_rate: 0.0100\nEpoch 16/50\n\u001b[1m7/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9507 - loss: 0.1263\nEpoch 16: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9481 - loss: 0.1378 - val_accuracy: 0.9286 - val_loss: 0.8402 - learning_rate: 0.0100\nEpoch 17/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9814 - loss: 0.0442 - val_accuracy: 0.9286 - val_loss: 0.5849 - learning_rate: 1.0000e-03\nEpoch 18/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9700 - loss: 0.0738 - val_accuracy: 0.9286 - val_loss: 0.2128 - learning_rate: 1.0000e-03\nEpoch 18: early stopping\nRestoring model weights from the end of the best epoch: 13.\nFold 10 - Train Accuracy: 83.58%, Validation Accuracy: 100.00%\n\nAverage Training Accuracy: 86.71%\nAverage Validation Accuracy: 87.05%\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"## 2.1 Flipping","metadata":{}},{"cell_type":"code","source":"X_train_flipped = np.flip(X_train, axis=2)\nX_test_flipped = np.flip(X_test, axis=2)\n\nX_train_augmented = np.concatenate((X_train, X_train_flipped), axis=0)\ny_train_augmented = np.concatenate((y_train, y_train), axis=0)\n\ntrain_evaluate_model_with_k_fold(\n    X_train=X_train_augmented,\n    y_train=y_train_augmented,\n    lr=0.01,\n    epochs=50,\n    batch_size=16)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T16:42:36.275328Z","iopub.execute_input":"2025-02-08T16:42:36.275668Z","iopub.status.idle":"2025-02-08T16:47:49.708190Z","shell.execute_reply.started":"2025-02-08T16:42:36.275644Z","shell.execute_reply":"2025-02-08T16:47:49.707381Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"\nTraining on Fold 1...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 649ms/step - accuracy: 0.6895 - loss: 1.0073 - val_accuracy: 0.5000 - val_loss: 517.1639 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.8969 - loss: 0.2602 - val_accuracy: 0.5000 - val_loss: 535.1197 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9644 - loss: 0.1087 - val_accuracy: 0.5000 - val_loss: 74.2511 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9703 - loss: 0.0852 - val_accuracy: 0.5000 - val_loss: 16.5240 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9772 - loss: 0.0753 - val_accuracy: 0.5000 - val_loss: 19.4749 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9704 - loss: 0.1123 - val_accuracy: 0.8000 - val_loss: 1.3290 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9596 - loss: 0.1127 - val_accuracy: 0.5000 - val_loss: 5.5532 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9864 - loss: 0.0592 - val_accuracy: 0.7667 - val_loss: 0.8874 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9944 - loss: 0.0311 - val_accuracy: 0.8333 - val_loss: 0.6663 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9778 - loss: 0.0423 - val_accuracy: 0.8667 - val_loss: 0.4558 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9785 - loss: 0.1363 - val_accuracy: 0.9667 - val_loss: 0.1895 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9638 - loss: 0.1311 - val_accuracy: 0.9333 - val_loss: 0.2122 - learning_rate: 0.0100\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9835 - loss: 0.0578 - val_accuracy: 0.9667 - val_loss: 0.0512 - learning_rate: 0.0100\nEpoch 15/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9871 - loss: 0.0414 - val_accuracy: 0.8667 - val_loss: 0.4814 - learning_rate: 0.0100\nEpoch 16/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9710 - loss: 0.0925 - val_accuracy: 0.9333 - val_loss: 0.1837 - learning_rate: 0.0100\nEpoch 17/50\n\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9773 - loss: 0.0447\nEpoch 17: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9792 - loss: 0.0421 - val_accuracy: 0.9000 - val_loss: 0.2747 - learning_rate: 0.0100\nEpoch 18/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9579 - loss: 0.1950 - val_accuracy: 0.9000 - val_loss: 0.2853 - learning_rate: 1.0000e-03\nEpoch 19/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0166 - val_accuracy: 0.9333 - val_loss: 0.2620 - learning_rate: 1.0000e-03\nEpoch 19: early stopping\nRestoring model weights from the end of the best epoch: 14.\nFold 1 - Train Accuracy: 99.62%, Validation Accuracy: 96.67%\n\nTraining on Fold 2...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 426ms/step - accuracy: 0.7023 - loss: 0.9168 - val_accuracy: 0.5333 - val_loss: 2241.4426 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9059 - loss: 0.2431 - val_accuracy: 0.5333 - val_loss: 106.5003 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9268 - loss: 0.1530 - val_accuracy: 0.5333 - val_loss: 80.4163 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9462 - loss: 0.1390 - val_accuracy: 0.5667 - val_loss: 26.7795 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9672 - loss: 0.0509 - val_accuracy: 0.5333 - val_loss: 3.6544 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9815 - loss: 0.0365 - val_accuracy: 0.4667 - val_loss: 4.9775 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9590 - loss: 0.1309 - val_accuracy: 0.6333 - val_loss: 2.4421 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9426 - loss: 0.1153 - val_accuracy: 0.7333 - val_loss: 1.4794 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9835 - loss: 0.0396 - val_accuracy: 0.7000 - val_loss: 1.8146 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9643 - loss: 0.1192 - val_accuracy: 0.9000 - val_loss: 0.3048 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9872 - loss: 0.0491 - val_accuracy: 0.9667 - val_loss: 0.3579 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9955 - loss: 0.0172 - val_accuracy: 0.9333 - val_loss: 0.2405 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9994 - loss: 0.0044 - val_accuracy: 0.9333 - val_loss: 0.3271 - learning_rate: 0.0100\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9928 - loss: 0.0240 - val_accuracy: 0.8667 - val_loss: 0.5576 - learning_rate: 0.0100\nEpoch 15/50\n\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9854 - loss: 0.0657\nEpoch 15: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9855 - loss: 0.0648 - val_accuracy: 0.9333 - val_loss: 0.2554 - learning_rate: 0.0100\nEpoch 16/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9798 - loss: 0.0578 - val_accuracy: 0.9333 - val_loss: 0.0891 - learning_rate: 1.0000e-03\nEpoch 17/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9978 - loss: 0.0103 - val_accuracy: 1.0000 - val_loss: 0.0072 - learning_rate: 1.0000e-03\nEpoch 18/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9937 - loss: 0.0215 - val_accuracy: 1.0000 - val_loss: 0.0152 - learning_rate: 1.0000e-03\nEpoch 19/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0093 - val_accuracy: 0.9667 - val_loss: 0.0290 - learning_rate: 1.0000e-03\nEpoch 20/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9886 - loss: 0.0289\nEpoch 20: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9884 - loss: 0.0293 - val_accuracy: 1.0000 - val_loss: 0.0230 - learning_rate: 1.0000e-03\nEpoch 21/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9994 - loss: 0.0105 - val_accuracy: 1.0000 - val_loss: 0.0202 - learning_rate: 1.0000e-04\nEpoch 22/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9946 - loss: 0.0077 - val_accuracy: 1.0000 - val_loss: 0.0177 - learning_rate: 1.0000e-04\nEpoch 22: early stopping\nRestoring model weights from the end of the best epoch: 17.\nFold 2 - Train Accuracy: 98.87%, Validation Accuracy: 100.00%\n\nTraining on Fold 3...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 426ms/step - accuracy: 0.6743 - loss: 1.0884 - val_accuracy: 0.4667 - val_loss: 2360.3074 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8753 - loss: 0.2331 - val_accuracy: 0.4667 - val_loss: 1054.9275 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8998 - loss: 0.2167 - val_accuracy: 0.5333 - val_loss: 153.6936 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9472 - loss: 0.1477 - val_accuracy: 0.8333 - val_loss: 0.9396 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9544 - loss: 0.1193 - val_accuracy: 0.5000 - val_loss: 14.2627 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9952 - loss: 0.0435 - val_accuracy: 0.9000 - val_loss: 0.3833 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9941 - loss: 0.0361 - val_accuracy: 1.0000 - val_loss: 0.0018 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9655 - loss: 0.0902 - val_accuracy: 1.0000 - val_loss: 0.0166 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9870 - loss: 0.0459 - val_accuracy: 0.9333 - val_loss: 0.0508 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9418 - loss: 0.2361\nEpoch 10: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9432 - loss: 0.2311 - val_accuracy: 0.9333 - val_loss: 0.1121 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9831 - loss: 0.0624 - val_accuracy: 0.8333 - val_loss: 0.1736 - learning_rate: 1.0000e-03\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9938 - loss: 0.0236 - val_accuracy: 0.8667 - val_loss: 0.1960 - learning_rate: 1.0000e-03\nEpoch 12: early stopping\nRestoring model weights from the end of the best epoch: 7.\nFold 3 - Train Accuracy: 92.86%, Validation Accuracy: 100.00%\n\nTraining on Fold 4...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 431ms/step - accuracy: 0.6971 - loss: 0.8587 - val_accuracy: 0.4333 - val_loss: 878.8416 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9526 - loss: 0.1740 - val_accuracy: 0.6000 - val_loss: 49.2581 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9550 - loss: 0.1196 - val_accuracy: 0.4333 - val_loss: 114.2756 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9098 - loss: 0.2317 - val_accuracy: 0.4333 - val_loss: 67.3186 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9664 - loss: 0.0932 - val_accuracy: 0.4333 - val_loss: 22.6809 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9520 - loss: 0.1413 - val_accuracy: 0.4667 - val_loss: 9.0303 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9852 - loss: 0.0738 - val_accuracy: 0.7333 - val_loss: 0.7770 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9734 - loss: 0.0870 - val_accuracy: 0.7667 - val_loss: 0.5250 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9313 - loss: 0.1334 - val_accuracy: 1.0000 - val_loss: 0.0787 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9838 - loss: 0.0534 - val_accuracy: 0.8333 - val_loss: 0.5731 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9673 - loss: 0.0721 - val_accuracy: 1.0000 - val_loss: 0.0062 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9785 - loss: 0.0802 - val_accuracy: 0.9333 - val_loss: 0.1272 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9949 - loss: 0.0295 - val_accuracy: 0.9667 - val_loss: 0.0704 - learning_rate: 0.0100\nEpoch 14/50\n\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9970 - loss: 0.0257\nEpoch 14: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9962 - loss: 0.0277 - val_accuracy: 0.9000 - val_loss: 0.3434 - learning_rate: 0.0100\nEpoch 15/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9665 - loss: 0.0890 - val_accuracy: 0.9333 - val_loss: 0.1204 - learning_rate: 1.0000e-03\nEpoch 16/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9816 - loss: 0.0376 - val_accuracy: 0.9667 - val_loss: 0.0800 - learning_rate: 1.0000e-03\nEpoch 16: early stopping\nRestoring model weights from the end of the best epoch: 11.\nFold 4 - Train Accuracy: 98.12%, Validation Accuracy: 100.00%\n\nTraining on Fold 5...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 421ms/step - accuracy: 0.7182 - loss: 0.8463 - val_accuracy: 0.4667 - val_loss: 564.3333 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.9321 - loss: 0.1649 - val_accuracy: 0.4667 - val_loss: 1239.3558 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9722 - loss: 0.0910 - val_accuracy: 0.4667 - val_loss: 59.1134 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9676 - loss: 0.0868 - val_accuracy: 0.4667 - val_loss: 17.5472 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9937 - loss: 0.0236 - val_accuracy: 0.4667 - val_loss: 3.9114 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9841 - loss: 0.0454 - val_accuracy: 0.5333 - val_loss: 5.9646 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9776 - loss: 0.0672 - val_accuracy: 0.7333 - val_loss: 0.9192 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9161 - loss: 0.1931 - val_accuracy: 0.5333 - val_loss: 5.1455 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8924 - loss: 0.2594 - val_accuracy: 0.9000 - val_loss: 0.3605 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9661 - loss: 0.0969 - val_accuracy: 0.8667 - val_loss: 0.4205 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9417 - loss: 0.2459 - val_accuracy: 0.8333 - val_loss: 0.2878 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9970 - loss: 0.0281 - val_accuracy: 0.8667 - val_loss: 0.2492 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9930 - loss: 0.0289 - val_accuracy: 0.9333 - val_loss: 0.0696 - learning_rate: 0.0100\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9797 - loss: 0.0743 - val_accuracy: 0.7667 - val_loss: 0.8907 - learning_rate: 0.0100\nEpoch 15/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9768 - loss: 0.0630 - val_accuracy: 1.0000 - val_loss: 0.0269 - learning_rate: 0.0100\nEpoch 16/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9782 - loss: 0.0405 - val_accuracy: 1.0000 - val_loss: 0.0273 - learning_rate: 0.0100\nEpoch 17/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9895 - loss: 0.0463 - val_accuracy: 1.0000 - val_loss: 0.0202 - learning_rate: 0.0100\nEpoch 18/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9944 - loss: 0.0226 - val_accuracy: 1.0000 - val_loss: 0.0654 - learning_rate: 0.0100\nEpoch 19/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0126 - val_accuracy: 1.0000 - val_loss: 0.0284 - learning_rate: 0.0100\nEpoch 20/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9926 - loss: 0.0261\nEpoch 20: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9926 - loss: 0.0257 - val_accuracy: 1.0000 - val_loss: 0.0204 - learning_rate: 0.0100\nEpoch 21/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9939 - loss: 0.0218 - val_accuracy: 1.0000 - val_loss: 0.0112 - learning_rate: 1.0000e-03\nEpoch 22/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9866 - loss: 0.0282 - val_accuracy: 1.0000 - val_loss: 0.0090 - learning_rate: 1.0000e-03\nEpoch 23/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9964 - loss: 0.0175 - val_accuracy: 1.0000 - val_loss: 0.0094 - learning_rate: 1.0000e-03\nEpoch 24/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9964 - loss: 0.0050 - val_accuracy: 1.0000 - val_loss: 0.0063 - learning_rate: 1.0000e-03\nEpoch 25/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0070 - val_accuracy: 1.0000 - val_loss: 0.0058 - learning_rate: 1.0000e-03\nEpoch 26/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0050 - val_accuracy: 1.0000 - val_loss: 0.0056 - learning_rate: 1.0000e-03\nEpoch 27/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0050 - val_accuracy: 1.0000 - val_loss: 0.0051 - learning_rate: 1.0000e-03\nEpoch 28/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9989 - loss: 0.0032 - val_accuracy: 1.0000 - val_loss: 0.0034 - learning_rate: 1.0000e-03\nEpoch 29/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9870 - loss: 0.0218 - val_accuracy: 1.0000 - val_loss: 0.0019 - learning_rate: 1.0000e-03\nEpoch 30/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9867 - loss: 0.0129 - val_accuracy: 1.0000 - val_loss: 0.0014 - learning_rate: 1.0000e-03\nEpoch 31/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0099 - val_accuracy: 1.0000 - val_loss: 0.0010 - learning_rate: 1.0000e-03\nEpoch 32/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9922 - loss: 0.0142 - val_accuracy: 1.0000 - val_loss: 0.0012 - learning_rate: 1.0000e-03\nEpoch 33/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9983 - loss: 0.0128 - val_accuracy: 1.0000 - val_loss: 0.0012 - learning_rate: 1.0000e-03\nEpoch 34/50\n\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0068\nEpoch 34: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0061 - val_accuracy: 1.0000 - val_loss: 0.0012 - learning_rate: 1.0000e-03\nEpoch 35/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9983 - loss: 0.0115 - val_accuracy: 1.0000 - val_loss: 0.0010 - learning_rate: 1.0000e-04\nEpoch 36/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9958 - loss: 0.0071 - val_accuracy: 1.0000 - val_loss: 9.6709e-04 - learning_rate: 1.0000e-04\nEpoch 37/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9909 - loss: 0.0122 - val_accuracy: 1.0000 - val_loss: 8.8935e-04 - learning_rate: 1.0000e-04\nEpoch 38/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0051 - val_accuracy: 1.0000 - val_loss: 8.4766e-04 - learning_rate: 1.0000e-04\nEpoch 39/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9972 - loss: 0.0074 - val_accuracy: 1.0000 - val_loss: 8.1593e-04 - learning_rate: 1.0000e-04\nEpoch 40/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0025\nEpoch 40: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 1.0000 - val_loss: 8.1936e-04 - learning_rate: 1.0000e-04\nEpoch 41/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9992 - loss: 0.0070 - val_accuracy: 1.0000 - val_loss: 8.0421e-04 - learning_rate: 1.0000e-05\nEpoch 42/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9913 - loss: 0.0341 - val_accuracy: 1.0000 - val_loss: 8.1434e-04 - learning_rate: 1.0000e-05\nEpoch 43/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0108\nEpoch 43: ReduceLROnPlateau reducing learning rate to 9.99999883788405e-07.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0104 - val_accuracy: 1.0000 - val_loss: 8.2855e-04 - learning_rate: 1.0000e-05\nEpoch 44/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9956 - loss: 0.0113 - val_accuracy: 1.0000 - val_loss: 8.1649e-04 - learning_rate: 1.0000e-06\nEpoch 45/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9973 - loss: 0.0059 - val_accuracy: 1.0000 - val_loss: 8.4331e-04 - learning_rate: 1.0000e-06\nEpoch 46/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9717 - loss: 0.0840\nEpoch 46: ReduceLROnPlateau reducing learning rate to 9.99999883788405e-08.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9723 - loss: 0.0812 - val_accuracy: 1.0000 - val_loss: 8.2182e-04 - learning_rate: 1.0000e-06\nEpoch 46: early stopping\nRestoring model weights from the end of the best epoch: 41.\nFold 5 - Train Accuracy: 100.00%, Validation Accuracy: 100.00%\n\nTraining on Fold 6...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 427ms/step - accuracy: 0.6548 - loss: 1.1007 - val_accuracy: 0.4667 - val_loss: 1129.4535 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9260 - loss: 0.2067 - val_accuracy: 0.5333 - val_loss: 82.2002 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9594 - loss: 0.1497 - val_accuracy: 0.5333 - val_loss: 379.3665 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9466 - loss: 0.1536 - val_accuracy: 0.6333 - val_loss: 7.3471 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9559 - loss: 0.0979 - val_accuracy: 0.6333 - val_loss: 8.8983 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9908 - loss: 0.0374 - val_accuracy: 0.7333 - val_loss: 3.2160 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9398 - loss: 0.2231 - val_accuracy: 0.6333 - val_loss: 4.5837 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9673 - loss: 0.0913 - val_accuracy: 0.8667 - val_loss: 1.2037 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9518 - loss: 0.1224 - val_accuracy: 0.9000 - val_loss: 0.3374 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9848 - loss: 0.0682 - val_accuracy: 0.9333 - val_loss: 0.4888 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9749 - loss: 0.0675 - val_accuracy: 0.9333 - val_loss: 0.1815 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9798 - loss: 0.0489 - val_accuracy: 0.9333 - val_loss: 0.0948 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9884 - loss: 0.0592 - val_accuracy: 0.9000 - val_loss: 0.2891 - learning_rate: 0.0100\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9933 - loss: 0.0306 - val_accuracy: 0.9667 - val_loss: 0.0399 - learning_rate: 0.0100\nEpoch 15/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9260 - loss: 0.2716 - val_accuracy: 0.9000 - val_loss: 0.2041 - learning_rate: 0.0100\nEpoch 16/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9916 - loss: 0.0456 - val_accuracy: 1.0000 - val_loss: 0.0017 - learning_rate: 0.0100\nEpoch 17/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9782 - loss: 0.0681 - val_accuracy: 0.9667 - val_loss: 0.1040 - learning_rate: 0.0100\nEpoch 18/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9831 - loss: 0.0469 - val_accuracy: 1.0000 - val_loss: 0.0043 - learning_rate: 0.0100\nEpoch 19/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9611 - loss: 0.1096\nEpoch 19: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9621 - loss: 0.1052 - val_accuracy: 0.9333 - val_loss: 0.2561 - learning_rate: 0.0100\nEpoch 20/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9798 - loss: 0.0573 - val_accuracy: 0.9333 - val_loss: 0.1225 - learning_rate: 1.0000e-03\nEpoch 21/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9848 - loss: 0.0454 - val_accuracy: 1.0000 - val_loss: 0.0101 - learning_rate: 1.0000e-03\nEpoch 21: early stopping\nRestoring model weights from the end of the best epoch: 16.\nFold 6 - Train Accuracy: 100.00%, Validation Accuracy: 100.00%\n\nTraining on Fold 7...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 645ms/step - accuracy: 0.6950 - loss: 1.5769 - val_accuracy: 0.4483 - val_loss: 881.0259 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9086 - loss: 0.2022 - val_accuracy: 0.4483 - val_loss: 144.6785 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9695 - loss: 0.1068 - val_accuracy: 0.4483 - val_loss: 198.3380 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9698 - loss: 0.1050 - val_accuracy: 0.4483 - val_loss: 29.3998 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9397 - loss: 0.1748 - val_accuracy: 0.4483 - val_loss: 6.8769 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9771 - loss: 0.0835 - val_accuracy: 0.4483 - val_loss: 8.4857 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9532 - loss: 0.1214 - val_accuracy: 0.6552 - val_loss: 1.0048 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9788 - loss: 0.0774 - val_accuracy: 0.9310 - val_loss: 0.1714 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9848 - loss: 0.0844 - val_accuracy: 0.9655 - val_loss: 0.0750 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9673 - loss: 0.0727 - val_accuracy: 0.8276 - val_loss: 0.6146 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9884 - loss: 0.0421 - val_accuracy: 0.9310 - val_loss: 0.3721 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9827 - loss: 0.0450\nEpoch 12: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9824 - loss: 0.0458 - val_accuracy: 0.6207 - val_loss: 2.4576 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9762 - loss: 0.0691 - val_accuracy: 0.7241 - val_loss: 1.0041 - learning_rate: 1.0000e-03\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9902 - loss: 0.0449 - val_accuracy: 0.8621 - val_loss: 0.3934 - learning_rate: 1.0000e-03\nEpoch 14: early stopping\nRestoring model weights from the end of the best epoch: 9.\nFold 7 - Train Accuracy: 89.89%, Validation Accuracy: 96.55%\n\nTraining on Fold 8...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 484ms/step - accuracy: 0.7530 - loss: 1.1073 - val_accuracy: 0.4483 - val_loss: 5543.4741 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8827 - loss: 0.3173 - val_accuracy: 0.5517 - val_loss: 345.1906 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9139 - loss: 0.2107 - val_accuracy: 0.6207 - val_loss: 23.7977 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9417 - loss: 0.1655 - val_accuracy: 0.4828 - val_loss: 29.2242 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9816 - loss: 0.0835 - val_accuracy: 0.5862 - val_loss: 2.7896 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9536 - loss: 0.1288 - val_accuracy: 0.7586 - val_loss: 1.7045 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9785 - loss: 0.0799 - val_accuracy: 0.7586 - val_loss: 0.7957 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9804 - loss: 0.0609 - val_accuracy: 0.8966 - val_loss: 0.3783 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9830 - loss: 0.0505 - val_accuracy: 0.8621 - val_loss: 0.4795 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9964 - loss: 0.0239 - val_accuracy: 0.8621 - val_loss: 0.5020 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9957 - loss: 0.0302\nEpoch 11: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9958 - loss: 0.0296 - val_accuracy: 0.9655 - val_loss: 0.4504 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9975 - loss: 0.0146 - val_accuracy: 0.9655 - val_loss: 0.3586 - learning_rate: 1.0000e-03\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9805 - loss: 0.0505 - val_accuracy: 0.9310 - val_loss: 0.2974 - learning_rate: 1.0000e-03\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9615 - loss: 0.0855 - val_accuracy: 0.9310 - val_loss: 0.3031 - learning_rate: 1.0000e-03\nEpoch 15/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9977 - loss: 0.0229 - val_accuracy: 0.9310 - val_loss: 0.3123 - learning_rate: 1.0000e-03\nEpoch 16/50\n\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9903 - loss: 0.0408\nEpoch 16: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9913 - loss: 0.0373 - val_accuracy: 0.9310 - val_loss: 0.2986 - learning_rate: 1.0000e-03\nEpoch 17/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0128 - val_accuracy: 0.9310 - val_loss: 0.2770 - learning_rate: 1.0000e-04\nEpoch 18/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9878 - loss: 0.0286 - val_accuracy: 0.9310 - val_loss: 0.2538 - learning_rate: 1.0000e-04\nEpoch 19/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9909 - loss: 0.0162 - val_accuracy: 0.9310 - val_loss: 0.2291 - learning_rate: 1.0000e-04\nEpoch 20/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9983 - loss: 0.0100 - val_accuracy: 0.9310 - val_loss: 0.2104 - learning_rate: 1.0000e-04\nEpoch 21/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9919 - loss: 0.0352 - val_accuracy: 0.9310 - val_loss: 0.1964 - learning_rate: 1.0000e-04\nEpoch 22/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9942 - loss: 0.0144 - val_accuracy: 0.9310 - val_loss: 0.1804 - learning_rate: 1.0000e-04\nEpoch 23/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9967 - loss: 0.0206 - val_accuracy: 0.9310 - val_loss: 0.1586 - learning_rate: 1.0000e-04\nEpoch 24/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9745 - loss: 0.0468 - val_accuracy: 0.9310 - val_loss: 0.1463 - learning_rate: 1.0000e-04\nEpoch 25/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9903 - loss: 0.0343 - val_accuracy: 0.9310 - val_loss: 0.1349 - learning_rate: 1.0000e-04\nEpoch 26/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9847 - loss: 0.0450 - val_accuracy: 0.9310 - val_loss: 0.1284 - learning_rate: 1.0000e-04\nEpoch 27/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9799 - loss: 0.0344 - val_accuracy: 0.9310 - val_loss: 0.1180 - learning_rate: 1.0000e-04\nEpoch 28/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9864 - loss: 0.0226 - val_accuracy: 0.9310 - val_loss: 0.1006 - learning_rate: 1.0000e-04\nEpoch 29/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9951 - loss: 0.0440 - val_accuracy: 0.9310 - val_loss: 0.0890 - learning_rate: 1.0000e-04\nEpoch 30/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9777 - loss: 0.0544 - val_accuracy: 0.9310 - val_loss: 0.0844 - learning_rate: 1.0000e-04\nEpoch 31/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9936 - loss: 0.0539 - val_accuracy: 0.9310 - val_loss: 0.0794 - learning_rate: 1.0000e-04\nEpoch 32/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9891 - loss: 0.0251 - val_accuracy: 0.9310 - val_loss: 0.0827 - learning_rate: 1.0000e-04\nEpoch 33/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9986 - loss: 0.0063 - val_accuracy: 0.9655 - val_loss: 0.0779 - learning_rate: 1.0000e-04\nEpoch 34/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9962 - loss: 0.0133 - val_accuracy: 0.9655 - val_loss: 0.0712 - learning_rate: 1.0000e-04\nEpoch 35/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9994 - loss: 0.0067 - val_accuracy: 0.9655 - val_loss: 0.0681 - learning_rate: 1.0000e-04\nEpoch 36/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9991 - loss: 0.0111 - val_accuracy: 0.9655 - val_loss: 0.0674 - learning_rate: 1.0000e-04\nEpoch 37/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0060 - val_accuracy: 0.9655 - val_loss: 0.0642 - learning_rate: 1.0000e-04\nEpoch 38/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9959 - loss: 0.0129 - val_accuracy: 0.9655 - val_loss: 0.0619 - learning_rate: 1.0000e-04\nEpoch 39/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9900 - loss: 0.0200 - val_accuracy: 0.9655 - val_loss: 0.0556 - learning_rate: 1.0000e-04\nEpoch 40/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9946 - loss: 0.0188 - val_accuracy: 0.9655 - val_loss: 0.0494 - learning_rate: 1.0000e-04\nEpoch 41/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9955 - loss: 0.0120 - val_accuracy: 0.9655 - val_loss: 0.0494 - learning_rate: 1.0000e-04\nEpoch 42/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9899 - loss: 0.0395 - val_accuracy: 0.9655 - val_loss: 0.0511 - learning_rate: 1.0000e-04\nEpoch 43/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0073\nEpoch 43: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0071 - val_accuracy: 0.9655 - val_loss: 0.0515 - learning_rate: 1.0000e-04\nEpoch 44/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9931 - loss: 0.0227 - val_accuracy: 0.9655 - val_loss: 0.0488 - learning_rate: 1.0000e-05\nEpoch 45/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9964 - loss: 0.0108 - val_accuracy: 0.9655 - val_loss: 0.0483 - learning_rate: 1.0000e-05\nEpoch 46/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9816 - loss: 0.0606 - val_accuracy: 0.9655 - val_loss: 0.0469 - learning_rate: 1.0000e-05\nEpoch 47/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9942 - loss: 0.0147 - val_accuracy: 0.9655 - val_loss: 0.0459 - learning_rate: 1.0000e-05\nEpoch 48/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0202 - val_accuracy: 0.9655 - val_loss: 0.0452 - learning_rate: 1.0000e-05\nEpoch 49/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9900 - loss: 0.0203 - val_accuracy: 0.9655 - val_loss: 0.0448 - learning_rate: 1.0000e-05\nEpoch 50/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9703 - loss: 0.0748 - val_accuracy: 0.9655 - val_loss: 0.0449 - learning_rate: 1.0000e-05\nRestoring model weights from the end of the best epoch: 49.\nFold 8 - Train Accuracy: 100.00%, Validation Accuracy: 96.55%\n\nTraining on Fold 9...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 422ms/step - accuracy: 0.7363 - loss: 1.0673 - val_accuracy: 0.5517 - val_loss: 2198.7944 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9299 - loss: 0.1909 - val_accuracy: 0.5517 - val_loss: 465.9266 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9663 - loss: 0.0943 - val_accuracy: 0.5517 - val_loss: 35.6763 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9570 - loss: 0.0992 - val_accuracy: 0.5517 - val_loss: 27.7634 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9670 - loss: 0.0722 - val_accuracy: 0.5517 - val_loss: 7.3746 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9807 - loss: 0.0436 - val_accuracy: 0.5862 - val_loss: 3.7430 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9811 - loss: 0.0732 - val_accuracy: 0.5517 - val_loss: 8.8837 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9711 - loss: 0.0832 - val_accuracy: 0.5862 - val_loss: 3.7700 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9920 - loss: 0.0275\nEpoch 9: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9913 - loss: 0.0286 - val_accuracy: 0.5517 - val_loss: 4.4879 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9818 - loss: 0.0445 - val_accuracy: 0.5517 - val_loss: 3.9628 - learning_rate: 1.0000e-03\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9895 - loss: 0.0255 - val_accuracy: 0.5517 - val_loss: 3.2194 - learning_rate: 1.0000e-03\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9896 - loss: 0.0482 - val_accuracy: 0.6207 - val_loss: 2.3398 - learning_rate: 1.0000e-03\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9983 - loss: 0.0162 - val_accuracy: 0.6207 - val_loss: 2.0079 - learning_rate: 1.0000e-03\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9909 - loss: 0.0192 - val_accuracy: 0.6897 - val_loss: 1.7207 - learning_rate: 1.0000e-03\nEpoch 15/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0030 - val_accuracy: 0.7586 - val_loss: 1.3867 - learning_rate: 1.0000e-03\nEpoch 16/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9827 - loss: 0.0332 - val_accuracy: 0.7586 - val_loss: 1.0292 - learning_rate: 1.0000e-03\nEpoch 17/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9786 - loss: 0.0462 - val_accuracy: 0.8276 - val_loss: 0.8303 - learning_rate: 1.0000e-03\nEpoch 18/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0104 - val_accuracy: 0.8621 - val_loss: 0.6284 - learning_rate: 1.0000e-03\nEpoch 19/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9983 - loss: 0.0062 - val_accuracy: 0.8966 - val_loss: 0.5156 - learning_rate: 1.0000e-03\nEpoch 20/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9977 - loss: 0.0081 - val_accuracy: 0.8966 - val_loss: 0.3737 - learning_rate: 1.0000e-03\nEpoch 21/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9891 - loss: 0.0219 - val_accuracy: 0.8966 - val_loss: 0.4508 - learning_rate: 1.0000e-03\nEpoch 22/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0060 - val_accuracy: 0.8966 - val_loss: 0.3817 - learning_rate: 1.0000e-03\nEpoch 23/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9952 - loss: 0.0130 - val_accuracy: 0.8966 - val_loss: 0.3366 - learning_rate: 1.0000e-03\nEpoch 24/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9931 - loss: 0.0158 - val_accuracy: 0.9310 - val_loss: 0.2270 - learning_rate: 1.0000e-03\nEpoch 25/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9810 - loss: 0.0272 - val_accuracy: 0.9655 - val_loss: 0.1520 - learning_rate: 1.0000e-03\nEpoch 26/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9989 - loss: 0.0074 - val_accuracy: 0.9655 - val_loss: 0.1253 - learning_rate: 1.0000e-03\nEpoch 27/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9980 - loss: 0.0033 - val_accuracy: 0.9655 - val_loss: 0.1176 - learning_rate: 1.0000e-03\nEpoch 28/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9832 - loss: 0.0292 - val_accuracy: 0.9655 - val_loss: 0.1017 - learning_rate: 1.0000e-03\nEpoch 29/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9899 - loss: 0.0266 - val_accuracy: 0.9655 - val_loss: 0.0684 - learning_rate: 1.0000e-03\nEpoch 30/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0097 - val_accuracy: 0.9655 - val_loss: 0.0260 - learning_rate: 1.0000e-03\nEpoch 31/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0175 - val_accuracy: 1.0000 - val_loss: 0.0150 - learning_rate: 1.0000e-03\nEpoch 32/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9945 - loss: 0.0171 - val_accuracy: 1.0000 - val_loss: 0.0025 - learning_rate: 1.0000e-03\nEpoch 33/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9980 - loss: 0.0109 - val_accuracy: 1.0000 - val_loss: 0.0134 - learning_rate: 1.0000e-03\nEpoch 34/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9974 - loss: 0.0107 - val_accuracy: 0.9655 - val_loss: 0.0518 - learning_rate: 1.0000e-03\nEpoch 35/50\n\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9731 - loss: 0.0594\nEpoch 35: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9757 - loss: 0.0538 - val_accuracy: 0.9655 - val_loss: 0.0931 - learning_rate: 1.0000e-03\nEpoch 36/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0116 - val_accuracy: 0.9655 - val_loss: 0.0887 - learning_rate: 1.0000e-04\nEpoch 37/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9992 - loss: 0.0031 - val_accuracy: 0.9655 - val_loss: 0.0865 - learning_rate: 1.0000e-04\nEpoch 37: early stopping\nRestoring model weights from the end of the best epoch: 32.\nFold 9 - Train Accuracy: 100.00%, Validation Accuracy: 100.00%\n\nTraining on Fold 10...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 428ms/step - accuracy: 0.7353 - loss: 0.7905 - val_accuracy: 0.5172 - val_loss: 2805.4246 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8972 - loss: 0.2846 - val_accuracy: 0.5172 - val_loss: 150.9823 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9491 - loss: 0.1497 - val_accuracy: 0.4483 - val_loss: 3.4399 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9734 - loss: 0.0734 - val_accuracy: 0.5172 - val_loss: 17.0838 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9425 - loss: 0.1953 - val_accuracy: 0.5172 - val_loss: 6.9158 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9735 - loss: 0.0871\nEpoch 6: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9729 - loss: 0.0884 - val_accuracy: 0.5172 - val_loss: 6.1810 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9785 - loss: 0.0602 - val_accuracy: 0.5172 - val_loss: 4.8977 - learning_rate: 1.0000e-03\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9878 - loss: 0.0341 - val_accuracy: 0.5172 - val_loss: 3.8222 - learning_rate: 1.0000e-03\nEpoch 8: early stopping\nRestoring model weights from the end of the best epoch: 3.\nFold 10 - Train Accuracy: 58.80%, Validation Accuracy: 44.83%\n\nAverage Training Accuracy: 93.82%\nAverage Validation Accuracy: 93.46%\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"## 2.2 Rotating 90 degrees","metadata":{}},{"cell_type":"code","source":"X_train_rotated = np.rot90(X_train, k=1, axes=(1,2))\nX_test_rotated = np.rot90(X_test, k=1, axes=(1,2))\n\nX_train_augmented = np.concatenate((X_train, X_train_rotated), axis=0)\ny_train_augmented = np.concatenate((y_train, y_train), axis=0)\n\ntrain_evaluate_model_with_k_fold(\n    X_train=X_train_augmented,\n    y_train=y_train_augmented,\n    lr=0.01,\n    epochs=50,\n    batch_size=16)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T16:47:49.709905Z","iopub.execute_input":"2025-02-08T16:47:49.710190Z","iopub.status.idle":"2025-02-08T16:52:55.352767Z","shell.execute_reply.started":"2025-02-08T16:47:49.710168Z","shell.execute_reply":"2025-02-08T16:52:55.351817Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"\nTraining on Fold 1...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 424ms/step - accuracy: 0.6615 - loss: 1.2817 - val_accuracy: 0.5000 - val_loss: 5088.9487 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.8816 - loss: 0.3398 - val_accuracy: 0.5000 - val_loss: 797.9446 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9522 - loss: 0.1362 - val_accuracy: 0.5000 - val_loss: 173.2852 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9520 - loss: 0.1402 - val_accuracy: 0.5000 - val_loss: 46.3706 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9198 - loss: 0.2595 - val_accuracy: 0.5000 - val_loss: 31.7026 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9450 - loss: 0.1357 - val_accuracy: 0.6333 - val_loss: 3.0842 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9447 - loss: 0.1746 - val_accuracy: 0.8000 - val_loss: 0.9620 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9388 - loss: 0.1803 - val_accuracy: 0.7667 - val_loss: 1.0300 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9580 - loss: 0.1177 - val_accuracy: 0.7000 - val_loss: 2.8132 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9610 - loss: 0.1384 - val_accuracy: 0.7667 - val_loss: 0.8651 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9845 - loss: 0.0518 - val_accuracy: 0.7000 - val_loss: 2.3700 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9719 - loss: 0.0752 - val_accuracy: 0.7333 - val_loss: 1.3374 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9602 - loss: 0.1260 - val_accuracy: 0.8667 - val_loss: 0.5043 - learning_rate: 0.0100\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9762 - loss: 0.0582 - val_accuracy: 0.9000 - val_loss: 0.6626 - learning_rate: 0.0100\nEpoch 15/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9660 - loss: 0.0579 - val_accuracy: 0.8667 - val_loss: 0.7394 - learning_rate: 0.0100\nEpoch 16/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9927 - loss: 0.0257\nEpoch 16: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9925 - loss: 0.0265 - val_accuracy: 0.8333 - val_loss: 0.9248 - learning_rate: 0.0100\nEpoch 17/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9530 - loss: 0.1087 - val_accuracy: 0.7667 - val_loss: 0.7144 - learning_rate: 1.0000e-03\nEpoch 18/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9793 - loss: 0.0856 - val_accuracy: 0.8667 - val_loss: 0.7200 - learning_rate: 1.0000e-03\nEpoch 18: early stopping\nRestoring model weights from the end of the best epoch: 13.\nFold 1 - Train Accuracy: 99.25%, Validation Accuracy: 86.67%\n\nTraining on Fold 2...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 432ms/step - accuracy: 0.7136 - loss: 1.0861 - val_accuracy: 0.5333 - val_loss: 2925.0056 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9101 - loss: 0.2412 - val_accuracy: 0.6000 - val_loss: 46.5686 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8972 - loss: 0.2819 - val_accuracy: 0.6667 - val_loss: 6.3940 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9469 - loss: 0.1581 - val_accuracy: 0.8000 - val_loss: 1.5190 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9892 - loss: 0.0566 - val_accuracy: 0.6000 - val_loss: 4.7649 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9863 - loss: 0.0344 - val_accuracy: 0.7000 - val_loss: 2.3387 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9591 - loss: 0.0824\nEpoch 7: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9569 - loss: 0.0910 - val_accuracy: 0.8667 - val_loss: 1.6077 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9810 - loss: 0.0543 - val_accuracy: 0.9000 - val_loss: 0.8898 - learning_rate: 1.0000e-03\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9551 - loss: 0.0828 - val_accuracy: 0.8667 - val_loss: 0.6961 - learning_rate: 1.0000e-03\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9714 - loss: 0.0599 - val_accuracy: 0.8667 - val_loss: 0.5757 - learning_rate: 1.0000e-03\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9795 - loss: 0.0710 - val_accuracy: 0.8667 - val_loss: 0.4890 - learning_rate: 1.0000e-03\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9762 - loss: 0.0479 - val_accuracy: 0.8667 - val_loss: 0.4754 - learning_rate: 1.0000e-03\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9832 - loss: 0.0308 - val_accuracy: 0.8667 - val_loss: 0.4697 - learning_rate: 1.0000e-03\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9767 - loss: 0.0776 - val_accuracy: 0.8000 - val_loss: 0.4477 - learning_rate: 1.0000e-03\nEpoch 15/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9926 - loss: 0.0196 - val_accuracy: 0.8333 - val_loss: 0.3987 - learning_rate: 1.0000e-03\nEpoch 16/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9661 - loss: 0.0522 - val_accuracy: 0.8333 - val_loss: 0.3880 - learning_rate: 1.0000e-03\nEpoch 17/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9838 - loss: 0.0453 - val_accuracy: 0.8667 - val_loss: 0.3618 - learning_rate: 1.0000e-03\nEpoch 18/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9872 - loss: 0.0262 - val_accuracy: 0.9333 - val_loss: 0.2270 - learning_rate: 1.0000e-03\nEpoch 19/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9676 - loss: 0.0629 - val_accuracy: 0.9667 - val_loss: 0.2197 - learning_rate: 1.0000e-03\nEpoch 20/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9836 - loss: 0.0414 - val_accuracy: 0.9333 - val_loss: 0.2149 - learning_rate: 1.0000e-03\nEpoch 21/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9880 - loss: 0.0406 - val_accuracy: 0.9333 - val_loss: 0.1954 - learning_rate: 1.0000e-03\nEpoch 22/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9917 - loss: 0.0353 - val_accuracy: 0.9333 - val_loss: 0.1677 - learning_rate: 1.0000e-03\nEpoch 23/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9743 - loss: 0.0432 - val_accuracy: 0.9667 - val_loss: 0.0884 - learning_rate: 1.0000e-03\nEpoch 24/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9911 - loss: 0.0253 - val_accuracy: 0.9667 - val_loss: 0.0881 - learning_rate: 1.0000e-03\nEpoch 25/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9743 - loss: 0.0533 - val_accuracy: 0.9667 - val_loss: 0.1412 - learning_rate: 1.0000e-03\nEpoch 26/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9963 - loss: 0.0135 - val_accuracy: 0.9667 - val_loss: 0.1759 - learning_rate: 1.0000e-03\nEpoch 27/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9943 - loss: 0.0243\nEpoch 27: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9936 - loss: 0.0255 - val_accuracy: 0.9667 - val_loss: 0.1527 - learning_rate: 1.0000e-03\nEpoch 28/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9958 - loss: 0.0081 - val_accuracy: 0.9667 - val_loss: 0.1279 - learning_rate: 1.0000e-04\nEpoch 29/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9934 - loss: 0.0140 - val_accuracy: 0.9667 - val_loss: 0.1042 - learning_rate: 1.0000e-04\nEpoch 29: early stopping\nRestoring model weights from the end of the best epoch: 24.\nFold 2 - Train Accuracy: 99.25%, Validation Accuracy: 96.67%\n\nTraining on Fold 3...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 413ms/step - accuracy: 0.6366 - loss: 1.1327 - val_accuracy: 0.5333 - val_loss: 2063.0327 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.9079 - loss: 0.2161 - val_accuracy: 0.5333 - val_loss: 421.4042 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9205 - loss: 0.2275 - val_accuracy: 0.5333 - val_loss: 26.6720 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9581 - loss: 0.1304 - val_accuracy: 0.4667 - val_loss: 24.4946 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9497 - loss: 0.1786 - val_accuracy: 0.4667 - val_loss: 10.8115 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9401 - loss: 0.1375 - val_accuracy: 0.6000 - val_loss: 3.5518 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9825 - loss: 0.0612 - val_accuracy: 0.6000 - val_loss: 2.8286 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9475 - loss: 0.0933 - val_accuracy: 0.6000 - val_loss: 2.1219 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9526 - loss: 0.1156 - val_accuracy: 0.7000 - val_loss: 1.9600 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9782 - loss: 0.0853 - val_accuracy: 0.9000 - val_loss: 0.1146 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9682 - loss: 0.0752 - val_accuracy: 0.8667 - val_loss: 0.6081 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9602 - loss: 0.1672 - val_accuracy: 0.9667 - val_loss: 0.0583 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9792 - loss: 0.0374 - val_accuracy: 0.9333 - val_loss: 0.1468 - learning_rate: 0.0100\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9906 - loss: 0.0261 - val_accuracy: 0.9667 - val_loss: 0.0569 - learning_rate: 0.0100\nEpoch 15/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9872 - loss: 0.0507 - val_accuracy: 1.0000 - val_loss: 0.0191 - learning_rate: 0.0100\nEpoch 16/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9763 - loss: 0.0629 - val_accuracy: 1.0000 - val_loss: 0.0067 - learning_rate: 0.0100\nEpoch 17/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9740 - loss: 0.0782 - val_accuracy: 0.9333 - val_loss: 0.1220 - learning_rate: 0.0100\nEpoch 18/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9850 - loss: 0.0672 - val_accuracy: 1.0000 - val_loss: 0.0018 - learning_rate: 0.0100\nEpoch 19/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9752 - loss: 0.0727 - val_accuracy: 0.9667 - val_loss: 0.0380 - learning_rate: 0.0100\nEpoch 20/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9672 - loss: 0.1229 - val_accuracy: 0.8333 - val_loss: 0.5600 - learning_rate: 0.0100\nEpoch 21/50\n\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9719 - loss: 0.1016\nEpoch 21: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9728 - loss: 0.1000 - val_accuracy: 0.9667 - val_loss: 0.1429 - learning_rate: 0.0100\nEpoch 22/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9839 - loss: 0.0490 - val_accuracy: 0.9000 - val_loss: 0.1470 - learning_rate: 1.0000e-03\nEpoch 23/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9734 - loss: 0.0587 - val_accuracy: 0.9000 - val_loss: 0.1378 - learning_rate: 1.0000e-03\nEpoch 23: early stopping\nRestoring model weights from the end of the best epoch: 18.\nFold 3 - Train Accuracy: 96.99%, Validation Accuracy: 100.00%\n\nTraining on Fold 4...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 431ms/step - accuracy: 0.6324 - loss: 1.2476 - val_accuracy: 0.4333 - val_loss: 2481.9285 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8934 - loss: 0.2669 - val_accuracy: 0.4333 - val_loss: 1418.3387 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8744 - loss: 0.2985 - val_accuracy: 0.4333 - val_loss: 26.1270 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9235 - loss: 0.2091 - val_accuracy: 0.6333 - val_loss: 32.6218 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8821 - loss: 0.3836 - val_accuracy: 0.4667 - val_loss: 5.0281 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9320 - loss: 0.1553 - val_accuracy: 0.4333 - val_loss: 31.4002 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9491 - loss: 0.1836 - val_accuracy: 0.4333 - val_loss: 7.4333 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9768 - loss: 0.0750 - val_accuracy: 0.5667 - val_loss: 2.0934 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9731 - loss: 0.0746 - val_accuracy: 0.6000 - val_loss: 2.1583 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9600 - loss: 0.1291 - val_accuracy: 0.5333 - val_loss: 1.1548 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9616 - loss: 0.1102 - val_accuracy: 0.6000 - val_loss: 3.1405 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9643 - loss: 0.0845 - val_accuracy: 0.9667 - val_loss: 0.0928 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9892 - loss: 0.0282 - val_accuracy: 0.9000 - val_loss: 0.3421 - learning_rate: 0.0100\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9719 - loss: 0.0996 - val_accuracy: 0.9333 - val_loss: 0.1197 - learning_rate: 0.0100\nEpoch 15/50\n\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9531 - loss: 0.1701\nEpoch 15: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9554 - loss: 0.1613 - val_accuracy: 0.8333 - val_loss: 0.2188 - learning_rate: 0.0100\nEpoch 16/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9288 - loss: 0.1559 - val_accuracy: 0.9667 - val_loss: 0.0418 - learning_rate: 1.0000e-03\nEpoch 17/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9731 - loss: 0.0928 - val_accuracy: 0.9667 - val_loss: 0.0304 - learning_rate: 1.0000e-03\nEpoch 18/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9793 - loss: 0.0459 - val_accuracy: 0.9667 - val_loss: 0.0323 - learning_rate: 1.0000e-03\nEpoch 19/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9976 - loss: 0.0200 - val_accuracy: 1.0000 - val_loss: 0.0161 - learning_rate: 1.0000e-03\nEpoch 20/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9942 - loss: 0.0288 - val_accuracy: 1.0000 - val_loss: 0.0188 - learning_rate: 1.0000e-03\nEpoch 21/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9955 - loss: 0.0180 - val_accuracy: 0.9667 - val_loss: 0.0264 - learning_rate: 1.0000e-03\nEpoch 22/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9964 - loss: 0.0129 - val_accuracy: 1.0000 - val_loss: 0.0133 - learning_rate: 1.0000e-03\nEpoch 23/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0086 - val_accuracy: 1.0000 - val_loss: 0.0077 - learning_rate: 1.0000e-03\nEpoch 24/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9788 - loss: 0.0484 - val_accuracy: 1.0000 - val_loss: 0.0072 - learning_rate: 1.0000e-03\nEpoch 25/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9994 - loss: 0.0139 - val_accuracy: 1.0000 - val_loss: 0.0056 - learning_rate: 1.0000e-03\nEpoch 26/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9926 - loss: 0.0190 - val_accuracy: 1.0000 - val_loss: 0.0065 - learning_rate: 1.0000e-03\nEpoch 27/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9986 - loss: 0.0149 - val_accuracy: 1.0000 - val_loss: 0.0053 - learning_rate: 1.0000e-03\nEpoch 28/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9994 - loss: 0.0057 - val_accuracy: 1.0000 - val_loss: 0.0038 - learning_rate: 1.0000e-03\nEpoch 29/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9983 - loss: 0.0083 - val_accuracy: 1.0000 - val_loss: 0.0037 - learning_rate: 1.0000e-03\nEpoch 30/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9980 - loss: 0.0063 - val_accuracy: 1.0000 - val_loss: 0.0054 - learning_rate: 1.0000e-03\nEpoch 31/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9958 - loss: 0.0202 - val_accuracy: 1.0000 - val_loss: 0.0062 - learning_rate: 1.0000e-03\nEpoch 32/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0081\nEpoch 32: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0082 - val_accuracy: 1.0000 - val_loss: 0.0049 - learning_rate: 1.0000e-03\nEpoch 33/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0060 - val_accuracy: 1.0000 - val_loss: 0.0043 - learning_rate: 1.0000e-04\nEpoch 34/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9942 - loss: 0.0234 - val_accuracy: 1.0000 - val_loss: 0.0041 - learning_rate: 1.0000e-04\nEpoch 34: early stopping\nRestoring model weights from the end of the best epoch: 29.\nFold 4 - Train Accuracy: 99.25%, Validation Accuracy: 100.00%\n\nTraining on Fold 5...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 426ms/step - accuracy: 0.6760 - loss: 1.1156 - val_accuracy: 0.4667 - val_loss: 5939.9395 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.8723 - loss: 0.3116 - val_accuracy: 0.4667 - val_loss: 1055.8463 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9281 - loss: 0.1983 - val_accuracy: 0.5000 - val_loss: 11.5657 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9681 - loss: 0.1319 - val_accuracy: 0.4667 - val_loss: 17.2976 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9534 - loss: 0.1466 - val_accuracy: 0.8667 - val_loss: 0.5130 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9431 - loss: 0.1354 - val_accuracy: 0.4667 - val_loss: 11.7671 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9271 - loss: 0.1428 - val_accuracy: 0.4667 - val_loss: 10.6427 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9540 - loss: 0.1263 - val_accuracy: 0.9000 - val_loss: 0.3399 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9478 - loss: 0.1461 - val_accuracy: 0.5000 - val_loss: 5.3995 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9546 - loss: 0.1122 - val_accuracy: 0.5667 - val_loss: 1.8239 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9473 - loss: 0.1644\nEpoch 11: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9491 - loss: 0.1585 - val_accuracy: 0.8667 - val_loss: 0.3461 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9753 - loss: 0.0979 - val_accuracy: 0.9000 - val_loss: 0.2308 - learning_rate: 1.0000e-03\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9925 - loss: 0.0199 - val_accuracy: 0.8667 - val_loss: 0.2629 - learning_rate: 1.0000e-03\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9805 - loss: 0.0563 - val_accuracy: 0.8667 - val_loss: 0.3135 - learning_rate: 1.0000e-03\nEpoch 15/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9914 - loss: 0.0232 - val_accuracy: 0.9000 - val_loss: 0.2007 - learning_rate: 1.0000e-03\nEpoch 16/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9864 - loss: 0.0415 - val_accuracy: 0.8667 - val_loss: 0.2674 - learning_rate: 1.0000e-03\nEpoch 17/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9890 - loss: 0.0211 - val_accuracy: 0.8667 - val_loss: 0.2935 - learning_rate: 1.0000e-03\nEpoch 18/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9831 - loss: 0.0402\nEpoch 18: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9833 - loss: 0.0395 - val_accuracy: 0.9000 - val_loss: 0.2984 - learning_rate: 1.0000e-03\nEpoch 19/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0140 - val_accuracy: 0.9000 - val_loss: 0.2390 - learning_rate: 1.0000e-04\nEpoch 20/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9914 - loss: 0.0378 - val_accuracy: 0.9333 - val_loss: 0.1941 - learning_rate: 1.0000e-04\nEpoch 21/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0162 - val_accuracy: 0.9333 - val_loss: 0.1568 - learning_rate: 1.0000e-04\nEpoch 22/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9913 - loss: 0.0227 - val_accuracy: 0.9333 - val_loss: 0.1253 - learning_rate: 1.0000e-04\nEpoch 23/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9716 - loss: 0.1179 - val_accuracy: 0.9667 - val_loss: 0.0920 - learning_rate: 1.0000e-04\nEpoch 24/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9798 - loss: 0.0462 - val_accuracy: 0.9667 - val_loss: 0.0696 - learning_rate: 1.0000e-04\nEpoch 25/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9992 - loss: 0.0106 - val_accuracy: 0.9667 - val_loss: 0.0551 - learning_rate: 1.0000e-04\nEpoch 26/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9788 - loss: 0.0662 - val_accuracy: 0.9667 - val_loss: 0.0502 - learning_rate: 1.0000e-04\nEpoch 27/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9848 - loss: 0.0484 - val_accuracy: 0.9667 - val_loss: 0.0441 - learning_rate: 1.0000e-04\nEpoch 28/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9991 - loss: 0.0113 - val_accuracy: 0.9667 - val_loss: 0.0393 - learning_rate: 1.0000e-04\nEpoch 29/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.9826 - loss: 0.0912 - val_accuracy: 0.9667 - val_loss: 0.0340 - learning_rate: 1.0000e-04\nEpoch 30/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9994 - loss: 0.0143 - val_accuracy: 0.9667 - val_loss: 0.0296 - learning_rate: 1.0000e-04\nEpoch 31/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9983 - loss: 0.0154 - val_accuracy: 1.0000 - val_loss: 0.0245 - learning_rate: 1.0000e-04\nEpoch 32/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9699 - loss: 0.0599 - val_accuracy: 1.0000 - val_loss: 0.0200 - learning_rate: 1.0000e-04\nEpoch 33/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9962 - loss: 0.0196 - val_accuracy: 1.0000 - val_loss: 0.0166 - learning_rate: 1.0000e-04\nEpoch 34/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9911 - loss: 0.0343 - val_accuracy: 1.0000 - val_loss: 0.0156 - learning_rate: 1.0000e-04\nEpoch 35/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9902 - loss: 0.0396 - val_accuracy: 1.0000 - val_loss: 0.0125 - learning_rate: 1.0000e-04\nEpoch 36/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9865 - loss: 0.0463 - val_accuracy: 1.0000 - val_loss: 0.0111 - learning_rate: 1.0000e-04\nEpoch 37/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9854 - loss: 0.0419 - val_accuracy: 1.0000 - val_loss: 0.0090 - learning_rate: 1.0000e-04\nEpoch 38/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9942 - loss: 0.0099 - val_accuracy: 1.0000 - val_loss: 0.0084 - learning_rate: 1.0000e-04\nEpoch 39/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0122 - val_accuracy: 1.0000 - val_loss: 0.0082 - learning_rate: 1.0000e-04\nEpoch 40/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9964 - loss: 0.0237 - val_accuracy: 1.0000 - val_loss: 0.0077 - learning_rate: 1.0000e-04\nEpoch 41/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9919 - loss: 0.0265 - val_accuracy: 1.0000 - val_loss: 0.0071 - learning_rate: 1.0000e-04\nEpoch 42/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9958 - loss: 0.0289 - val_accuracy: 1.0000 - val_loss: 0.0070 - learning_rate: 1.0000e-04\nEpoch 43/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9862 - loss: 0.0222 - val_accuracy: 1.0000 - val_loss: 0.0063 - learning_rate: 1.0000e-04\nEpoch 44/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9840 - loss: 0.0321 - val_accuracy: 1.0000 - val_loss: 0.0060 - learning_rate: 1.0000e-04\nEpoch 45/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9868 - loss: 0.0374 - val_accuracy: 1.0000 - val_loss: 0.0062 - learning_rate: 1.0000e-04\nEpoch 46/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9940 - loss: 0.0283 - val_accuracy: 1.0000 - val_loss: 0.0058 - learning_rate: 1.0000e-04\nEpoch 47/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9687 - loss: 0.0800 - val_accuracy: 1.0000 - val_loss: 0.0059 - learning_rate: 1.0000e-04\nEpoch 48/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9987 - loss: 0.0093 - val_accuracy: 1.0000 - val_loss: 0.0062 - learning_rate: 1.0000e-04\nEpoch 49/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0082\nEpoch 49: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0083 - val_accuracy: 1.0000 - val_loss: 0.0067 - learning_rate: 1.0000e-04\nEpoch 50/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0128 - val_accuracy: 1.0000 - val_loss: 0.0067 - learning_rate: 1.0000e-05\nRestoring model weights from the end of the best epoch: 46.\nFold 5 - Train Accuracy: 100.00%, Validation Accuracy: 100.00%\n\nTraining on Fold 6...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 422ms/step - accuracy: 0.6827 - loss: 1.2412 - val_accuracy: 0.4667 - val_loss: 602.1849 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8989 - loss: 0.2687 - val_accuracy: 0.5333 - val_loss: 835.1565 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9316 - loss: 0.2259 - val_accuracy: 0.5333 - val_loss: 71.2212 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9475 - loss: 0.1531 - val_accuracy: 0.5667 - val_loss: 21.5887 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9390 - loss: 0.1729 - val_accuracy: 0.5333 - val_loss: 7.9354 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9596 - loss: 0.1211 - val_accuracy: 0.6000 - val_loss: 4.8145 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9861 - loss: 0.0902 - val_accuracy: 0.6667 - val_loss: 2.5150 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9504 - loss: 0.1619 - val_accuracy: 0.8333 - val_loss: 0.9024 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9062 - loss: 0.2251 - val_accuracy: 0.7000 - val_loss: 1.2051 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9623 - loss: 0.1177 - val_accuracy: 0.8667 - val_loss: 0.6742 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9775 - loss: 0.1111 - val_accuracy: 0.9000 - val_loss: 0.5108 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9913 - loss: 0.0224 - val_accuracy: 0.9000 - val_loss: 0.4602 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9894 - loss: 0.0416 - val_accuracy: 0.8000 - val_loss: 0.7320 - learning_rate: 0.0100\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9764 - loss: 0.1112 - val_accuracy: 0.8000 - val_loss: 0.5535 - learning_rate: 0.0100\nEpoch 15/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9538 - loss: 0.1545 - val_accuracy: 0.9667 - val_loss: 0.0936 - learning_rate: 0.0100\nEpoch 16/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9738 - loss: 0.0872 - val_accuracy: 1.0000 - val_loss: 0.0140 - learning_rate: 0.0100\nEpoch 17/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9693 - loss: 0.0546 - val_accuracy: 0.9667 - val_loss: 0.1137 - learning_rate: 0.0100\nEpoch 18/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9673 - loss: 0.0906 - val_accuracy: 0.8333 - val_loss: 0.4582 - learning_rate: 0.0100\nEpoch 19/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9791 - loss: 0.0746\nEpoch 19: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9801 - loss: 0.0721 - val_accuracy: 0.9333 - val_loss: 0.1437 - learning_rate: 0.0100\nEpoch 20/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9709 - loss: 0.0755 - val_accuracy: 0.9667 - val_loss: 0.0705 - learning_rate: 1.0000e-03\nEpoch 21/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9836 - loss: 0.0800 - val_accuracy: 1.0000 - val_loss: 0.0736 - learning_rate: 1.0000e-03\nEpoch 21: early stopping\nRestoring model weights from the end of the best epoch: 16.\nFold 6 - Train Accuracy: 99.25%, Validation Accuracy: 100.00%\n\nTraining on Fold 7...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 421ms/step - accuracy: 0.6952 - loss: 0.9733 - val_accuracy: 0.7241 - val_loss: 101.4537 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.8818 - loss: 0.2581 - val_accuracy: 0.5517 - val_loss: 535.5162 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9462 - loss: 0.1557 - val_accuracy: 0.4483 - val_loss: 223.8940 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9152 - loss: 0.2152 - val_accuracy: 0.4483 - val_loss: 52.4155 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9374 - loss: 0.1467 - val_accuracy: 0.4138 - val_loss: 7.3641 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9640 - loss: 0.1067 - val_accuracy: 0.6207 - val_loss: 14.2424 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9105 - loss: 0.2595 - val_accuracy: 0.6207 - val_loss: 2.5511 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9305 - loss: 0.1683 - val_accuracy: 0.8621 - val_loss: 0.9128 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9664 - loss: 0.1120 - val_accuracy: 0.7931 - val_loss: 1.3273 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9391 - loss: 0.1651 - val_accuracy: 0.8621 - val_loss: 0.4188 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9720 - loss: 0.1012 - val_accuracy: 0.8621 - val_loss: 1.3133 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9512 - loss: 0.1453 - val_accuracy: 0.8966 - val_loss: 0.3108 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9831 - loss: 0.0385 - val_accuracy: 1.0000 - val_loss: 0.0319 - learning_rate: 0.0100\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9832 - loss: 0.0360 - val_accuracy: 0.8966 - val_loss: 0.6083 - learning_rate: 0.0100\nEpoch 15/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9553 - loss: 0.1438 - val_accuracy: 0.8276 - val_loss: 0.5490 - learning_rate: 0.0100\nEpoch 16/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9615 - loss: 0.0776\nEpoch 16: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9616 - loss: 0.0806 - val_accuracy: 0.7241 - val_loss: 1.3423 - learning_rate: 0.0100\nEpoch 17/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9194 - loss: 0.2785 - val_accuracy: 0.8966 - val_loss: 0.2690 - learning_rate: 1.0000e-03\nEpoch 18/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9540 - loss: 0.0863 - val_accuracy: 0.8966 - val_loss: 0.1847 - learning_rate: 1.0000e-03\nEpoch 18: early stopping\nRestoring model weights from the end of the best epoch: 13.\nFold 7 - Train Accuracy: 96.63%, Validation Accuracy: 100.00%\n\nTraining on Fold 8...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 423ms/step - accuracy: 0.7336 - loss: 0.9695 - val_accuracy: 0.4483 - val_loss: 1613.8933 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9381 - loss: 0.1770 - val_accuracy: 0.5517 - val_loss: 322.1740 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9419 - loss: 0.1404 - val_accuracy: 0.5517 - val_loss: 38.1236 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9755 - loss: 0.0678 - val_accuracy: 0.5172 - val_loss: 15.1328 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9540 - loss: 0.0949 - val_accuracy: 0.6897 - val_loss: 3.6795 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9388 - loss: 0.1655 - val_accuracy: 0.7931 - val_loss: 1.1366 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9595 - loss: 0.0809 - val_accuracy: 0.8276 - val_loss: 0.7875 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9785 - loss: 0.0563 - val_accuracy: 0.7241 - val_loss: 2.9612 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9790 - loss: 0.0489 - val_accuracy: 0.7931 - val_loss: 1.3706 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9949 - loss: 0.0259\nEpoch 10: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9947 - loss: 0.0257 - val_accuracy: 0.8621 - val_loss: 0.8968 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9890 - loss: 0.0292 - val_accuracy: 0.8966 - val_loss: 0.7519 - learning_rate: 1.0000e-03\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9777 - loss: 0.0469 - val_accuracy: 0.8966 - val_loss: 0.7015 - learning_rate: 1.0000e-03\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9954 - loss: 0.0248 - val_accuracy: 0.8621 - val_loss: 0.7117 - learning_rate: 1.0000e-03\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9935 - loss: 0.0185 - val_accuracy: 0.8276 - val_loss: 0.7506 - learning_rate: 1.0000e-03\nEpoch 15/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9814 - loss: 0.0352 - val_accuracy: 0.8276 - val_loss: 0.6923 - learning_rate: 1.0000e-03\nEpoch 16/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0080 - val_accuracy: 0.8276 - val_loss: 0.7462 - learning_rate: 1.0000e-03\nEpoch 17/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9909 - loss: 0.0243 - val_accuracy: 0.8276 - val_loss: 0.9372 - learning_rate: 1.0000e-03\nEpoch 18/50\n\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9686 - loss: 0.0355\nEpoch 18: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9713 - loss: 0.0346 - val_accuracy: 0.8276 - val_loss: 0.9612 - learning_rate: 1.0000e-03\nEpoch 19/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9980 - loss: 0.0140 - val_accuracy: 0.8276 - val_loss: 0.9150 - learning_rate: 1.0000e-04\nEpoch 20/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9809 - loss: 0.0357 - val_accuracy: 0.8621 - val_loss: 0.8809 - learning_rate: 1.0000e-04\nEpoch 20: early stopping\nRestoring model weights from the end of the best epoch: 15.\nFold 8 - Train Accuracy: 95.13%, Validation Accuracy: 82.76%\n\nTraining on Fold 9...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 425ms/step - accuracy: 0.6392 - loss: 1.0955 - val_accuracy: 0.5517 - val_loss: 1399.4109 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9007 - loss: 0.2447 - val_accuracy: 0.5517 - val_loss: 191.7805 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9324 - loss: 0.2056 - val_accuracy: 0.5517 - val_loss: 242.2785 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9719 - loss: 0.0901 - val_accuracy: 0.5517 - val_loss: 28.1440 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9483 - loss: 0.1429 - val_accuracy: 0.5517 - val_loss: 18.0332 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9153 - loss: 0.1674 - val_accuracy: 0.5862 - val_loss: 6.3584 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9625 - loss: 0.0854 - val_accuracy: 0.6207 - val_loss: 2.6027 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9714 - loss: 0.0935 - val_accuracy: 0.8276 - val_loss: 1.1533 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9792 - loss: 0.0727 - val_accuracy: 0.8621 - val_loss: 0.9452 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9895 - loss: 0.0348 - val_accuracy: 0.8621 - val_loss: 0.7022 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9829 - loss: 0.0614 - val_accuracy: 0.9310 - val_loss: 0.3046 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9920 - loss: 0.0227 - val_accuracy: 0.8966 - val_loss: 0.3352 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9889 - loss: 0.0245 - val_accuracy: 0.8621 - val_loss: 0.4076 - learning_rate: 0.0100\nEpoch 14/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9978 - loss: 0.0159\nEpoch 14: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9972 - loss: 0.0183 - val_accuracy: 0.8966 - val_loss: 0.4171 - learning_rate: 0.0100\nEpoch 15/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9841 - loss: 0.0488 - val_accuracy: 0.8966 - val_loss: 0.3492 - learning_rate: 1.0000e-03\nEpoch 16/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9878 - loss: 0.0368 - val_accuracy: 0.9310 - val_loss: 0.3293 - learning_rate: 1.0000e-03\nEpoch 16: early stopping\nRestoring model weights from the end of the best epoch: 11.\nFold 9 - Train Accuracy: 93.63%, Validation Accuracy: 93.10%\n\nTraining on Fold 10...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 420ms/step - accuracy: 0.7165 - loss: 1.1933 - val_accuracy: 0.5172 - val_loss: 4742.8901 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.8934 - loss: 0.2713 - val_accuracy: 0.6552 - val_loss: 13.6177 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9616 - loss: 0.1436 - val_accuracy: 0.5172 - val_loss: 31.2641 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9550 - loss: 0.1732 - val_accuracy: 0.4828 - val_loss: 18.9136 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9258 - loss: 0.1835 - val_accuracy: 0.4828 - val_loss: 4.8892 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9686 - loss: 0.0802 - val_accuracy: 0.6207 - val_loss: 3.1294 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9606 - loss: 0.1585 - val_accuracy: 0.6207 - val_loss: 2.3099 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9445 - loss: 0.1206 - val_accuracy: 0.4828 - val_loss: 2.9615 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9521 - loss: 0.1371 - val_accuracy: 0.7241 - val_loss: 2.1831 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9584 - loss: 0.1331 - val_accuracy: 0.9310 - val_loss: 0.3300 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9804 - loss: 0.0748 - val_accuracy: 0.8276 - val_loss: 0.9542 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9600 - loss: 0.1228 - val_accuracy: 0.8966 - val_loss: 0.2321 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9390 - loss: 0.1912 - val_accuracy: 0.9310 - val_loss: 0.1711 - learning_rate: 0.0100\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9267 - loss: 0.1581 - val_accuracy: 0.9310 - val_loss: 0.1171 - learning_rate: 0.0100\nEpoch 15/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9811 - loss: 0.0593 - val_accuracy: 0.9655 - val_loss: 0.0888 - learning_rate: 0.0100\nEpoch 16/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9893 - loss: 0.0362 - val_accuracy: 1.0000 - val_loss: 0.0410 - learning_rate: 0.0100\nEpoch 17/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9951 - loss: 0.0283 - val_accuracy: 0.9310 - val_loss: 0.0877 - learning_rate: 0.0100\nEpoch 18/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9859 - loss: 0.0177 - val_accuracy: 0.9655 - val_loss: 0.0307 - learning_rate: 0.0100\nEpoch 19/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9954 - loss: 0.0183 - val_accuracy: 0.9655 - val_loss: 0.1517 - learning_rate: 0.0100\nEpoch 20/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9822 - loss: 0.1062 - val_accuracy: 1.0000 - val_loss: 0.0255 - learning_rate: 0.0100\nEpoch 21/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9708 - loss: 0.0753 - val_accuracy: 0.9310 - val_loss: 0.1052 - learning_rate: 0.0100\nEpoch 22/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9822 - loss: 0.0400 - val_accuracy: 1.0000 - val_loss: 0.0060 - learning_rate: 0.0100\nEpoch 23/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9901 - loss: 0.0200 - val_accuracy: 1.0000 - val_loss: 0.0179 - learning_rate: 0.0100\nEpoch 24/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9764 - loss: 0.0656 - val_accuracy: 1.0000 - val_loss: 0.0068 - learning_rate: 0.0100\nEpoch 25/50\n\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9765 - loss: 0.0996\nEpoch 25: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9760 - loss: 0.0985 - val_accuracy: 1.0000 - val_loss: 0.0115 - learning_rate: 0.0100\nEpoch 26/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9892 - loss: 0.0387 - val_accuracy: 1.0000 - val_loss: 0.0078 - learning_rate: 1.0000e-03\nEpoch 27/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9879 - loss: 0.0323 - val_accuracy: 1.0000 - val_loss: 0.0068 - learning_rate: 1.0000e-03\nEpoch 27: early stopping\nRestoring model weights from the end of the best epoch: 22.\nFold 10 - Train Accuracy: 100.00%, Validation Accuracy: 100.00%\n\nAverage Training Accuracy: 97.94%\nAverage Validation Accuracy: 95.92%\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"## 2.3 Rotating 180 degrees","metadata":{}},{"cell_type":"code","source":"X_train_rotated = np.rot90(X_train, k=2, axes=(1,2))\nX_test_rotated = np.rot90(X_test, k=2, axes=(1,2))\n\nX_train_augmented = np.concatenate((X_train, X_train_rotated), axis=0)\ny_train_augmented = np.concatenate((y_train, y_train), axis=0)\n\ntrain_evaluate_model_with_k_fold(\n    X_train=X_train_augmented,\n    y_train=y_train_augmented,\n    lr=0.01,\n    epochs=50,\n    batch_size=16)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T16:55:16.485900Z","iopub.execute_input":"2025-02-08T16:55:16.486293Z","iopub.status.idle":"2025-02-08T17:00:02.077638Z","shell.execute_reply.started":"2025-02-08T16:55:16.486263Z","shell.execute_reply":"2025-02-08T17:00:02.076769Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"\nTraining on Fold 1...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 424ms/step - accuracy: 0.7077 - loss: 0.9023 - val_accuracy: 0.5000 - val_loss: 2942.4922 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.8874 - loss: 0.2147 - val_accuracy: 0.5000 - val_loss: 336.4429 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9270 - loss: 0.1583 - val_accuracy: 0.5667 - val_loss: 15.1709 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9673 - loss: 0.0931 - val_accuracy: 0.5000 - val_loss: 5.9874 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9730 - loss: 0.0930 - val_accuracy: 0.7333 - val_loss: 1.9789 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9505 - loss: 0.1144 - val_accuracy: 0.8333 - val_loss: 1.1617 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9679 - loss: 0.1015 - val_accuracy: 0.8333 - val_loss: 0.5649 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9797 - loss: 0.0554 - val_accuracy: 0.8333 - val_loss: 1.0114 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9851 - loss: 0.0515 - val_accuracy: 0.7333 - val_loss: 1.5465 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9757 - loss: 0.0471\nEpoch 10: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9759 - loss: 0.0482 - val_accuracy: 0.7000 - val_loss: 1.9250 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9962 - loss: 0.0288 - val_accuracy: 0.6667 - val_loss: 1.7169 - learning_rate: 1.0000e-03\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0115 - val_accuracy: 0.7000 - val_loss: 1.5613 - learning_rate: 1.0000e-03\nEpoch 12: early stopping\nRestoring model weights from the end of the best epoch: 7.\nFold 1 - Train Accuracy: 90.60%, Validation Accuracy: 83.33%\n\nTraining on Fold 2...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 423ms/step - accuracy: 0.7148 - loss: 0.8676 - val_accuracy: 0.4667 - val_loss: 1262.3243 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9330 - loss: 0.2146 - val_accuracy: 0.5333 - val_loss: 528.3356 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9175 - loss: 0.1767 - val_accuracy: 0.5333 - val_loss: 81.5286 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9498 - loss: 0.1415 - val_accuracy: 0.5000 - val_loss: 31.1666 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9829 - loss: 0.0761 - val_accuracy: 0.5333 - val_loss: 27.6723 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9549 - loss: 0.1170 - val_accuracy: 0.4667 - val_loss: 7.0473 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9380 - loss: 0.1720 - val_accuracy: 0.4667 - val_loss: 2.7358 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9873 - loss: 0.0481 - val_accuracy: 0.8667 - val_loss: 0.6557 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9762 - loss: 0.0667 - val_accuracy: 0.5333 - val_loss: 3.5792 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9660 - loss: 0.0723 - val_accuracy: 0.7667 - val_loss: 1.1430 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9561 - loss: 0.1707 - val_accuracy: 0.8333 - val_loss: 0.5232 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9775 - loss: 0.0734 - val_accuracy: 0.8667 - val_loss: 0.4751 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9869 - loss: 0.0385 - val_accuracy: 0.9333 - val_loss: 0.3640 - learning_rate: 0.0100\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9996 - loss: 0.0198 - val_accuracy: 0.8333 - val_loss: 1.2820 - learning_rate: 0.0100\nEpoch 15/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9844 - loss: 0.0388 - val_accuracy: 0.8333 - val_loss: 0.7461 - learning_rate: 0.0100\nEpoch 16/50\n\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9618 - loss: 0.1161\nEpoch 16: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9643 - loss: 0.1149 - val_accuracy: 0.9000 - val_loss: 0.5268 - learning_rate: 0.0100\nEpoch 17/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9844 - loss: 0.0419 - val_accuracy: 0.9000 - val_loss: 0.4354 - learning_rate: 1.0000e-03\nEpoch 18/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9896 - loss: 0.0409 - val_accuracy: 0.9333 - val_loss: 0.3226 - learning_rate: 1.0000e-03\nEpoch 19/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9964 - loss: 0.0332 - val_accuracy: 0.9333 - val_loss: 0.2212 - learning_rate: 1.0000e-03\nEpoch 20/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9791 - loss: 0.0413 - val_accuracy: 0.9333 - val_loss: 0.1610 - learning_rate: 1.0000e-03\nEpoch 21/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9925 - loss: 0.0261 - val_accuracy: 0.9333 - val_loss: 0.1018 - learning_rate: 1.0000e-03\nEpoch 22/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9702 - loss: 0.0569 - val_accuracy: 0.9333 - val_loss: 0.0892 - learning_rate: 1.0000e-03\nEpoch 23/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9956 - loss: 0.0205 - val_accuracy: 0.9333 - val_loss: 0.0892 - learning_rate: 1.0000e-03\nEpoch 24/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9852 - loss: 0.0300 - val_accuracy: 0.9667 - val_loss: 0.0612 - learning_rate: 1.0000e-03\nEpoch 25/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9857 - loss: 0.0528 - val_accuracy: 0.9667 - val_loss: 0.0438 - learning_rate: 1.0000e-03\nEpoch 26/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9873 - loss: 0.0376 - val_accuracy: 0.9667 - val_loss: 0.0424 - learning_rate: 1.0000e-03\nEpoch 27/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9888 - loss: 0.0362 - val_accuracy: 0.9667 - val_loss: 0.0482 - learning_rate: 1.0000e-03\nEpoch 28/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9819 - loss: 0.0476 - val_accuracy: 1.0000 - val_loss: 0.0279 - learning_rate: 1.0000e-03\nEpoch 29/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0072 - val_accuracy: 0.9667 - val_loss: 0.0319 - learning_rate: 1.0000e-03\nEpoch 30/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9878 - loss: 0.0319 - val_accuracy: 0.9667 - val_loss: 0.0319 - learning_rate: 1.0000e-03\nEpoch 31/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9942 - loss: 0.0142 - val_accuracy: 1.0000 - val_loss: 0.0205 - learning_rate: 1.0000e-03\nEpoch 32/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9985 - loss: 0.0072 - val_accuracy: 1.0000 - val_loss: 0.0179 - learning_rate: 1.0000e-03\nEpoch 33/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9862 - loss: 0.0246 - val_accuracy: 1.0000 - val_loss: 0.0126 - learning_rate: 1.0000e-03\nEpoch 34/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9890 - loss: 0.0230 - val_accuracy: 1.0000 - val_loss: 0.0105 - learning_rate: 1.0000e-03\nEpoch 35/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9861 - loss: 0.0342 - val_accuracy: 1.0000 - val_loss: 0.0074 - learning_rate: 1.0000e-03\nEpoch 36/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9940 - loss: 0.0172 - val_accuracy: 1.0000 - val_loss: 0.0170 - learning_rate: 1.0000e-03\nEpoch 37/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9867 - loss: 0.0437 - val_accuracy: 1.0000 - val_loss: 0.0193 - learning_rate: 1.0000e-03\nEpoch 38/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9955 - loss: 0.0227\nEpoch 38: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9954 - loss: 0.0230 - val_accuracy: 1.0000 - val_loss: 0.0104 - learning_rate: 1.0000e-03\nEpoch 39/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0070 - val_accuracy: 1.0000 - val_loss: 0.0104 - learning_rate: 1.0000e-04\nEpoch 40/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9931 - loss: 0.0340 - val_accuracy: 1.0000 - val_loss: 0.0103 - learning_rate: 1.0000e-04\nEpoch 40: early stopping\nRestoring model weights from the end of the best epoch: 35.\nFold 2 - Train Accuracy: 100.00%, Validation Accuracy: 100.00%\n\nTraining on Fold 3...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 431ms/step - accuracy: 0.7341 - loss: 0.8034 - val_accuracy: 0.4667 - val_loss: 2269.4688 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9138 - loss: 0.2568 - val_accuracy: 0.2333 - val_loss: 96.9846 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9565 - loss: 0.1256 - val_accuracy: 0.4667 - val_loss: 211.4268 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9470 - loss: 0.1207 - val_accuracy: 0.4667 - val_loss: 65.5776 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9631 - loss: 0.1077 - val_accuracy: 0.4667 - val_loss: 29.8394 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9540 - loss: 0.1181 - val_accuracy: 0.6333 - val_loss: 3.4882 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9697 - loss: 0.1069 - val_accuracy: 0.4667 - val_loss: 6.3713 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9645 - loss: 0.1086 - val_accuracy: 0.5333 - val_loss: 2.9491 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9758 - loss: 0.1155 - val_accuracy: 0.9000 - val_loss: 0.1838 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9897 - loss: 0.0562 - val_accuracy: 0.9000 - val_loss: 0.6342 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9726 - loss: 0.0782 - val_accuracy: 1.0000 - val_loss: 0.0156 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9964 - loss: 0.0236 - val_accuracy: 0.9667 - val_loss: 0.0940 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9886 - loss: 0.0197 - val_accuracy: 1.0000 - val_loss: 0.0359 - learning_rate: 0.0100\nEpoch 14/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9941 - loss: 0.0353\nEpoch 14: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9935 - loss: 0.0391 - val_accuracy: 0.8333 - val_loss: 0.8060 - learning_rate: 0.0100\nEpoch 15/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9773 - loss: 0.0452 - val_accuracy: 0.9333 - val_loss: 0.3713 - learning_rate: 1.0000e-03\nEpoch 16/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9839 - loss: 0.0610 - val_accuracy: 0.9333 - val_loss: 0.1243 - learning_rate: 1.0000e-03\nEpoch 16: early stopping\nRestoring model weights from the end of the best epoch: 11.\nFold 3 - Train Accuracy: 97.37%, Validation Accuracy: 100.00%\n\nTraining on Fold 4...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 427ms/step - accuracy: 0.7399 - loss: 0.9152 - val_accuracy: 0.4333 - val_loss: 15858.2842 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8742 - loss: 0.2452 - val_accuracy: 0.4333 - val_loss: 349.6428 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9265 - loss: 0.1858 - val_accuracy: 0.4333 - val_loss: 255.3466 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9549 - loss: 0.1227 - val_accuracy: 0.4333 - val_loss: 95.2928 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9798 - loss: 0.0608 - val_accuracy: 0.4333 - val_loss: 24.4088 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9609 - loss: 0.0867 - val_accuracy: 0.5000 - val_loss: 10.2235 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9661 - loss: 0.1091 - val_accuracy: 0.7000 - val_loss: 1.6607 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9757 - loss: 0.0647 - val_accuracy: 0.7000 - val_loss: 2.9415 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9248 - loss: 0.2698 - val_accuracy: 0.7667 - val_loss: 0.8660 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9610 - loss: 0.1112 - val_accuracy: 0.8333 - val_loss: 0.4492 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9817 - loss: 0.0492 - val_accuracy: 0.7333 - val_loss: 1.1500 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9824 - loss: 0.0650 - val_accuracy: 0.9000 - val_loss: 0.2885 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9858 - loss: 0.0628 - val_accuracy: 0.7667 - val_loss: 0.8329 - learning_rate: 0.0100\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9951 - loss: 0.0270 - val_accuracy: 0.7333 - val_loss: 0.6980 - learning_rate: 0.0100\nEpoch 15/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9831 - loss: 0.0476 - val_accuracy: 0.8667 - val_loss: 0.2695 - learning_rate: 0.0100\nEpoch 16/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9799 - loss: 0.0542 - val_accuracy: 0.6333 - val_loss: 1.9726 - learning_rate: 0.0100\nEpoch 17/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9777 - loss: 0.0694 - val_accuracy: 0.6000 - val_loss: 1.9030 - learning_rate: 0.0100\nEpoch 18/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9836 - loss: 0.0410 - val_accuracy: 0.9000 - val_loss: 0.1296 - learning_rate: 0.0100\nEpoch 19/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9910 - loss: 0.0312 - val_accuracy: 0.8333 - val_loss: 0.4885 - learning_rate: 0.0100\nEpoch 20/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9777 - loss: 0.0539 - val_accuracy: 0.9667 - val_loss: 0.0809 - learning_rate: 0.0100\nEpoch 21/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9465 - loss: 0.1487 - val_accuracy: 1.0000 - val_loss: 0.0016 - learning_rate: 0.0100\nEpoch 22/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9531 - loss: 0.0856 - val_accuracy: 1.0000 - val_loss: 0.0280 - learning_rate: 0.0100\nEpoch 23/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9775 - loss: 0.0518 - val_accuracy: 0.9667 - val_loss: 0.1589 - learning_rate: 0.0100\nEpoch 24/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9702 - loss: 0.0768\nEpoch 24: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9693 - loss: 0.0810 - val_accuracy: 0.9333 - val_loss: 0.1161 - learning_rate: 0.0100\nEpoch 25/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9942 - loss: 0.0205 - val_accuracy: 1.0000 - val_loss: 0.0363 - learning_rate: 1.0000e-03\nEpoch 26/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9946 - loss: 0.0244 - val_accuracy: 0.9667 - val_loss: 0.0316 - learning_rate: 1.0000e-03\nEpoch 26: early stopping\nRestoring model weights from the end of the best epoch: 21.\nFold 4 - Train Accuracy: 98.87%, Validation Accuracy: 100.00%\n\nTraining on Fold 5...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 426ms/step - accuracy: 0.7153 - loss: 1.1808 - val_accuracy: 0.4000 - val_loss: 998.3141 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9070 - loss: 0.2478 - val_accuracy: 0.4667 - val_loss: 402.6511 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9254 - loss: 0.2320 - val_accuracy: 0.5333 - val_loss: 64.0143 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9738 - loss: 0.0816 - val_accuracy: 0.4333 - val_loss: 12.2592 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9547 - loss: 0.0985 - val_accuracy: 0.5000 - val_loss: 3.2309 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9758 - loss: 0.0987 - val_accuracy: 0.5000 - val_loss: 8.2701 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9651 - loss: 0.0956 - val_accuracy: 0.7667 - val_loss: 1.0327 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9814 - loss: 0.0523 - val_accuracy: 0.9000 - val_loss: 0.3741 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9798 - loss: 0.0650 - val_accuracy: 0.8000 - val_loss: 1.0995 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9744 - loss: 0.0661 - val_accuracy: 0.6667 - val_loss: 1.2015 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9780 - loss: 0.0513 - val_accuracy: 0.9333 - val_loss: 0.3243 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9850 - loss: 0.0502 - val_accuracy: 0.9333 - val_loss: 0.3368 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9490 - loss: 0.0990 - val_accuracy: 0.9667 - val_loss: 0.0411 - learning_rate: 0.0100\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9847 - loss: 0.0613 - val_accuracy: 0.9667 - val_loss: 0.0939 - learning_rate: 0.0100\nEpoch 15/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9826 - loss: 0.0502 - val_accuracy: 0.9667 - val_loss: 0.0798 - learning_rate: 0.0100\nEpoch 16/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9500 - loss: 0.1428\nEpoch 16: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9505 - loss: 0.1416 - val_accuracy: 0.9667 - val_loss: 0.1735 - learning_rate: 0.0100\nEpoch 17/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9766 - loss: 0.0797 - val_accuracy: 0.9667 - val_loss: 0.1319 - learning_rate: 1.0000e-03\nEpoch 18/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9939 - loss: 0.0351 - val_accuracy: 0.9667 - val_loss: 0.0936 - learning_rate: 1.0000e-03\nEpoch 18: early stopping\nRestoring model weights from the end of the best epoch: 13.\nFold 5 - Train Accuracy: 94.36%, Validation Accuracy: 96.67%\n\nTraining on Fold 6...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 425ms/step - accuracy: 0.7955 - loss: 0.7475 - val_accuracy: 0.3667 - val_loss: 423.0002 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9380 - loss: 0.1989 - val_accuracy: 0.5333 - val_loss: 383.7958 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9153 - loss: 0.2139 - val_accuracy: 0.5333 - val_loss: 70.9142 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9662 - loss: 0.0897 - val_accuracy: 0.5333 - val_loss: 18.3732 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9521 - loss: 0.0882 - val_accuracy: 0.5667 - val_loss: 8.2593 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9505 - loss: 0.1428 - val_accuracy: 0.7000 - val_loss: 1.7499 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9203 - loss: 0.2980 - val_accuracy: 0.5667 - val_loss: 1.7688 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9525 - loss: 0.1229 - val_accuracy: 0.5333 - val_loss: 10.9409 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9670 - loss: 0.0975\nEpoch 9: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9668 - loss: 0.0982 - val_accuracy: 0.5333 - val_loss: 9.6849 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9893 - loss: 0.0532 - val_accuracy: 0.5333 - val_loss: 8.4786 - learning_rate: 1.0000e-03\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9807 - loss: 0.0640 - val_accuracy: 0.5333 - val_loss: 7.1865 - learning_rate: 1.0000e-03\nEpoch 11: early stopping\nRestoring model weights from the end of the best epoch: 6.\nFold 6 - Train Accuracy: 60.53%, Validation Accuracy: 70.00%\n\nTraining on Fold 7...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 423ms/step - accuracy: 0.6727 - loss: 1.0066 - val_accuracy: 0.5517 - val_loss: 3636.0256 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9172 - loss: 0.1684 - val_accuracy: 0.2759 - val_loss: 152.3537 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9549 - loss: 0.1319 - val_accuracy: 0.4483 - val_loss: 277.5447 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9772 - loss: 0.0747 - val_accuracy: 0.3448 - val_loss: 18.0424 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9583 - loss: 0.1267 - val_accuracy: 0.4483 - val_loss: 17.7296 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9323 - loss: 0.1356 - val_accuracy: 0.4138 - val_loss: 8.1391 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9691 - loss: 0.0950 - val_accuracy: 0.5172 - val_loss: 4.3228 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9816 - loss: 0.0698 - val_accuracy: 0.6552 - val_loss: 3.2616 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9585 - loss: 0.0943 - val_accuracy: 0.7241 - val_loss: 1.7020 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9528 - loss: 0.1161 - val_accuracy: 0.9310 - val_loss: 0.4000 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9561 - loss: 0.1080 - val_accuracy: 0.9310 - val_loss: 0.6003 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9879 - loss: 0.0646 - val_accuracy: 0.8966 - val_loss: 0.9402 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9785 - loss: 0.0775 - val_accuracy: 0.9655 - val_loss: 0.0280 - learning_rate: 0.0100\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9465 - loss: 0.0907 - val_accuracy: 0.9310 - val_loss: 0.6926 - learning_rate: 0.0100\nEpoch 15/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9846 - loss: 0.0574 - val_accuracy: 0.8966 - val_loss: 0.7291 - learning_rate: 0.0100\nEpoch 16/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9777 - loss: 0.0671\nEpoch 16: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9772 - loss: 0.0683 - val_accuracy: 0.9310 - val_loss: 0.3607 - learning_rate: 0.0100\nEpoch 17/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9444 - loss: 0.1326 - val_accuracy: 0.9310 - val_loss: 0.3486 - learning_rate: 1.0000e-03\nEpoch 18/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9942 - loss: 0.0342 - val_accuracy: 0.9310 - val_loss: 0.3397 - learning_rate: 1.0000e-03\nEpoch 18: early stopping\nRestoring model weights from the end of the best epoch: 13.\nFold 7 - Train Accuracy: 98.13%, Validation Accuracy: 96.55%\n\nTraining on Fold 8...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 436ms/step - accuracy: 0.7590 - loss: 0.7623 - val_accuracy: 0.3103 - val_loss: 392.2799 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9452 - loss: 0.1578 - val_accuracy: 0.5517 - val_loss: 241.8168 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9855 - loss: 0.0801 - val_accuracy: 0.5517 - val_loss: 48.8813 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9934 - loss: 0.0218 - val_accuracy: 0.5517 - val_loss: 56.0605 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9486 - loss: 0.1691 - val_accuracy: 0.5517 - val_loss: 4.9129 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9430 - loss: 0.1634 - val_accuracy: 0.5172 - val_loss: 3.9126 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9585 - loss: 0.1410 - val_accuracy: 0.4138 - val_loss: 3.1512 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9789 - loss: 0.0890 - val_accuracy: 0.5862 - val_loss: 2.6725 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9482 - loss: 0.1884 - val_accuracy: 0.5862 - val_loss: 4.7265 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9947 - loss: 0.0225 - val_accuracy: 0.6552 - val_loss: 2.8341 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9879 - loss: 0.0430\nEpoch 11: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9869 - loss: 0.0454 - val_accuracy: 0.6207 - val_loss: 2.9982 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9609 - loss: 0.0773 - val_accuracy: 0.7241 - val_loss: 1.9811 - learning_rate: 1.0000e-03\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9785 - loss: 0.0699 - val_accuracy: 0.7586 - val_loss: 1.2025 - learning_rate: 1.0000e-03\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9692 - loss: 0.0961 - val_accuracy: 0.8276 - val_loss: 0.8172 - learning_rate: 1.0000e-03\nEpoch 15/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9894 - loss: 0.0539 - val_accuracy: 0.8276 - val_loss: 0.7750 - learning_rate: 1.0000e-03\nEpoch 16/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9958 - loss: 0.0135 - val_accuracy: 0.8276 - val_loss: 0.8509 - learning_rate: 1.0000e-03\nEpoch 17/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9938 - loss: 0.0149 - val_accuracy: 0.8276 - val_loss: 0.9109 - learning_rate: 1.0000e-03\nEpoch 18/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9959 - loss: 0.0165\nEpoch 18: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9947 - loss: 0.0180 - val_accuracy: 0.8276 - val_loss: 0.9563 - learning_rate: 1.0000e-03\nEpoch 19/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9991 - loss: 0.0147 - val_accuracy: 0.8276 - val_loss: 0.9237 - learning_rate: 1.0000e-04\nEpoch 20/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0084 - val_accuracy: 0.8276 - val_loss: 0.8779 - learning_rate: 1.0000e-04\nEpoch 20: early stopping\nRestoring model weights from the end of the best epoch: 15.\nFold 8 - Train Accuracy: 96.25%, Validation Accuracy: 82.76%\n\nTraining on Fold 9...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 421ms/step - accuracy: 0.7739 - loss: 0.8447 - val_accuracy: 0.5517 - val_loss: 3878.8726 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9125 - loss: 0.2360 - val_accuracy: 0.5517 - val_loss: 280.9954 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9180 - loss: 0.1903 - val_accuracy: 0.5517 - val_loss: 67.9099 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9231 - loss: 0.1887 - val_accuracy: 0.5517 - val_loss: 63.7142 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9799 - loss: 0.0566 - val_accuracy: 0.5172 - val_loss: 16.9661 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9167 - loss: 0.2953 - val_accuracy: 0.5172 - val_loss: 6.4911 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9775 - loss: 0.0662 - val_accuracy: 0.5172 - val_loss: 9.5364 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9597 - loss: 0.1130 - val_accuracy: 0.8621 - val_loss: 0.6477 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9775 - loss: 0.0889 - val_accuracy: 0.7241 - val_loss: 0.8571 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9853 - loss: 0.0650 - val_accuracy: 0.7931 - val_loss: 0.5431 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9539 - loss: 0.0958 - val_accuracy: 0.7586 - val_loss: 0.7678 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9708 - loss: 0.0693 - val_accuracy: 0.6552 - val_loss: 1.6401 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9727 - loss: 0.0693 - val_accuracy: 0.9310 - val_loss: 0.0966 - learning_rate: 0.0100\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9800 - loss: 0.0533 - val_accuracy: 0.9655 - val_loss: 0.1679 - learning_rate: 0.0100\nEpoch 15/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9818 - loss: 0.0488 - val_accuracy: 0.9655 - val_loss: 0.0832 - learning_rate: 0.0100\nEpoch 16/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9864 - loss: 0.0471 - val_accuracy: 0.9310 - val_loss: 0.5403 - learning_rate: 0.0100\nEpoch 17/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9873 - loss: 0.0267 - val_accuracy: 0.9310 - val_loss: 0.1757 - learning_rate: 0.0100\nEpoch 18/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9816 - loss: 0.0490 - val_accuracy: 0.9655 - val_loss: 0.0466 - learning_rate: 0.0100\nEpoch 19/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9744 - loss: 0.0799 - val_accuracy: 0.8966 - val_loss: 0.1208 - learning_rate: 0.0100\nEpoch 20/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9872 - loss: 0.0349 - val_accuracy: 0.9310 - val_loss: 0.0691 - learning_rate: 0.0100\nEpoch 21/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9915 - loss: 0.0369 - val_accuracy: 1.0000 - val_loss: 0.0192 - learning_rate: 0.0100\nEpoch 22/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9861 - loss: 0.0620 - val_accuracy: 1.0000 - val_loss: 0.0334 - learning_rate: 0.0100\nEpoch 23/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9903 - loss: 0.0394 - val_accuracy: 0.9655 - val_loss: 0.1487 - learning_rate: 0.0100\nEpoch 24/50\n\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9950 - loss: 0.0185\nEpoch 24: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9946 - loss: 0.0189 - val_accuracy: 0.9655 - val_loss: 0.0510 - learning_rate: 0.0100\nEpoch 25/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9853 - loss: 0.0515 - val_accuracy: 0.9655 - val_loss: 0.0550 - learning_rate: 1.0000e-03\nEpoch 26/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9986 - loss: 0.0038 - val_accuracy: 0.9655 - val_loss: 0.0264 - learning_rate: 1.0000e-03\nEpoch 26: early stopping\nRestoring model weights from the end of the best epoch: 21.\nFold 9 - Train Accuracy: 98.88%, Validation Accuracy: 100.00%\n\nTraining on Fold 10...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 424ms/step - accuracy: 0.7383 - loss: 1.0202 - val_accuracy: 0.5172 - val_loss: 2064.6157 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9356 - loss: 0.1579 - val_accuracy: 0.5172 - val_loss: 759.0772 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9588 - loss: 0.1608 - val_accuracy: 0.5172 - val_loss: 151.6989 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9696 - loss: 0.0929 - val_accuracy: 0.4138 - val_loss: 17.5517 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9528 - loss: 0.1487 - val_accuracy: 0.4828 - val_loss: 20.0528 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9525 - loss: 0.1263 - val_accuracy: 0.5517 - val_loss: 3.2221 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9656 - loss: 0.1249 - val_accuracy: 0.7586 - val_loss: 1.1465 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9873 - loss: 0.0634 - val_accuracy: 0.8276 - val_loss: 0.3849 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9645 - loss: 0.0952 - val_accuracy: 0.6552 - val_loss: 1.9738 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9712 - loss: 0.0826 - val_accuracy: 0.8621 - val_loss: 0.2965 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9567 - loss: 0.0883 - val_accuracy: 0.9655 - val_loss: 0.2020 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9838 - loss: 0.0429 - val_accuracy: 0.8621 - val_loss: 0.2957 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9458 - loss: 0.1954 - val_accuracy: 0.8621 - val_loss: 0.4019 - learning_rate: 0.0100\nEpoch 14/50\n\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9813 - loss: 0.0693\nEpoch 14: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9821 - loss: 0.0653 - val_accuracy: 0.9310 - val_loss: 0.2592 - learning_rate: 0.0100\nEpoch 15/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9771 - loss: 0.0480 - val_accuracy: 0.8966 - val_loss: 0.2780 - learning_rate: 1.0000e-03\nEpoch 16/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9769 - loss: 0.0316 - val_accuracy: 0.9310 - val_loss: 0.1921 - learning_rate: 1.0000e-03\nEpoch 17/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9930 - loss: 0.0389 - val_accuracy: 0.9310 - val_loss: 0.1062 - learning_rate: 1.0000e-03\nEpoch 18/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9914 - loss: 0.0233 - val_accuracy: 0.9310 - val_loss: 0.0795 - learning_rate: 1.0000e-03\nEpoch 19/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9687 - loss: 0.1215 - val_accuracy: 0.9655 - val_loss: 0.0737 - learning_rate: 1.0000e-03\nEpoch 20/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9971 - loss: 0.0174 - val_accuracy: 0.9655 - val_loss: 0.0348 - learning_rate: 1.0000e-03\nEpoch 21/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9861 - loss: 0.0416 - val_accuracy: 1.0000 - val_loss: 0.0097 - learning_rate: 1.0000e-03\nEpoch 22/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9973 - loss: 0.0185 - val_accuracy: 1.0000 - val_loss: 0.0160 - learning_rate: 1.0000e-03\nEpoch 23/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9870 - loss: 0.0305 - val_accuracy: 1.0000 - val_loss: 0.0198 - learning_rate: 1.0000e-03\nEpoch 24/50\n\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9800 - loss: 0.0448\nEpoch 24: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9811 - loss: 0.0436 - val_accuracy: 0.9655 - val_loss: 0.0517 - learning_rate: 1.0000e-03\nEpoch 25/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0069 - val_accuracy: 0.9655 - val_loss: 0.0603 - learning_rate: 1.0000e-04\nEpoch 26/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9986 - loss: 0.0083 - val_accuracy: 0.9655 - val_loss: 0.0657 - learning_rate: 1.0000e-04\nEpoch 26: early stopping\nRestoring model weights from the end of the best epoch: 21.\nFold 10 - Train Accuracy: 99.63%, Validation Accuracy: 100.00%\n\nAverage Training Accuracy: 93.46%\nAverage Validation Accuracy: 92.93%\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"## 2.4 Rotating 270 degrees","metadata":{}},{"cell_type":"code","source":"X_train_rotated = np.rot90(X_train, k=3, axes=(1,2))\nX_test_rotated = np.rot90(X_test, k=3, axes=(1,2))\n\nX_train_augmented = np.concatenate((X_train, X_train_rotated), axis=0)\ny_train_augmented = np.concatenate((y_train, y_train), axis=0)\n\ntrain_evaluate_model_with_k_fold(\n    X_train=X_train_augmented,\n    y_train=y_train_augmented,\n    lr=0.01,\n    epochs=50,\n    batch_size=16)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T17:00:02.078961Z","iopub.execute_input":"2025-02-08T17:00:02.079262Z","iopub.status.idle":"2025-02-08T17:04:57.335843Z","shell.execute_reply.started":"2025-02-08T17:00:02.079239Z","shell.execute_reply":"2025-02-08T17:04:57.335085Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"\nTraining on Fold 1...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 421ms/step - accuracy: 0.7169 - loss: 1.0117 - val_accuracy: 0.5000 - val_loss: 1604.9010 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8863 - loss: 0.3056 - val_accuracy: 0.5000 - val_loss: 178.8962 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9495 - loss: 0.1588 - val_accuracy: 0.5000 - val_loss: 88.6067 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.9278 - loss: 0.2066 - val_accuracy: 0.4333 - val_loss: 8.5048 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9481 - loss: 0.1054 - val_accuracy: 0.5000 - val_loss: 9.6142 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9268 - loss: 0.1600 - val_accuracy: 0.5333 - val_loss: 10.3046 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9128 - loss: 0.2417 - val_accuracy: 0.5667 - val_loss: 2.9091 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9420 - loss: 0.1768 - val_accuracy: 0.6333 - val_loss: 3.5421 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9737 - loss: 0.1393 - val_accuracy: 0.6333 - val_loss: 2.3755 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9836 - loss: 0.0360 - val_accuracy: 0.6000 - val_loss: 2.6917 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9661 - loss: 0.0772 - val_accuracy: 0.7000 - val_loss: 1.7700 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9705 - loss: 0.0826 - val_accuracy: 0.8000 - val_loss: 0.6918 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9874 - loss: 0.0410 - val_accuracy: 0.8667 - val_loss: 0.4145 - learning_rate: 0.0100\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9720 - loss: 0.0760 - val_accuracy: 0.7000 - val_loss: 0.9315 - learning_rate: 0.0100\nEpoch 15/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9851 - loss: 0.0347 - val_accuracy: 0.9000 - val_loss: 0.4041 - learning_rate: 0.0100\nEpoch 16/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9978 - loss: 0.0215 - val_accuracy: 0.8667 - val_loss: 0.5600 - learning_rate: 0.0100\nEpoch 17/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9795 - loss: 0.0777 - val_accuracy: 0.8667 - val_loss: 0.5895 - learning_rate: 0.0100\nEpoch 18/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9673 - loss: 0.0940 - val_accuracy: 0.9333 - val_loss: 0.2451 - learning_rate: 0.0100\nEpoch 19/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9647 - loss: 0.0933 - val_accuracy: 0.8333 - val_loss: 0.6032 - learning_rate: 0.0100\nEpoch 20/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9886 - loss: 0.0502 - val_accuracy: 0.8667 - val_loss: 0.6604 - learning_rate: 0.0100\nEpoch 21/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9764 - loss: 0.0969\nEpoch 21: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9758 - loss: 0.0982 - val_accuracy: 0.8333 - val_loss: 0.4794 - learning_rate: 0.0100\nEpoch 22/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9639 - loss: 0.1073 - val_accuracy: 0.8667 - val_loss: 0.4119 - learning_rate: 1.0000e-03\nEpoch 23/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9862 - loss: 0.0297 - val_accuracy: 0.8667 - val_loss: 0.3993 - learning_rate: 1.0000e-03\nEpoch 23: early stopping\nRestoring model weights from the end of the best epoch: 18.\nFold 1 - Train Accuracy: 96.99%, Validation Accuracy: 93.33%\n\nTraining on Fold 2...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 426ms/step - accuracy: 0.6887 - loss: 1.0682 - val_accuracy: 0.5333 - val_loss: 3883.9109 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8220 - loss: 0.3801 - val_accuracy: 0.7667 - val_loss: 9.5682 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9186 - loss: 0.1845 - val_accuracy: 0.5333 - val_loss: 58.1823 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9433 - loss: 0.1331 - val_accuracy: 0.4667 - val_loss: 33.2598 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9375 - loss: 0.1463\nEpoch 5: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9359 - loss: 0.1537 - val_accuracy: 0.5333 - val_loss: 9.8115 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9392 - loss: 0.1072 - val_accuracy: 0.6333 - val_loss: 3.1043 - learning_rate: 1.0000e-03\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9724 - loss: 0.0830 - val_accuracy: 0.7000 - val_loss: 1.3681 - learning_rate: 1.0000e-03\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.9735 - loss: 0.1065 - val_accuracy: 0.7667 - val_loss: 0.8203 - learning_rate: 1.0000e-03\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9866 - loss: 0.0640 - val_accuracy: 0.8333 - val_loss: 0.3817 - learning_rate: 1.0000e-03\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9913 - loss: 0.0617 - val_accuracy: 0.9000 - val_loss: 0.1427 - learning_rate: 1.0000e-03\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9575 - loss: 0.0912 - val_accuracy: 0.9333 - val_loss: 0.0683 - learning_rate: 1.0000e-03\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9753 - loss: 0.0720 - val_accuracy: 0.9667 - val_loss: 0.0816 - learning_rate: 1.0000e-03\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9761 - loss: 0.0577 - val_accuracy: 0.9667 - val_loss: 0.0635 - learning_rate: 1.0000e-03\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9959 - loss: 0.0254 - val_accuracy: 0.9667 - val_loss: 0.0534 - learning_rate: 1.0000e-03\nEpoch 15/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9734 - loss: 0.0664 - val_accuracy: 0.9667 - val_loss: 0.0333 - learning_rate: 1.0000e-03\nEpoch 16/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9960 - loss: 0.0303 - val_accuracy: 1.0000 - val_loss: 0.0191 - learning_rate: 1.0000e-03\nEpoch 17/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9973 - loss: 0.0149 - val_accuracy: 1.0000 - val_loss: 0.0524 - learning_rate: 1.0000e-03\nEpoch 18/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9709 - loss: 0.0993 - val_accuracy: 0.9667 - val_loss: 0.0774 - learning_rate: 1.0000e-03\nEpoch 19/50\n\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9988 - loss: 0.0093\nEpoch 19: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9979 - loss: 0.0123 - val_accuracy: 0.9667 - val_loss: 0.0760 - learning_rate: 1.0000e-03\nEpoch 20/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9949 - loss: 0.0338 - val_accuracy: 0.9667 - val_loss: 0.0488 - learning_rate: 1.0000e-04\nEpoch 21/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9770 - loss: 0.0489 - val_accuracy: 1.0000 - val_loss: 0.0341 - learning_rate: 1.0000e-04\nEpoch 21: early stopping\nRestoring model weights from the end of the best epoch: 16.\nFold 2 - Train Accuracy: 97.37%, Validation Accuracy: 100.00%\n\nTraining on Fold 3...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 407ms/step - accuracy: 0.7110 - loss: 1.2996 - val_accuracy: 0.5333 - val_loss: 1298.3214 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8296 - loss: 0.4185 - val_accuracy: 0.5333 - val_loss: 459.2036 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8692 - loss: 0.3227 - val_accuracy: 0.4667 - val_loss: 305.7938 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9151 - loss: 0.2293 - val_accuracy: 0.4667 - val_loss: 77.6243 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9259 - loss: 0.2070 - val_accuracy: 0.4667 - val_loss: 28.7192 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9213 - loss: 0.1970 - val_accuracy: 0.9333 - val_loss: 0.1488 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9359 - loss: 0.1653 - val_accuracy: 0.9000 - val_loss: 0.3392 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9604 - loss: 0.0777 - val_accuracy: 0.6000 - val_loss: 2.3113 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9454 - loss: 0.1171\nEpoch 9: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9448 - loss: 0.1210 - val_accuracy: 0.9333 - val_loss: 0.1520 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9671 - loss: 0.1098 - val_accuracy: 0.9000 - val_loss: 0.1732 - learning_rate: 1.0000e-03\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9569 - loss: 0.1078 - val_accuracy: 0.9000 - val_loss: 0.2675 - learning_rate: 1.0000e-03\nEpoch 11: early stopping\nRestoring model weights from the end of the best epoch: 6.\nFold 3 - Train Accuracy: 84.59%, Validation Accuracy: 93.33%\n\nTraining on Fold 4...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 421ms/step - accuracy: 0.6313 - loss: 1.1684 - val_accuracy: 0.4333 - val_loss: 3072.3979 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.8333 - loss: 0.3718 - val_accuracy: 0.5667 - val_loss: 101.3490 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9011 - loss: 0.1711 - val_accuracy: 0.4333 - val_loss: 15.0988 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9653 - loss: 0.1006 - val_accuracy: 0.4333 - val_loss: 14.2853 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9579 - loss: 0.0707 - val_accuracy: 0.4333 - val_loss: 18.0441 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9558 - loss: 0.0887 - val_accuracy: 0.4667 - val_loss: 7.6212 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9710 - loss: 0.0712 - val_accuracy: 0.5000 - val_loss: 6.7526 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9814 - loss: 0.0705 - val_accuracy: 0.5333 - val_loss: 3.9272 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9293 - loss: 0.1938 - val_accuracy: 0.5000 - val_loss: 10.9582 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9395 - loss: 0.1609 - val_accuracy: 0.5667 - val_loss: 5.4642 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9515 - loss: 0.0960 - val_accuracy: 0.5333 - val_loss: 2.5210 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9512 - loss: 0.1304 - val_accuracy: 0.6000 - val_loss: 4.1321 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9618 - loss: 0.0877 - val_accuracy: 0.6000 - val_loss: 6.4279 - learning_rate: 0.0100\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9553 - loss: 0.1118 - val_accuracy: 0.7000 - val_loss: 1.3026 - learning_rate: 0.0100\nEpoch 15/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9708 - loss: 0.1067 - val_accuracy: 0.9333 - val_loss: 0.1494 - learning_rate: 0.0100\nEpoch 16/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9769 - loss: 0.0890 - val_accuracy: 0.7333 - val_loss: 1.3989 - learning_rate: 0.0100\nEpoch 17/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9777 - loss: 0.0526 - val_accuracy: 0.9333 - val_loss: 0.1655 - learning_rate: 0.0100\nEpoch 18/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9853 - loss: 0.0337 - val_accuracy: 0.9667 - val_loss: 0.0664 - learning_rate: 0.0100\nEpoch 19/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9784 - loss: 0.0637 - val_accuracy: 0.9000 - val_loss: 0.3518 - learning_rate: 0.0100\nEpoch 20/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9717 - loss: 0.0915 - val_accuracy: 1.0000 - val_loss: 0.0279 - learning_rate: 0.0100\nEpoch 21/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9823 - loss: 0.0539 - val_accuracy: 0.9000 - val_loss: 0.2558 - learning_rate: 0.0100\nEpoch 22/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9777 - loss: 0.0917 - val_accuracy: 0.9667 - val_loss: 0.0801 - learning_rate: 0.0100\nEpoch 23/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9699 - loss: 0.1305 - val_accuracy: 1.0000 - val_loss: 0.0019 - learning_rate: 0.0100\nEpoch 24/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9933 - loss: 0.0302 - val_accuracy: 1.0000 - val_loss: 0.0035 - learning_rate: 0.0100\nEpoch 25/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9811 - loss: 0.0812 - val_accuracy: 0.9667 - val_loss: 0.1133 - learning_rate: 0.0100\nEpoch 26/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9757 - loss: 0.0786\nEpoch 26: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9760 - loss: 0.0775 - val_accuracy: 0.9667 - val_loss: 0.1124 - learning_rate: 0.0100\nEpoch 27/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9883 - loss: 0.0276 - val_accuracy: 0.9667 - val_loss: 0.0859 - learning_rate: 1.0000e-03\nEpoch 28/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0104 - val_accuracy: 0.9667 - val_loss: 0.0787 - learning_rate: 1.0000e-03\nEpoch 28: early stopping\nRestoring model weights from the end of the best epoch: 23.\nFold 4 - Train Accuracy: 100.00%, Validation Accuracy: 100.00%\n\nTraining on Fold 5...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 421ms/step - accuracy: 0.6307 - loss: 1.4060 - val_accuracy: 0.4667 - val_loss: 12852.6045 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8729 - loss: 0.2989 - val_accuracy: 0.4667 - val_loss: 630.1938 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9219 - loss: 0.2138 - val_accuracy: 0.4667 - val_loss: 110.7399 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9679 - loss: 0.1176 - val_accuracy: 0.4667 - val_loss: 24.0001 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9609 - loss: 0.1293 - val_accuracy: 0.5333 - val_loss: 4.7132 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9175 - loss: 0.2819 - val_accuracy: 0.4667 - val_loss: 6.1651 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9291 - loss: 0.1453 - val_accuracy: 0.7667 - val_loss: 0.7682 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9705 - loss: 0.0726 - val_accuracy: 0.7000 - val_loss: 1.4167 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9603 - loss: 0.0756 - val_accuracy: 0.8000 - val_loss: 0.9330 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9806 - loss: 0.0732 - val_accuracy: 0.8333 - val_loss: 0.5530 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9769 - loss: 0.1037 - val_accuracy: 0.8000 - val_loss: 0.8290 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9716 - loss: 0.0877 - val_accuracy: 0.9000 - val_loss: 0.2411 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9643 - loss: 0.1000 - val_accuracy: 0.9333 - val_loss: 0.1407 - learning_rate: 0.0100\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9579 - loss: 0.1113 - val_accuracy: 0.9000 - val_loss: 0.1634 - learning_rate: 0.0100\nEpoch 15/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9832 - loss: 0.0678 - val_accuracy: 0.8333 - val_loss: 0.5932 - learning_rate: 0.0100\nEpoch 16/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9779 - loss: 0.0420\nEpoch 16: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9770 - loss: 0.0435 - val_accuracy: 0.9333 - val_loss: 0.2173 - learning_rate: 0.0100\nEpoch 17/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9826 - loss: 0.0561 - val_accuracy: 0.9667 - val_loss: 0.0782 - learning_rate: 1.0000e-03\nEpoch 18/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9796 - loss: 0.0697 - val_accuracy: 0.9667 - val_loss: 0.0677 - learning_rate: 1.0000e-03\nEpoch 19/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9796 - loss: 0.0533 - val_accuracy: 0.9667 - val_loss: 0.0514 - learning_rate: 1.0000e-03\nEpoch 20/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9853 - loss: 0.0289 - val_accuracy: 1.0000 - val_loss: 0.0279 - learning_rate: 1.0000e-03\nEpoch 21/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9981 - loss: 0.0152 - val_accuracy: 1.0000 - val_loss: 0.0143 - learning_rate: 1.0000e-03\nEpoch 22/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9835 - loss: 0.0331 - val_accuracy: 1.0000 - val_loss: 0.0168 - learning_rate: 1.0000e-03\nEpoch 23/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9733 - loss: 0.0456 - val_accuracy: 1.0000 - val_loss: 0.0097 - learning_rate: 1.0000e-03\nEpoch 24/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9877 - loss: 0.0174 - val_accuracy: 1.0000 - val_loss: 0.0124 - learning_rate: 1.0000e-03\nEpoch 25/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0126 - val_accuracy: 1.0000 - val_loss: 0.0098 - learning_rate: 1.0000e-03\nEpoch 26/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9902 - loss: 0.0226 - val_accuracy: 1.0000 - val_loss: 0.0089 - learning_rate: 1.0000e-03\nEpoch 27/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9775 - loss: 0.0670 - val_accuracy: 1.0000 - val_loss: 0.0110 - learning_rate: 1.0000e-03\nEpoch 28/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9991 - loss: 0.0060 - val_accuracy: 1.0000 - val_loss: 0.0098 - learning_rate: 1.0000e-03\nEpoch 29/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9788 - loss: 0.0577\nEpoch 29: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9792 - loss: 0.0565 - val_accuracy: 1.0000 - val_loss: 0.0105 - learning_rate: 1.0000e-03\nEpoch 30/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9983 - loss: 0.0087 - val_accuracy: 1.0000 - val_loss: 0.0092 - learning_rate: 1.0000e-04\nEpoch 31/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9920 - loss: 0.0174 - val_accuracy: 1.0000 - val_loss: 0.0090 - learning_rate: 1.0000e-04\nEpoch 31: early stopping\nRestoring model weights from the end of the best epoch: 26.\nFold 5 - Train Accuracy: 99.62%, Validation Accuracy: 100.00%\n\nTraining on Fold 6...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 428ms/step - accuracy: 0.6636 - loss: 1.2271 - val_accuracy: 0.5333 - val_loss: 17456.7422 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9002 - loss: 0.2367 - val_accuracy: 0.5333 - val_loss: 1157.6676 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9518 - loss: 0.1349 - val_accuracy: 0.5333 - val_loss: 111.2523 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9602 - loss: 0.1197 - val_accuracy: 0.5333 - val_loss: 59.4495 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9464 - loss: 0.0973 - val_accuracy: 0.5333 - val_loss: 33.4746 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9596 - loss: 0.1011 - val_accuracy: 0.5333 - val_loss: 17.3106 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9555 - loss: 0.1332 - val_accuracy: 0.5333 - val_loss: 9.4330 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9647 - loss: 0.1236 - val_accuracy: 0.5333 - val_loss: 3.7780 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9754 - loss: 0.0906 - val_accuracy: 0.5333 - val_loss: 8.9516 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9371 - loss: 0.1680 - val_accuracy: 0.7333 - val_loss: 2.1920 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9656 - loss: 0.0752 - val_accuracy: 0.6000 - val_loss: 3.2713 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9941 - loss: 0.0371 - val_accuracy: 0.6667 - val_loss: 2.8159 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9752 - loss: 0.0691\nEpoch 13: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9734 - loss: 0.0755 - val_accuracy: 0.6667 - val_loss: 4.6193 - learning_rate: 0.0100\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9701 - loss: 0.1027 - val_accuracy: 0.6667 - val_loss: 2.8898 - learning_rate: 1.0000e-03\nEpoch 15/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9800 - loss: 0.0926 - val_accuracy: 0.7333 - val_loss: 1.6003 - learning_rate: 1.0000e-03\nEpoch 16/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9902 - loss: 0.0353 - val_accuracy: 0.8000 - val_loss: 0.9536 - learning_rate: 1.0000e-03\nEpoch 17/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9936 - loss: 0.0344 - val_accuracy: 0.8000 - val_loss: 0.5240 - learning_rate: 1.0000e-03\nEpoch 18/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9827 - loss: 0.0226 - val_accuracy: 0.8667 - val_loss: 0.2252 - learning_rate: 1.0000e-03\nEpoch 19/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9994 - loss: 0.0060 - val_accuracy: 0.9333 - val_loss: 0.1084 - learning_rate: 1.0000e-03\nEpoch 20/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9805 - loss: 0.0908 - val_accuracy: 0.9667 - val_loss: 0.0669 - learning_rate: 1.0000e-03\nEpoch 21/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9933 - loss: 0.0220 - val_accuracy: 0.9667 - val_loss: 0.0581 - learning_rate: 1.0000e-03\nEpoch 22/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9962 - loss: 0.0285 - val_accuracy: 0.9667 - val_loss: 0.0459 - learning_rate: 1.0000e-03\nEpoch 23/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9768 - loss: 0.1234 - val_accuracy: 0.9667 - val_loss: 0.0782 - learning_rate: 1.0000e-03\nEpoch 24/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9854 - loss: 0.0316 - val_accuracy: 0.9667 - val_loss: 0.0583 - learning_rate: 1.0000e-03\nEpoch 25/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9894 - loss: 0.0231 - val_accuracy: 0.9667 - val_loss: 0.0438 - learning_rate: 1.0000e-03\nEpoch 26/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9980 - loss: 0.0240 - val_accuracy: 0.9667 - val_loss: 0.0397 - learning_rate: 1.0000e-03\nEpoch 27/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0107 - val_accuracy: 0.9667 - val_loss: 0.0358 - learning_rate: 1.0000e-03\nEpoch 28/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9931 - loss: 0.0359 - val_accuracy: 0.9667 - val_loss: 0.0554 - learning_rate: 1.0000e-03\nEpoch 29/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0110 - val_accuracy: 0.9667 - val_loss: 0.0485 - learning_rate: 1.0000e-03\nEpoch 30/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9715 - loss: 0.1286\nEpoch 30: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9726 - loss: 0.1214 - val_accuracy: 0.9667 - val_loss: 0.0408 - learning_rate: 1.0000e-03\nEpoch 31/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9964 - loss: 0.0170 - val_accuracy: 0.9667 - val_loss: 0.0384 - learning_rate: 1.0000e-04\nEpoch 32/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9913 - loss: 0.0156 - val_accuracy: 0.9667 - val_loss: 0.0426 - learning_rate: 1.0000e-04\nEpoch 32: early stopping\nRestoring model weights from the end of the best epoch: 27.\nFold 6 - Train Accuracy: 99.62%, Validation Accuracy: 96.67%\n\nTraining on Fold 7...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 426ms/step - accuracy: 0.6778 - loss: 1.2493 - val_accuracy: 0.5517 - val_loss: 752.2700 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8774 - loss: 0.2906 - val_accuracy: 0.4483 - val_loss: 38.6736 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9343 - loss: 0.1896 - val_accuracy: 0.4483 - val_loss: 87.2092 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9502 - loss: 0.1491 - val_accuracy: 0.4483 - val_loss: 36.7179 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9573 - loss: 0.1252 - val_accuracy: 0.4483 - val_loss: 16.7736 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9511 - loss: 0.1148 - val_accuracy: 0.5517 - val_loss: 5.7924 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9783 - loss: 0.0567 - val_accuracy: 0.5862 - val_loss: 3.7483 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9771 - loss: 0.0586 - val_accuracy: 0.6552 - val_loss: 2.9543 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9332 - loss: 0.1629 - val_accuracy: 0.7586 - val_loss: 0.8310 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9613 - loss: 0.0844 - val_accuracy: 0.7586 - val_loss: 2.1843 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9573 - loss: 0.1151 - val_accuracy: 0.7586 - val_loss: 1.3481 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9732 - loss: 0.0764\nEpoch 12: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9737 - loss: 0.0768 - val_accuracy: 0.7241 - val_loss: 1.4976 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9846 - loss: 0.0456 - val_accuracy: 0.8966 - val_loss: 0.8025 - learning_rate: 1.0000e-03\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9976 - loss: 0.0193 - val_accuracy: 0.8966 - val_loss: 0.5051 - learning_rate: 1.0000e-03\nEpoch 15/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9857 - loss: 0.0401 - val_accuracy: 0.9310 - val_loss: 0.2937 - learning_rate: 1.0000e-03\nEpoch 16/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9989 - loss: 0.0179 - val_accuracy: 0.9310 - val_loss: 0.2895 - learning_rate: 1.0000e-03\nEpoch 17/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9899 - loss: 0.0201 - val_accuracy: 0.9655 - val_loss: 0.2630 - learning_rate: 1.0000e-03\nEpoch 18/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9991 - loss: 0.0174 - val_accuracy: 0.9655 - val_loss: 0.2515 - learning_rate: 1.0000e-03\nEpoch 19/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9806 - loss: 0.0434 - val_accuracy: 0.9310 - val_loss: 0.2728 - learning_rate: 1.0000e-03\nEpoch 20/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9741 - loss: 0.0531 - val_accuracy: 0.8966 - val_loss: 0.2140 - learning_rate: 1.0000e-03\nEpoch 21/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9991 - loss: 0.0138 - val_accuracy: 0.9310 - val_loss: 0.2209 - learning_rate: 1.0000e-03\nEpoch 22/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9996 - loss: 0.0131 - val_accuracy: 0.9310 - val_loss: 0.2530 - learning_rate: 1.0000e-03\nEpoch 23/50\n\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0133\nEpoch 23: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0128 - val_accuracy: 0.8966 - val_loss: 0.2711 - learning_rate: 1.0000e-03\nEpoch 24/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9902 - loss: 0.0221 - val_accuracy: 0.8621 - val_loss: 0.2797 - learning_rate: 1.0000e-04\nEpoch 25/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9942 - loss: 0.0284 - val_accuracy: 0.8621 - val_loss: 0.2891 - learning_rate: 1.0000e-04\nEpoch 25: early stopping\nRestoring model weights from the end of the best epoch: 20.\nFold 7 - Train Accuracy: 99.63%, Validation Accuracy: 89.66%\n\nTraining on Fold 8...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 421ms/step - accuracy: 0.5984 - loss: 1.1537 - val_accuracy: 0.4483 - val_loss: 1816.4895 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.8788 - loss: 0.3347 - val_accuracy: 0.5517 - val_loss: 185.3175 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9265 - loss: 0.2026 - val_accuracy: 0.5517 - val_loss: 93.0481 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9687 - loss: 0.1022 - val_accuracy: 0.5517 - val_loss: 58.1232 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9394 - loss: 0.1866 - val_accuracy: 0.5172 - val_loss: 4.1313 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9118 - loss: 0.2373 - val_accuracy: 0.5517 - val_loss: 14.2497 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9394 - loss: 0.1397 - val_accuracy: 0.5517 - val_loss: 13.1647 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9540 - loss: 0.1511 - val_accuracy: 0.5517 - val_loss: 2.9692 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9380 - loss: 0.1441 - val_accuracy: 0.5517 - val_loss: 5.7730 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9719 - loss: 0.0628 - val_accuracy: 0.7586 - val_loss: 1.8817 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9676 - loss: 0.1080 - val_accuracy: 0.7241 - val_loss: 2.3023 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9836 - loss: 0.0352 - val_accuracy: 0.8621 - val_loss: 1.0374 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9816 - loss: 0.0397 - val_accuracy: 0.7586 - val_loss: 1.6259 - learning_rate: 0.0100\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9855 - loss: 0.0424 - val_accuracy: 0.8276 - val_loss: 0.7443 - learning_rate: 0.0100\nEpoch 15/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9714 - loss: 0.0424 - val_accuracy: 0.7931 - val_loss: 1.4304 - learning_rate: 0.0100\nEpoch 16/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9702 - loss: 0.1050 - val_accuracy: 0.9310 - val_loss: 0.3610 - learning_rate: 0.0100\nEpoch 17/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9747 - loss: 0.0751 - val_accuracy: 0.7931 - val_loss: 0.5002 - learning_rate: 0.0100\nEpoch 18/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9743 - loss: 0.0551 - val_accuracy: 0.7931 - val_loss: 0.6137 - learning_rate: 0.0100\nEpoch 19/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9744 - loss: 0.0741\nEpoch 19: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9743 - loss: 0.0745 - val_accuracy: 0.8276 - val_loss: 0.7562 - learning_rate: 0.0100\nEpoch 20/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9525 - loss: 0.1356 - val_accuracy: 0.8276 - val_loss: 0.6035 - learning_rate: 1.0000e-03\nEpoch 21/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9911 - loss: 0.0239 - val_accuracy: 0.8621 - val_loss: 0.5149 - learning_rate: 1.0000e-03\nEpoch 21: early stopping\nRestoring model weights from the end of the best epoch: 16.\nFold 8 - Train Accuracy: 97.38%, Validation Accuracy: 93.10%\n\nTraining on Fold 9...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 420ms/step - accuracy: 0.6888 - loss: 1.3548 - val_accuracy: 0.5517 - val_loss: 6545.2246 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.8474 - loss: 0.4233 - val_accuracy: 0.5517 - val_loss: 376.7035 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9182 - loss: 0.2235 - val_accuracy: 0.5517 - val_loss: 78.1082 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9150 - loss: 0.1928 - val_accuracy: 0.5517 - val_loss: 28.0995 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9340 - loss: 0.1345 - val_accuracy: 0.5862 - val_loss: 2.6421 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9450 - loss: 0.1706 - val_accuracy: 0.7586 - val_loss: 0.5979 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9587 - loss: 0.1462 - val_accuracy: 0.5517 - val_loss: 7.9373 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9598 - loss: 0.1058 - val_accuracy: 0.5862 - val_loss: 2.7969 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9535 - loss: 0.0979\nEpoch 9: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9537 - loss: 0.0985 - val_accuracy: 0.6897 - val_loss: 1.1110 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9527 - loss: 0.1214 - val_accuracy: 0.7586 - val_loss: 0.6429 - learning_rate: 1.0000e-03\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9718 - loss: 0.0505 - val_accuracy: 0.8276 - val_loss: 0.4603 - learning_rate: 1.0000e-03\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9734 - loss: 0.0839 - val_accuracy: 0.8966 - val_loss: 0.2997 - learning_rate: 1.0000e-03\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9944 - loss: 0.0352 - val_accuracy: 0.8621 - val_loss: 0.2340 - learning_rate: 1.0000e-03\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9900 - loss: 0.0572 - val_accuracy: 0.8621 - val_loss: 0.1643 - learning_rate: 1.0000e-03\nEpoch 15/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9793 - loss: 0.0452 - val_accuracy: 0.9655 - val_loss: 0.1018 - learning_rate: 1.0000e-03\nEpoch 16/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9705 - loss: 0.0927 - val_accuracy: 0.9655 - val_loss: 0.0727 - learning_rate: 1.0000e-03\nEpoch 17/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9958 - loss: 0.0270 - val_accuracy: 1.0000 - val_loss: 0.0423 - learning_rate: 1.0000e-03\nEpoch 18/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9770 - loss: 0.0505 - val_accuracy: 1.0000 - val_loss: 0.0249 - learning_rate: 1.0000e-03\nEpoch 19/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9844 - loss: 0.0396 - val_accuracy: 1.0000 - val_loss: 0.0289 - learning_rate: 1.0000e-03\nEpoch 20/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9973 - loss: 0.0212 - val_accuracy: 1.0000 - val_loss: 0.0339 - learning_rate: 1.0000e-03\nEpoch 21/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0162\nEpoch 21: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9996 - loss: 0.0196 - val_accuracy: 1.0000 - val_loss: 0.0335 - learning_rate: 1.0000e-03\nEpoch 22/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9909 - loss: 0.0202 - val_accuracy: 1.0000 - val_loss: 0.0312 - learning_rate: 1.0000e-04\nEpoch 23/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9852 - loss: 0.0305 - val_accuracy: 1.0000 - val_loss: 0.0303 - learning_rate: 1.0000e-04\nEpoch 23: early stopping\nRestoring model weights from the end of the best epoch: 18.\nFold 9 - Train Accuracy: 98.50%, Validation Accuracy: 100.00%\n\nTraining on Fold 10...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 434ms/step - accuracy: 0.7591 - loss: 1.0440 - val_accuracy: 0.5172 - val_loss: 13950.8896 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.8873 - loss: 0.2634 - val_accuracy: 0.5172 - val_loss: 1253.1417 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9404 - loss: 0.1755 - val_accuracy: 0.5172 - val_loss: 284.4818 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9628 - loss: 0.1245 - val_accuracy: 0.6207 - val_loss: 11.1005 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9500 - loss: 0.1330 - val_accuracy: 0.5517 - val_loss: 16.7686 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9721 - loss: 0.0989 - val_accuracy: 0.5517 - val_loss: 6.0621 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9641 - loss: 0.0876 - val_accuracy: 0.5172 - val_loss: 4.9505 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9710 - loss: 0.0654 - val_accuracy: 0.7241 - val_loss: 1.4154 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9647 - loss: 0.0871 - val_accuracy: 0.5517 - val_loss: 2.1763 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9747 - loss: 0.0818 - val_accuracy: 0.6897 - val_loss: 0.9333 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9402 - loss: 0.1149 - val_accuracy: 0.8966 - val_loss: 0.1452 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9923 - loss: 0.0507 - val_accuracy: 0.8276 - val_loss: 0.4870 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9739 - loss: 0.0746 - val_accuracy: 0.6897 - val_loss: 0.8850 - learning_rate: 0.0100\nEpoch 14/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9878 - loss: 0.0507\nEpoch 14: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9871 - loss: 0.0523 - val_accuracy: 0.6897 - val_loss: 1.0137 - learning_rate: 0.0100\nEpoch 15/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9823 - loss: 0.0696 - val_accuracy: 0.6897 - val_loss: 1.0810 - learning_rate: 1.0000e-03\nEpoch 16/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9878 - loss: 0.0301 - val_accuracy: 0.7241 - val_loss: 0.7037 - learning_rate: 1.0000e-03\nEpoch 16: early stopping\nRestoring model weights from the end of the best epoch: 11.\nFold 10 - Train Accuracy: 88.76%, Validation Accuracy: 89.66%\n\nAverage Training Accuracy: 96.25%\nAverage Validation Accuracy: 95.57%\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"# 3 Network Training","metadata":{}},{"cell_type":"markdown","source":"## 3.1 Data Preparation","metadata":{}},{"cell_type":"code","source":"X_train_flipped = np.flip(X_train, axis=2)\nX_train_rotated_90 = np.rot90(X_train, k=1, axes=(1,2))\nX_train_rotated_180 = np.rot90(X_train, k=2, axes=(1,2))\nX_train_rotated_270 = np.rot90(X_train, k=3, axes=(1,2))\n\nX_train_augmented = np.concatenate((X_train, X_train_flipped, X_train_rotated_90, X_train_rotated_180, X_train_rotated_270), axis=0)\ny_train_augmented = np.concatenate((y_train, y_train, y_train, y_train, y_train), axis=0)\n\nindices = np.arange(X_train_augmented.shape[0])\nnp.random.shuffle(indices)\nX_train_augmented = X_train_augmented[indices]\ny_train_augmented = y_train_augmented[indices]\n\n# Split the data into training and validation sets\nX_train_final, X_val_final, y_train_final, y_val_final = train_test_split(X_train_augmented, y_train_augmented, test_size=0.5, random_state=33)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T18:27:14.418006Z","iopub.execute_input":"2025-02-08T18:27:14.418333Z","iopub.status.idle":"2025-02-08T18:27:15.069087Z","shell.execute_reply.started":"2025-02-08T18:27:14.418306Z","shell.execute_reply":"2025-02-08T18:27:15.068114Z"}},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":"## 3.2 Training","metadata":{}},{"cell_type":"code","source":"model = define_model(\n    input_shape=(150,150,3),\n    lr=0.020\n)\n\nhistory = model.fit(\n    X_train_final, y_train_final,\n    validation_data=(X_val_final, y_val_final),\n    epochs=50,\n    batch_size=32,\n    callbacks=[\n        EarlyStopping(monitor=\"val_loss\", patience=15, restore_best_weights=True, verbose=1),\n        ReduceLROnPlateau(monitor='val_loss', factor=0.05, patience=3, verbose=1)\n    ],\n    verbose=1,\n    shuffle=True\n)\n\n# Extract loss & accuracy\nloss = history.history['loss']\nloss = np.log(loss)\nval_loss = history.history['val_loss']\nval_loss = np.log(val_loss)\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\n# Plot Loss\nplt.figure(figsize=(12, 5))\nplt.subplot(1, 2, 1)\nplt.plot(loss, label=\"Train Loss\")\nplt.plot(val_loss, label=\"Validation Loss\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Logarithmic loss\")\nplt.legend()\nplt.title(\"Logarithmic loss over epochs\")\n\n# Plot Accuracy\nplt.subplot(1, 2, 2)\nplt.plot(acc, label=\"Train Accuracy\")\nplt.plot(val_acc, label=\"Validation Accuracy\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Accuracy\")\nplt.legend()\nplt.title(\"Accuracy over epochs\")\n\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T17:11:19.170526Z","iopub.execute_input":"2025-02-08T17:11:19.170816Z","iopub.status.idle":"2025-02-08T17:12:08.229093Z","shell.execute_reply.started":"2025-02-08T17:11:19.170793Z","shell.execute_reply":"2025-02-08T17:12:08.228115Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Epoch 1/50\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 675ms/step - accuracy: 0.5873 - loss: 1.6219 - val_accuracy: 0.4892 - val_loss: 75999.9844 - learning_rate: 0.0200\nEpoch 2/50\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.8278 - loss: 0.4233 - val_accuracy: 0.4892 - val_loss: 6698.3379 - learning_rate: 0.0200\nEpoch 3/50\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.8945 - loss: 0.2619 - val_accuracy: 0.4892 - val_loss: 650.1356 - learning_rate: 0.0200\nEpoch 4/50\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9443 - loss: 0.1342 - val_accuracy: 0.4757 - val_loss: 101.4697 - learning_rate: 0.0200\nEpoch 5/50\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9543 - loss: 0.1021 - val_accuracy: 0.4892 - val_loss: 85.7497 - learning_rate: 0.0200\nEpoch 6/50\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9736 - loss: 0.0906 - val_accuracy: 0.4865 - val_loss: 26.4476 - learning_rate: 0.0200\nEpoch 7/50\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9834 - loss: 0.0535 - val_accuracy: 0.4838 - val_loss: 19.8426 - learning_rate: 0.0200\nEpoch 8/50\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9630 - loss: 0.0692 - val_accuracy: 0.5514 - val_loss: 4.5438 - learning_rate: 0.0200\nEpoch 9/50\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9833 - loss: 0.0500 - val_accuracy: 0.5541 - val_loss: 4.0840 - learning_rate: 0.0200\nEpoch 10/50\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9875 - loss: 0.0296 - val_accuracy: 0.5243 - val_loss: 5.1270 - learning_rate: 0.0200\nEpoch 11/50\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9839 - loss: 0.0474 - val_accuracy: 0.6568 - val_loss: 2.8608 - learning_rate: 0.0200\nEpoch 12/50\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9778 - loss: 0.0805 - val_accuracy: 0.4919 - val_loss: 23.0871 - learning_rate: 0.0200\nEpoch 13/50\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9947 - loss: 0.0244 - val_accuracy: 0.4919 - val_loss: 10.9827 - learning_rate: 0.0200\nEpoch 14/50\n\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9947 - loss: 0.0177\nEpoch 14: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9938 - loss: 0.0182 - val_accuracy: 0.5297 - val_loss: 7.0073 - learning_rate: 0.0200\nEpoch 15/50\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9637 - loss: 0.0696 - val_accuracy: 0.5730 - val_loss: 3.7155 - learning_rate: 1.0000e-03\nEpoch 16/50\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9927 - loss: 0.0158 - val_accuracy: 0.6892 - val_loss: 1.8547 - learning_rate: 1.0000e-03\nEpoch 17/50\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9888 - loss: 0.0345 - val_accuracy: 0.7838 - val_loss: 0.9281 - learning_rate: 1.0000e-03\nEpoch 18/50\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9976 - loss: 0.0096 - val_accuracy: 0.8730 - val_loss: 0.5735 - learning_rate: 1.0000e-03\nEpoch 19/50\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.0124 - val_accuracy: 0.9000 - val_loss: 0.4109 - learning_rate: 1.0000e-03\nEpoch 20/50\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9923 - loss: 0.0168 - val_accuracy: 0.9108 - val_loss: 0.3224 - learning_rate: 1.0000e-03\nEpoch 21/50\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9991 - loss: 0.0088 - val_accuracy: 0.9297 - val_loss: 0.2658 - learning_rate: 1.0000e-03\nEpoch 22/50\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9879 - loss: 0.0231 - val_accuracy: 0.9432 - val_loss: 0.2393 - learning_rate: 1.0000e-03\nEpoch 23/50\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.0039 - val_accuracy: 0.9514 - val_loss: 0.2257 - learning_rate: 1.0000e-03\nEpoch 24/50\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.0101 - val_accuracy: 0.9514 - val_loss: 0.2166 - learning_rate: 1.0000e-03\nEpoch 25/50\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.0049 - val_accuracy: 0.9541 - val_loss: 0.2065 - learning_rate: 1.0000e-03\nEpoch 26/50\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9923 - loss: 0.0164 - val_accuracy: 0.9541 - val_loss: 0.1984 - learning_rate: 1.0000e-03\nEpoch 27/50\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.9871 - loss: 0.0190 - val_accuracy: 0.9568 - val_loss: 0.1917 - learning_rate: 1.0000e-03\nEpoch 28/50\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.9978 - loss: 0.0116 - val_accuracy: 0.9595 - val_loss: 0.1883 - learning_rate: 1.0000e-03\nEpoch 29/50\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9996 - loss: 0.0061 - val_accuracy: 0.9595 - val_loss: 0.1869 - learning_rate: 1.0000e-03\nEpoch 30/50\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9933 - loss: 0.0147 - val_accuracy: 0.9541 - val_loss: 0.1852 - learning_rate: 1.0000e-03\nEpoch 31/50\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.0036 - val_accuracy: 0.9568 - val_loss: 0.1875 - learning_rate: 1.0000e-03\nEpoch 32/50\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9982 - loss: 0.0092 - val_accuracy: 0.9595 - val_loss: 0.1927 - learning_rate: 1.0000e-03\nEpoch 33/50\n\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9988 - loss: 0.0114\nEpoch 33: ReduceLROnPlateau reducing learning rate to 4.9999996554106475e-05.\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9986 - loss: 0.0116 - val_accuracy: 0.9595 - val_loss: 0.1916 - learning_rate: 1.0000e-03\nEpoch 34/50\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9983 - loss: 0.0043 - val_accuracy: 0.9568 - val_loss: 0.1916 - learning_rate: 5.0000e-05\nEpoch 35/50\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9975 - loss: 0.0115 - val_accuracy: 0.9568 - val_loss: 0.1923 - learning_rate: 5.0000e-05\nEpoch 36/50\n\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9979 - loss: 0.0088\nEpoch 36: ReduceLROnPlateau reducing learning rate to 2.499999754945748e-06.\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9978 - loss: 0.0089 - val_accuracy: 0.9568 - val_loss: 0.1926 - learning_rate: 5.0000e-05\nEpoch 37/50\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.9568 - val_loss: 0.1931 - learning_rate: 2.5000e-06\nEpoch 38/50\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.0056 - val_accuracy: 0.9568 - val_loss: 0.1937 - learning_rate: 2.5000e-06\nEpoch 39/50\n\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 0.0016\nEpoch 39: ReduceLROnPlateau reducing learning rate to 1.2499998547355062e-07.\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9996 - loss: 0.0022 - val_accuracy: 0.9568 - val_loss: 0.1944 - learning_rate: 2.5000e-06\nEpoch 40/50\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9967 - loss: 0.0052 - val_accuracy: 0.9568 - val_loss: 0.1946 - learning_rate: 1.2500e-07\nEpoch 41/50\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9978 - loss: 0.0120 - val_accuracy: 0.9568 - val_loss: 0.1952 - learning_rate: 1.2500e-07\nEpoch 42/50\n\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9943 - loss: 0.0081\nEpoch 42: ReduceLROnPlateau reducing learning rate to 6.249999273677532e-09.\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9947 - loss: 0.0080 - val_accuracy: 0.9568 - val_loss: 0.1956 - learning_rate: 1.2500e-07\nEpoch 43/50\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.0033 - val_accuracy: 0.9568 - val_loss: 0.1960 - learning_rate: 6.2500e-09\nEpoch 44/50\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.0047 - val_accuracy: 0.9568 - val_loss: 0.1961 - learning_rate: 6.2500e-09\nEpoch 45/50\n\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 0.0033\nEpoch 45: ReduceLROnPlateau reducing learning rate to 3.124999592429845e-10.\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.0033 - val_accuracy: 0.9568 - val_loss: 0.1963 - learning_rate: 6.2500e-09\nEpoch 45: early stopping\nRestoring model weights from the end of the best epoch: 30.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1200x500 with 2 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":14},{"cell_type":"markdown","source":"# 4 Network Evaluation","metadata":{}},{"cell_type":"markdown","source":"## 4.1 Evaluation Metrics","metadata":{}},{"cell_type":"code","source":"y_pred = model.predict(X_test)\ny_pred_classes = (y_pred.reshape(-1) >= 0.5).astype(int)\n\n# Report the evaluation metrics\naccuracy = accuracy_score(y_test, y_pred_classes)\nprecision = precision_score(y_test, y_pred_classes, average='weighted')\nsensitivity = recall_score(y_test, y_pred_classes, average='weighted') # Sensitivity = Recall\nspecificity = recall_score(y_test, y_pred_classes, average='weighted') # Specificity is (1 - False Positive Rate)\nf1 = f1_score(y_test, y_pred_classes, average='weighted')\n\n# Print the classification report (for precision, recall, F1)\nprint(\"Classification Report:\")\nprint(classification_report(y_test, y_pred_classes))\n\n# Print the evaluation metrics\nprint(f\"Accuracy: {accuracy:.4f}\")\nprint(f\"Precision: {precision:.4f}\")\nprint(f\"Sensitivity: {sensitivity:.4f}\")\nprint(f\"Specificity: {specificity:.4f}\")\nprint(f\"F1 Score: {f1:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T17:57:21.928265Z","iopub.execute_input":"2025-02-08T17:57:21.928574Z","iopub.status.idle":"2025-02-08T17:57:25.755105Z","shell.execute_reply.started":"2025-02-08T17:57:21.928553Z","shell.execute_reply":"2025-02-08T17:57:25.754353Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.95      1.00      0.98        20\n           1       1.00      0.95      0.97        20\n\n    accuracy                           0.97        40\n   macro avg       0.98      0.97      0.97        40\nweighted avg       0.98      0.97      0.97        40\n\nAccuracy: 0.9750\nPrecision: 0.9762\nSensitivity: 0.9750\nSpecificity: 0.9750\nF1 Score: 0.9750\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"## 4.2 Confusion Matrix","metadata":{}},{"cell_type":"code","source":"# Confusion Matrix\ncm = confusion_matrix(y_test, y_pred_classes)\n\n# Plot the confusion matrix\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=np.unique(y_test), yticklabels=np.unique(y_test))\nplt.title(\"Confusion Matrix\")\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T17:58:06.175923Z","iopub.execute_input":"2025-02-08T17:58:06.176283Z","iopub.status.idle":"2025-02-08T17:58:06.441097Z","shell.execute_reply.started":"2025-02-08T17:58:06.176254Z","shell.execute_reply":"2025-02-08T17:58:06.440150Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 800x600 with 2 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":4},{"cell_type":"markdown","source":"## 4.3 10-fold cross-validation","metadata":{}},{"cell_type":"code","source":"train_evaluate_model_with_k_fold(\n    X_train_augmented, y_train_augmented,\n    lr=0.02,\n    epochs=50,\n    batch_size=32,\n    early_stopping_pat=15,\n    red_lr_factor=0.05,\n    red_lr_par=3\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T17:12:10.234790Z","iopub.execute_input":"2025-02-08T17:12:10.235054Z","iopub.status.idle":"2025-02-08T17:21:34.327805Z","shell.execute_reply.started":"2025-02-08T17:12:10.235020Z","shell.execute_reply":"2025-02-08T17:21:34.326897Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"\nTraining on Fold 1...\nEpoch 1/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 553ms/step - accuracy: 0.5922 - loss: 1.2816 - val_accuracy: 0.4730 - val_loss: 26603.7188 - learning_rate: 0.0200\nEpoch 2/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9091 - loss: 0.2303 - val_accuracy: 0.4730 - val_loss: 1148.8433 - learning_rate: 0.0200\nEpoch 3/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9703 - loss: 0.1015 - val_accuracy: 0.5270 - val_loss: 263.7365 - learning_rate: 0.0200\nEpoch 4/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9324 - loss: 0.2071 - val_accuracy: 0.6081 - val_loss: 11.4365 - learning_rate: 0.0200\nEpoch 5/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9533 - loss: 0.0940 - val_accuracy: 0.6757 - val_loss: 2.1804 - learning_rate: 0.0200\nEpoch 6/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9816 - loss: 0.0471 - val_accuracy: 0.7973 - val_loss: 0.9284 - learning_rate: 0.0200\nEpoch 7/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9852 - loss: 0.0358 - val_accuracy: 0.5405 - val_loss: 4.4718 - learning_rate: 0.0200\nEpoch 8/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9781 - loss: 0.0570 - val_accuracy: 0.4865 - val_loss: 15.0847 - learning_rate: 0.0200\nEpoch 9/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9728 - loss: 0.0795\nEpoch 9: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9729 - loss: 0.0794 - val_accuracy: 0.7973 - val_loss: 1.3579 - learning_rate: 0.0200\nEpoch 10/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9873 - loss: 0.0426 - val_accuracy: 0.9054 - val_loss: 0.4249 - learning_rate: 1.0000e-03\nEpoch 11/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9883 - loss: 0.0379 - val_accuracy: 0.9595 - val_loss: 0.1237 - learning_rate: 1.0000e-03\nEpoch 12/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9890 - loss: 0.0307 - val_accuracy: 0.9865 - val_loss: 0.0272 - learning_rate: 1.0000e-03\nEpoch 13/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9874 - loss: 0.0361 - val_accuracy: 1.0000 - val_loss: 0.0054 - learning_rate: 1.0000e-03\nEpoch 14/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9858 - loss: 0.0235 - val_accuracy: 1.0000 - val_loss: 0.0037 - learning_rate: 1.0000e-03\nEpoch 15/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9948 - loss: 0.0153 - val_accuracy: 1.0000 - val_loss: 0.0104 - learning_rate: 1.0000e-03\nEpoch 16/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9836 - loss: 0.0528 - val_accuracy: 0.9865 - val_loss: 0.0169 - learning_rate: 1.0000e-03\nEpoch 17/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9983 - loss: 0.0097\nEpoch 17: ReduceLROnPlateau reducing learning rate to 4.9999996554106475e-05.\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9980 - loss: 0.0105 - val_accuracy: 0.9730 - val_loss: 0.0334 - learning_rate: 1.0000e-03\nEpoch 18/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9963 - loss: 0.0126 - val_accuracy: 0.9730 - val_loss: 0.0487 - learning_rate: 5.0000e-05\nEpoch 19/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9916 - loss: 0.0169 - val_accuracy: 0.9730 - val_loss: 0.0622 - learning_rate: 5.0000e-05\nEpoch 20/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9948 - loss: 0.0147\nEpoch 20: ReduceLROnPlateau reducing learning rate to 2.499999754945748e-06.\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9947 - loss: 0.0148 - val_accuracy: 0.9730 - val_loss: 0.0773 - learning_rate: 5.0000e-05\nEpoch 21/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9869 - loss: 0.0250 - val_accuracy: 0.9459 - val_loss: 0.0908 - learning_rate: 2.5000e-06\nEpoch 22/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9888 - loss: 0.0312 - val_accuracy: 0.9459 - val_loss: 0.1019 - learning_rate: 2.5000e-06\nEpoch 23/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9925 - loss: 0.0228\nEpoch 23: ReduceLROnPlateau reducing learning rate to 1.2499998547355062e-07.\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9925 - loss: 0.0228 - val_accuracy: 0.9459 - val_loss: 0.1130 - learning_rate: 2.5000e-06\nEpoch 24/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9831 - loss: 0.0472 - val_accuracy: 0.9459 - val_loss: 0.1210 - learning_rate: 1.2500e-07\nEpoch 25/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9900 - loss: 0.0265 - val_accuracy: 0.9459 - val_loss: 0.1240 - learning_rate: 1.2500e-07\nEpoch 26/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9894 - loss: 0.0237\nEpoch 26: ReduceLROnPlateau reducing learning rate to 6.249999273677532e-09.\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9895 - loss: 0.0234 - val_accuracy: 0.9459 - val_loss: 0.1274 - learning_rate: 1.2500e-07\nEpoch 27/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9936 - loss: 0.0134 - val_accuracy: 0.9459 - val_loss: 0.1278 - learning_rate: 6.2500e-09\nEpoch 28/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9909 - loss: 0.0254 - val_accuracy: 0.9459 - val_loss: 0.1292 - learning_rate: 6.2500e-09\nEpoch 29/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9941 - loss: 0.0201\nEpoch 29: ReduceLROnPlateau reducing learning rate to 3.124999592429845e-10.\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9941 - loss: 0.0200 - val_accuracy: 0.9459 - val_loss: 0.1308 - learning_rate: 6.2500e-09\nEpoch 29: early stopping\nRestoring model weights from the end of the best epoch: 14.\nFold 1 - Train Accuracy: 99.25%, Validation Accuracy: 100.00%\n\nTraining on Fold 2...\nEpoch 1/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 354ms/step - accuracy: 0.7331 - loss: 1.3322 - val_accuracy: 0.5000 - val_loss: 4014.6787 - learning_rate: 0.0200\nEpoch 2/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9385 - loss: 0.1702 - val_accuracy: 0.3378 - val_loss: 38.4043 - learning_rate: 0.0200\nEpoch 3/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 0.9442 - loss: 0.1737 - val_accuracy: 0.5000 - val_loss: 123.4247 - learning_rate: 0.0200\nEpoch 4/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 0.9697 - loss: 0.0861 - val_accuracy: 0.5000 - val_loss: 53.4590 - learning_rate: 0.0200\nEpoch 5/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9767 - loss: 0.0683 - val_accuracy: 0.5135 - val_loss: 16.9977 - learning_rate: 0.0200\nEpoch 6/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9522 - loss: 0.1072 - val_accuracy: 0.5135 - val_loss: 6.1718 - learning_rate: 0.0200\nEpoch 7/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9803 - loss: 0.0567 - val_accuracy: 0.5000 - val_loss: 8.0791 - learning_rate: 0.0200\nEpoch 8/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9789 - loss: 0.0571 - val_accuracy: 0.8649 - val_loss: 0.5613 - learning_rate: 0.0200\nEpoch 9/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9746 - loss: 0.0583 - val_accuracy: 0.8378 - val_loss: 0.7520 - learning_rate: 0.0200\nEpoch 10/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9856 - loss: 0.0498 - val_accuracy: 0.9730 - val_loss: 0.0788 - learning_rate: 0.0200\nEpoch 11/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9860 - loss: 0.0407 - val_accuracy: 0.9865 - val_loss: 0.0203 - learning_rate: 0.0200\nEpoch 12/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9772 - loss: 0.0518 - val_accuracy: 0.9595 - val_loss: 0.0697 - learning_rate: 0.0200\nEpoch 13/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9899 - loss: 0.0463 - val_accuracy: 0.8919 - val_loss: 0.4537 - learning_rate: 0.0200\nEpoch 14/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9921 - loss: 0.0353\nEpoch 14: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9917 - loss: 0.0360 - val_accuracy: 0.9865 - val_loss: 0.0310 - learning_rate: 0.0200\nEpoch 15/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9780 - loss: 0.0779 - val_accuracy: 1.0000 - val_loss: 0.0124 - learning_rate: 1.0000e-03\nEpoch 16/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9941 - loss: 0.0196 - val_accuracy: 1.0000 - val_loss: 0.0084 - learning_rate: 1.0000e-03\nEpoch 17/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9958 - loss: 0.0218 - val_accuracy: 1.0000 - val_loss: 0.0057 - learning_rate: 1.0000e-03\nEpoch 18/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9899 - loss: 0.0209 - val_accuracy: 1.0000 - val_loss: 0.0044 - learning_rate: 1.0000e-03\nEpoch 19/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 0.0057 - val_accuracy: 1.0000 - val_loss: 0.0036 - learning_rate: 1.0000e-03\nEpoch 20/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9882 - loss: 0.0348 - val_accuracy: 1.0000 - val_loss: 0.0022 - learning_rate: 1.0000e-03\nEpoch 21/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9969 - loss: 0.0175 - val_accuracy: 1.0000 - val_loss: 0.0017 - learning_rate: 1.0000e-03\nEpoch 22/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9961 - loss: 0.0128 - val_accuracy: 1.0000 - val_loss: 0.0017 - learning_rate: 1.0000e-03\nEpoch 23/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9900 - loss: 0.0234 - val_accuracy: 1.0000 - val_loss: 0.0013 - learning_rate: 1.0000e-03\nEpoch 24/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9996 - loss: 0.0050 - val_accuracy: 1.0000 - val_loss: 0.0011 - learning_rate: 1.0000e-03\nEpoch 25/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9911 - loss: 0.0175 - val_accuracy: 1.0000 - val_loss: 0.0014 - learning_rate: 1.0000e-03\nEpoch 26/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9921 - loss: 0.0136 - val_accuracy: 1.0000 - val_loss: 0.0015 - learning_rate: 1.0000e-03\nEpoch 27/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9946 - loss: 0.0121\nEpoch 27: ReduceLROnPlateau reducing learning rate to 4.9999996554106475e-05.\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9948 - loss: 0.0119 - val_accuracy: 1.0000 - val_loss: 0.0013 - learning_rate: 1.0000e-03\nEpoch 28/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 0.0046 - val_accuracy: 1.0000 - val_loss: 0.0013 - learning_rate: 5.0000e-05\nEpoch 29/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9986 - loss: 0.0058 - val_accuracy: 1.0000 - val_loss: 0.0013 - learning_rate: 5.0000e-05\nEpoch 30/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9986 - loss: 0.0066\nEpoch 30: ReduceLROnPlateau reducing learning rate to 2.499999754945748e-06.\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9986 - loss: 0.0066 - val_accuracy: 1.0000 - val_loss: 0.0013 - learning_rate: 5.0000e-05\nEpoch 31/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 0.0044 - val_accuracy: 1.0000 - val_loss: 0.0013 - learning_rate: 2.5000e-06\nEpoch 32/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9960 - loss: 0.0085 - val_accuracy: 1.0000 - val_loss: 0.0013 - learning_rate: 2.5000e-06\nEpoch 33/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9991 - loss: 0.0053\nEpoch 33: ReduceLROnPlateau reducing learning rate to 1.2499998547355062e-07.\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9990 - loss: 0.0053 - val_accuracy: 1.0000 - val_loss: 0.0013 - learning_rate: 2.5000e-06\nEpoch 34/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9961 - loss: 0.0116 - val_accuracy: 1.0000 - val_loss: 0.0013 - learning_rate: 1.2500e-07\nEpoch 35/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9993 - loss: 0.0056 - val_accuracy: 1.0000 - val_loss: 0.0014 - learning_rate: 1.2500e-07\nEpoch 36/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9891 - loss: 0.0225\nEpoch 36: ReduceLROnPlateau reducing learning rate to 6.249999273677532e-09.\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9895 - loss: 0.0219 - val_accuracy: 1.0000 - val_loss: 0.0014 - learning_rate: 1.2500e-07\nEpoch 37/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9997 - loss: 0.0054 - val_accuracy: 1.0000 - val_loss: 0.0014 - learning_rate: 6.2500e-09\nEpoch 38/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9985 - loss: 0.0107 - val_accuracy: 1.0000 - val_loss: 0.0014 - learning_rate: 6.2500e-09\nEpoch 39/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 0.0044\nEpoch 39: ReduceLROnPlateau reducing learning rate to 3.124999592429845e-10.\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 0.0043 - val_accuracy: 1.0000 - val_loss: 0.0014 - learning_rate: 6.2500e-09\nEpoch 39: early stopping\nRestoring model weights from the end of the best epoch: 24.\nFold 2 - Train Accuracy: 100.00%, Validation Accuracy: 100.00%\n\nTraining on Fold 3...\nEpoch 1/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 371ms/step - accuracy: 0.6630 - loss: 1.4463 - val_accuracy: 0.4324 - val_loss: 6080.1328 - learning_rate: 0.0200\nEpoch 2/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9250 - loss: 0.2201 - val_accuracy: 0.4324 - val_loss: 1080.5813 - learning_rate: 0.0200\nEpoch 3/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9383 - loss: 0.1476 - val_accuracy: 0.4324 - val_loss: 242.4764 - learning_rate: 0.0200\nEpoch 4/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9652 - loss: 0.0826 - val_accuracy: 0.4324 - val_loss: 149.1497 - learning_rate: 0.0200\nEpoch 5/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9659 - loss: 0.0932 - val_accuracy: 0.4324 - val_loss: 51.1551 - learning_rate: 0.0200\nEpoch 6/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9866 - loss: 0.0706 - val_accuracy: 0.4865 - val_loss: 13.8223 - learning_rate: 0.0200\nEpoch 7/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9806 - loss: 0.0579 - val_accuracy: 0.5135 - val_loss: 7.8410 - learning_rate: 0.0200\nEpoch 8/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9471 - loss: 0.1280 - val_accuracy: 0.7973 - val_loss: 1.2078 - learning_rate: 0.0200\nEpoch 9/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9568 - loss: 0.1097 - val_accuracy: 0.4865 - val_loss: 3.1703 - learning_rate: 0.0200\nEpoch 10/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9629 - loss: 0.0981 - val_accuracy: 0.5811 - val_loss: 2.5089 - learning_rate: 0.0200\nEpoch 11/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9878 - loss: 0.0427 - val_accuracy: 0.7973 - val_loss: 0.9403 - learning_rate: 0.0200\nEpoch 12/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9462 - loss: 0.1741 - val_accuracy: 0.6081 - val_loss: 2.1341 - learning_rate: 0.0200\nEpoch 13/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9905 - loss: 0.0408 - val_accuracy: 0.4459 - val_loss: 5.5448 - learning_rate: 0.0200\nEpoch 14/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9848 - loss: 0.0351\nEpoch 14: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9847 - loss: 0.0352 - val_accuracy: 0.6892 - val_loss: 2.1410 - learning_rate: 0.0200\nEpoch 15/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9797 - loss: 0.0381 - val_accuracy: 0.7973 - val_loss: 1.2169 - learning_rate: 1.0000e-03\nEpoch 16/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9929 - loss: 0.0284 - val_accuracy: 0.8784 - val_loss: 0.7202 - learning_rate: 1.0000e-03\nEpoch 17/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9875 - loss: 0.0291 - val_accuracy: 0.9189 - val_loss: 0.5024 - learning_rate: 1.0000e-03\nEpoch 18/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9992 - loss: 0.0068 - val_accuracy: 0.9189 - val_loss: 0.3955 - learning_rate: 1.0000e-03\nEpoch 19/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 0.0096 - val_accuracy: 0.9189 - val_loss: 0.2984 - learning_rate: 1.0000e-03\nEpoch 20/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9986 - loss: 0.0079 - val_accuracy: 0.9324 - val_loss: 0.2125 - learning_rate: 1.0000e-03\nEpoch 21/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9954 - loss: 0.0094 - val_accuracy: 0.9324 - val_loss: 0.1437 - learning_rate: 1.0000e-03\nEpoch 22/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9904 - loss: 0.0206 - val_accuracy: 0.9459 - val_loss: 0.1384 - learning_rate: 1.0000e-03\nEpoch 23/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9921 - loss: 0.0151 - val_accuracy: 0.9459 - val_loss: 0.1189 - learning_rate: 1.0000e-03\nEpoch 24/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9879 - loss: 0.0283 - val_accuracy: 0.9595 - val_loss: 0.0787 - learning_rate: 1.0000e-03\nEpoch 25/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9899 - loss: 0.0314 - val_accuracy: 0.9595 - val_loss: 0.0905 - learning_rate: 1.0000e-03\nEpoch 26/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9996 - loss: 0.0056 - val_accuracy: 0.9595 - val_loss: 0.0735 - learning_rate: 1.0000e-03\nEpoch 27/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9963 - loss: 0.0062 - val_accuracy: 0.9595 - val_loss: 0.0608 - learning_rate: 1.0000e-03\nEpoch 28/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9969 - loss: 0.0164 - val_accuracy: 0.9730 - val_loss: 0.0567 - learning_rate: 1.0000e-03\nEpoch 29/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9988 - loss: 0.0049 - val_accuracy: 0.9730 - val_loss: 0.0545 - learning_rate: 1.0000e-03\nEpoch 30/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9842 - loss: 0.0222 - val_accuracy: 0.9595 - val_loss: 0.0543 - learning_rate: 1.0000e-03\nEpoch 31/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 0.0049 - val_accuracy: 0.9865 - val_loss: 0.0449 - learning_rate: 1.0000e-03\nEpoch 32/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9993 - loss: 0.0057 - val_accuracy: 0.9865 - val_loss: 0.0369 - learning_rate: 1.0000e-03\nEpoch 33/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9941 - loss: 0.0099 - val_accuracy: 0.9865 - val_loss: 0.0281 - learning_rate: 1.0000e-03\nEpoch 34/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9969 - loss: 0.0091 - val_accuracy: 0.9865 - val_loss: 0.0323 - learning_rate: 1.0000e-03\nEpoch 35/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9993 - loss: 0.0060 - val_accuracy: 0.9730 - val_loss: 0.0322 - learning_rate: 1.0000e-03\nEpoch 36/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 0.0050\nEpoch 36: ReduceLROnPlateau reducing learning rate to 4.9999996554106475e-05.\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 0.0051 - val_accuracy: 0.9865 - val_loss: 0.0317 - learning_rate: 1.0000e-03\nEpoch 37/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9969 - loss: 0.0069 - val_accuracy: 0.9865 - val_loss: 0.0300 - learning_rate: 5.0000e-05\nEpoch 38/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9990 - loss: 0.0071 - val_accuracy: 0.9865 - val_loss: 0.0289 - learning_rate: 5.0000e-05\nEpoch 39/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9996 - loss: 0.0041 - val_accuracy: 0.9865 - val_loss: 0.0274 - learning_rate: 5.0000e-05\nEpoch 40/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9972 - loss: 0.0089 - val_accuracy: 0.9865 - val_loss: 0.0265 - learning_rate: 5.0000e-05\nEpoch 41/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9980 - loss: 0.0056 - val_accuracy: 0.9865 - val_loss: 0.0265 - learning_rate: 5.0000e-05\nEpoch 42/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9958 - loss: 0.0094 - val_accuracy: 0.9865 - val_loss: 0.0257 - learning_rate: 5.0000e-05\nEpoch 43/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9989 - loss: 0.0035 - val_accuracy: 0.9865 - val_loss: 0.0247 - learning_rate: 5.0000e-05\nEpoch 44/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9971 - loss: 0.0092 - val_accuracy: 0.9865 - val_loss: 0.0241 - learning_rate: 5.0000e-05\nEpoch 45/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9982 - loss: 0.0035 - val_accuracy: 0.9865 - val_loss: 0.0236 - learning_rate: 5.0000e-05\nEpoch 46/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9962 - loss: 0.0073 - val_accuracy: 0.9865 - val_loss: 0.0232 - learning_rate: 5.0000e-05\nEpoch 47/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9977 - loss: 0.0056 - val_accuracy: 0.9865 - val_loss: 0.0226 - learning_rate: 5.0000e-05\nEpoch 48/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9995 - loss: 0.0027 - val_accuracy: 0.9865 - val_loss: 0.0227 - learning_rate: 5.0000e-05\nEpoch 49/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9976 - loss: 0.0044 - val_accuracy: 0.9865 - val_loss: 0.0234 - learning_rate: 5.0000e-05\nEpoch 50/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9944 - loss: 0.0244\nEpoch 50: ReduceLROnPlateau reducing learning rate to 2.499999754945748e-06.\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9943 - loss: 0.0247 - val_accuracy: 0.9865 - val_loss: 0.0234 - learning_rate: 5.0000e-05\nRestoring model weights from the end of the best epoch: 47.\nFold 3 - Train Accuracy: 100.00%, Validation Accuracy: 98.65%\n\nTraining on Fold 4...\nEpoch 1/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 374ms/step - accuracy: 0.7288 - loss: 0.9574 - val_accuracy: 0.5135 - val_loss: 27334.3359 - learning_rate: 0.0200\nEpoch 2/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9558 - loss: 0.1333 - val_accuracy: 0.5135 - val_loss: 1131.0995 - learning_rate: 0.0200\nEpoch 3/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9677 - loss: 0.0977 - val_accuracy: 0.5135 - val_loss: 153.1699 - learning_rate: 0.0200\nEpoch 4/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9719 - loss: 0.0701 - val_accuracy: 0.5135 - val_loss: 67.5228 - learning_rate: 0.0200\nEpoch 5/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9827 - loss: 0.0515 - val_accuracy: 0.5135 - val_loss: 22.3620 - learning_rate: 0.0200\nEpoch 6/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9829 - loss: 0.0517 - val_accuracy: 0.5270 - val_loss: 11.1746 - learning_rate: 0.0200\nEpoch 7/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9563 - loss: 0.1631 - val_accuracy: 0.5676 - val_loss: 2.4212 - learning_rate: 0.0200\nEpoch 8/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9812 - loss: 0.0587 - val_accuracy: 0.8378 - val_loss: 0.5086 - learning_rate: 0.0200\nEpoch 9/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9924 - loss: 0.0162 - val_accuracy: 0.9189 - val_loss: 0.4202 - learning_rate: 0.0200\nEpoch 10/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9896 - loss: 0.0317 - val_accuracy: 0.9054 - val_loss: 0.4484 - learning_rate: 0.0200\nEpoch 11/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9618 - loss: 0.1385 - val_accuracy: 0.8919 - val_loss: 0.3857 - learning_rate: 0.0200\nEpoch 12/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9718 - loss: 0.0757 - val_accuracy: 0.8378 - val_loss: 0.7167 - learning_rate: 0.0200\nEpoch 13/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9770 - loss: 0.0617 - val_accuracy: 0.9054 - val_loss: 0.4562 - learning_rate: 0.0200\nEpoch 14/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9939 - loss: 0.0147\nEpoch 14: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9939 - loss: 0.0146 - val_accuracy: 0.8108 - val_loss: 1.8565 - learning_rate: 0.0200\nEpoch 15/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9840 - loss: 0.0724 - val_accuracy: 0.8378 - val_loss: 0.9595 - learning_rate: 1.0000e-03\nEpoch 16/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9952 - loss: 0.0107 - val_accuracy: 0.8784 - val_loss: 0.5069 - learning_rate: 1.0000e-03\nEpoch 17/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9946 - loss: 0.0140 - val_accuracy: 0.9324 - val_loss: 0.2678 - learning_rate: 1.0000e-03\nEpoch 18/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9880 - loss: 0.0292 - val_accuracy: 0.9730 - val_loss: 0.1461 - learning_rate: 1.0000e-03\nEpoch 19/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9980 - loss: 0.0126 - val_accuracy: 0.9865 - val_loss: 0.1280 - learning_rate: 1.0000e-03\nEpoch 20/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9975 - loss: 0.0054 - val_accuracy: 0.9865 - val_loss: 0.1220 - learning_rate: 1.0000e-03\nEpoch 21/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9931 - loss: 0.0163 - val_accuracy: 0.9865 - val_loss: 0.1138 - learning_rate: 1.0000e-03\nEpoch 22/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9973 - loss: 0.0097 - val_accuracy: 0.9730 - val_loss: 0.1097 - learning_rate: 1.0000e-03\nEpoch 23/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9895 - loss: 0.0321 - val_accuracy: 0.9865 - val_loss: 0.1068 - learning_rate: 1.0000e-03\nEpoch 24/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9970 - loss: 0.0087 - val_accuracy: 0.9865 - val_loss: 0.1023 - learning_rate: 1.0000e-03\nEpoch 25/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 0.0062 - val_accuracy: 0.9865 - val_loss: 0.1012 - learning_rate: 1.0000e-03\nEpoch 26/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 0.0045 - val_accuracy: 0.9730 - val_loss: 0.1016 - learning_rate: 1.0000e-03\nEpoch 27/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9994 - loss: 0.0022 - val_accuracy: 0.9730 - val_loss: 0.1033 - learning_rate: 1.0000e-03\nEpoch 28/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 0.0039\nEpoch 28: ReduceLROnPlateau reducing learning rate to 4.9999996554106475e-05.\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 0.0038 - val_accuracy: 0.9730 - val_loss: 0.1077 - learning_rate: 1.0000e-03\nEpoch 29/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9991 - loss: 0.0080 - val_accuracy: 0.9730 - val_loss: 0.1071 - learning_rate: 5.0000e-05\nEpoch 30/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9927 - loss: 0.0400 - val_accuracy: 0.9730 - val_loss: 0.1045 - learning_rate: 5.0000e-05\nEpoch 31/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9962 - loss: 0.0125\nEpoch 31: ReduceLROnPlateau reducing learning rate to 2.499999754945748e-06.\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9961 - loss: 0.0126 - val_accuracy: 0.9730 - val_loss: 0.1039 - learning_rate: 5.0000e-05\nEpoch 32/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9996 - loss: 0.0025 - val_accuracy: 0.9730 - val_loss: 0.1034 - learning_rate: 2.5000e-06\nEpoch 33/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 0.9730 - val_loss: 0.1029 - learning_rate: 2.5000e-06\nEpoch 34/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9996 - loss: 0.0025 \nEpoch 34: ReduceLROnPlateau reducing learning rate to 1.2499998547355062e-07.\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9996 - loss: 0.0026 - val_accuracy: 0.9730 - val_loss: 0.1029 - learning_rate: 2.5000e-06\nEpoch 35/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9990 - loss: 0.0033 - val_accuracy: 0.9730 - val_loss: 0.1026 - learning_rate: 1.2500e-07\nEpoch 36/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9990 - loss: 0.0026 - val_accuracy: 0.9730 - val_loss: 0.1023 - learning_rate: 1.2500e-07\nEpoch 37/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 0.0018\nEpoch 37: ReduceLROnPlateau reducing learning rate to 6.249999273677532e-09.\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.9730 - val_loss: 0.1020 - learning_rate: 1.2500e-07\nEpoch 38/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9982 - loss: 0.0064 - val_accuracy: 0.9730 - val_loss: 0.1024 - learning_rate: 6.2500e-09\nEpoch 39/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.9730 - val_loss: 0.1026 - learning_rate: 6.2500e-09\nEpoch 40/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 0.0022\nEpoch 40: ReduceLROnPlateau reducing learning rate to 3.124999592429845e-10.\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.9730 - val_loss: 0.1023 - learning_rate: 6.2500e-09\nEpoch 40: early stopping\nRestoring model weights from the end of the best epoch: 25.\nFold 4 - Train Accuracy: 100.00%, Validation Accuracy: 98.65%\n\nTraining on Fold 5...\nEpoch 1/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 374ms/step - accuracy: 0.6194 - loss: 1.5370 - val_accuracy: 0.5270 - val_loss: 12014.5215 - learning_rate: 0.0200\nEpoch 2/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.8949 - loss: 0.2561 - val_accuracy: 0.5270 - val_loss: 411.7061 - learning_rate: 0.0200\nEpoch 3/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9514 - loss: 0.1172 - val_accuracy: 0.5000 - val_loss: 23.6745 - learning_rate: 0.0200\nEpoch 4/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9607 - loss: 0.1132 - val_accuracy: 0.5270 - val_loss: 46.0922 - learning_rate: 0.0200\nEpoch 5/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9340 - loss: 0.1610 - val_accuracy: 0.5270 - val_loss: 78.5103 - learning_rate: 0.0200\nEpoch 6/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9443 - loss: 0.1098 - val_accuracy: 0.5541 - val_loss: 10.4384 - learning_rate: 0.0200\nEpoch 7/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9780 - loss: 0.0563 - val_accuracy: 0.5541 - val_loss: 11.1288 - learning_rate: 0.0200\nEpoch 8/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9812 - loss: 0.0403 - val_accuracy: 0.7568 - val_loss: 1.1250 - learning_rate: 0.0200\nEpoch 9/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9580 - loss: 0.1492 - val_accuracy: 0.8649 - val_loss: 0.4669 - learning_rate: 0.0200\nEpoch 10/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9682 - loss: 0.0737 - val_accuracy: 0.9054 - val_loss: 0.3487 - learning_rate: 0.0200\nEpoch 11/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9917 - loss: 0.0291 - val_accuracy: 0.8919 - val_loss: 0.3184 - learning_rate: 0.0200\nEpoch 12/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9891 - loss: 0.0302 - val_accuracy: 1.0000 - val_loss: 0.0017 - learning_rate: 0.0200\nEpoch 13/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9963 - loss: 0.0124 - val_accuracy: 0.9730 - val_loss: 0.1245 - learning_rate: 0.0200\nEpoch 14/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9792 - loss: 0.0532 - val_accuracy: 0.9324 - val_loss: 0.1436 - learning_rate: 0.0200\nEpoch 15/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9838 - loss: 0.0459\nEpoch 15: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9838 - loss: 0.0462 - val_accuracy: 1.0000 - val_loss: 0.0040 - learning_rate: 0.0200\nEpoch 16/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 365ms/step - accuracy: 0.6603 - loss: 1.1562 - val_accuracy: 0.4324 - val_loss: 16226.1279 - learning_rate: 0.0200\nEpoch 2/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.9240 - loss: 0.2272 - val_accuracy: 0.5676 - val_loss: 469.9126 - learning_rate: 0.0200\nEpoch 3/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9483 - loss: 0.1166 - val_accuracy: 0.4054 - val_loss: 43.6593 - learning_rate: 0.0200\nEpoch 4/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9515 - loss: 0.1212 - val_accuracy: 0.4324 - val_loss: 22.1790 - learning_rate: 0.0200\nEpoch 5/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9662 - loss: 0.0821 - val_accuracy: 0.6351 - val_loss: 10.0640 - learning_rate: 0.0200\nEpoch 6/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9718 - loss: 0.0581 - val_accuracy: 0.4054 - val_loss: 6.7343 - learning_rate: 0.0200\nEpoch 7/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9820 - loss: 0.0528 - val_accuracy: 0.7027 - val_loss: 1.3077 - learning_rate: 0.0200\nEpoch 8/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9894 - loss: 0.0344 - val_accuracy: 0.8514 - val_loss: 0.7034 - learning_rate: 0.0200\nEpoch 9/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9770 - loss: 0.0773 - val_accuracy: 0.9324 - val_loss: 0.3996 - learning_rate: 0.0200\nEpoch 10/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9899 - loss: 0.0366 - val_accuracy: 0.9865 - val_loss: 0.0936 - learning_rate: 0.0200\nEpoch 11/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9945 - loss: 0.0259 - val_accuracy: 0.9459 - val_loss: 0.1729 - learning_rate: 0.0200\nEpoch 12/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9815 - loss: 0.0595 - val_accuracy: 0.9189 - val_loss: 0.4211 - learning_rate: 0.0200\nEpoch 13/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9738 - loss: 0.0867\nEpoch 13: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9740 - loss: 0.0866 - val_accuracy: 0.8514 - val_loss: 0.7271 - learning_rate: 0.0200\nEpoch 14/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9768 - loss: 0.0582 - val_accuracy: 0.9459 - val_loss: 0.2620 - learning_rate: 1.0000e-03\nEpoch 15/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9762 - loss: 0.0717 - val_accuracy: 0.9730 - val_loss: 0.1450 - learning_rate: 1.0000e-03\nEpoch 16/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9957 - loss: 0.0206\nEpoch 16: ReduceLROnPlateau reducing learning rate to 4.9999996554106475e-05.\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9957 - loss: 0.0205 - val_accuracy: 0.9865 - val_loss: 0.1108 - learning_rate: 1.0000e-03\nEpoch 17/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9969 - loss: 0.0165 - val_accuracy: 0.9865 - val_loss: 0.0981 - learning_rate: 5.0000e-05\nEpoch 18/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9962 - loss: 0.0192 - val_accuracy: 0.9865 - val_loss: 0.0911 - learning_rate: 5.0000e-05\nEpoch 19/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9880 - loss: 0.0315 - val_accuracy: 0.9865 - val_loss: 0.0859 - learning_rate: 5.0000e-05\nEpoch 20/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9890 - loss: 0.0297 - val_accuracy: 0.9730 - val_loss: 0.0822 - learning_rate: 5.0000e-05\nEpoch 21/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9881 - loss: 0.0356 - val_accuracy: 0.9730 - val_loss: 0.0784 - learning_rate: 5.0000e-05\nEpoch 22/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9978 - loss: 0.0215 - val_accuracy: 0.9730 - val_loss: 0.0753 - learning_rate: 5.0000e-05\nEpoch 23/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9830 - loss: 0.0368 - val_accuracy: 0.9730 - val_loss: 0.0713 - learning_rate: 5.0000e-05\nEpoch 24/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9977 - loss: 0.0109 - val_accuracy: 0.9595 - val_loss: 0.0664 - learning_rate: 5.0000e-05\nEpoch 25/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9933 - loss: 0.0199 - val_accuracy: 0.9595 - val_loss: 0.0625 - learning_rate: 5.0000e-05\nEpoch 26/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9912 - loss: 0.0255 - val_accuracy: 0.9595 - val_loss: 0.0593 - learning_rate: 5.0000e-05\nEpoch 27/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9833 - loss: 0.0362 - val_accuracy: 0.9595 - val_loss: 0.0556 - learning_rate: 5.0000e-05\nEpoch 28/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9936 - loss: 0.0254 - val_accuracy: 0.9595 - val_loss: 0.0530 - learning_rate: 5.0000e-05\nEpoch 29/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9900 - loss: 0.0225 - val_accuracy: 0.9595 - val_loss: 0.0509 - learning_rate: 5.0000e-05\nEpoch 30/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9928 - loss: 0.0200 - val_accuracy: 0.9730 - val_loss: 0.0492 - learning_rate: 5.0000e-05\nEpoch 31/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9906 - loss: 0.0281 - val_accuracy: 0.9730 - val_loss: 0.0481 - learning_rate: 5.0000e-05\nEpoch 32/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9912 - loss: 0.0286 - val_accuracy: 0.9730 - val_loss: 0.0473 - learning_rate: 5.0000e-05\nEpoch 33/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9940 - loss: 0.0242 - val_accuracy: 0.9730 - val_loss: 0.0463 - learning_rate: 5.0000e-05\nEpoch 34/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9976 - loss: 0.0119 - val_accuracy: 0.9730 - val_loss: 0.0470 - learning_rate: 5.0000e-05\nEpoch 35/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9930 - loss: 0.0386 - val_accuracy: 0.9730 - val_loss: 0.0481 - learning_rate: 5.0000e-05\nEpoch 36/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9938 - loss: 0.0279\nEpoch 36: ReduceLROnPlateau reducing learning rate to 2.499999754945748e-06.\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9938 - loss: 0.0277 - val_accuracy: 0.9730 - val_loss: 0.0467 - learning_rate: 5.0000e-05\nEpoch 37/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9913 - loss: 0.0180 - val_accuracy: 0.9730 - val_loss: 0.0475 - learning_rate: 2.5000e-06\nEpoch 38/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9964 - loss: 0.0143 - val_accuracy: 0.9730 - val_loss: 0.0481 - learning_rate: 2.5000e-06\nEpoch 39/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9890 - loss: 0.0208\nEpoch 39: ReduceLROnPlateau reducing learning rate to 1.2499998547355062e-07.\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9891 - loss: 0.0209 - val_accuracy: 0.9730 - val_loss: 0.0483 - learning_rate: 2.5000e-06\nEpoch 40/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9703 - loss: 0.0658 - val_accuracy: 0.9730 - val_loss: 0.0487 - learning_rate: 1.2500e-07\nEpoch 41/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9980 - loss: 0.0188 - val_accuracy: 0.9730 - val_loss: 0.0493 - learning_rate: 1.2500e-07\nEpoch 42/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9956 - loss: 0.0177\nEpoch 42: ReduceLROnPlateau reducing learning rate to 6.249999273677532e-09.\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9954 - loss: 0.0181 - val_accuracy: 0.9730 - val_loss: 0.0501 - learning_rate: 1.2500e-07\nEpoch 43/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9965 - loss: 0.0163 - val_accuracy: 0.9730 - val_loss: 0.0504 - learning_rate: 6.2500e-09\nEpoch 44/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9945 - loss: 0.0192 - val_accuracy: 0.9730 - val_loss: 0.0503 - learning_rate: 6.2500e-09\nEpoch 45/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9896 - loss: 0.0250\nEpoch 45: ReduceLROnPlateau reducing learning rate to 3.124999592429845e-10.\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9898 - loss: 0.0246 - val_accuracy: 0.9730 - val_loss: 0.0499 - learning_rate: 6.2500e-09\nEpoch 46/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9883 - loss: 0.0322 - val_accuracy: 0.9730 - val_loss: 0.0499 - learning_rate: 3.1250e-10\nEpoch 47/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9855 - loss: 0.0241 - val_accuracy: 0.9730 - val_loss: 0.0501 - learning_rate: 3.1250e-10\nEpoch 48/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9964 - loss: 0.0131\nEpoch 48: ReduceLROnPlateau reducing learning rate to 1.5624998517260736e-11.\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9964 - loss: 0.0133 - val_accuracy: 0.9730 - val_loss: 0.0509 - learning_rate: 3.1250e-10\nEpoch 48: early stopping\nRestoring model weights from the end of the best epoch: 33.\nFold 9 - Train Accuracy: 99.70%, Validation Accuracy: 97.30%\n\nTraining on Fold 10...\nEpoch 1/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 366ms/step - accuracy: 0.6809 - loss: 1.1304 - val_accuracy: 0.4459 - val_loss: 7318.7451 - learning_rate: 0.0200\nEpoch 2/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.8860 - loss: 0.2643 - val_accuracy: 0.4459 - val_loss: 84.4589 - learning_rate: 0.0200\nEpoch 3/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9559 - loss: 0.1336 - val_accuracy: 0.4459 - val_loss: 134.0148 - learning_rate: 0.0200\nEpoch 4/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9768 - loss: 0.0649 - val_accuracy: 0.4459 - val_loss: 61.7695 - learning_rate: 0.0200\nEpoch 5/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9770 - loss: 0.0476 - val_accuracy: 0.4459 - val_loss: 32.3646 - learning_rate: 0.0200\nEpoch 6/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9603 - loss: 0.0837 - val_accuracy: 0.4459 - val_loss: 6.0865 - learning_rate: 0.0200\nEpoch 7/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9766 - loss: 0.0554 - val_accuracy: 0.5405 - val_loss: 3.1266 - learning_rate: 0.0200\nEpoch 8/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9869 - loss: 0.0371 - val_accuracy: 0.5541 - val_loss: 3.6020 - learning_rate: 0.0200\nEpoch 9/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9768 - loss: 0.0900 - val_accuracy: 0.7568 - val_loss: 1.3029 - learning_rate: 0.0200\nEpoch 10/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9743 - loss: 0.0567 - val_accuracy: 0.8514 - val_loss: 0.5728 - learning_rate: 0.0200\nEpoch 11/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9869 - loss: 0.0319 - val_accuracy: 0.6216 - val_loss: 2.6141 - learning_rate: 0.0200\nEpoch 12/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9710 - loss: 0.0826 - val_accuracy: 0.8108 - val_loss: 1.2001 - learning_rate: 0.0200\nEpoch 13/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9784 - loss: 0.0563 - val_accuracy: 0.9865 - val_loss: 0.0478 - learning_rate: 0.0200\nEpoch 14/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 0.9824 - loss: 0.0366 - val_accuracy: 0.6892 - val_loss: 2.3197 - learning_rate: 0.0200\nEpoch 15/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9737 - loss: 0.0860 - val_accuracy: 0.9865 - val_loss: 0.0171 - learning_rate: 0.0200\nEpoch 16/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9714 - loss: 0.0783 - val_accuracy: 0.8919 - val_loss: 0.7328 - learning_rate: 0.0200\nEpoch 17/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9879 - loss: 0.0482 - val_accuracy: 0.9324 - val_loss: 0.4144 - learning_rate: 0.0200\nEpoch 18/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9899 - loss: 0.0279\nEpoch 18: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9898 - loss: 0.0280 - val_accuracy: 0.9189 - val_loss: 0.4743 - learning_rate: 0.0200\nEpoch 19/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9922 - loss: 0.0228 - val_accuracy: 0.9595 - val_loss: 0.2659 - learning_rate: 1.0000e-03\nEpoch 20/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9874 - loss: 0.0329 - val_accuracy: 0.9595 - val_loss: 0.1677 - learning_rate: 1.0000e-03\nEpoch 21/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9998 - loss: 0.0074\nEpoch 21: ReduceLROnPlateau reducing learning rate to 4.9999996554106475e-05.\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9997 - loss: 0.0076 - val_accuracy: 0.9730 - val_loss: 0.1171 - learning_rate: 1.0000e-03\nEpoch 22/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9860 - loss: 0.0244 - val_accuracy: 0.9865 - val_loss: 0.0984 - learning_rate: 5.0000e-05\nEpoch 23/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9786 - loss: 0.0527 - val_accuracy: 0.9865 - val_loss: 0.0923 - learning_rate: 5.0000e-05\nEpoch 24/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9929 - loss: 0.0227\nEpoch 24: ReduceLROnPlateau reducing learning rate to 2.499999754945748e-06.\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9930 - loss: 0.0224 - val_accuracy: 0.9865 - val_loss: 0.0892 - learning_rate: 5.0000e-05\nEpoch 25/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9954 - loss: 0.0138 - val_accuracy: 0.9865 - val_loss: 0.0876 - learning_rate: 2.5000e-06\nEpoch 26/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9863 - loss: 0.0273 - val_accuracy: 0.9865 - val_loss: 0.0865 - learning_rate: 2.5000e-06\nEpoch 27/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9968 - loss: 0.0059\nEpoch 27: ReduceLROnPlateau reducing learning rate to 1.2499998547355062e-07.\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9967 - loss: 0.0061 - val_accuracy: 0.9865 - val_loss: 0.0855 - learning_rate: 2.5000e-06\nEpoch 28/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9972 - loss: 0.0154 - val_accuracy: 0.9865 - val_loss: 0.0848 - learning_rate: 1.2500e-07\nEpoch 29/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9822 - loss: 0.0230 - val_accuracy: 0.9865 - val_loss: 0.0843 - learning_rate: 1.2500e-07\nEpoch 30/50\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9734 - loss: 0.0477\nEpoch 30: ReduceLROnPlateau reducing learning rate to 6.249999273677532e-09.\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9738 - loss: 0.0470 - val_accuracy: 0.9865 - val_loss: 0.0840 - learning_rate: 1.2500e-07\nEpoch 30: early stopping\nRestoring model weights from the end of the best epoch: 15.\nFold 10 - Train Accuracy: 99.55%, Validation Accuracy: 98.65%\n\nAverage Training Accuracy: 99.41%\nAverage Validation Accuracy: 98.92%\n","output_type":"stream"}],"execution_count":17},{"cell_type":"markdown","source":"# 5 Extra Network Evaluation","metadata":{}},{"cell_type":"code","source":"# Split the data into training and validation sets\nX_train_final, X_val_final, y_train_final, y_val_final = train_test_split(X_train_augmented, y_train_augmented, test_size=0.3, random_state=33)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T18:40:30.794408Z","iopub.execute_input":"2025-02-08T18:40:30.794729Z","iopub.status.idle":"2025-02-08T18:40:30.924802Z","shell.execute_reply.started":"2025-02-08T18:40:30.794702Z","shell.execute_reply":"2025-02-08T18:40:30.923869Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"## 5.1 Using One Conv2D Layer","metadata":{}},{"cell_type":"code","source":"def define_model(input_shape=(150,150,3), lr=0.001):\n    model = Sequential(\n        [\n            # Input\n            Input(shape=input_shape),\n            \n            # Conv1\n            Conv2D(64, kernel_size=(3,3), activation='relu', padding='same'),\n            BatchNormalization(axis=-1),\n            MaxPooling2D(pool_size=(2,2)),\n            Dropout(0.2),\n\n            # Flatten Layer\n            Flatten(),\n\n            # FCL\n            Dense(512, activation='relu'),\n            BatchNormalization(axis=-1),\n            Dense(256, activation='relu'),\n            BatchNormalization(axis=-1),\n\n            # Output\n            Dense(1, activation='sigmoid')\n        ]\n    )\n\n    model.compile(\n        optimizer=Adam(learning_rate=lr),\n        loss='binary_crossentropy',\n        metrics=['accuracy']\n    )\n\n    return model\n\nmodel = define_model(\n    input_shape=(150,150,3),\n    lr=0.020\n)\n\nhistory = model.fit(\n    X_train_final, y_train_final,\n    validation_data=(X_val_final, y_val_final),\n    epochs=50,\n    batch_size=32,\n    callbacks=[\n        EarlyStopping(monitor=\"val_loss\", patience=15, restore_best_weights=True, verbose=1),\n        ReduceLROnPlateau(monitor='val_loss', factor=0.05, patience=3, verbose=1)\n    ],\n    verbose=1,\n    shuffle=True\n)\n\ny_pred = model.predict(X_test)\ny_pred_classes = (y_pred.reshape(-1) >= 0.5).astype(int)\n\n# Report the evaluation metrics\naccuracy = accuracy_score(y_test, y_pred_classes)\n\nprint(f\"Accuracy: {accuracy:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T18:40:32.973840Z","iopub.execute_input":"2025-02-08T18:40:32.974164Z","iopub.status.idle":"2025-02-08T18:41:27.207265Z","shell.execute_reply.started":"2025-02-08T18:40:32.974139Z","shell.execute_reply":"2025-02-08T18:41:27.206523Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 503ms/step - accuracy: 0.8057 - loss: 0.7279 - val_accuracy: 0.5090 - val_loss: 19.6246 - learning_rate: 0.0200\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.9305 - loss: 0.1920 - val_accuracy: 0.5045 - val_loss: 26.6646 - learning_rate: 0.0200\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 121ms/step - accuracy: 0.8953 - loss: 0.2636 - val_accuracy: 0.5901 - val_loss: 5.9210 - learning_rate: 0.0200\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 121ms/step - accuracy: 0.9759 - loss: 0.0927 - val_accuracy: 0.6667 - val_loss: 1.6741 - learning_rate: 0.0200\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 122ms/step - accuracy: 0.9952 - loss: 0.0281 - val_accuracy: 0.7838 - val_loss: 0.9778 - learning_rate: 0.0200\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.9553 - loss: 0.1298 - val_accuracy: 0.7432 - val_loss: 1.5924 - learning_rate: 0.0200\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.9131 - loss: 0.1969 - val_accuracy: 0.7387 - val_loss: 2.0998 - learning_rate: 0.0200\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 122ms/step - accuracy: 0.9375 - loss: 0.2362 - val_accuracy: 0.9144 - val_loss: 0.3988 - learning_rate: 0.0200\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.9766 - loss: 0.0847 - val_accuracy: 0.7477 - val_loss: 1.5185 - learning_rate: 0.0200\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.9746 - loss: 0.0582 - val_accuracy: 0.9324 - val_loss: 0.3997 - learning_rate: 0.0200\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 122ms/step - accuracy: 0.9944 - loss: 0.0184 - val_accuracy: 0.9279 - val_loss: 0.3699 - learning_rate: 0.0200\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 122ms/step - accuracy: 0.9962 - loss: 0.0250 - val_accuracy: 0.9234 - val_loss: 0.3149 - learning_rate: 0.0200\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 122ms/step - accuracy: 0.9984 - loss: 0.0041 - val_accuracy: 0.9414 - val_loss: 0.1977 - learning_rate: 0.0200\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 120ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.9505 - val_loss: 0.1935 - learning_rate: 0.0200\nEpoch 15/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 121ms/step - accuracy: 0.9996 - loss: 0.0053 - val_accuracy: 0.9459 - val_loss: 0.1861 - learning_rate: 0.0200\nEpoch 16/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.9973 - loss: 0.0081 - val_accuracy: 0.9324 - val_loss: 0.2470 - learning_rate: 0.0200\nEpoch 17/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.9970 - loss: 0.0087 - val_accuracy: 0.9459 - val_loss: 0.1916 - learning_rate: 0.0200\nEpoch 18/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9807 - loss: 0.0479\nEpoch 18: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.9798 - loss: 0.0515 - val_accuracy: 0.8108 - val_loss: 1.2755 - learning_rate: 0.0200\nEpoch 19/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.9770 - loss: 0.0828 - val_accuracy: 0.8739 - val_loss: 0.5102 - learning_rate: 1.0000e-03\nEpoch 20/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.9839 - loss: 0.0571 - val_accuracy: 0.9054 - val_loss: 0.3349 - learning_rate: 1.0000e-03\nEpoch 21/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9937 - loss: 0.0184\nEpoch 21: ReduceLROnPlateau reducing learning rate to 4.9999996554106475e-05.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.9934 - loss: 0.0193 - val_accuracy: 0.9234 - val_loss: 0.2866 - learning_rate: 1.0000e-03\nEpoch 22/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.9937 - loss: 0.0218 - val_accuracy: 0.9279 - val_loss: 0.2635 - learning_rate: 5.0000e-05\nEpoch 23/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.9993 - loss: 0.0082 - val_accuracy: 0.9369 - val_loss: 0.2505 - learning_rate: 5.0000e-05\nEpoch 24/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9908 - loss: 0.0131\nEpoch 24: ReduceLROnPlateau reducing learning rate to 2.499999754945748e-06.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.9910 - loss: 0.0131 - val_accuracy: 0.9414 - val_loss: 0.2431 - learning_rate: 5.0000e-05\nEpoch 25/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.9933 - loss: 0.0206 - val_accuracy: 0.9369 - val_loss: 0.2405 - learning_rate: 2.5000e-06\nEpoch 26/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.9958 - loss: 0.0132 - val_accuracy: 0.9369 - val_loss: 0.2369 - learning_rate: 2.5000e-06\nEpoch 27/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 0.0025\nEpoch 27: ReduceLROnPlateau reducing learning rate to 1.2499998547355062e-07.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 0.0029 - val_accuracy: 0.9414 - val_loss: 0.2354 - learning_rate: 2.5000e-06\nEpoch 28/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.9863 - loss: 0.0372 - val_accuracy: 0.9414 - val_loss: 0.2355 - learning_rate: 1.2500e-07\nEpoch 29/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.9971 - loss: 0.0107 - val_accuracy: 0.9414 - val_loss: 0.2355 - learning_rate: 1.2500e-07\nEpoch 30/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9895 - loss: 0.0295\nEpoch 30: ReduceLROnPlateau reducing learning rate to 6.249999273677532e-09.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.9898 - loss: 0.0289 - val_accuracy: 0.9414 - val_loss: 0.2358 - learning_rate: 1.2500e-07\nEpoch 30: early stopping\nRestoring model weights from the end of the best epoch: 15.\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step  \nAccuracy: 0.9750\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"## 5.2 Using Two Conv2D Layer","metadata":{}},{"cell_type":"code","source":"def define_model(input_shape=(150,150,3), lr=0.001):\n    model = Sequential(\n        [\n            # Input\n            Input(shape=input_shape),\n            \n            # Conv1\n            Conv2D(64, kernel_size=(3,3), activation='relu', padding='same'),\n            BatchNormalization(axis=-1),\n            MaxPooling2D(pool_size=(2,2)),\n            Dropout(0.2),\n\n            # Conv2\n            Conv2D(64, kernel_size=(3,3), activation='relu', padding='same'),\n            BatchNormalization(axis=-1),\n            MaxPooling2D(pool_size=(2,2)),\n            Dropout(0.2),\n\n            # Flatten Layer\n            Flatten(),\n\n            # FCL\n            Dense(512, activation='relu'),\n            BatchNormalization(axis=-1),\n            Dense(256, activation='relu'),\n            BatchNormalization(axis=-1),\n\n            # Output\n            Dense(1, activation='sigmoid')\n        ]\n    )\n\n    model.compile(\n        optimizer=Adam(learning_rate=lr),\n        loss='binary_crossentropy',\n        metrics=['accuracy']\n    )\n\n    return model\n\nmodel = define_model(\n    input_shape=(150,150,3),\n    lr=0.020\n)\n\nhistory = model.fit(\n    X_train_final, y_train_final,\n    validation_data=(X_val_final, y_val_final),\n    epochs=50,\n    batch_size=32,\n    callbacks=[\n        EarlyStopping(monitor=\"val_loss\", patience=15, restore_best_weights=True, verbose=1),\n        ReduceLROnPlateau(monitor='val_loss', factor=0.05, patience=3, verbose=1)\n    ],\n    verbose=1,\n    shuffle=True\n)\n\ny_pred = model.predict(X_test)\ny_pred_classes = (y_pred.reshape(-1) >= 0.5).astype(int)\n\n# Report the evaluation metrics\naccuracy = accuracy_score(y_test, y_pred_classes)\n\nprint(f\"Accuracy: {accuracy:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T18:41:54.251141Z","iopub.execute_input":"2025-02-08T18:41:54.251439Z","iopub.status.idle":"2025-02-08T18:42:56.912458Z","shell.execute_reply.started":"2025-02-08T18:41:54.251419Z","shell.execute_reply":"2025-02-08T18:42:56.911731Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 428ms/step - accuracy: 0.7606 - loss: 0.6527 - val_accuracy: 0.5045 - val_loss: 418.7181 - learning_rate: 0.0200\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.9360 - loss: 0.1849 - val_accuracy: 0.5045 - val_loss: 115.3768 - learning_rate: 0.0200\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.9611 - loss: 0.1190 - val_accuracy: 0.5045 - val_loss: 55.0712 - learning_rate: 0.0200\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.9763 - loss: 0.0760 - val_accuracy: 0.5045 - val_loss: 29.0821 - learning_rate: 0.0200\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.9818 - loss: 0.0581 - val_accuracy: 0.5045 - val_loss: 9.0214 - learning_rate: 0.0200\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.9437 - loss: 0.1411 - val_accuracy: 0.5405 - val_loss: 5.5610 - learning_rate: 0.0200\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.9492 - loss: 0.1047 - val_accuracy: 0.6216 - val_loss: 1.6289 - learning_rate: 0.0200\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.9895 - loss: 0.0315 - val_accuracy: 0.8739 - val_loss: 0.6183 - learning_rate: 0.0200\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9634 - loss: 0.1437 - val_accuracy: 0.7658 - val_loss: 1.1975 - learning_rate: 0.0200\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9763 - loss: 0.0836 - val_accuracy: 0.7252 - val_loss: 1.2417 - learning_rate: 0.0200\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9881 - loss: 0.0475\nEpoch 11: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9871 - loss: 0.0500 - val_accuracy: 0.8378 - val_loss: 0.9872 - learning_rate: 0.0200\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.9944 - loss: 0.0183 - val_accuracy: 0.8829 - val_loss: 0.4860 - learning_rate: 1.0000e-03\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.9918 - loss: 0.0304 - val_accuracy: 0.9144 - val_loss: 0.2985 - learning_rate: 1.0000e-03\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.9653 - loss: 0.0772 - val_accuracy: 0.9505 - val_loss: 0.2164 - learning_rate: 1.0000e-03\nEpoch 15/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.9985 - loss: 0.0098 - val_accuracy: 0.9550 - val_loss: 0.1787 - learning_rate: 1.0000e-03\nEpoch 16/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.9889 - loss: 0.0225 - val_accuracy: 0.9685 - val_loss: 0.1598 - learning_rate: 1.0000e-03\nEpoch 17/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 0.0094 - val_accuracy: 0.9730 - val_loss: 0.1499 - learning_rate: 1.0000e-03\nEpoch 18/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 0.0045 - val_accuracy: 0.9730 - val_loss: 0.1444 - learning_rate: 1.0000e-03\nEpoch 19/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 0.0057 - val_accuracy: 0.9730 - val_loss: 0.1405 - learning_rate: 1.0000e-03\nEpoch 20/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.9965 - loss: 0.0147 - val_accuracy: 0.9730 - val_loss: 0.1375 - learning_rate: 1.0000e-03\nEpoch 21/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.9904 - loss: 0.0146 - val_accuracy: 0.9775 - val_loss: 0.1334 - learning_rate: 1.0000e-03\nEpoch 22/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.9965 - loss: 0.0081 - val_accuracy: 0.9775 - val_loss: 0.1274 - learning_rate: 1.0000e-03\nEpoch 23/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.9951 - loss: 0.0153 - val_accuracy: 0.9775 - val_loss: 0.1235 - learning_rate: 1.0000e-03\nEpoch 24/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.9988 - loss: 0.0063 - val_accuracy: 0.9730 - val_loss: 0.1231 - learning_rate: 1.0000e-03\nEpoch 25/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9941 - loss: 0.0173 - val_accuracy: 0.9730 - val_loss: 0.1264 - learning_rate: 1.0000e-03\nEpoch 26/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9963 - loss: 0.0205 - val_accuracy: 0.9730 - val_loss: 0.1233 - learning_rate: 1.0000e-03\nEpoch 27/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.9876 - loss: 0.0327 - val_accuracy: 0.9685 - val_loss: 0.1115 - learning_rate: 1.0000e-03\nEpoch 28/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.9983 - loss: 0.0078 - val_accuracy: 0.9730 - val_loss: 0.1096 - learning_rate: 1.0000e-03\nEpoch 29/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 0.0063 - val_accuracy: 0.9775 - val_loss: 0.1038 - learning_rate: 1.0000e-03\nEpoch 30/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.9982 - loss: 0.0095 - val_accuracy: 0.9775 - val_loss: 0.0944 - learning_rate: 1.0000e-03\nEpoch 31/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.9945 - loss: 0.0143 - val_accuracy: 0.9865 - val_loss: 0.0913 - learning_rate: 1.0000e-03\nEpoch 32/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 0.0041 - val_accuracy: 0.9820 - val_loss: 0.0900 - learning_rate: 1.0000e-03\nEpoch 33/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.9934 - loss: 0.0113 - val_accuracy: 0.9820 - val_loss: 0.0898 - learning_rate: 1.0000e-03\nEpoch 34/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.9998 - loss: 0.0146 - val_accuracy: 0.9820 - val_loss: 0.0887 - learning_rate: 1.0000e-03\nEpoch 35/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.9988 - loss: 0.0125 - val_accuracy: 0.9820 - val_loss: 0.0865 - learning_rate: 1.0000e-03\nEpoch 36/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 0.0136 - val_accuracy: 0.9775 - val_loss: 0.0954 - learning_rate: 1.0000e-03\nEpoch 37/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9994 - loss: 0.0087 - val_accuracy: 0.9730 - val_loss: 0.0959 - learning_rate: 1.0000e-03\nEpoch 38/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9995 - loss: 0.0079\nEpoch 38: ReduceLROnPlateau reducing learning rate to 4.9999996554106475e-05.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9994 - loss: 0.0080 - val_accuracy: 0.9775 - val_loss: 0.1130 - learning_rate: 1.0000e-03\nEpoch 39/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9998 - loss: 0.0163 - val_accuracy: 0.9775 - val_loss: 0.1063 - learning_rate: 5.0000e-05\nEpoch 40/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9977 - loss: 0.0130 - val_accuracy: 0.9775 - val_loss: 0.1014 - learning_rate: 5.0000e-05\nEpoch 41/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9957 - loss: 0.0146\nEpoch 41: ReduceLROnPlateau reducing learning rate to 2.499999754945748e-06.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9957 - loss: 0.0146 - val_accuracy: 0.9775 - val_loss: 0.0980 - learning_rate: 5.0000e-05\nEpoch 42/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9949 - loss: 0.0155 - val_accuracy: 0.9775 - val_loss: 0.0953 - learning_rate: 2.5000e-06\nEpoch 43/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9970 - loss: 0.0109 - val_accuracy: 0.9775 - val_loss: 0.0925 - learning_rate: 2.5000e-06\nEpoch 44/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9998 - loss: 0.0070\nEpoch 44: ReduceLROnPlateau reducing learning rate to 1.2499998547355062e-07.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9997 - loss: 0.0071 - val_accuracy: 0.9775 - val_loss: 0.0899 - learning_rate: 2.5000e-06\nEpoch 45/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9984 - loss: 0.0193 - val_accuracy: 0.9775 - val_loss: 0.0879 - learning_rate: 1.2500e-07\nEpoch 46/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.9996 - loss: 0.0057 - val_accuracy: 0.9775 - val_loss: 0.0862 - learning_rate: 1.2500e-07\nEpoch 47/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.9938 - loss: 0.0152 - val_accuracy: 0.9775 - val_loss: 0.0851 - learning_rate: 1.2500e-07\nEpoch 48/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.9990 - loss: 0.0120 - val_accuracy: 0.9775 - val_loss: 0.0842 - learning_rate: 1.2500e-07\nEpoch 49/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.9996 - loss: 0.0076 - val_accuracy: 0.9775 - val_loss: 0.0837 - learning_rate: 1.2500e-07\nEpoch 50/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 0.0087 - val_accuracy: 0.9820 - val_loss: 0.0829 - learning_rate: 1.2500e-07\nRestoring model weights from the end of the best epoch: 50.\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 670ms/step\nAccuracy: 1.0000\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"## 5.3 Using Three Conv2D Layer","metadata":{}},{"cell_type":"code","source":"def define_model(input_shape=(150,150,3), lr=0.001):\n    model = Sequential(\n        [\n            # Input\n            Input(shape=input_shape),\n            \n            # Conv1\n            Conv2D(64, kernel_size=(3,3), activation='relu', padding='same'),\n            BatchNormalization(axis=-1),\n            MaxPooling2D(pool_size=(2,2)),\n            Dropout(0.2),\n\n            # Conv2\n            Conv2D(64, kernel_size=(3,3), activation='relu', padding='same'),\n            BatchNormalization(axis=-1),\n            MaxPooling2D(pool_size=(2,2)),\n            Dropout(0.2),\n\n            # Conv3\n            Conv2D(128, kernel_size=(3,3), activation='relu', padding='same'),\n            BatchNormalization(axis=-1),\n            MaxPooling2D(pool_size=(2,2)),\n            Dropout(0.2),\n\n            # Flatten Layer\n            Flatten(),\n\n            # FCL\n            Dense(512, activation='relu'),\n            BatchNormalization(axis=-1),\n            Dense(256, activation='relu'),\n            BatchNormalization(axis=-1),\n\n            # Output\n            Dense(1, activation='sigmoid')\n        ]\n    )\n\n    model.compile(\n        optimizer=Adam(learning_rate=lr),\n        loss='binary_crossentropy',\n        metrics=['accuracy']\n    )\n\n    return model\n\nmodel = define_model(\n    input_shape=(150,150,3),\n    lr=0.020\n)\n\nhistory = model.fit(\n    X_train_final, y_train_final,\n    validation_data=(X_val_final, y_val_final),\n    epochs=50,\n    batch_size=32,\n    callbacks=[\n        EarlyStopping(monitor=\"val_loss\", patience=15, restore_best_weights=True, verbose=1),\n        ReduceLROnPlateau(monitor='val_loss', factor=0.05, patience=3, verbose=1)\n    ],\n    verbose=1,\n    shuffle=True\n)\n\ny_pred = model.predict(X_test)\ny_pred_classes = (y_pred.reshape(-1) >= 0.5).astype(int)\n\n# Report the evaluation metrics\naccuracy = accuracy_score(y_test, y_pred_classes)\n\nprint(f\"Accuracy: {accuracy:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T18:42:56.913665Z","iopub.execute_input":"2025-02-08T18:42:56.914057Z","execution_failed":"2025-02-08T18:50:00.076Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 421ms/step - accuracy: 0.6912 - loss: 1.0569 - val_accuracy: 0.5045 - val_loss: 631.0231 - learning_rate: 0.0200\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.9195 - loss: 0.2026 - val_accuracy: 0.4955 - val_loss: 44.1057 - learning_rate: 0.0200\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.9496 - loss: 0.1484 - val_accuracy: 0.5315 - val_loss: 13.7233 - learning_rate: 0.0200\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9602 - loss: 0.0982 - val_accuracy: 0.5045 - val_loss: 38.4522 - learning_rate: 0.0200\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9832 - loss: 0.0556 - val_accuracy: 0.5270 - val_loss: 14.7814 - learning_rate: 0.0200\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9640 - loss: 0.1198\nEpoch 6: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9639 - loss: 0.1205 - val_accuracy: 0.5270 - val_loss: 18.2472 - learning_rate: 0.0200\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.9664 - loss: 0.0778 - val_accuracy: 0.5586 - val_loss: 7.9713 - learning_rate: 1.0000e-03\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.9672 - loss: 0.0795 - val_accuracy: 0.6396 - val_loss: 3.1044 - learning_rate: 1.0000e-03\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.9861 - loss: 0.0406 - val_accuracy: 0.7883 - val_loss: 1.2263 - learning_rate: 1.0000e-03\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.9808 - loss: 0.0601 - val_accuracy: 0.8378 - val_loss: 0.5542 - learning_rate: 1.0000e-03\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.9911 - loss: 0.0329 - val_accuracy: 0.9369 - val_loss: 0.2518 - learning_rate: 1.0000e-03\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.9940 - loss: 0.0280 - val_accuracy: 0.9459 - val_loss: 0.1873 - learning_rate: 1.0000e-03\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.9908 - loss: 0.0279 - val_accuracy: 0.9595 - val_loss: 0.1630 - learning_rate: 1.0000e-03\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.9932 - loss: 0.0291 - val_accuracy: 0.9550 - val_loss: 0.1497 - learning_rate: 1.0000e-03\nEpoch 15/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.9951 - loss: 0.0229 - val_accuracy: 0.9685 - val_loss: 0.1421 - learning_rate: 1.0000e-03\nEpoch 16/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.9988 - loss: 0.0162 - val_accuracy: 0.9685 - val_loss: 0.1342 - learning_rate: 1.0000e-03\nEpoch 17/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.9956 - loss: 0.0235 - val_accuracy: 0.9685 - val_loss: 0.1265 - learning_rate: 1.0000e-03\nEpoch 18/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.9894 - loss: 0.0301 - val_accuracy: 0.9640 - val_loss: 0.1236 - learning_rate: 1.0000e-03\nEpoch 19/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.9984 - loss: 0.0177 - val_accuracy: 0.9640 - val_loss: 0.1216 - learning_rate: 1.0000e-03\nEpoch 20/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.9988 - loss: 0.0144 - val_accuracy: 0.9640 - val_loss: 0.1157 - learning_rate: 1.0000e-03\nEpoch 21/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.9972 - loss: 0.0158 - val_accuracy: 0.9730 - val_loss: 0.1156 - learning_rate: 1.0000e-03\nEpoch 22/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.9927 - loss: 0.0208 - val_accuracy: 0.9730 - val_loss: 0.1127 - learning_rate: 1.0000e-03\nEpoch 23/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.9988 - loss: 0.0130 - val_accuracy: 0.9730 - val_loss: 0.1107 - learning_rate: 1.0000e-03\nEpoch 24/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.9966 - loss: 0.0123 - val_accuracy: 0.9730 - val_loss: 0.1053 - learning_rate: 1.0000e-03\nEpoch 25/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.9945 - loss: 0.0142 - val_accuracy: 0.9730 - val_loss: 0.1036 - learning_rate: 1.0000e-03\nEpoch 26/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 0.0118 - val_accuracy: 0.9730 - val_loss: 0.1018 - learning_rate: 1.0000e-03\nEpoch 27/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.9846 - loss: 0.0391 - val_accuracy: 0.9775 - val_loss: 0.0984 - learning_rate: 1.0000e-03\nEpoch 28/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9949 - loss: 0.0125 - val_accuracy: 0.9775 - val_loss: 0.1098 - learning_rate: 1.0000e-03\nEpoch 29/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9989 - loss: 0.0139 - val_accuracy: 0.9775 - val_loss: 0.1074 - learning_rate: 1.0000e-03\nEpoch 30/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9988 - loss: 0.0097\nEpoch 30: ReduceLROnPlateau reducing learning rate to 4.9999996554106475e-05.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9986 - loss: 0.0100 - val_accuracy: 0.9775 - val_loss: 0.0999 - learning_rate: 1.0000e-03\nEpoch 31/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.9885 - loss: 0.0283 - val_accuracy: 0.9775 - val_loss: 0.0969 - learning_rate: 5.0000e-05\nEpoch 32/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.9943 - loss: 0.0189 - val_accuracy: 0.9775 - val_loss: 0.0953 - learning_rate: 5.0000e-05\nEpoch 33/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.9977 - loss: 0.0173 - val_accuracy: 0.9775 - val_loss: 0.0933 - learning_rate: 5.0000e-05\nEpoch 34/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 0.0174 - val_accuracy: 0.9820 - val_loss: 0.0904 - learning_rate: 5.0000e-05\nEpoch 35/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.9961 - loss: 0.0230 - val_accuracy: 0.9820 - val_loss: 0.0889 - learning_rate: 5.0000e-05\nEpoch 36/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.9917 - loss: 0.0208 - val_accuracy: 0.9820 - val_loss: 0.0875 - learning_rate: 5.0000e-05\nEpoch 37/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.9951 - loss: 0.0105 - val_accuracy: 0.9820 - val_loss: 0.0868 - learning_rate: 5.0000e-05\nEpoch 38/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.9979 - loss: 0.0175 - val_accuracy: 0.9820 - val_loss: 0.0856 - learning_rate: 5.0000e-05\nEpoch 39/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.9878 - loss: 0.0385 - val_accuracy: 0.9820 - val_loss: 0.0847 - learning_rate: 5.0000e-05\nEpoch 40/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.9918 - loss: 0.0218 - val_accuracy: 0.9820 - val_loss: 0.0839 - learning_rate: 5.0000e-05\nEpoch 41/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 0.0069 - val_accuracy: 0.9820 - val_loss: 0.0836 - learning_rate: 5.0000e-05\nEpoch 42/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9954 - loss: 0.0145 - val_accuracy: 0.9820 - val_loss: 0.0838 - learning_rate: 5.0000e-05\nEpoch 43/50\n\u001b[1m 3/17\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9913 - loss: 0.0128","output_type":"stream"}],"execution_count":null},{"cell_type":"markdown","source":"## 5.4 Using Four Conv2D Layer","metadata":{}},{"cell_type":"code","source":"def define_model(input_shape=(150,150,3), lr=0.001):\n    model = Sequential(\n        [\n            # Input\n            Input(shape=input_shape),\n            \n            # Conv1\n            Conv2D(64, kernel_size=(3,3), activation='relu', padding='same'),\n            BatchNormalization(axis=-1),\n            MaxPooling2D(pool_size=(2,2)),\n            Dropout(0.2),\n\n            # Conv2\n            Conv2D(64, kernel_size=(3,3), activation='relu', padding='same'),\n            BatchNormalization(axis=-1),\n            MaxPooling2D(pool_size=(2,2)),\n            Dropout(0.2),\n\n            # Conv3\n            Conv2D(128, kernel_size=(3,3), activation='relu', padding='same'),\n            BatchNormalization(axis=-1),\n            MaxPooling2D(pool_size=(2,2)),\n            Dropout(0.2),\n\n            # Conv4\n            Conv2D(128, kernel_size=(3,3), activation='relu', padding='same'),\n            BatchNormalization(axis=-1),\n            MaxPooling2D(pool_size=(2,2)),\n            Dropout(0.2),\n\n            # Flatten Layer\n            Flatten(),\n\n            # FCL\n            Dense(512, activation='relu'),\n            BatchNormalization(axis=-1),\n            Dense(256, activation='relu'),\n            BatchNormalization(axis=-1),\n\n            # Output\n            Dense(1, activation='sigmoid')\n        ]\n    )\n\n    model.compile(\n        optimizer=Adam(learning_rate=lr),\n        loss='binary_crossentropy',\n        metrics=['accuracy']\n    )\n\n    return model\n\nmodel = define_model(\n    input_shape=(150,150,3),\n    lr=0.020\n)\n\nhistory = model.fit(\n    X_train_final, y_train_final,\n    validation_data=(X_val_final, y_val_final),\n    epochs=50,\n    batch_size=32,\n    callbacks=[\n        EarlyStopping(monitor=\"val_loss\", patience=15, restore_best_weights=True, verbose=1),\n        ReduceLROnPlateau(monitor='val_loss', factor=0.05, patience=3, verbose=1)\n    ],\n    verbose=1,\n    shuffle=True\n)\n\ny_pred = model.predict(X_test)\ny_pred_classes = (y_pred.reshape(-1) >= 0.5).astype(int)\n\n# Report the evaluation metrics\naccuracy = accuracy_score(y_test, y_pred_classes)\n\nprint(f\"Accuracy: {accuracy:.4f}\")","metadata":{"trusted":true,"execution":{"execution_failed":"2025-02-08T18:50:00.076Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 5.5 Using Five Conv2D Layer","metadata":{}},{"cell_type":"code","source":"def define_model(input_shape=(150,150,3), lr=0.001):\n    model = Sequential(\n        [\n            # Input\n            Input(shape=input_shape),\n            \n            # Conv1\n            Conv2D(64, kernel_size=(3,3), activation='relu', padding='same'),\n            BatchNormalization(axis=-1),\n            MaxPooling2D(pool_size=(2,2)),\n            Dropout(0.2),\n\n            # Conv2\n            Conv2D(64, kernel_size=(3,3), activation='relu', padding='same'),\n            BatchNormalization(axis=-1),\n            MaxPooling2D(pool_size=(2,2)),\n            Dropout(0.2),\n\n            # Conv3\n            Conv2D(128, kernel_size=(3,3), activation='relu', padding='same'),\n            BatchNormalization(axis=-1),\n            MaxPooling2D(pool_size=(2,2)),\n            Dropout(0.2),\n\n            # Conv4\n            Conv2D(128, kernel_size=(3,3), activation='relu', padding='same'),\n            BatchNormalization(axis=-1),\n            MaxPooling2D(pool_size=(2,2)),\n            Dropout(0.2),\n\n            # Conv5\n            Conv2D(256, kernel_size=(3,3), activation='relu', padding='same'),\n            BatchNormalization(axis=-1),\n            MaxPooling2D(pool_size=(2,2)),\n            Dropout(0.2),\n\n            # Flatten Layer\n            Flatten(),\n\n            # FCL\n            Dense(512, activation='relu'),\n            BatchNormalization(axis=-1),\n            Dense(256, activation='relu'),\n            BatchNormalization(axis=-1),\n\n            # Output\n            Dense(1, activation='sigmoid')\n        ]\n    )\n\n    model.compile(\n        optimizer=Adam(learning_rate=lr),\n        loss='binary_crossentropy',\n        metrics=['accuracy']\n    )\n\n    return model\n\nmodel = define_model(\n    input_shape=(150,150,3),\n    lr=0.020\n)\n\nhistory = model.fit(\n    X_train_final, y_train_final,\n    validation_data=(X_val_final, y_val_final),\n    epochs=50,\n    batch_size=32,\n    callbacks=[\n        EarlyStopping(monitor=\"val_loss\", patience=15, restore_best_weights=True, verbose=1),\n        ReduceLROnPlateau(monitor='val_loss', factor=0.05, patience=3, verbose=1)\n    ],\n    verbose=1,\n    shuffle=True\n)\n\ny_pred = model.predict(X_test)\ny_pred_classes = (y_pred.reshape(-1) >= 0.5).astype(int)\n\n# Report the evaluation metrics\naccuracy = accuracy_score(y_test, y_pred_classes)\n\nprint(f\"Accuracy: {accuracy:.4f}\")","metadata":{"trusted":true,"execution":{"execution_failed":"2025-02-08T18:50:00.077Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}