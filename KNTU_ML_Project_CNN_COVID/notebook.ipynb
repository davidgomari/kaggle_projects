{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 1 Prerequisites","metadata":{}},{"cell_type":"code","source":"import gdown\nfrom pickle import dump, load\nimport shutil\nimport os\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, Input\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\nimport seaborn as sns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T22:36:04.173924Z","iopub.execute_input":"2025-02-07T22:36:04.174259Z","iopub.status.idle":"2025-02-07T22:36:04.900690Z","shell.execute_reply.started":"2025-02-07T22:36:04.174230Z","shell.execute_reply":"2025-02-07T22:36:04.900017Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"np.random.seed(33)\ntf.random.set_seed(33)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T22:36:07.184394Z","iopub.execute_input":"2025-02-07T22:36:07.185005Z","iopub.status.idle":"2025-02-07T22:36:07.192041Z","shell.execute_reply.started":"2025-02-07T22:36:07.184977Z","shell.execute_reply":"2025-02-07T22:36:07.191230Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"## 1.1 Required global functions","metadata":{}},{"cell_type":"code","source":"def download_from_drive(filename, file_id):\n    url = f\"https://drive.google.com/uc?export=download&id={file_id}\"\n    gdown.download(url, filename, quiet=False)\n\ndef load_dataset(image_size=(150, 150)):\n\n    categories = [\"NORMAL\", \"COVID\"]\n    datasets_name_list = [\"test\", \"train\"]\n    X = [[], []] # 0 for test & 1 for train\n    y = [[], []] # 0 for test & 1 for train\n\n    for i, dataset_name in enumerate(datasets_name_list):\n        for label, category in enumerate(categories):\n            dir_path = \"/kaggle/working/dataset1/\" + dataset_name + '/' + category + '/'\n            for filename in os.listdir(dir_path):\n                img_path = os.path.join(dir_path, filename)\n                img = Image.open(img_path).convert(\"RGB\")\n                img = img.resize(image_size)\n                img_array = np.array(img)\n                X[i].append(img_array)\n                y[i].append(label) # NORMAL = 0, COVID = 1\n\n    X_train = np.array(X[1]) / 255.0\n    y_train = np.array(y[1])\n    X_test = np.array(X[0]) / 255.0\n    y_test = np.array(y[0])\n\n    indices = np.arange(X_train.shape[0])\n    np.random.shuffle(indices)\n    X_train = X_train[indices]\n    y_train = y_train[indices]\n\n    return X_train, y_train, X_test, y_test\n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T22:36:09.506865Z","iopub.execute_input":"2025-02-07T22:36:09.507173Z","iopub.status.idle":"2025-02-07T22:36:09.513844Z","shell.execute_reply.started":"2025-02-07T22:36:09.507150Z","shell.execute_reply":"2025-02-07T22:36:09.512898Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"## 1.2 Downloading & Loading the dataset","metadata":{}},{"cell_type":"code","source":"download_from_drive(\n    filename=\"Datasets.rar\",\n    file_id=\"1wM1NufVrRtbHuLmeBjiOls_e80Qrsoy-\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T09:59:56.327216Z","iopub.execute_input":"2025-02-07T09:59:56.327604Z","iopub.status.idle":"2025-02-07T10:00:02.919933Z","shell.execute_reply.started":"2025-02-07T09:59:56.327571Z","shell.execute_reply":"2025-02-07T10:00:02.918908Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stderr","text":"Downloading...\nFrom (original): https://drive.google.com/uc?export=download&id=1wM1NufVrRtbHuLmeBjiOls_e80Qrsoy-\nFrom (redirected): https://drive.google.com/uc?export=download&id=1wM1NufVrRtbHuLmeBjiOls_e80Qrsoy-&confirm=t&uuid=4c6dd7af-157c-41c9-bdd4-0caa4dc59bae\nTo: /kaggle/working/Datasets.rar\n100%|██████████| 220M/220M [00:02<00:00, 81.0MB/s] \n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# Extract the Datasets.rar file in the current directory\n!unrar x \"Datasets.rar\" ./","metadata":{"trusted":true,"_kg_hide-output":true,"scrolled":true,"execution":{"iopub.status.busy":"2025-02-07T10:00:02.921204Z","iopub.execute_input":"2025-02-07T10:00:02.921494Z","iopub.status.idle":"2025-02-07T10:00:05.358943Z","shell.execute_reply.started":"2025-02-07T10:00:02.921468Z","shell.execute_reply":"2025-02-07T10:00:05.357315Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"\nUNRAR 6.11 beta 1 freeware      Copyright (c) 1993-2022 Alexander Roshal\n\n\nExtracting from Datasets.rar\n\nCreating    ./dataset2                                                OK\nCreating    ./dataset2/test                                           OK\nCreating    ./dataset2/test/NORMAL                                    OK\nExtracting  ./dataset2/test/NORMAL/NORMAL(1266).jpg                      0  OK \nExtracting  ./dataset2/test/NORMAL/NORMAL(1267).jpg                      0  OK \nExtracting  ./dataset2/test/NORMAL/NORMAL(1268).jpg                      0  OK \nExtracting  ./dataset2/test/NORMAL/NORMAL(1269).jpg                      1  OK \nExtracting  ./dataset2/test/NORMAL/NORMAL(1270).jpg                      1  OK \nExtracting  ./dataset2/test/NORMAL/NORMAL(1271).jpg                      1  OK \nExtracting  ./dataset2/test/NORMAL/NORMAL(1272).jpg                      2  OK \nExtracting  ./dataset2/test/NORMAL/NORMAL(1273).jpg                      2  OK \nExtracting  ./dataset2/test/NORMAL/NORMAL(1274).jpg                      2  OK \nExtracting  ./dataset2/test/NORMAL/NORMAL(1275).jpg                      2  OK \nExtracting  ./dataset2/test/NORMAL/NORMAL(1276).jpg                      3  OK \nExtracting  ./dataset2/test/NORMAL/NORMAL(1277).jpg                      3  OK \nExtracting  ./dataset2/test/NORMAL/NORMAL(1278).jpg                      3  OK \nExtracting  ./dataset2/test/NORMAL/NORMAL(1279).jpg                      3  OK \nExtracting  ./dataset2/test/NORMAL/NORMAL(1280).jpg                      4  OK \nExtracting  ./dataset2/test/NORMAL/NORMAL(1281).jpg                      4  OK \nExtracting  ./dataset2/test/NORMAL/NORMAL(1282).jpg                      4  OK \nExtracting  ./dataset2/test/NORMAL/NORMAL(1283).jpg                      5  OK \nExtracting  ./dataset2/test/NORMAL/NORMAL(1284).jpg                      5  OK \nExtracting  ./dataset2/test/NORMAL/NORMAL(1285).jpg                      6  OK \nExtracting  ./dataset2/test/NORMAL/NORMAL(1286).jpg                      6  OK \nExtracting  ./dataset2/test/NORMAL/NORMAL(1287).jpg                      6  OK \nExtracting  ./dataset2/test/NORMAL/NORMAL(1288).jpg                      7  OK \nExtracting  ./dataset2/test/NORMAL/NORMAL(1289).jpg                      7  OK \nExtracting  ./dataset2/test/NORMAL/NORMAL(1290).jpg                      7  OK \nExtracting  ./dataset2/test/NORMAL/NORMAL(1291).jpg                      8  OK \nExtracting  ./dataset2/test/NORMAL/NORMAL(1292).jpg                      8  OK \nExtracting  ./dataset2/test/NORMAL/NORMAL(1293).jpg                      8  OK \nExtracting  ./dataset2/test/NORMAL/NORMAL(1294).jpg                      9  OK \nExtracting  ./dataset2/test/NORMAL/NORMAL(1295).jpg                      9  OK \nExtracting  ./dataset2/test/NORMAL/NORMAL(1296).jpg                      9  OK \nExtracting  ./dataset2/test/NORMAL/NORMAL(1297).jpg                      9  OK \nExtracting  ./dataset2/test/NORMAL/NORMAL(1298).jpg                     10  OK \nExtracting  ./dataset2/test/NORMAL/NORMAL(1299).jpg                     1 11  OK \nExtracting  ./dataset2/test/NORMAL/NORMAL(1300).jpg                     11  OK \nExtracting  ./dataset2/test/NORMAL/NORMAL(1301).jpg                     11  OK \nExtracting  ./dataset2/test/NORMAL/NORMAL(1302).jpg                     11  OK \nExtracting  ./dataset2/test/NORMAL/NORMAL(1303).jpg                     12  OK \nExtracting  ./dataset2/test/NORMAL/NORMAL(1304).jpg                     12  OK \nExtracting  ./dataset2/test/NORMAL/NORMAL(1305).jpg                     12  OK \nCreating    ./dataset2/test/PNEUMONIA                                 OK\nExtracting  ./dataset2/test/PNEUMONIA/PNEUMONIA(3418).jpg               12  OK \nExtracting  ./dataset2/test/PNEUMONIA/PNEUMONIA(3419).jpg               12  OK \nExtracting  ./dataset2/test/PNEUMONIA/PNEUMONIA(3420).jpg               12  OK \nExtracting  ./dataset2/test/PNEUMONIA/PNEUMONIA(3421).jpg               12  OK \nExtracting  ./dataset2/test/PNEUMONIA/PNEUMONIA(3422).jpg               12  OK \nExtracting  ./dataset2/test/PNEUMONIA/PNEUMONIA(3423).jpg               12  OK \nExtracting  ./dataset2/test/PNEUMONIA/PNEUMONIA(3424).jpg               13  OK \nExtracting  ./dataset2/test/PNEUMONIA/PNEUMONIA(3425).jpg               13  OK \nExtracting  ./dataset2/test/PNEUMONIA/PNEUMONIA(3426).jpg               13  OK \nExtracting  ./dataset2/test/PNEUMONIA/PNEUMONIA(3427).jpg               13  OK \nExtracting  ./dataset2/test/PNEUMONIA/PNEUMONIA(3428).jpg               13  OK \nExtracting  ./dataset2/test/PNEUMONIA/PNEUMONIA(3429).jpg               13  OK \nExtracting  ./dataset2/test/PNEUMONIA/PNEUMONIA(3430).jpg               13  OK \nExtracting  ./dataset2/test/PNEUMONIA/PNEUMONIA(3431).jpg               13  OK \nExtracting  ./dataset2/test/PNEUMONIA/PNEUMONIA(3432).jpg               13  OK \nExtracting  ./dataset2/test/PNEUMONIA/PNEUMONIA(3433).jpg               13  OK \nExtracting  ./dataset2/test/PNEUMONIA/PNEUMONIA(3434).jpg               13  OK \nExtracting  ./dataset2/test/PNEUMONIA/PNEUMONIA(3435).jpg               13  OK \nExtracting  ./dataset2/test/PNEUMONIA/PNEUMONIA(3436).jpg               13  OK \nExtracting  ./dataset2/test/PNEUMONIA/PNEUMONIA(3437).jpg               13  OK \nExtracting  ./dataset2/test/PNEUMONIA/PNEUMONIA(3438).jpg               13  OK \nExtracting  ./dataset2/test/PNEUMONIA/PNEUMONIA(3439).jpg               13  OK \nExtracting  ./dataset2/test/PNEUMONIA/PNEUMONIA(3440).jpg               13  OK \nExtracting  ./dataset2/test/PNEUMONIA/PNEUMONIA(3441).jpg               14  OK \nExtracting  ./dataset2/test/PNEUMONIA/PNEUMONIA(3442).jpg               14  OK \nExtracting  ./dataset2/test/PNEUMONIA/PNEUMONIA(3443).jpg               14  OK \nExtracting  ./dataset2/test/PNEUMONIA/PNEUMONIA(3444).jpg               14  OK \nExtracting  ./dataset2/test/PNEUMONIA/PNEUMONIA(3445).jpg               14  OK \nExtracting  ./dataset2/test/PNEUMONIA/PNEUMONIA(3446).jpg               14  OK \nExtracting  ./dataset2/test/PNEUMONIA/PNEUMONIA(3447).jpg               14  OK \nExtracting  ./dataset2/test/PNEUMONIA/PNEUMONIA(3448).jpg               14  OK \nExtracting  ./dataset2/test/PNEUMONIA/PNEUMONIA(3449).jpg               14  OK \nExtracting  ./dataset2/test/PNEUMONIA/PNEUMONIA(3450).jpg               14  OK \nExtracting  ./dataset2/test/PNEUMONIA/PNEUMONIA(3451).jpg               14  OK \nExtracting  ./dataset2/test/PNEUMONIA/PNEUMONIA(3452).jpg               14  OK \nExtracting  ./dataset2/test/PNEUMONIA/PNEUMONIA(3453).jpg               14  OK \nExtracting  ./dataset2/test/PNEUMONIA/PNEUMONIA(3454).jpg               15  OK \nExtracting  ./dataset2/test/PNEUMONIA/PNEUMONIA(3455).jpg               15  OK \nExtracting  ./dataset2/test/PNEUMONIA/PNEUMONIA(3456).jpg               15  OK \nExtracting  ./dataset2/test/PNEUMONIA/PNEUMONIA(3457).jpg               15  OK \nCreating    ./dataset2/train                                          OK\nCreating    ./dataset2/train/NORMAL                                   OK\nExtracting  ./dataset2/train/NORMAL/NORMAL(0).jpg                       15  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(1).jpg                       15  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(10).jpg                      16  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(11).jpg                      16  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(12).jpg                      17  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(13).jpg                      17  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(14).jpg                      17  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(15).jpg                      18  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(16).jpg                      18  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(17).jpg                      18  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(18).jpg                      19  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(19).jpg                      20  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(2).jpg                       20  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(20).jpg                      21  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(21).jpg                      21  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(22).jpg                      21  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(23).jpg                      22  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(24).jpg                      22  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(25).jpg                      23  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(26).jpg                      23  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(27).jpg                      24  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(28).jpg                      24  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(29).jpg                      24  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(3).jpg                       24  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(30).jpg                      25  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(31).jpg                      25  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(32).jpg                      26  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(33).jpg                      27  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(34).jpg                      27  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(35).jpg                      27  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(36).jpg                      28  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(37).jpg                      28  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(38).jpg                      28  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(39).jpg                      28  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(4).jpg                       29  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(40).jpg                      29  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(41).jpg                      29  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(42).jpg                      29  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(43).jpg                      30  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(44).jpg                      30  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(45).jpg                      30  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(46).jpg                      30  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(47).jpg                      30  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(48).jpg                      30  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(49).jpg                      31  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(5).jpg                       31  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(50).jpg                      31  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(51).jpg                      31  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(52).jpg                      31  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(53).jpg                      31  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(54).jpg                      32  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(55).jpg                      32  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(56).jpg                      32  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(57).jpg                      32  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(58).jpg                      32  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(59).jpg                      32  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(6).jpg                       33  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(60).jpg                      33  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(61).jpg                      33  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(62).jpg                      33  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(63).jpg                      34  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(64).jpg                      34  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(65).jpg                      34  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(66).jpg                      34  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(67).jpg                      34  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(68).jpg                      34  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(69).jpg                      35  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(7).jpg                       35  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(70).jpg                      36  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(71).jpg                      36  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(72).jpg                      36  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(73).jpg                      36  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(74).jpg                      37  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(75).jpg                      37  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(76).jpg                      37  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(77).jpg                      37  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(78).jpg                      37  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(79).jpg                      38  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(8).jpg                       38  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(80).jpg                      38  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(81).jpg                      39  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(82).jpg                      39  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(83).jpg                      39  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(84).jpg                      40  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(85).jpg                      40  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(86).jpg                      40  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(87).jpg                      41  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(88).jpg                      41  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(89).jpg                      41  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(9).jpg                       41  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(90).jpg                      42  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(91).jpg                      42  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(92).jpg                      42  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(93).jpg                      42  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(94).jpg                      42  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(95).jpg                      43  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(96).jpg                      43  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(97).jpg                      43  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(98).jpg                      44  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(99).jpg                      44  OK \nCreating    ./dataset2/train/PNEUMONIA                                OK\nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(0).jpg                 44  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(1).jpg                 44  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(10).jpg                44  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(100).jpg               45  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(101).jpg               45  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(102).jpg               45  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(103).jpg               45  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(104).jpg               45  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(105).jpg               45  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(106).jpg               45  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(107).jpg               45  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(108).jpg               45  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(109).jpg               45  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(11).jpg                45  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(110).jpg               45  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(111).jpg               45  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(112).jpg               46  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(113).jpg               46  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(114).jpg               46  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(115).jpg               46  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(116).jpg               46  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(117).jpg               46  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(118).jpg               46  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(119).jpg               46  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(12).jpg                46  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(120).jpg               46  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(121).jpg               46  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(122).jpg               46  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(123).jpg               46  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(124).jpg               46  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(125).jpg               46  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(126).jpg               47  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(127).jpg               47  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(128).jpg               47  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(129).jpg               47  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(13).jpg                47  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(130).jpg               47  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(131).jpg               47  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(132).jpg               47  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(133).jpg               47  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(134).jpg               47  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(135).jpg               47  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(136).jpg               47  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(137).jpg               48  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(138).jpg               48  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(139).jpg               48  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(14).jpg                48  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(140).jpg               48  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(141).jpg               48  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(142).jpg               48  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(143).jpg               48  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(144).jpg               48  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(145).jpg               48  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(146).jpg               48  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(147).jpg               48  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(148).jpg               48  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(149).jpg               49  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(15).jpg                49  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(150).jpg               49  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(151).jpg               49  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(152).jpg               49  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(153).jpg               49  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(154).jpg               49  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(155).jpg               49  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(156).jpg               49  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(157).jpg               49  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(158).jpg               49  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(159).jpg               49  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(16).jpg                49  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(160).jpg               50  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(161).jpg               50  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(162).jpg               50  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(163).jpg               50  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(164).jpg               50  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(165).jpg               50  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(166).jpg               50  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(167).jpg               50  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(168).jpg               50  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(169).jpg               50  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(17).jpg                50  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(170).jpg               50  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(171).jpg               50  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(172).jpg               50  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(173).jpg               51  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(174).jpg               51  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(175).jpg               51  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(176).jpg               51  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(177).jpg               51  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(178).jpg               51  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(179).jpg               51  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(18).jpg                51  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(180).jpg               51  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(181).jpg               51  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(182).jpg               51  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(183).jpg               52  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(184).jpg               52  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(185).jpg               52  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(186).jpg               52  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(187).jpg               52  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(188).jpg               52  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(189).jpg               52  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(19).jpg                52  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(190).jpg               52  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(191).jpg               52  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(192).jpg               52  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(193).jpg               52  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(194).jpg               52  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(195).jpg               52  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(196).jpg               52  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(197).jpg               52  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(198).jpg               53  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(199).jpg               53  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(2).jpg                 53  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(20).jpg                53  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(21).jpg                53  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(22).jpg                53  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(23).jpg                53  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(24).jpg                53  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(25).jpg                53  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(26).jpg                53  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(27).jpg                53  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(28).jpg                53  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(29).jpg                53  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(3).jpg                 53  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(30).jpg                54  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(31).jpg                54  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(32).jpg                54  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(33).jpg                54  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(34).jpg                54  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(35).jpg                54  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(36).jpg                54  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(37).jpg                54  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(38).jpg                54  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(39).jpg                54  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(4).jpg                 55  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(40).jpg                55  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(41).jpg                55  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(42).jpg                55  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(43).jpg                55  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(44).jpg                55  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(45).jpg                55  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(46).jpg                55  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(47).jpg                55  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(48).jpg                55  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(49).jpg                55  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(5).jpg                 55  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(50).jpg                56  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(51).jpg                56  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(52).jpg                56  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(53).jpg                56  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(54).jpg                56  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(55).jpg                56  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(56).jpg                56  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(57).jpg                56  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(58).jpg                56  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(59).jpg                56  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(6).jpg                 56  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(60).jpg                56  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(61).jpg                56  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(62).jpg                57  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(63).jpg                57  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(64).jpg                57  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(65).jpg                57  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(66).jpg                57  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(67).jpg                57  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(68).jpg                57  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(69).jpg                57  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(7).jpg                 57  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(70).jpg                57  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(71).jpg                57  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(72).jpg                57  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(73).jpg                57  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(74).jpg                57  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(75).jpg                57  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(76).jpg                58  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(77).jpg                58  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(78).jpg                58  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(79).jpg                58  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(8).jpg                 58  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(80).jpg                58  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(81).jpg                58  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(82).jpg                58  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(83).jpg                58  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(84).jpg                58  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(85).jpg                58  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(86).jpg                58  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(87).jpg                58  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(88).jpg                58  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(89).jpg                59  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(9).jpg                 59  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(90).jpg                59  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(91).jpg                59  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(92).jpg                59  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(93).jpg                59  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(94).jpg                59  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(95).jpg                59  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(96).jpg                59  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(97).jpg                59  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(98).jpg                59  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(99).jpg                59  OK \nCreating    ./dataset1                                                OK\nCreating    ./dataset1/test                                           OK\nCreating    ./dataset1/test/COVID                                     OK\nExtracting  ./dataset1/test/COVID/ryct.2020200034.fig2.jpeg             59  OK \nExtracting  ./dataset1/test/COVID/ryct.2020200034.fig5-day0.jpeg        59  OK \nExtracting  ./dataset1/test/COVID/ryct.2020200034.fig5-day4.jpeg        60  OK \nExtracting  ./dataset1/test/COVID/ryct.2020200034.fig5-day7.jpeg        60  OK \nExtracting  ./dataset1/test/COVID/SARS-10.1148rg.242035193-g04mr34g0-Fig8a-day0.jpeg    60  OK \nExtracting  ./dataset1/test/COVID/SARS-10.1148rg.242035193-g04mr34g0-Fig8b-day5.jpeg    60  OK \nExtracting  ./dataset1/test/COVID/SARS-10.1148rg.242035193-g04mr34g0-Fig8c-day10.jpeg    60  OK \nExtracting  ./dataset1/test/COVID/SARS-10.1148rg.242035193-g04mr34g04a-Fig4a-day7.jpeg    60  OK \nExtracting  ./dataset1/test/COVID/SARS-10.1148rg.242035193-g04mr34g04b-Fig4b-day12.jpeg    61  OK \nExtracting  ./dataset1/test/COVID/SARS-10.1148rg.242035193-g04mr34g05x-Fig5-day9.jpeg    61  OK \nExtracting  ./dataset1/test/COVID/SARS-10.1148rg.242035193-g04mr34g07a-Fig7a-day5.jpeg    61  OK \nExtracting  ./dataset1/test/COVID/SARS-10.1148rg.242035193-g04mr34g07b-Fig7b-day12.jpeg    61  OK \nExtracting  ./dataset1/test/COVID/SARS-10.1148rg.242035193-g04mr34g09a-Fig9a-day17.jpeg    61  OK \nExtracting  ./dataset1/test/COVID/SARS-10.1148rg.242035193-g04mr34g09b-Fig9b-day19.jpeg    61  OK \nExtracting  ./dataset1/test/COVID/SARS-10.1148rg.242035193-g04mr34g09c-Fig9c-day27.jpeg    61  OK \nExtracting  ./dataset1/test/COVID/streptococcus-pneumoniae-pneumonia-1.jpg    62  OK \nExtracting  ./dataset1/test/COVID/streptococcus-pneumoniae-pneumonia-temporal-evolution-1-day0.jpg    62  OK \nExtracting  ./dataset1/test/COVID/streptococcus-pneumoniae-pneumonia-temporal-evolution-1-day1.jpg    62  OK \nExtracting  ./dataset1/test/COVID/streptococcus-pneumoniae-pneumonia-temporal-evolution-1-day2.jpg    62  OK \nExtracting  ./dataset1/test/COVID/streptococcus-pneumoniae-pneumonia-temporal-evolution-1-day3.jpg    62  OK \nCreating    ./dataset1/test/NORMAL                                    OK\nExtracting  ./dataset1/test/NORMAL/NORMAL2-IM-0035-0001.jpeg            62  OK \nExtracting  ./dataset1/test/NORMAL/NORMAL2-IM-0052-0001.jpeg            62  OK \nExtracting  ./dataset1/test/NORMAL/NORMAL2-IM-0058-0001.jpeg            62  OK \nExtracting  ./dataset1/test/NORMAL/NORMAL2-IM-0059-0001.jpeg            62  OK \nExtracting  ./dataset1/test/NORMAL/NORMAL2-IM-0072-0001.jpeg            62  OK \nExtracting  ./dataset1/test/NORMAL/NORMAL2-IM-0073-0001.jpeg            63  OK \nExtracting  ./dataset1/test/NORMAL/NORMAL2-IM-0092-0001.jpeg            63  OK \nExtracting  ./dataset1/test/NORMAL/NORMAL2-IM-0105-0001.jpeg            63  OK \nExtracting  ./dataset1/test/NORMAL/NORMAL2-IM-0110-0001.jpeg            63  OK \nExtracting  ./dataset1/test/NORMAL/NORMAL2-IM-0111-0001.jpeg            63  OK \nExtracting  ./dataset1/test/NORMAL/NORMAL2-IM-0112-0001.jpeg            63  OK \nExtracting  ./dataset1/test/NORMAL/NORMAL2-IM-0117-0001.jpeg            63  OK \nExtracting  ./dataset1/test/NORMAL/NORMAL2-IM-0120-0001.jpeg            63  OK \nExtracting  ./dataset1/test/NORMAL/NORMAL2-IM-0123-0001.jpeg            63  OK \nExtracting  ./dataset1/test/NORMAL/NORMAL2-IM-0130-0001.jpeg            63  OK \nExtracting  ./dataset1/test/NORMAL/NORMAL2-IM-0131-0001.jpeg            63  OK \nExtracting  ./dataset1/test/NORMAL/NORMAL2-IM-0132-0001.jpeg            64  OK \nExtracting  ./dataset1/test/NORMAL/NORMAL2-IM-0139-0001.jpeg            64  OK \nExtracting  ./dataset1/test/NORMAL/NORMAL2-IM-0145-0001.jpeg            64  OK \nExtracting  ./dataset1/test/NORMAL/NORMAL2-IM-0171-0001.jpeg            64  OK \nCreating    ./dataset1/train                                          OK\nCreating    ./dataset1/train/COVID                                    OK\nExtracting  ./dataset1/train/COVID/01E392EE-69F9-4E33-BFCE-E5C968654078.jpeg    64  OK \nExtracting  ./dataset1/train/COVID/1-s2.0-S0140673620303706-fx1_lrg.jpg    64  OK \nExtracting  ./dataset1/train/COVID/1-s2.0-S1684118220300608-main.pdf-001.jpg    64  OK \nExtracting  ./dataset1/train/COVID/1-s2.0-S1684118220300608-main.pdf-002.jpg    64  OK \nExtracting  ./dataset1/train/COVID/1-s2.0-S1684118220300682-main.pdf-002-a1.png    64  OK \nExtracting  ./dataset1/train/COVID/1-s2.0-S1684118220300682-main.pdf-002-a2.png    64  OK \nExtracting  ./dataset1/train/COVID/1-s2.0-S1684118220300682-main.pdf-003-b1.png    64  OK \nExtracting  ./dataset1/train/COVID/1-s2.0-S1684118220300682-main.pdf-003-b2.png    65  OK \nExtracting  ./dataset1/train/COVID/1312A392-67A3-4EBF-9319-810CF6DA5EF6.jpeg    65  OK \nExtracting  ./dataset1/train/COVID/171CB377-62FF-4B76-906C-F3787A01CB2E.jpeg    65  OK \nExtracting  ./dataset1/train/COVID/1B734A89-A1BF-49A8-A1D3-66FAFA4FAC5D.jpeg    65  OK \nExtracting  ./dataset1/train/COVID/23E99E2E-447C-46E5-8EB2-D35D12473C39.png    66  OK \nExtracting  ./dataset1/train/COVID/2C10A413-AABE-4807-8CCE-6A2025594067.jpeg    6 70  OK \nExtracting  ./dataset1/train/COVID/2C26F453-AF3B-4517-BB9E-802CF2179543.jpeg    70  OK \nExtracting  ./dataset1/train/COVID/31BA3780-2323-493F-8AED-62081B9C383B.jpeg    70  OK \nExtracting  ./dataset1/train/COVID/39EE8E69-5801-48DE-B6E3-BE7D1BCF3092.jpeg    70  OK \nExtracting  ./dataset1/train/COVID/41591_2020_819_Fig1_HTML.webp-day10.png    70  OK \nExtracting  ./dataset1/train/COVID/41591_2020_819_Fig1_HTML.webp-day5.png    70  OK \nExtracting  ./dataset1/train/COVID/446B2CB6-B572-40AB-B01F-1910CA07086A.jpeg    71  OK \nExtracting  ./dataset1/train/COVID/5931B64A-7B97-485D-BE60-3F1EA76BC4F0.jpeg    71  OK \nExtracting  ./dataset1/train/COVID/5CBC2E94-D358-401E-8928-965CCD965C5C.jpeg    72  OK \nExtracting  ./dataset1/train/COVID/5e6dd879fde9502400e58b2f.jpeg        72  OK \nExtracting  ./dataset1/train/COVID/6CB4EFC6-68FA-4CD5-940C-BEFA8DAFE9A7.jpeg    73  OK \nExtracting  ./dataset1/train/COVID/7AF6C1AF-D249-4BD2-8C26-449304105D03.jpeg    73  OK \nExtracting  ./dataset1/train/COVID/7C69C012-7479-493F-8722-ABC29C60A2DD.jpeg    73  OK \nExtracting  ./dataset1/train/COVID/7D2CF6CE-F529-4470-8356-D33FFAF98600.jpeg    73  OK \nExtracting  ./dataset1/train/COVID/7E335538-2F86-424E-A0AB-6397783A38D0.jpeg    7 76  OK \nExtracting  ./dataset1/train/COVID/7EF28E12-F628-4BEC-A8C5-E6277C2E4F60.png    76  OK \nExtracting  ./dataset1/train/COVID/80446565-E090-4187-A031-9D3CEAA586C8.jpeg    76  OK \nExtracting  ./dataset1/train/COVID/85E52EB3-56E9-4D67-82DA-DEA247C82886.jpeg    77  OK \nExtracting  ./dataset1/train/COVID/8FDE8DBA-CFBD-4B4C-B1A4-6F36A93B7E87.jpeg    77  OK \nExtracting  ./dataset1/train/COVID/93FE0BB1-022D-4F24-9727-987A07975FFB.jpeg    77  OK \nExtracting  ./dataset1/train/COVID/9C34AF49-E589-44D5-92D3-168B3B04E4A6.jpeg    77  OK \nExtracting  ./dataset1/train/COVID/acute-respiratory-distress-syndrome-ards-1.jpg    77  OK \nExtracting  ./dataset1/train/COVID/all14238-fig-0001-m-b.jpg            77  OK \nExtracting  ./dataset1/train/COVID/all14238-fig-0001-m-c.jpg            77  OK \nExtracting  ./dataset1/train/COVID/all14238-fig-0002-m-e.jpg            77  OK \nExtracting  ./dataset1/train/COVID/ards-secondary-to-tiger-snake-bite.png    78  OK \nExtracting  ./dataset1/train/COVID/ARDSSevere.png                       78  OK \nExtracting  ./dataset1/train/COVID/auntminnie-2020_01_31_20_24_2322_2020_01_31_x-ray_coronavirus_US.jpg    78  OK \nExtracting  ./dataset1/train/COVID/auntminnie-b-2020_01_28_23_51_6665_2020_01_28_Vietnam_coronavirus.jpeg    78  OK \nExtracting  ./dataset1/train/COVID/auntminnie-c-2020_01_28_23_51_6665_2020_01_28_Vietnam_coronavirus.jpeg    78  OK \nExtracting  ./dataset1/train/COVID/auntminnie-d-2020_01_28_23_51_6665_2020_01_28_Vietnam_coronavirus.jpeg    78  OK \nExtracting  ./dataset1/train/COVID/B59DD164-51D5-40DF-A926-6A42DD52EBE8.jpeg    78  OK \nExtracting  ./dataset1/train/COVID/C6EA0BE5-B01E-4113-B194-18D956675E25.jpeg    79  OK \nExtracting  ./dataset1/train/COVID/CD50BA96-6982-4C80-AE7B-5F67ACDBFA56.jpeg    79  OK \nExtracting  ./dataset1/train/COVID/covid-19-pneumonia-12.jpg            80  OK \nExtracting  ./dataset1/train/COVID/covid-19-pneumonia-14-PA.png         82  OK \nExtracting  ./dataset1/train/COVID/covid-19-pneumonia-15-PA.jpg         83  OK \nExtracting  ./dataset1/train/COVID/covid-19-pneumonia-7-PA.jpg          83  OK \nExtracting  ./dataset1/train/COVID/E1724330-1866-4581-8CD8-CEC9B8AFEDDE.jpeg    8 87  OK \nExtracting  ./dataset1/train/COVID/E63574A7-4188-4C8D-8D17-9D67A18A1AFA.jpeg    87  OK \nExtracting  ./dataset1/train/COVID/F051E018-DAD1-4506-AD43-BE4CA29E960B.jpeg    87  OK \nExtracting  ./dataset1/train/COVID/F4341CE7-73C9-45C6-99C8-8567A5484B63.jpeg    87  OK \nExtracting  ./dataset1/train/COVID/F63AB6CE-1968-4154-A70F-913AF154F53D.jpeg    87  OK \nExtracting  ./dataset1/train/COVID/jkms-35-e79-g001-l-a.jpg             88  OK \nExtracting  ./dataset1/train/COVID/jkms-35-e79-g001-l-b.jpg             88  OK \nExtracting  ./dataset1/train/COVID/jkms-35-e79-g001-l-c.jpg             88  OK \nExtracting  ./dataset1/train/COVID/kjr-21-e24-g001-l-a.jpg              88  OK \nExtracting  ./dataset1/train/COVID/kjr-21-e24-g002-l-a.jpg              88  OK \nExtracting  ./dataset1/train/COVID/kjr-21-e24-g003-l-a.jpg              88  OK \nExtracting  ./dataset1/train/COVID/kjr-21-e25-g001-l-a.jpg              88  OK \nExtracting  ./dataset1/train/COVID/lancet-case2a.jpg                    88  OK \nExtracting  ./dataset1/train/COVID/MERS-CoV-1-s2.0-S0378603X1500248X-gr4e.jpg    88  OK \nExtracting  ./dataset1/train/COVID/nCoV-radiol.2020200269.fig1-day7.jpeg    88  OK \nExtracting  ./dataset1/train/COVID/nCoV-Snohomish-20382862_web1_M1-Lungs-EDH-200201-640x300@2x.jpg    88  OK \nExtracting  ./dataset1/train/COVID/nejmc2001573_f1a.jpeg                88  OK \nExtracting  ./dataset1/train/COVID/nejmc2001573_f1b.jpeg                88  OK \nExtracting  ./dataset1/train/COVID/nejmoa2001191_f1-PA.jpeg             88  OK \nExtracting  ./dataset1/train/COVID/nejmoa2001191_f3-PA.jpeg             88  OK \nExtracting  ./dataset1/train/COVID/nejmoa2001191_f4.jpeg                89  OK \nExtracting  ./dataset1/train/COVID/nejmoa2001191_f5-PA.jpeg             89  OK \nExtracting  ./dataset1/train/COVID/pneumocystis-pneumonia-2-PA.png      89  OK \nExtracting  ./dataset1/train/COVID/ryct.2020200028.fig1a.jpeg           90  OK \nCreating    ./dataset1/train/NORMAL                                   OK\nExtracting  ./dataset1/train/NORMAL/IM-0001-0001.jpeg                   90  OK \nExtracting  ./dataset1/train/NORMAL/IM-0003-0001.jpeg                   90  OK \nExtracting  ./dataset1/train/NORMAL/IM-0005-0001.jpeg                   90  OK \nExtracting  ./dataset1/train/NORMAL/IM-0006-0001.jpeg                   90  OK \nExtracting  ./dataset1/train/NORMAL/IM-0007-0001.jpeg                   91  OK \nExtracting  ./dataset1/train/NORMAL/IM-0009-0001.jpeg                   91  OK \nExtracting  ./dataset1/train/NORMAL/IM-0010-0001.jpeg                   91  OK \nExtracting  ./dataset1/train/NORMAL/IM-0011-0001-0001.jpeg              91  OK \nExtracting  ./dataset1/train/NORMAL/IM-0011-0001-0002.jpeg              91  OK \nExtracting  ./dataset1/train/NORMAL/IM-0011-0001.jpeg                   91  OK \nExtracting  ./dataset1/train/NORMAL/IM-0013-0001.jpeg                   92  OK \nExtracting  ./dataset1/train/NORMAL/IM-0015-0001.jpeg                   92  OK \nExtracting  ./dataset1/train/NORMAL/IM-0016-0001.jpeg                   92  OK \nExtracting  ./dataset1/train/NORMAL/IM-0017-0001.jpeg                   92  OK \nExtracting  ./dataset1/train/NORMAL/IM-0019-0001.jpeg                   92  OK \nExtracting  ./dataset1/train/NORMAL/IM-0021-0001.jpeg                   93  OK \nExtracting  ./dataset1/train/NORMAL/IM-0022-0001.jpeg                   93  OK \nExtracting  ./dataset1/train/NORMAL/IM-0023-0001.jpeg                   93  OK \nExtracting  ./dataset1/train/NORMAL/IM-0025-0001.jpeg                   93  OK \nExtracting  ./dataset1/train/NORMAL/IM-0027-0001.jpeg                   93  OK \nExtracting  ./dataset1/train/NORMAL/IM-0029-0001.jpeg                   94  OK \nExtracting  ./dataset1/train/NORMAL/IM-0030-0001.jpeg                   94  OK \nExtracting  ./dataset1/train/NORMAL/IM-0031-0001.jpeg                   94  OK \nExtracting  ./dataset1/train/NORMAL/IM-0033-0001-0001.jpeg              94  OK \nExtracting  ./dataset1/train/NORMAL/IM-0033-0001-0002.jpeg              94  OK \nExtracting  ./dataset1/train/NORMAL/IM-0033-0001.jpeg                   94  OK \nExtracting  ./dataset1/train/NORMAL/IM-0035-0001.jpeg                   95  OK \nExtracting  ./dataset1/train/NORMAL/IM-0036-0001.jpeg                   95  OK \nExtracting  ./dataset1/train/NORMAL/IM-0037-0001.jpeg                   95  OK \nExtracting  ./dataset1/train/NORMAL/IM-0039-0001.jpeg                   95  OK \nExtracting  ./dataset1/train/NORMAL/IM-0041-0001.jpeg                   95  OK \nExtracting  ./dataset1/train/NORMAL/IM-0043-0001.jpeg                   96  OK \nExtracting  ./dataset1/train/NORMAL/IM-0045-0001.jpeg                   96  OK \nExtracting  ./dataset1/train/NORMAL/IM-0046-0001.jpeg                   96  OK \nExtracting  ./dataset1/train/NORMAL/IM-0049-0001.jpeg                   96  OK \nExtracting  ./dataset1/train/NORMAL/IM-0050-0001.jpeg                   96  OK \nExtracting  ./dataset1/train/NORMAL/IM-0059-0001.jpeg                   96  OK \nExtracting  ./dataset1/train/NORMAL/IM-0061-0001.jpeg                   96  OK \nExtracting  ./dataset1/train/NORMAL/IM-0063-0001.jpeg                   97  OK \nExtracting  ./dataset1/train/NORMAL/IM-0069-0001.jpeg                   97  OK \nExtracting  ./dataset1/train/NORMAL/IM-0070-0001.jpeg                   97  OK \nExtracting  ./dataset1/train/NORMAL/IM-0071-0001.jpeg                   97  OK \nExtracting  ./dataset1/train/NORMAL/IM-0073-0001.jpeg                   97  OK \nExtracting  ./dataset1/train/NORMAL/IM-0075-0001.jpeg                   97  OK \nExtracting  ./dataset1/train/NORMAL/IM-0077-0001.jpeg                   97  OK \nExtracting  ./dataset1/train/NORMAL/IM-0079-0001.jpeg                   97  OK \nExtracting  ./dataset1/train/NORMAL/IM-0081-0001.jpeg                   97  OK \nExtracting  ./dataset1/train/NORMAL/IM-0083-0001.jpeg                   97  OK \nExtracting  ./dataset1/train/NORMAL/IM-0084-0001.jpeg                   97  OK \nExtracting  ./dataset1/train/NORMAL/IM-0085-0001.jpeg                   97  OK \nExtracting  ./dataset1/train/NORMAL/IM-0086-0001.jpeg                   97  OK \nExtracting  ./dataset1/train/NORMAL/IM-0087-0001.jpeg                   98  OK \nExtracting  ./dataset1/train/NORMAL/IM-0089-0001.jpeg                   98  OK \nExtracting  ./dataset1/train/NORMAL/IM-0091-0001.jpeg                   98  OK \nExtracting  ./dataset1/train/NORMAL/IM-0093-0001.jpeg                   98  OK \nExtracting  ./dataset1/train/NORMAL/IM-0095-0001.jpeg                   98  OK \nExtracting  ./dataset1/train/NORMAL/IM-0097-0001.jpeg                   98  OK \nExtracting  ./dataset1/train/NORMAL/IM-0099-0001.jpeg                   98  OK \nExtracting  ./dataset1/train/NORMAL/IM-0101-0001.jpeg                   98  OK \nExtracting  ./dataset1/train/NORMAL/IM-0102-0001.jpeg                   98  OK \nExtracting  ./dataset1/train/NORMAL/IM-0103-0001.jpeg                   98  OK \nExtracting  ./dataset1/train/NORMAL/IM-0105-0001.jpeg                   98  OK \nExtracting  ./dataset1/train/NORMAL/IM-0107-0001.jpeg                   98  OK \nExtracting  ./dataset1/train/NORMAL/IM-0110-0001.jpeg                   98  OK \nExtracting  ./dataset1/train/NORMAL/IM-0111-0001.jpeg                   99  OK \nExtracting  ./dataset1/train/NORMAL/NORMAL2-IM-0007-0001.jpeg           99  OK \nExtracting  ./dataset1/train/NORMAL/NORMAL2-IM-0012-0001.jpeg           99  OK \nExtracting  ./dataset1/train/NORMAL/NORMAL2-IM-0013-0001.jpeg           99  OK \nExtracting  ./dataset1/train/NORMAL/NORMAL2-IM-0023-0001.jpeg           99  OK \nExtracting  ./dataset1/train/NORMAL/NORMAL2-IM-0027-0001.jpeg           99  OK \nExtracting  ./dataset1/train/NORMAL/NORMAL2-IM-0028-0001.jpeg           99  OK \nExtracting  ./dataset1/train/NORMAL/NORMAL2-IM-0029-0001.jpeg           99  OK \nExtracting  ./dataset1/train/NORMAL/NORMAL2-IM-0030-0001.jpeg           99  OK \nExtracting  ./dataset1/train/NORMAL/NORMAL2-IM-0033-0001.jpeg           99  OK \nAll OK\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"X_train, y_train, X_test, y_test = load_dataset()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T22:36:14.532968Z","iopub.execute_input":"2025-02-07T22:36:14.533261Z","iopub.status.idle":"2025-02-07T22:36:22.070931Z","shell.execute_reply.started":"2025-02-07T22:36:14.533239Z","shell.execute_reply":"2025-02-07T22:36:22.070165Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"num_train = X_train.shape[0]\nnum_test = X_test.shape[0]\nnum_covid = sum(y_train[y_train==1]) + sum(y_test[y_test==1])\nprint(f\"Number of Training Samples: {num_train}\\nNumber of Test Samples: {num_test}\\nNumber of COVID samples: {num_covid}\\nNumber of Normal samples: {num_train + num_test - num_covid}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T22:36:22.071911Z","iopub.execute_input":"2025-02-07T22:36:22.072121Z","iopub.status.idle":"2025-02-07T22:36:22.079103Z","shell.execute_reply.started":"2025-02-07T22:36:22.072103Z","shell.execute_reply":"2025-02-07T22:36:22.078342Z"}},"outputs":[{"name":"stdout","text":"Number of Training Samples: 148\nNumber of Test Samples: 40\nNumber of COVID samples: 94\nNumber of Normal samples: 94\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"## 1.3 CNN Architecture","metadata":{}},{"cell_type":"code","source":"def define_model(input_shape=(150,150,3), lr=0.001):\n    model = Sequential(\n        [\n            # Input\n            Input(shape=input_shape),\n            \n            # Conv1\n            Conv2D(64, kernel_size=(3,3), activation='relu', padding='same'),\n            BatchNormalization(axis=-1),\n            MaxPooling2D(pool_size=(2,2)),\n            Dropout(0.2),\n\n            # Conv2\n            Conv2D(64, kernel_size=(3,3), activation='relu', padding='same'),\n            BatchNormalization(axis=-1),\n            MaxPooling2D(pool_size=(2,2)),\n            Dropout(0.2),\n\n            # Conv3\n            Conv2D(128, kernel_size=(3,3), activation='relu', padding='same'),\n            BatchNormalization(axis=-1),\n            MaxPooling2D(pool_size=(2,2)),\n            Dropout(0.2),\n\n            # Conv4\n            Conv2D(128, kernel_size=(3,3), activation='relu', padding='same'),\n            BatchNormalization(axis=-1),\n            MaxPooling2D(pool_size=(2,2)),\n            Dropout(0.2),\n\n            # Conv5\n            Conv2D(256, kernel_size=(3,3), activation='relu', padding='same'),\n            BatchNormalization(axis=-1),\n            MaxPooling2D(pool_size=(2,2)),\n            Dropout(0.2),\n\n            # Conv6\n            Conv2D(256, kernel_size=(3,3), activation='relu', padding='same'),\n            BatchNormalization(axis=-1),\n            MaxPooling2D(pool_size=(2,2)),\n            Dropout(0.2),\n\n            # Flatten Layer\n            Flatten(),\n\n            # FCL\n            Dense(512, activation='relu'),\n            BatchNormalization(axis=-1),\n            Dense(256, activation='relu'),\n            BatchNormalization(axis=-1),\n\n            # Output\n            Dense(1, activation='sigmoid')\n        ]\n    )\n\n    model.compile(\n        optimizer=Adam(learning_rate=lr),\n        loss='binary_crossentropy',\n        metrics=['accuracy']\n    )\n\n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T22:36:25.325174Z","iopub.execute_input":"2025-02-07T22:36:25.325498Z","iopub.status.idle":"2025-02-07T22:36:25.333194Z","shell.execute_reply.started":"2025-02-07T22:36:25.325437Z","shell.execute_reply":"2025-02-07T22:36:25.332336Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"## 1.4 Train & Evaluation of model with k-fold cross-validation","metadata":{}},{"cell_type":"code","source":"def train_evaluate_model_with_k_fold(X_train, y_train, lr=0.01, epochs=50, batch_size=16, output_model=False):\n    \n    kf = KFold(n_splits=10, shuffle=True, random_state=33)\n\n    fold_no = 1\n    train_acc_scores = []\n    val_acc_scores = []\n    \n    for train_index, val_index in kf.split(X_train, y_train):\n        print(f\"\\nTraining on Fold {fold_no}...\")\n        \n        X_tr, X_val = X_train[train_index], X_train[val_index]\n        y_tr, y_val = y_train[train_index], y_train[val_index]\n        \n        # Recreate a fresh model for each fold\n        model = define_model(input_shape=(150,150,3), lr=lr)\n        \n        history = model.fit(\n            X_tr, y_tr,\n            validation_data=(X_val, y_val),\n            epochs=epochs,\n            batch_size=batch_size,\n            callbacks=[\n                EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True, verbose=1),\n                ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1)\n            ],\n            verbose=1,\n            shuffle=True\n        )\n        \n        # Evaluate the model on the fold's training and validation sets\n        train_loss, train_acc = model.evaluate(X_tr, y_tr, verbose=0)\n        val_loss, val_acc = model.evaluate(X_val, y_val, verbose=0)\n        \n        print(f\"Fold {fold_no} - Train Accuracy: {train_acc*100:.2f}%, Validation Accuracy: {val_acc*100:.2f}%\")\n        train_acc_scores.append(train_acc)\n        val_acc_scores.append(val_acc)\n        \n        fold_no += 1\n    \n    print(\"\\nAverage Training Accuracy: {:.2f}%\".format(np.mean(train_acc_scores)*100))\n    print(\"Average Validation Accuracy: {:.2f}%\".format(np.mean(val_acc_scores)*100))\n\n    if output_model:\n        return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T22:36:28.358892Z","iopub.execute_input":"2025-02-07T22:36:28.359196Z","iopub.status.idle":"2025-02-07T22:36:28.366034Z","shell.execute_reply.started":"2025-02-07T22:36:28.359173Z","shell.execute_reply":"2025-02-07T22:36:28.365273Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"# 2 Data Collection and Image Preprocessing","metadata":{}},{"cell_type":"markdown","source":"## 2.0 Evaluation before adding augmented dataset","metadata":{}},{"cell_type":"code","source":"train_evaluate_model_with_k_fold(X_train, y_train, lr=0.01, epochs=50, batch_size=16)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T20:01:36.341934Z","iopub.execute_input":"2025-02-07T20:01:36.342226Z","iopub.status.idle":"2025-02-07T20:05:41.528033Z","shell.execute_reply.started":"2025-02-07T20:01:36.342203Z","shell.execute_reply":"2025-02-07T20:05:41.527262Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"\nTraining on Fold 1...\nEpoch 1/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 885ms/step - accuracy: 0.6716 - loss: 1.1087 - val_accuracy: 0.4667 - val_loss: 12465.7129 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8765 - loss: 0.4161 - val_accuracy: 0.4667 - val_loss: 883.4987 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9377 - loss: 0.1560 - val_accuracy: 0.4667 - val_loss: 1059.7609 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9854 - loss: 0.0820 - val_accuracy: 0.4667 - val_loss: 206.0867 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9867 - loss: 0.0418 - val_accuracy: 0.4667 - val_loss: 31.8108 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0326 - val_accuracy: 0.5333 - val_loss: 38.1015 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0107 - val_accuracy: 0.5333 - val_loss: 18.0174 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0040 - val_accuracy: 0.6000 - val_loss: 6.1719 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0050 - val_accuracy: 0.6000 - val_loss: 6.2366 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0046 - val_accuracy: 0.6000 - val_loss: 3.7785 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0033 - val_accuracy: 0.8000 - val_loss: 1.1556 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.7333 - val_loss: 1.2924 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.6667 - val_loss: 1.5341 - learning_rate: 0.0100\nEpoch 14/50\n\u001b[1m7/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 6.9206e-04\nEpoch 14: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 7.2345e-04 - val_accuracy: 0.6000 - val_loss: 1.8807 - learning_rate: 0.0100\nEpoch 15/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.6000 - val_loss: 1.8409 - learning_rate: 1.0000e-03\nEpoch 16/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 8.0861e-04 - val_accuracy: 0.6667 - val_loss: 1.7107 - learning_rate: 1.0000e-03\nEpoch 16: early stopping\nRestoring model weights from the end of the best epoch: 11.\nFold 1 - Train Accuracy: 60.15%, Validation Accuracy: 80.00%\n\nTraining on Fold 2...\nEpoch 1/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 754ms/step - accuracy: 0.7375 - loss: 0.6620 - val_accuracy: 0.5333 - val_loss: 7886.8574 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8837 - loss: 0.3516 - val_accuracy: 0.6000 - val_loss: 915.2784 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9080 - loss: 0.2801 - val_accuracy: 0.5333 - val_loss: 386.3588 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9592 - loss: 0.1436 - val_accuracy: 0.5333 - val_loss: 340.5612 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9444 - loss: 0.0915 - val_accuracy: 0.5333 - val_loss: 131.0680 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9495 - loss: 0.0913 - val_accuracy: 0.5333 - val_loss: 56.9932 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9715 - loss: 0.0744 - val_accuracy: 0.5333 - val_loss: 22.0873 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9958 - loss: 0.0242 - val_accuracy: 0.5333 - val_loss: 10.5532 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9792 - loss: 0.0467 - val_accuracy: 0.6000 - val_loss: 5.6033 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9815 - loss: 0.0402 - val_accuracy: 0.6000 - val_loss: 6.3514 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0110 - val_accuracy: 0.6000 - val_loss: 5.1115 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0078 - val_accuracy: 0.8000 - val_loss: 2.0723 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9977 - loss: 0.0107 - val_accuracy: 0.8000 - val_loss: 1.9418 - learning_rate: 0.0100\nEpoch 14/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9954 - loss: 0.0196 - val_accuracy: 0.6000 - val_loss: 4.4229 - learning_rate: 0.0100\nEpoch 15/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9903 - loss: 0.0539 - val_accuracy: 0.8000 - val_loss: 1.6030 - learning_rate: 0.0100\nEpoch 16/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9838 - loss: 0.0498 - val_accuracy: 0.7333 - val_loss: 2.1197 - learning_rate: 0.0100\nEpoch 17/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9977 - loss: 0.0225 - val_accuracy: 0.6667 - val_loss: 3.7783 - learning_rate: 0.0100\nEpoch 18/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9815 - loss: 0.0389 - val_accuracy: 0.9333 - val_loss: 0.2081 - learning_rate: 0.0100\nEpoch 19/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9560 - loss: 0.0847 - val_accuracy: 0.8667 - val_loss: 0.3722 - learning_rate: 0.0100\nEpoch 20/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0127 - val_accuracy: 0.8667 - val_loss: 0.4019 - learning_rate: 0.0100\nEpoch 21/50\n\u001b[1m7/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0035\nEpoch 21: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0048 - val_accuracy: 0.8000 - val_loss: 0.3173 - learning_rate: 0.0100\nEpoch 22/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0051 - val_accuracy: 0.8000 - val_loss: 0.4566 - learning_rate: 1.0000e-03\nEpoch 23/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0049 - val_accuracy: 0.8000 - val_loss: 0.5684 - learning_rate: 1.0000e-03\nEpoch 23: early stopping\nRestoring model weights from the end of the best epoch: 18.\nFold 2 - Train Accuracy: 94.74%, Validation Accuracy: 93.33%\n\nTraining on Fold 3...\nEpoch 1/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 765ms/step - accuracy: 0.6695 - loss: 1.4414 - val_accuracy: 0.5333 - val_loss: 301.3988 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9007 - loss: 0.2649 - val_accuracy: 0.4667 - val_loss: 1160.6516 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9750 - loss: 0.0983 - val_accuracy: 0.5333 - val_loss: 135.2151 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9775 - loss: 0.0699 - val_accuracy: 0.5333 - val_loss: 74.2654 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9958 - loss: 0.0306 - val_accuracy: 0.5333 - val_loss: 63.1838 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9871 - loss: 0.0378 - val_accuracy: 0.6667 - val_loss: 5.2567 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9958 - loss: 0.0225 - val_accuracy: 0.5333 - val_loss: 18.2138 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9930 - loss: 0.0199 - val_accuracy: 0.5333 - val_loss: 23.8600 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m7/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9902 - loss: 0.0215\nEpoch 9: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9909 - loss: 0.0215 - val_accuracy: 0.6000 - val_loss: 11.2142 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0088 - val_accuracy: 0.5333 - val_loss: 6.4387 - learning_rate: 1.0000e-03\nEpoch 11/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0114 - val_accuracy: 0.5333 - val_loss: 3.6848 - learning_rate: 1.0000e-03\nEpoch 12/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9958 - loss: 0.0130 - val_accuracy: 0.6000 - val_loss: 2.0157 - learning_rate: 1.0000e-03\nEpoch 13/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0081 - val_accuracy: 0.6667 - val_loss: 1.0853 - learning_rate: 1.0000e-03\nEpoch 14/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0063 - val_accuracy: 0.7333 - val_loss: 0.6190 - learning_rate: 1.0000e-03\nEpoch 15/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0046 - val_accuracy: 0.8000 - val_loss: 0.3415 - learning_rate: 1.0000e-03\nEpoch 16/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0061 - val_accuracy: 0.8667 - val_loss: 0.2312 - learning_rate: 1.0000e-03\nEpoch 17/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9958 - loss: 0.0089 - val_accuracy: 0.9333 - val_loss: 0.1432 - learning_rate: 1.0000e-03\nEpoch 18/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9977 - loss: 0.0059 - val_accuracy: 1.0000 - val_loss: 0.0724 - learning_rate: 1.0000e-03\nEpoch 19/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0049 - val_accuracy: 1.0000 - val_loss: 0.0775 - learning_rate: 1.0000e-03\nEpoch 20/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0044 - val_accuracy: 0.9333 - val_loss: 0.1076 - learning_rate: 1.0000e-03\nEpoch 21/50\n\u001b[1m7/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0041\nEpoch 21: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0043 - val_accuracy: 0.9333 - val_loss: 0.1341 - learning_rate: 1.0000e-03\nEpoch 22/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0032 - val_accuracy: 0.9333 - val_loss: 0.1508 - learning_rate: 1.0000e-04\nEpoch 23/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0032 - val_accuracy: 0.9333 - val_loss: 0.1602 - learning_rate: 1.0000e-04\nEpoch 23: early stopping\nRestoring model weights from the end of the best epoch: 18.\nFold 3 - Train Accuracy: 81.95%, Validation Accuracy: 100.00%\n\nTraining on Fold 4...\nEpoch 1/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 758ms/step - accuracy: 0.6544 - loss: 0.9348 - val_accuracy: 0.5333 - val_loss: 387.9161 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9537 - loss: 0.2127 - val_accuracy: 0.4667 - val_loss: 643.5619 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9328 - loss: 0.1788 - val_accuracy: 0.4667 - val_loss: 3484.5117 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9739 - loss: 0.0805 - val_accuracy: 0.4667 - val_loss: 377.8097 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9903 - loss: 0.0458 - val_accuracy: 0.4667 - val_loss: 139.7285 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9916 - loss: 0.0230 - val_accuracy: 0.4667 - val_loss: 46.0601 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9958 - loss: 0.0214 - val_accuracy: 0.5333 - val_loss: 18.4508 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0085 - val_accuracy: 0.7333 - val_loss: 7.7101 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0034 - val_accuracy: 0.8000 - val_loss: 5.9020 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9985 - loss: 0.0100 - val_accuracy: 0.7333 - val_loss: 6.5947 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9935 - loss: 0.0162 - val_accuracy: 0.7333 - val_loss: 6.5569 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m7/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9902 - loss: 0.0346\nEpoch 12: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9909 - loss: 0.0330 - val_accuracy: 0.5333 - val_loss: 7.4810 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9854 - loss: 0.0274 - val_accuracy: 0.5333 - val_loss: 5.5711 - learning_rate: 1.0000e-03\nEpoch 14/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9945 - loss: 0.0243 - val_accuracy: 0.6000 - val_loss: 3.2783 - learning_rate: 1.0000e-03\nEpoch 15/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0095 - val_accuracy: 0.6000 - val_loss: 1.7324 - learning_rate: 1.0000e-03\nEpoch 16/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9909 - loss: 0.0201 - val_accuracy: 0.6667 - val_loss: 1.1653 - learning_rate: 1.0000e-03\nEpoch 17/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0035 - val_accuracy: 0.8000 - val_loss: 0.5294 - learning_rate: 1.0000e-03\nEpoch 18/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9878 - loss: 0.0129 - val_accuracy: 0.9333 - val_loss: 0.1498 - learning_rate: 1.0000e-03\nEpoch 19/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 1.0000 - val_loss: 0.0464 - learning_rate: 1.0000e-03\nEpoch 20/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0036 - val_accuracy: 1.0000 - val_loss: 0.0214 - learning_rate: 1.0000e-03\nEpoch 21/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 1.0000 - val_loss: 0.0483 - learning_rate: 1.0000e-03\nEpoch 22/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0044 - val_accuracy: 0.9333 - val_loss: 0.0909 - learning_rate: 1.0000e-03\nEpoch 23/50\n\u001b[1m7/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0012    \nEpoch 23: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.9333 - val_loss: 0.1089 - learning_rate: 1.0000e-03\nEpoch 24/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.9333 - val_loss: 0.1164 - learning_rate: 1.0000e-04\nEpoch 25/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.9333 - val_loss: 0.1159 - learning_rate: 1.0000e-04\nEpoch 25: early stopping\nRestoring model weights from the end of the best epoch: 20.\nFold 4 - Train Accuracy: 94.74%, Validation Accuracy: 100.00%\n\nTraining on Fold 5...\nEpoch 1/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 779ms/step - accuracy: 0.6810 - loss: 1.0574 - val_accuracy: 0.5333 - val_loss: 17272.9395 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9064 - loss: 0.2461 - val_accuracy: 0.4667 - val_loss: 354.2272 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9583 - loss: 0.1495 - val_accuracy: 0.4667 - val_loss: 189.4381 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9876 - loss: 0.0625 - val_accuracy: 0.6000 - val_loss: 29.6793 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0312 - val_accuracy: 0.4667 - val_loss: 292.3539 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9922 - loss: 0.0512 - val_accuracy: 0.4667 - val_loss: 259.6829 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m7/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9723 - loss: 0.0404\nEpoch 7: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9760 - loss: 0.0363 - val_accuracy: 0.4667 - val_loss: 59.4705 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0158 - val_accuracy: 0.4667 - val_loss: 34.3677 - learning_rate: 1.0000e-03\nEpoch 9/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9855 - loss: 0.0222 - val_accuracy: 0.4667 - val_loss: 24.2294 - learning_rate: 1.0000e-03\nEpoch 10/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0088 - val_accuracy: 0.4667 - val_loss: 17.2175 - learning_rate: 1.0000e-03\nEpoch 11/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0070 - val_accuracy: 0.5333 - val_loss: 11.6263 - learning_rate: 1.0000e-03\nEpoch 12/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0105 - val_accuracy: 0.5333 - val_loss: 7.5757 - learning_rate: 1.0000e-03\nEpoch 13/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0079 - val_accuracy: 0.5333 - val_loss: 4.6189 - learning_rate: 1.0000e-03\nEpoch 14/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0052 - val_accuracy: 0.5333 - val_loss: 2.8495 - learning_rate: 1.0000e-03\nEpoch 15/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0039 - val_accuracy: 0.6667 - val_loss: 2.0877 - learning_rate: 1.0000e-03\nEpoch 16/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0061 - val_accuracy: 0.6667 - val_loss: 1.7129 - learning_rate: 1.0000e-03\nEpoch 17/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0083 - val_accuracy: 0.6667 - val_loss: 1.6493 - learning_rate: 1.0000e-03\nEpoch 18/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0039 - val_accuracy: 0.6667 - val_loss: 1.4460 - learning_rate: 1.0000e-03\nEpoch 19/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0094 - val_accuracy: 0.7333 - val_loss: 1.2664 - learning_rate: 1.0000e-03\nEpoch 20/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0094 - val_accuracy: 0.7333 - val_loss: 0.9668 - learning_rate: 1.0000e-03\nEpoch 21/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9878 - loss: 0.0180 - val_accuracy: 0.8000 - val_loss: 0.8645 - learning_rate: 1.0000e-03\nEpoch 22/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 0.8667 - val_loss: 0.7771 - learning_rate: 1.0000e-03\nEpoch 23/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9945 - loss: 0.0122 - val_accuracy: 0.8667 - val_loss: 0.7016 - learning_rate: 1.0000e-03\nEpoch 24/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0023 - val_accuracy: 0.8667 - val_loss: 0.6534 - learning_rate: 1.0000e-03\nEpoch 25/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0050 - val_accuracy: 0.9333 - val_loss: 0.6208 - learning_rate: 1.0000e-03\nEpoch 26/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.9333 - val_loss: 0.6016 - learning_rate: 1.0000e-03\nEpoch 27/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0039 - val_accuracy: 0.9333 - val_loss: 0.5841 - learning_rate: 1.0000e-03\nEpoch 28/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.9333 - val_loss: 0.5646 - learning_rate: 1.0000e-03\nEpoch 29/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 0.9333 - val_loss: 0.5463 - learning_rate: 1.0000e-03\nEpoch 30/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0036 - val_accuracy: 0.9333 - val_loss: 0.5281 - learning_rate: 1.0000e-03\nEpoch 31/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.9333 - val_loss: 0.5151 - learning_rate: 1.0000e-03\nEpoch 32/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.9333 - val_loss: 0.5078 - learning_rate: 1.0000e-03\nEpoch 33/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.9333 - val_loss: 0.5055 - learning_rate: 1.0000e-03\nEpoch 34/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0023 - val_accuracy: 0.9333 - val_loss: 0.5016 - learning_rate: 1.0000e-03\nEpoch 35/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.9333 - val_loss: 0.5007 - learning_rate: 1.0000e-03\nEpoch 36/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.9333 - val_loss: 0.4971 - learning_rate: 1.0000e-03\nEpoch 37/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 0.9333 - val_loss: 0.4922 - learning_rate: 1.0000e-03\nEpoch 38/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.9333 - val_loss: 0.4893 - learning_rate: 1.0000e-03\nEpoch 39/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.9333 - val_loss: 0.4871 - learning_rate: 1.0000e-03\nEpoch 40/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.9333 - val_loss: 0.4864 - learning_rate: 1.0000e-03\nEpoch 41/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 9.5835e-04 - val_accuracy: 0.9333 - val_loss: 0.4850 - learning_rate: 1.0000e-03\nEpoch 42/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.9333 - val_loss: 0.4825 - learning_rate: 1.0000e-03\nEpoch 43/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.9333 - val_loss: 0.4811 - learning_rate: 1.0000e-03\nEpoch 44/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.9333 - val_loss: 0.4785 - learning_rate: 1.0000e-03\nEpoch 45/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 8.3462e-04 - val_accuracy: 0.9333 - val_loss: 0.4753 - learning_rate: 1.0000e-03\nEpoch 46/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 0.9333 - val_loss: 0.4681 - learning_rate: 1.0000e-03\nEpoch 47/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 8.4460e-04 - val_accuracy: 0.9333 - val_loss: 0.4626 - learning_rate: 1.0000e-03\nEpoch 48/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.9333 - val_loss: 0.4552 - learning_rate: 1.0000e-03\nEpoch 49/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.9333 - val_loss: 0.4494 - learning_rate: 1.0000e-03\nEpoch 50/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 9.2122e-04 - val_accuracy: 0.9333 - val_loss: 0.4498 - learning_rate: 1.0000e-03\nRestoring model weights from the end of the best epoch: 49.\nFold 5 - Train Accuracy: 100.00%, Validation Accuracy: 93.33%\n\nTraining on Fold 6...\nEpoch 1/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 762ms/step - accuracy: 0.6717 - loss: 1.1966 - val_accuracy: 0.4667 - val_loss: 3614.4275 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8561 - loss: 0.4010 - val_accuracy: 0.2667 - val_loss: 345.6579 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9098 - loss: 0.2026 - val_accuracy: 0.5333 - val_loss: 167.4444 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9624 - loss: 0.1183 - val_accuracy: 0.5333 - val_loss: 95.4086 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9668 - loss: 0.0754 - val_accuracy: 0.5333 - val_loss: 35.4747 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9842 - loss: 0.0530 - val_accuracy: 0.5333 - val_loss: 10.2827 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9777 - loss: 0.0627 - val_accuracy: 0.5333 - val_loss: 6.3157 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9977 - loss: 0.0384 - val_accuracy: 0.3333 - val_loss: 2.2337 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9977 - loss: 0.0174 - val_accuracy: 0.4000 - val_loss: 2.2173 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0141 - val_accuracy: 0.4667 - val_loss: 3.2752 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9783 - loss: 0.0352 - val_accuracy: 0.5333 - val_loss: 4.3769 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m7/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0068\nEpoch 12: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9977 - loss: 0.0120 - val_accuracy: 0.7333 - val_loss: 2.4426 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0062 - val_accuracy: 0.7333 - val_loss: 1.7223 - learning_rate: 1.0000e-03\nEpoch 14/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0058 - val_accuracy: 0.8667 - val_loss: 1.3436 - learning_rate: 1.0000e-03\nEpoch 15/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0076 - val_accuracy: 0.8667 - val_loss: 1.0805 - learning_rate: 1.0000e-03\nEpoch 16/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0067 - val_accuracy: 0.9333 - val_loss: 0.8693 - learning_rate: 1.0000e-03\nEpoch 17/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0043 - val_accuracy: 0.9333 - val_loss: 0.7113 - learning_rate: 1.0000e-03\nEpoch 18/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0046 - val_accuracy: 0.9333 - val_loss: 0.5562 - learning_rate: 1.0000e-03\nEpoch 19/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0031 - val_accuracy: 0.9333 - val_loss: 0.4615 - learning_rate: 1.0000e-03\nEpoch 20/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0043 - val_accuracy: 0.9333 - val_loss: 0.3651 - learning_rate: 1.0000e-03\nEpoch 21/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.9333 - val_loss: 0.2712 - learning_rate: 1.0000e-03\nEpoch 22/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0049 - val_accuracy: 0.9333 - val_loss: 0.2093 - learning_rate: 1.0000e-03\nEpoch 23/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.9333 - val_loss: 0.1486 - learning_rate: 1.0000e-03\nEpoch 24/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.9333 - val_loss: 0.0671 - learning_rate: 1.0000e-03\nEpoch 25/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 1.0000 - val_loss: 0.0307 - learning_rate: 1.0000e-03\nEpoch 26/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 1.0000 - val_loss: 0.0125 - learning_rate: 1.0000e-03\nEpoch 27/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 1.0000 - val_loss: 0.0056 - learning_rate: 1.0000e-03\nEpoch 28/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 1.0000 - val_loss: 0.0035 - learning_rate: 1.0000e-03\nEpoch 29/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 1.0000 - val_loss: 0.0028 - learning_rate: 1.0000e-03\nEpoch 30/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 1.0000 - val_loss: 0.0025 - learning_rate: 1.0000e-03\nEpoch 31/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 1.0000 - val_loss: 0.0022 - learning_rate: 1.0000e-03\nEpoch 32/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 1.0000 - val_loss: 0.0021 - learning_rate: 1.0000e-03\nEpoch 33/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 1.0000 - val_loss: 0.0022 - learning_rate: 1.0000e-03\nEpoch 34/50\n\u001b[1m7/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0013    \nEpoch 34: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0023 - val_accuracy: 1.0000 - val_loss: 0.0025 - learning_rate: 1.0000e-03\nEpoch 35/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 1.0000 - val_loss: 0.0030 - learning_rate: 1.0000e-04\nEpoch 36/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0035 - val_accuracy: 1.0000 - val_loss: 0.0036 - learning_rate: 1.0000e-04\nEpoch 37/50\n\u001b[1m7/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 9.4305e-04\nEpoch 37: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 1.0000 - val_loss: 0.0048 - learning_rate: 1.0000e-04\nEpoch 37: early stopping\nRestoring model weights from the end of the best epoch: 32.\nFold 6 - Train Accuracy: 97.74%, Validation Accuracy: 100.00%\n\nTraining on Fold 7...\nEpoch 1/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 767ms/step - accuracy: 0.7689 - loss: 0.9487 - val_accuracy: 0.5333 - val_loss: 3646.8135 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8375 - loss: 0.4361 - val_accuracy: 0.5333 - val_loss: 1631.9688 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9443 - loss: 0.1562 - val_accuracy: 0.5333 - val_loss: 95.2392 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9630 - loss: 0.0992 - val_accuracy: 0.4667 - val_loss: 229.8753 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9844 - loss: 0.0453 - val_accuracy: 0.4667 - val_loss: 80.3652 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0268 - val_accuracy: 0.4667 - val_loss: 56.1819 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0219 - val_accuracy: 0.4667 - val_loss: 39.8879 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0078 - val_accuracy: 0.4667 - val_loss: 32.3757 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0060 - val_accuracy: 0.5333 - val_loss: 11.9778 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0049 - val_accuracy: 0.6000 - val_loss: 4.1707 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.6000 - val_loss: 3.2083 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.7333 - val_loss: 2.0536 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9783 - loss: 0.0275 - val_accuracy: 0.6667 - val_loss: 2.4578 - learning_rate: 0.0100\nEpoch 14/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9777 - loss: 0.0407 - val_accuracy: 0.7333 - val_loss: 1.0755 - learning_rate: 0.0100\nEpoch 15/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9768 - loss: 0.0966 - val_accuracy: 0.6000 - val_loss: 5.5854 - learning_rate: 0.0100\nEpoch 16/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9379 - loss: 0.1863 - val_accuracy: 1.0000 - val_loss: 0.0299 - learning_rate: 0.0100\nEpoch 17/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9977 - loss: 0.0243 - val_accuracy: 0.6000 - val_loss: 4.1563 - learning_rate: 0.0100\nEpoch 18/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9945 - loss: 0.0270 - val_accuracy: 0.7333 - val_loss: 1.7820 - learning_rate: 0.0100\nEpoch 19/50\n\u001b[1m7/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0102\nEpoch 19: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0104 - val_accuracy: 0.8667 - val_loss: 0.6349 - learning_rate: 0.0100\nEpoch 20/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0100 - val_accuracy: 0.8667 - val_loss: 0.3338 - learning_rate: 1.0000e-03\nEpoch 21/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0086 - val_accuracy: 0.8667 - val_loss: 0.1670 - learning_rate: 1.0000e-03\nEpoch 21: early stopping\nRestoring model weights from the end of the best epoch: 16.\nFold 7 - Train Accuracy: 90.23%, Validation Accuracy: 100.00%\n\nTraining on Fold 8...\nEpoch 1/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 768ms/step - accuracy: 0.6014 - loss: 1.0826 - val_accuracy: 0.5333 - val_loss: 5205.0156 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9170 - loss: 0.2904 - val_accuracy: 0.4667 - val_loss: 3072.7756 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9564 - loss: 0.1106 - val_accuracy: 0.4667 - val_loss: 1160.0426 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9839 - loss: 0.0364 - val_accuracy: 0.4667 - val_loss: 485.4072 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9909 - loss: 0.0326 - val_accuracy: 0.4667 - val_loss: 289.2257 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9909 - loss: 0.0319 - val_accuracy: 0.4667 - val_loss: 143.5277 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9792 - loss: 0.0295 - val_accuracy: 0.4000 - val_loss: 40.3450 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0054 - val_accuracy: 0.4667 - val_loss: 27.2909 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 0.4667 - val_loss: 17.5357 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.5333 - val_loss: 7.8722 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 0.6000 - val_loss: 4.4673 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.6667 - val_loss: 2.5986 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.7333 - val_loss: 1.6147 - learning_rate: 0.0100\nEpoch 14/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 7.9640e-04 - val_accuracy: 0.8667 - val_loss: 1.2343 - learning_rate: 0.0100\nEpoch 15/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 8.4428e-04 - val_accuracy: 0.8667 - val_loss: 1.0670 - learning_rate: 0.0100\nEpoch 16/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 4.3774e-04 - val_accuracy: 0.8000 - val_loss: 1.0612 - learning_rate: 0.0100\nEpoch 17/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 0.8000 - val_loss: 0.9809 - learning_rate: 0.0100\nEpoch 18/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 4.5988e-04 - val_accuracy: 0.8000 - val_loss: 0.8816 - learning_rate: 0.0100\nEpoch 19/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 5.1100e-04 - val_accuracy: 0.8667 - val_loss: 0.8135 - learning_rate: 0.0100\nEpoch 20/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 2.2611e-04 - val_accuracy: 0.8667 - val_loss: 0.7517 - learning_rate: 0.0100\nEpoch 21/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 1.8408e-04 - val_accuracy: 0.8667 - val_loss: 0.6913 - learning_rate: 0.0100\nEpoch 22/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 4.9305e-04 - val_accuracy: 0.8667 - val_loss: 0.6622 - learning_rate: 0.0100\nEpoch 23/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 2.1483e-04 - val_accuracy: 0.8667 - val_loss: 0.6940 - learning_rate: 0.0100\nEpoch 24/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 1.8932e-04 - val_accuracy: 0.8667 - val_loss: 0.7638 - learning_rate: 0.0100\nEpoch 25/50\n\u001b[1m7/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 3.8096e-04\nEpoch 25: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 3.6251e-04 - val_accuracy: 0.8667 - val_loss: 0.7981 - learning_rate: 0.0100\nEpoch 26/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 7.2794e-04 - val_accuracy: 0.8667 - val_loss: 0.7881 - learning_rate: 1.0000e-03\nEpoch 27/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 1.9483e-04 - val_accuracy: 0.8667 - val_loss: 0.7578 - learning_rate: 1.0000e-03\nEpoch 27: early stopping\nRestoring model weights from the end of the best epoch: 22.\nFold 8 - Train Accuracy: 97.74%, Validation Accuracy: 86.67%\n\nTraining on Fold 9...\nEpoch 1/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1s/step - accuracy: 0.7010 - loss: 0.8866 - val_accuracy: 0.5000 - val_loss: 9161.7529 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8778 - loss: 0.4616 - val_accuracy: 0.5000 - val_loss: 4503.3022 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9670 - loss: 0.1262 - val_accuracy: 0.5000 - val_loss: 2504.0261 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9945 - loss: 0.0366 - val_accuracy: 0.5000 - val_loss: 951.7460 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9815 - loss: 0.0248 - val_accuracy: 0.5000 - val_loss: 435.9248 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0056 - val_accuracy: 0.5000 - val_loss: 225.2595 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0105 - val_accuracy: 0.5000 - val_loss: 124.2107 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0107 - val_accuracy: 0.5000 - val_loss: 66.5899 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0097 - val_accuracy: 0.5000 - val_loss: 40.0657 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 0.5000 - val_loss: 24.4561 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0043 - val_accuracy: 0.5714 - val_loss: 15.1804 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0123 - val_accuracy: 0.5714 - val_loss: 7.9592 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.6429 - val_loss: 3.7053 - learning_rate: 0.0100\nEpoch 14/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 9.0752e-04 - val_accuracy: 0.7143 - val_loss: 1.0451 - learning_rate: 0.0100\nEpoch 15/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0042 - val_accuracy: 0.7857 - val_loss: 0.4552 - learning_rate: 0.0100\nEpoch 16/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 8.7988e-04 - val_accuracy: 0.7143 - val_loss: 0.7438 - learning_rate: 0.0100\nEpoch 17/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 4.3384e-04 - val_accuracy: 0.7143 - val_loss: 1.0599 - learning_rate: 0.0100\nEpoch 18/50\n\u001b[1m7/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0026\nEpoch 18: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.7143 - val_loss: 0.8423 - learning_rate: 0.0100\nEpoch 19/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 2.2718e-04 - val_accuracy: 0.7143 - val_loss: 0.8245 - learning_rate: 1.0000e-03\nEpoch 20/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 2.7886e-04 - val_accuracy: 0.7857 - val_loss: 0.7708 - learning_rate: 1.0000e-03\nEpoch 20: early stopping\nRestoring model weights from the end of the best epoch: 15.\nFold 9 - Train Accuracy: 65.67%, Validation Accuracy: 78.57%\n\nTraining on Fold 10...\nEpoch 1/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 802ms/step - accuracy: 0.7340 - loss: 0.8674 - val_accuracy: 0.5000 - val_loss: 11946.4775 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8347 - loss: 0.5087 - val_accuracy: 0.5000 - val_loss: 11255.2051 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9245 - loss: 0.1939 - val_accuracy: 0.5000 - val_loss: 2254.7307 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9536 - loss: 0.0743 - val_accuracy: 0.5000 - val_loss: 364.9631 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9945 - loss: 0.0298 - val_accuracy: 0.5714 - val_loss: 23.3272 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9945 - loss: 0.0193 - val_accuracy: 0.5000 - val_loss: 57.5167 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0113 - val_accuracy: 0.5000 - val_loss: 47.2059 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0052 - val_accuracy: 0.5000 - val_loss: 20.3296 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0038 - val_accuracy: 0.5000 - val_loss: 8.7200 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0051 - val_accuracy: 0.5000 - val_loss: 3.2984 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0039 - val_accuracy: 0.5000 - val_loss: 2.2810 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 9.1255e-04 - val_accuracy: 0.6429 - val_loss: 1.4279 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.7857 - val_loss: 0.9072 - learning_rate: 0.0100\nEpoch 14/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9945 - loss: 0.0068 - val_accuracy: 0.7857 - val_loss: 0.5153 - learning_rate: 0.0100\nEpoch 15/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.8571 - val_loss: 0.4462 - learning_rate: 0.0100\nEpoch 16/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9909 - loss: 0.0110 - val_accuracy: 0.7143 - val_loss: 0.7698 - learning_rate: 0.0100\nEpoch 17/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 7.1177e-04 - val_accuracy: 0.6429 - val_loss: 1.0951 - learning_rate: 0.0100\nEpoch 18/50\n\u001b[1m7/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0043\nEpoch 18: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0043 - val_accuracy: 0.7857 - val_loss: 0.7033 - learning_rate: 0.0100\nEpoch 19/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.7857 - val_loss: 0.6231 - learning_rate: 1.0000e-03\nEpoch 20/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0060 - val_accuracy: 0.8571 - val_loss: 0.5632 - learning_rate: 1.0000e-03\nEpoch 20: early stopping\nRestoring model weights from the end of the best epoch: 15.\nFold 10 - Train Accuracy: 90.30%, Validation Accuracy: 85.71%\n\nAverage Training Accuracy: 87.33%\nAverage Validation Accuracy: 91.76%\n","output_type":"stream"}],"execution_count":91},{"cell_type":"markdown","source":"## 2.1 Flipping","metadata":{}},{"cell_type":"code","source":"X_train_flipped = np.flip(X_train, axis=2)\nX_test_flipped = np.flip(X_test, axis=2)\n\nX_train_augmented = np.concatenate((X_train, X_train_flipped), axis=0)\ny_train_augmented = np.concatenate((y_train, y_train), axis=0)\n\ntrain_evaluate_model_with_k_fold(\n    X_train=X_train_augmented,\n    y_train=y_train_augmented,\n    lr=0.01,\n    epochs=50,\n    batch_size=16)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T20:07:32.726250Z","iopub.execute_input":"2025-02-07T20:07:32.726603Z","iopub.status.idle":"2025-02-07T20:12:27.809953Z","shell.execute_reply.started":"2025-02-07T20:07:32.726574Z","shell.execute_reply":"2025-02-07T20:12:27.809138Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"\nTraining on Fold 1...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 587ms/step - accuracy: 0.7027 - loss: 1.3310 - val_accuracy: 0.5000 - val_loss: 16620.5059 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8934 - loss: 0.3664 - val_accuracy: 0.5000 - val_loss: 427.3303 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9478 - loss: 0.1739 - val_accuracy: 0.7667 - val_loss: 6.4587 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9412 - loss: 0.1210 - val_accuracy: 0.5000 - val_loss: 30.9617 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9833 - loss: 0.0664 - val_accuracy: 0.5333 - val_loss: 6.3170 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9857 - loss: 0.0385 - val_accuracy: 0.6333 - val_loss: 2.1121 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9832 - loss: 0.0373 - val_accuracy: 0.5667 - val_loss: 4.1205 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9958 - loss: 0.0289 - val_accuracy: 0.7667 - val_loss: 1.2864 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9813 - loss: 0.0309 - val_accuracy: 0.7333 - val_loss: 2.1451 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9751 - loss: 0.0596 - val_accuracy: 0.8000 - val_loss: 1.3798 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9888 - loss: 0.0416 - val_accuracy: 0.8000 - val_loss: 1.0002 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9821 - loss: 0.0496 - val_accuracy: 0.8000 - val_loss: 0.9705 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9828 - loss: 0.0752 - val_accuracy: 0.9000 - val_loss: 0.4471 - learning_rate: 0.0100\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9873 - loss: 0.0291 - val_accuracy: 0.8333 - val_loss: 0.5800 - learning_rate: 0.0100\nEpoch 15/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9715 - loss: 0.0484 - val_accuracy: 0.9333 - val_loss: 0.6710 - learning_rate: 0.0100\nEpoch 16/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9958 - loss: 0.0176 - val_accuracy: 0.9000 - val_loss: 0.3724 - learning_rate: 0.0100\nEpoch 17/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9915 - loss: 0.0285 - val_accuracy: 0.9333 - val_loss: 0.6232 - learning_rate: 0.0100\nEpoch 18/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9958 - loss: 0.0137 - val_accuracy: 0.9333 - val_loss: 0.4389 - learning_rate: 0.0100\nEpoch 19/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0066 - val_accuracy: 0.9667 - val_loss: 0.3089 - learning_rate: 0.0100\nEpoch 20/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 0.9333 - val_loss: 0.3173 - learning_rate: 0.0100\nEpoch 21/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 0.9333 - val_loss: 0.3239 - learning_rate: 0.0100\nEpoch 22/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.9333 - val_loss: 0.2683 - learning_rate: 0.0100\nEpoch 23/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 8.7328e-04 - val_accuracy: 0.9333 - val_loss: 0.2182 - learning_rate: 0.0100\nEpoch 24/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 8.0141e-04 - val_accuracy: 0.9333 - val_loss: 0.1689 - learning_rate: 0.0100\nEpoch 25/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 8.6493e-04 - val_accuracy: 0.9667 - val_loss: 0.1346 - learning_rate: 0.0100\nEpoch 26/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 7.8507e-04 - val_accuracy: 0.9667 - val_loss: 0.1179 - learning_rate: 0.0100\nEpoch 27/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0070 - val_accuracy: 0.9667 - val_loss: 0.4106 - learning_rate: 0.0100\nEpoch 28/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9937 - loss: 0.0173 - val_accuracy: 0.9333 - val_loss: 0.8180 - learning_rate: 0.0100\nEpoch 29/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9989 - loss: 0.0123\nEpoch 29: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9986 - loss: 0.0130 - val_accuracy: 0.9000 - val_loss: 1.2867 - learning_rate: 0.0100\nEpoch 30/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9931 - loss: 0.0312 - val_accuracy: 0.9333 - val_loss: 0.7785 - learning_rate: 1.0000e-03\nEpoch 31/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0051 - val_accuracy: 0.9333 - val_loss: 0.6175 - learning_rate: 1.0000e-03\nEpoch 31: early stopping\nRestoring model weights from the end of the best epoch: 26.\nFold 1 - Train Accuracy: 98.87%, Validation Accuracy: 96.67%\n\nTraining on Fold 2...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 419ms/step - accuracy: 0.7275 - loss: 0.9014 - val_accuracy: 0.5000 - val_loss: 1960.6597 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.9259 - loss: 0.2505 - val_accuracy: 0.5000 - val_loss: 193.4128 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9415 - loss: 0.1260 - val_accuracy: 0.5000 - val_loss: 108.3874 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9838 - loss: 0.0479 - val_accuracy: 0.8333 - val_loss: 3.5453 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9797 - loss: 0.0386 - val_accuracy: 0.8667 - val_loss: 1.4603 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9798 - loss: 0.0434 - val_accuracy: 0.6333 - val_loss: 4.1378 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9655 - loss: 0.0892 - val_accuracy: 0.9000 - val_loss: 1.3894 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9856 - loss: 0.0304 - val_accuracy: 0.6667 - val_loss: 3.2065 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9972 - loss: 0.0251 - val_accuracy: 0.6333 - val_loss: 2.4322 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9821 - loss: 0.0364\nEpoch 10: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9819 - loss: 0.0384 - val_accuracy: 0.6000 - val_loss: 4.5285 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9687 - loss: 0.1192 - val_accuracy: 0.7667 - val_loss: 1.5679 - learning_rate: 1.0000e-03\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9980 - loss: 0.0236 - val_accuracy: 0.8333 - val_loss: 0.6830 - learning_rate: 1.0000e-03\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0067 - val_accuracy: 0.8333 - val_loss: 0.3972 - learning_rate: 1.0000e-03\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0061 - val_accuracy: 0.8667 - val_loss: 0.2768 - learning_rate: 1.0000e-03\nEpoch 15/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0059 - val_accuracy: 0.9000 - val_loss: 0.2063 - learning_rate: 1.0000e-03\nEpoch 16/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 0.9000 - val_loss: 0.1504 - learning_rate: 1.0000e-03\nEpoch 17/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0039 - val_accuracy: 0.9333 - val_loss: 0.1183 - learning_rate: 1.0000e-03\nEpoch 18/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0036 - val_accuracy: 0.9333 - val_loss: 0.0973 - learning_rate: 1.0000e-03\nEpoch 19/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0031 - val_accuracy: 0.9333 - val_loss: 0.0758 - learning_rate: 1.0000e-03\nEpoch 20/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 0.9333 - val_loss: 0.0575 - learning_rate: 1.0000e-03\nEpoch 21/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 1.0000 - val_loss: 0.0472 - learning_rate: 1.0000e-03\nEpoch 22/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 1.0000 - val_loss: 0.0383 - learning_rate: 1.0000e-03\nEpoch 23/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 1.0000 - val_loss: 0.0297 - learning_rate: 1.0000e-03\nEpoch 24/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 1.0000 - val_loss: 0.0236 - learning_rate: 1.0000e-03\nEpoch 25/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0035 - val_accuracy: 1.0000 - val_loss: 0.0199 - learning_rate: 1.0000e-03\nEpoch 26/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0032 - val_accuracy: 1.0000 - val_loss: 0.0171 - learning_rate: 1.0000e-03\nEpoch 27/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 1.0000 - val_loss: 0.0164 - learning_rate: 1.0000e-03\nEpoch 28/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 1.0000 - val_loss: 0.0159 - learning_rate: 1.0000e-03\nEpoch 29/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 1.0000 - val_loss: 0.0147 - learning_rate: 1.0000e-03\nEpoch 30/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 1.0000 - val_loss: 0.0145 - learning_rate: 1.0000e-03\nEpoch 31/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 1.0000 - val_loss: 0.0150 - learning_rate: 1.0000e-03\nEpoch 32/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 1.0000 - val_loss: 0.0154 - learning_rate: 1.0000e-03\nEpoch 33/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0010    \nEpoch 33: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 1.0000 - val_loss: 0.0160 - learning_rate: 1.0000e-03\nEpoch 34/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 1.0000 - val_loss: 0.0166 - learning_rate: 1.0000e-04\nEpoch 35/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0023 - val_accuracy: 1.0000 - val_loss: 0.0168 - learning_rate: 1.0000e-04\nEpoch 35: early stopping\nRestoring model weights from the end of the best epoch: 30.\nFold 2 - Train Accuracy: 100.00%, Validation Accuracy: 100.00%\n\nTraining on Fold 3...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 416ms/step - accuracy: 0.7413 - loss: 1.0052 - val_accuracy: 0.5000 - val_loss: 321.9003 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9111 - loss: 0.2235 - val_accuracy: 0.4667 - val_loss: 53.7540 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9571 - loss: 0.1889 - val_accuracy: 0.3000 - val_loss: 11.3137 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9834 - loss: 0.0471 - val_accuracy: 0.6667 - val_loss: 3.8711 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9698 - loss: 0.0582 - val_accuracy: 0.6333 - val_loss: 4.9022 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9844 - loss: 0.0311 - val_accuracy: 0.7333 - val_loss: 1.2166 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9959 - loss: 0.0187 - val_accuracy: 0.7667 - val_loss: 1.0136 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9919 - loss: 0.0219 - val_accuracy: 0.8333 - val_loss: 0.7915 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9952 - loss: 0.0118 - val_accuracy: 0.8667 - val_loss: 0.5879 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9895 - loss: 0.0780 - val_accuracy: 0.9333 - val_loss: 0.6822 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9934 - loss: 0.0147 - val_accuracy: 1.0000 - val_loss: 0.0256 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9783 - loss: 0.0459 - val_accuracy: 0.7667 - val_loss: 1.4888 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9837 - loss: 0.0308 - val_accuracy: 0.8333 - val_loss: 0.9383 - learning_rate: 0.0100\nEpoch 14/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9718 - loss: 0.0585\nEpoch 14: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9728 - loss: 0.0568 - val_accuracy: 0.9333 - val_loss: 0.4212 - learning_rate: 0.0100\nEpoch 15/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9779 - loss: 0.0230 - val_accuracy: 0.9333 - val_loss: 0.1815 - learning_rate: 1.0000e-03\nEpoch 16/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9983 - loss: 0.0078 - val_accuracy: 0.9667 - val_loss: 0.0497 - learning_rate: 1.0000e-03\nEpoch 16: early stopping\nRestoring model weights from the end of the best epoch: 11.\nFold 3 - Train Accuracy: 83.83%, Validation Accuracy: 100.00%\n\nTraining on Fold 4...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 411ms/step - accuracy: 0.7313 - loss: 0.9982 - val_accuracy: 0.5000 - val_loss: 1036.3601 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.8500 - loss: 0.3436 - val_accuracy: 0.5000 - val_loss: 282.9016 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9068 - loss: 0.2196 - val_accuracy: 0.5000 - val_loss: 79.3200 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9374 - loss: 0.1556 - val_accuracy: 0.5000 - val_loss: 47.8281 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9532 - loss: 0.1009 - val_accuracy: 0.5000 - val_loss: 40.5223 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9639 - loss: 0.0695 - val_accuracy: 0.5333 - val_loss: 41.6773 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9593 - loss: 0.0971 - val_accuracy: 0.5333 - val_loss: 10.7694 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9830 - loss: 0.0859 - val_accuracy: 0.8333 - val_loss: 0.4875 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9609 - loss: 0.0855 - val_accuracy: 0.8000 - val_loss: 0.8538 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9747 - loss: 0.0511 - val_accuracy: 0.7667 - val_loss: 0.7994 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9943 - loss: 0.0277\nEpoch 11: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9941 - loss: 0.0275 - val_accuracy: 0.7667 - val_loss: 1.2644 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9728 - loss: 0.0605 - val_accuracy: 0.8667 - val_loss: 0.5261 - learning_rate: 1.0000e-03\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9977 - loss: 0.0144 - val_accuracy: 0.9000 - val_loss: 0.3659 - learning_rate: 1.0000e-03\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9942 - loss: 0.0165 - val_accuracy: 0.9000 - val_loss: 0.3638 - learning_rate: 1.0000e-03\nEpoch 15/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0099 - val_accuracy: 0.9000 - val_loss: 0.3791 - learning_rate: 1.0000e-03\nEpoch 16/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0102 - val_accuracy: 0.9000 - val_loss: 0.3636 - learning_rate: 1.0000e-03\nEpoch 17/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0065 - val_accuracy: 0.9000 - val_loss: 0.3450 - learning_rate: 1.0000e-03\nEpoch 18/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9977 - loss: 0.0114 - val_accuracy: 0.9000 - val_loss: 0.4096 - learning_rate: 1.0000e-03\nEpoch 19/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0069 - val_accuracy: 0.8667 - val_loss: 0.4033 - learning_rate: 1.0000e-03\nEpoch 20/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0083 - val_accuracy: 0.8667 - val_loss: 0.3299 - learning_rate: 1.0000e-03\nEpoch 21/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0076 - val_accuracy: 0.8667 - val_loss: 0.3043 - learning_rate: 1.0000e-03\nEpoch 22/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0069 - val_accuracy: 0.8667 - val_loss: 0.2867 - learning_rate: 1.0000e-03\nEpoch 23/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0037 - val_accuracy: 0.9000 - val_loss: 0.2860 - learning_rate: 1.0000e-03\nEpoch 24/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0040 - val_accuracy: 0.9000 - val_loss: 0.3214 - learning_rate: 1.0000e-03\nEpoch 25/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0071 - val_accuracy: 0.9000 - val_loss: 0.3017 - learning_rate: 1.0000e-03\nEpoch 26/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0060\nEpoch 26: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0060 - val_accuracy: 0.9000 - val_loss: 0.3307 - learning_rate: 1.0000e-03\nEpoch 27/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0041 - val_accuracy: 0.9000 - val_loss: 0.3310 - learning_rate: 1.0000e-04\nEpoch 28/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0046 - val_accuracy: 0.9000 - val_loss: 0.3431 - learning_rate: 1.0000e-04\nEpoch 28: early stopping\nRestoring model weights from the end of the best epoch: 23.\nFold 4 - Train Accuracy: 98.50%, Validation Accuracy: 90.00%\n\nTraining on Fold 5...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 414ms/step - accuracy: 0.7724 - loss: 0.7265 - val_accuracy: 0.5000 - val_loss: 852.1312 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8633 - loss: 0.2694 - val_accuracy: 0.5000 - val_loss: 538.6650 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9373 - loss: 0.1387 - val_accuracy: 0.5667 - val_loss: 43.1859 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9753 - loss: 0.0790 - val_accuracy: 0.5333 - val_loss: 18.3740 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9846 - loss: 0.0568 - val_accuracy: 0.8333 - val_loss: 1.7281 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9769 - loss: 0.0569 - val_accuracy: 0.7667 - val_loss: 1.5927 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9798 - loss: 0.0437 - val_accuracy: 0.7333 - val_loss: 1.5111 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9789 - loss: 0.0568 - val_accuracy: 0.7000 - val_loss: 1.8700 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9938 - loss: 0.0458 - val_accuracy: 0.9333 - val_loss: 0.3278 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9983 - loss: 0.0316 - val_accuracy: 0.9000 - val_loss: 0.4695 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9765 - loss: 0.0696 - val_accuracy: 0.7333 - val_loss: 1.4645 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9938 - loss: 0.0188 - val_accuracy: 0.9333 - val_loss: 0.2075 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9693 - loss: 0.1357 - val_accuracy: 0.8000 - val_loss: 1.2899 - learning_rate: 0.0100\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9728 - loss: 0.0582 - val_accuracy: 0.9333 - val_loss: 0.1870 - learning_rate: 0.0100\nEpoch 15/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9815 - loss: 0.0478 - val_accuracy: 0.9333 - val_loss: 0.1246 - learning_rate: 0.0100\nEpoch 16/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9906 - loss: 0.0189 - val_accuracy: 0.9000 - val_loss: 0.3572 - learning_rate: 0.0100\nEpoch 17/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0048 - val_accuracy: 0.9667 - val_loss: 0.1284 - learning_rate: 0.0100\nEpoch 18/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0039\nEpoch 18: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0038 - val_accuracy: 0.9667 - val_loss: 0.1486 - learning_rate: 0.0100\nEpoch 19/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.9667 - val_loss: 0.1392 - learning_rate: 1.0000e-03\nEpoch 20/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.9667 - val_loss: 0.1319 - learning_rate: 1.0000e-03\nEpoch 20: early stopping\nRestoring model weights from the end of the best epoch: 15.\nFold 5 - Train Accuracy: 95.86%, Validation Accuracy: 93.33%\n\nTraining on Fold 6...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 410ms/step - accuracy: 0.7035 - loss: 0.8208 - val_accuracy: 0.5000 - val_loss: 1159.8646 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.9384 - loss: 0.1623 - val_accuracy: 0.5000 - val_loss: 460.0631 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9614 - loss: 0.0878 - val_accuracy: 0.7333 - val_loss: 4.9971 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9890 - loss: 0.0451 - val_accuracy: 0.5000 - val_loss: 25.8830 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9459 - loss: 0.1100 - val_accuracy: 0.6000 - val_loss: 9.7861 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9743 - loss: 0.1125\nEpoch 6: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9730 - loss: 0.1152 - val_accuracy: 0.5333 - val_loss: 19.2874 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9848 - loss: 0.0422 - val_accuracy: 0.5333 - val_loss: 6.6809 - learning_rate: 1.0000e-03\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9934 - loss: 0.0291 - val_accuracy: 0.6000 - val_loss: 2.5047 - learning_rate: 1.0000e-03\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9940 - loss: 0.0237 - val_accuracy: 0.8000 - val_loss: 1.0468 - learning_rate: 1.0000e-03\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9951 - loss: 0.0211 - val_accuracy: 0.8667 - val_loss: 0.4761 - learning_rate: 1.0000e-03\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9983 - loss: 0.0149 - val_accuracy: 0.8667 - val_loss: 0.3204 - learning_rate: 1.0000e-03\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9969 - loss: 0.0126 - val_accuracy: 0.9000 - val_loss: 0.3143 - learning_rate: 1.0000e-03\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0086 - val_accuracy: 0.9000 - val_loss: 0.3760 - learning_rate: 1.0000e-03\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0075 - val_accuracy: 0.9000 - val_loss: 0.4447 - learning_rate: 1.0000e-03\nEpoch 15/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0052\nEpoch 15: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0055 - val_accuracy: 0.9000 - val_loss: 0.4761 - learning_rate: 1.0000e-03\nEpoch 16/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0072 - val_accuracy: 0.9000 - val_loss: 0.4825 - learning_rate: 1.0000e-04\nEpoch 17/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9986 - loss: 0.0088 - val_accuracy: 0.9000 - val_loss: 0.4765 - learning_rate: 1.0000e-04\nEpoch 17: early stopping\nRestoring model weights from the end of the best epoch: 12.\nFold 6 - Train Accuracy: 96.62%, Validation Accuracy: 90.00%\n\nTraining on Fold 7...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 648ms/step - accuracy: 0.6803 - loss: 1.3878 - val_accuracy: 0.4828 - val_loss: 14831.5273 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8948 - loss: 0.3442 - val_accuracy: 0.5172 - val_loss: 543.3107 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9290 - loss: 0.2448 - val_accuracy: 0.5172 - val_loss: 186.9715 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9188 - loss: 0.1818 - val_accuracy: 0.5172 - val_loss: 40.1445 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9538 - loss: 0.1089 - val_accuracy: 0.5172 - val_loss: 25.0545 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9945 - loss: 0.0501 - val_accuracy: 0.4828 - val_loss: 9.1966 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9983 - loss: 0.0276 - val_accuracy: 0.4828 - val_loss: 6.9879 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9901 - loss: 0.0321 - val_accuracy: 0.5862 - val_loss: 3.4000 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9890 - loss: 0.0354 - val_accuracy: 0.6207 - val_loss: 4.4053 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9787 - loss: 0.0649 - val_accuracy: 0.7241 - val_loss: 2.6660 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9620 - loss: 0.0997 - val_accuracy: 0.5172 - val_loss: 8.6096 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9604 - loss: 0.1355 - val_accuracy: 0.7586 - val_loss: 1.8325 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9760 - loss: 0.0591 - val_accuracy: 0.7931 - val_loss: 0.9336 - learning_rate: 0.0100\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9878 - loss: 0.0529 - val_accuracy: 0.7241 - val_loss: 2.0851 - learning_rate: 0.0100\nEpoch 15/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0252 - val_accuracy: 1.0000 - val_loss: 0.0270 - learning_rate: 0.0100\nEpoch 16/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9964 - loss: 0.0176 - val_accuracy: 0.7931 - val_loss: 1.1161 - learning_rate: 0.0100\nEpoch 17/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9914 - loss: 0.0221 - val_accuracy: 1.0000 - val_loss: 0.0236 - learning_rate: 0.0100\nEpoch 18/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9808 - loss: 0.0434 - val_accuracy: 0.8621 - val_loss: 0.6437 - learning_rate: 0.0100\nEpoch 19/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9888 - loss: 0.0280 - val_accuracy: 0.8621 - val_loss: 0.3904 - learning_rate: 0.0100\nEpoch 20/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9826 - loss: 0.0392\nEpoch 20: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9820 - loss: 0.0395 - val_accuracy: 0.8621 - val_loss: 0.3324 - learning_rate: 0.0100\nEpoch 21/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9968 - loss: 0.0078 - val_accuracy: 0.8966 - val_loss: 0.2192 - learning_rate: 1.0000e-03\nEpoch 22/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9931 - loss: 0.0118 - val_accuracy: 0.9310 - val_loss: 0.1293 - learning_rate: 1.0000e-03\nEpoch 22: early stopping\nRestoring model weights from the end of the best epoch: 17.\nFold 7 - Train Accuracy: 98.13%, Validation Accuracy: 100.00%\n\nTraining on Fold 8...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 415ms/step - accuracy: 0.7922 - loss: 0.6227 - val_accuracy: 0.4138 - val_loss: 252.6774 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.9411 - loss: 0.1330 - val_accuracy: 0.4828 - val_loss: 329.9691 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9778 - loss: 0.0476 - val_accuracy: 0.5172 - val_loss: 62.8196 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9916 - loss: 0.0287 - val_accuracy: 0.5172 - val_loss: 18.7114 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9930 - loss: 0.0268 - val_accuracy: 0.6207 - val_loss: 2.8108 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9964 - loss: 0.0113 - val_accuracy: 0.5517 - val_loss: 5.5355 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9931 - loss: 0.0154 - val_accuracy: 0.5517 - val_loss: 3.8799 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0063 - val_accuracy: 0.7931 - val_loss: 1.1057 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0041 - val_accuracy: 0.7241 - val_loss: 2.2098 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.6897 - val_loss: 2.1121 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9925 - loss: 0.0175\nEpoch 11: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9921 - loss: 0.0178 - val_accuracy: 0.8621 - val_loss: 1.9091 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9983 - loss: 0.0139 - val_accuracy: 0.8276 - val_loss: 1.8961 - learning_rate: 1.0000e-03\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9983 - loss: 0.0060 - val_accuracy: 0.8276 - val_loss: 1.8547 - learning_rate: 1.0000e-03\nEpoch 13: early stopping\nRestoring model weights from the end of the best epoch: 8.\nFold 8 - Train Accuracy: 61.80%, Validation Accuracy: 79.31%\n\nTraining on Fold 9...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 417ms/step - accuracy: 0.7600 - loss: 0.8179 - val_accuracy: 0.5172 - val_loss: 677.0947 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9319 - loss: 0.1718 - val_accuracy: 0.5172 - val_loss: 127.7192 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9569 - loss: 0.1074 - val_accuracy: 0.4828 - val_loss: 10.7426 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9724 - loss: 0.0581 - val_accuracy: 0.4828 - val_loss: 5.0490 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9883 - loss: 0.0379 - val_accuracy: 0.4828 - val_loss: 5.2252 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9973 - loss: 0.0191 - val_accuracy: 0.5517 - val_loss: 2.6785 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9854 - loss: 0.0229 - val_accuracy: 0.7931 - val_loss: 1.5825 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9881 - loss: 0.0262 - val_accuracy: 0.7931 - val_loss: 0.7501 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9881 - loss: 0.0306 - val_accuracy: 0.8276 - val_loss: 0.9315 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9932 - loss: 0.0357 - val_accuracy: 0.9310 - val_loss: 0.6435 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9845 - loss: 0.0297 - val_accuracy: 0.8276 - val_loss: 1.0861 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9973 - loss: 0.0149 - val_accuracy: 0.8966 - val_loss: 0.6240 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9960 - loss: 0.0249 - val_accuracy: 0.9310 - val_loss: 0.8474 - learning_rate: 0.0100\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9938 - loss: 0.0103 - val_accuracy: 0.9310 - val_loss: 0.2575 - learning_rate: 0.0100\nEpoch 15/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9969 - loss: 0.0142 - val_accuracy: 0.9310 - val_loss: 0.4247 - learning_rate: 0.0100\nEpoch 16/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9915 - loss: 0.0201 - val_accuracy: 0.9310 - val_loss: 0.2878 - learning_rate: 0.0100\nEpoch 17/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9961 - loss: 0.0073 \nEpoch 17: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9957 - loss: 0.0089 - val_accuracy: 0.9310 - val_loss: 0.4483 - learning_rate: 0.0100\nEpoch 18/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0051 - val_accuracy: 0.9310 - val_loss: 0.3753 - learning_rate: 1.0000e-03\nEpoch 19/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.9655 - val_loss: 0.3142 - learning_rate: 1.0000e-03\nEpoch 19: early stopping\nRestoring model weights from the end of the best epoch: 14.\nFold 9 - Train Accuracy: 98.13%, Validation Accuracy: 93.10%\n\nTraining on Fold 10...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 410ms/step - accuracy: 0.7854 - loss: 0.7082 - val_accuracy: 0.4828 - val_loss: 9705.5928 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.8391 - loss: 0.3779 - val_accuracy: 0.5172 - val_loss: 161.1179 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9239 - loss: 0.1830 - val_accuracy: 0.4828 - val_loss: 76.9329 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9700 - loss: 0.0868 - val_accuracy: 0.5172 - val_loss: 8.8986 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9783 - loss: 0.0718 - val_accuracy: 0.4828 - val_loss: 7.0644 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0244 - val_accuracy: 0.5172 - val_loss: 8.1642 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0130 - val_accuracy: 0.5517 - val_loss: 4.2839 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9898 - loss: 0.0388 - val_accuracy: 0.8621 - val_loss: 1.4607 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9732 - loss: 0.0834 - val_accuracy: 0.7241 - val_loss: 1.8758 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9670 - loss: 0.0889 - val_accuracy: 0.6897 - val_loss: 2.3471 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9859 - loss: 0.0627 - val_accuracy: 0.7586 - val_loss: 1.0156 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9822 - loss: 0.0474 - val_accuracy: 0.8621 - val_loss: 0.2683 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9894 - loss: 0.0499 - val_accuracy: 0.8966 - val_loss: 0.4822 - learning_rate: 0.0100\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9812 - loss: 0.0437 - val_accuracy: 0.9655 - val_loss: 0.4538 - learning_rate: 0.0100\nEpoch 15/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9901 - loss: 0.0343\nEpoch 15: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9899 - loss: 0.0345 - val_accuracy: 0.8966 - val_loss: 0.5675 - learning_rate: 0.0100\nEpoch 16/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9983 - loss: 0.0126 - val_accuracy: 0.9655 - val_loss: 0.1227 - learning_rate: 1.0000e-03\nEpoch 17/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0079 - val_accuracy: 0.9655 - val_loss: 0.0568 - learning_rate: 1.0000e-03\nEpoch 18/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0082 - val_accuracy: 0.9655 - val_loss: 0.0758 - learning_rate: 1.0000e-03\nEpoch 19/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0073 - val_accuracy: 0.9655 - val_loss: 0.0869 - learning_rate: 1.0000e-03\nEpoch 20/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0053\nEpoch 20: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0053 - val_accuracy: 0.9655 - val_loss: 0.0862 - learning_rate: 1.0000e-03\nEpoch 21/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0046 - val_accuracy: 0.9655 - val_loss: 0.0766 - learning_rate: 1.0000e-04\nEpoch 22/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0039 - val_accuracy: 0.9655 - val_loss: 0.0684 - learning_rate: 1.0000e-04\nEpoch 22: early stopping\nRestoring model weights from the end of the best epoch: 17.\nFold 10 - Train Accuracy: 100.00%, Validation Accuracy: 96.55%\n\nAverage Training Accuracy: 93.17%\nAverage Validation Accuracy: 93.90%\n","output_type":"stream"}],"execution_count":92},{"cell_type":"markdown","source":"## 2.2 Rotating 90 degrees","metadata":{}},{"cell_type":"code","source":"X_train_rotated = np.rot90(X_train, k=1, axes=(1,2))\nX_test_rotated = np.rot90(X_test, k=1, axes=(1,2))\n\nX_train_augmented = np.concatenate((X_train, X_train_rotated), axis=0)\ny_train_augmented = np.concatenate((y_train, y_train), axis=0)\n\ntrain_evaluate_model_with_k_fold(\n    X_train=X_train_augmented,\n    y_train=y_train_augmented,\n    lr=0.01,\n    epochs=50,\n    batch_size=16)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T20:12:27.811225Z","iopub.execute_input":"2025-02-07T20:12:27.811503Z","iopub.status.idle":"2025-02-07T20:17:38.216602Z","shell.execute_reply.started":"2025-02-07T20:12:27.811481Z","shell.execute_reply":"2025-02-07T20:17:38.215799Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"\nTraining on Fold 1...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 417ms/step - accuracy: 0.6361 - loss: 1.2447 - val_accuracy: 0.5000 - val_loss: 4839.6313 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8952 - loss: 0.2765 - val_accuracy: 0.5000 - val_loss: 1245.4366 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9409 - loss: 0.1635 - val_accuracy: 0.5000 - val_loss: 204.4291 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9410 - loss: 0.1255 - val_accuracy: 0.5000 - val_loss: 54.3854 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9684 - loss: 0.0888 - val_accuracy: 0.5000 - val_loss: 22.5367 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9722 - loss: 0.0923 - val_accuracy: 0.5333 - val_loss: 13.4147 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9915 - loss: 0.0482 - val_accuracy: 0.7333 - val_loss: 1.8227 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9838 - loss: 0.0417 - val_accuracy: 0.8000 - val_loss: 1.8836 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9828 - loss: 0.0449 - val_accuracy: 0.9667 - val_loss: 0.0355 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9757 - loss: 0.0798 - val_accuracy: 0.8000 - val_loss: 1.1263 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9653 - loss: 0.0690 - val_accuracy: 0.9000 - val_loss: 0.8889 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9856 - loss: 0.0492\nEpoch 12: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9839 - loss: 0.0527 - val_accuracy: 0.9000 - val_loss: 0.5334 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9595 - loss: 0.1061 - val_accuracy: 0.7000 - val_loss: 1.0600 - learning_rate: 1.0000e-03\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9718 - loss: 0.0459 - val_accuracy: 0.8333 - val_loss: 0.5079 - learning_rate: 1.0000e-03\nEpoch 14: early stopping\nRestoring model weights from the end of the best epoch: 9.\nFold 1 - Train Accuracy: 89.85%, Validation Accuracy: 96.67%\n\nTraining on Fold 2...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 417ms/step - accuracy: 0.7120 - loss: 0.9730 - val_accuracy: 0.5000 - val_loss: 1991.7644 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.8461 - loss: 0.3232 - val_accuracy: 0.5000 - val_loss: 292.3757 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9233 - loss: 0.2093 - val_accuracy: 0.5000 - val_loss: 157.4633 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9392 - loss: 0.1256 - val_accuracy: 0.5000 - val_loss: 41.4227 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9580 - loss: 0.0870 - val_accuracy: 0.5667 - val_loss: 11.3872 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9810 - loss: 0.0445 - val_accuracy: 0.5667 - val_loss: 14.0562 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9899 - loss: 0.0279 - val_accuracy: 0.7000 - val_loss: 1.8718 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9648 - loss: 0.0848 - val_accuracy: 0.8333 - val_loss: 1.0863 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9810 - loss: 0.0515 - val_accuracy: 0.9333 - val_loss: 0.0832 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9739 - loss: 0.1116 - val_accuracy: 0.8667 - val_loss: 0.6277 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9482 - loss: 0.1277 - val_accuracy: 0.9667 - val_loss: 0.0526 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9839 - loss: 0.0492 - val_accuracy: 0.9667 - val_loss: 0.0544 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9834 - loss: 0.0485 - val_accuracy: 1.0000 - val_loss: 0.0428 - learning_rate: 0.0100\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9810 - loss: 0.0522 - val_accuracy: 0.9667 - val_loss: 0.1681 - learning_rate: 0.0100\nEpoch 15/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9747 - loss: 0.0528 - val_accuracy: 0.9667 - val_loss: 0.6010 - learning_rate: 0.0100\nEpoch 16/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9956 - loss: 0.0235\nEpoch 16: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9952 - loss: 0.0233 - val_accuracy: 0.9667 - val_loss: 0.2127 - learning_rate: 0.0100\nEpoch 17/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0087 - val_accuracy: 0.9667 - val_loss: 0.2069 - learning_rate: 1.0000e-03\nEpoch 18/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0051 - val_accuracy: 0.9667 - val_loss: 0.2055 - learning_rate: 1.0000e-03\nEpoch 18: early stopping\nRestoring model weights from the end of the best epoch: 13.\nFold 2 - Train Accuracy: 98.12%, Validation Accuracy: 100.00%\n\nTraining on Fold 3...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 414ms/step - accuracy: 0.6849 - loss: 1.0669 - val_accuracy: 0.5000 - val_loss: 1187.1964 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8933 - loss: 0.3032 - val_accuracy: 0.5000 - val_loss: 233.9431 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9563 - loss: 0.1137 - val_accuracy: 0.5000 - val_loss: 73.1968 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9598 - loss: 0.0986 - val_accuracy: 0.5000 - val_loss: 36.9917 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9652 - loss: 0.1139 - val_accuracy: 0.5000 - val_loss: 20.9795 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9783 - loss: 0.0566 - val_accuracy: 0.7333 - val_loss: 3.4409 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9859 - loss: 0.0337 - val_accuracy: 0.6000 - val_loss: 7.8507 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9825 - loss: 0.0628 - val_accuracy: 0.6000 - val_loss: 2.8036 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9904 - loss: 0.0335 - val_accuracy: 0.6333 - val_loss: 7.5293 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9896 - loss: 0.0300 - val_accuracy: 0.7667 - val_loss: 3.1352 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9899 - loss: 0.0406\nEpoch 11: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9898 - loss: 0.0412 - val_accuracy: 0.6333 - val_loss: 4.2462 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9851 - loss: 0.0329 - val_accuracy: 0.7333 - val_loss: 2.5814 - learning_rate: 1.0000e-03\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0122 - val_accuracy: 0.8000 - val_loss: 1.3988 - learning_rate: 1.0000e-03\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9986 - loss: 0.0109 - val_accuracy: 0.8667 - val_loss: 0.8145 - learning_rate: 1.0000e-03\nEpoch 15/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0078 - val_accuracy: 0.9000 - val_loss: 0.4846 - learning_rate: 1.0000e-03\nEpoch 16/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0055 - val_accuracy: 0.9000 - val_loss: 0.2851 - learning_rate: 1.0000e-03\nEpoch 17/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0035 - val_accuracy: 0.9000 - val_loss: 0.1879 - learning_rate: 1.0000e-03\nEpoch 18/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0043 - val_accuracy: 0.9333 - val_loss: 0.1264 - learning_rate: 1.0000e-03\nEpoch 19/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0031 - val_accuracy: 0.9667 - val_loss: 0.0825 - learning_rate: 1.0000e-03\nEpoch 20/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0034 - val_accuracy: 0.9667 - val_loss: 0.0620 - learning_rate: 1.0000e-03\nEpoch 21/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 1.0000 - val_loss: 0.0437 - learning_rate: 1.0000e-03\nEpoch 22/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 1.0000 - val_loss: 0.0285 - learning_rate: 1.0000e-03\nEpoch 23/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9983 - loss: 0.0035 - val_accuracy: 1.0000 - val_loss: 0.0282 - learning_rate: 1.0000e-03\nEpoch 24/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 1.0000 - val_loss: 0.0319 - learning_rate: 1.0000e-03\nEpoch 25/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0053 - val_accuracy: 1.0000 - val_loss: 0.0326 - learning_rate: 1.0000e-03\nEpoch 26/50\n\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0019\nEpoch 26: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 1.0000 - val_loss: 0.0285 - learning_rate: 1.0000e-03\nEpoch 27/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 1.0000 - val_loss: 0.0271 - learning_rate: 1.0000e-04\nEpoch 28/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 1.0000 - val_loss: 0.0257 - learning_rate: 1.0000e-04\nEpoch 29/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 1.0000 - val_loss: 0.0239 - learning_rate: 1.0000e-04\nEpoch 30/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 1.0000 - val_loss: 0.0219 - learning_rate: 1.0000e-04\nEpoch 31/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 1.0000 - val_loss: 0.0215 - learning_rate: 1.0000e-04\nEpoch 32/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 1.0000 - val_loss: 0.0214 - learning_rate: 1.0000e-04\nEpoch 33/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 1.0000 - val_loss: 0.0212 - learning_rate: 1.0000e-04\nEpoch 34/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 1.0000 - val_loss: 0.0210 - learning_rate: 1.0000e-04\nEpoch 35/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 1.0000 - val_loss: 0.0215 - learning_rate: 1.0000e-04\nEpoch 36/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 1.0000 - val_loss: 0.0214 - learning_rate: 1.0000e-04\nEpoch 37/50\n\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0011    \nEpoch 37: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 1.0000 - val_loss: 0.0210 - learning_rate: 1.0000e-04\nEpoch 38/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 1.0000 - val_loss: 0.0209 - learning_rate: 1.0000e-05\nEpoch 39/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 1.0000 - val_loss: 0.0210 - learning_rate: 1.0000e-05\nEpoch 40/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 1.0000 - val_loss: 0.0207 - learning_rate: 1.0000e-05\nEpoch 41/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 1.0000 - val_loss: 0.0203 - learning_rate: 1.0000e-05\nEpoch 42/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 1.0000 - val_loss: 0.0208 - learning_rate: 1.0000e-05\nEpoch 43/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 1.0000 - val_loss: 0.0209 - learning_rate: 1.0000e-05\nEpoch 44/50\n\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0014  \nEpoch 44: ReduceLROnPlateau reducing learning rate to 9.99999883788405e-07.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 1.0000 - val_loss: 0.0208 - learning_rate: 1.0000e-05\nEpoch 45/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 1.0000 - val_loss: 0.0209 - learning_rate: 1.0000e-06\nEpoch 46/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 1.0000 - val_loss: 0.0209 - learning_rate: 1.0000e-06\nEpoch 46: early stopping\nRestoring model weights from the end of the best epoch: 41.\nFold 3 - Train Accuracy: 99.62%, Validation Accuracy: 100.00%\n\nTraining on Fold 4...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 414ms/step - accuracy: 0.6296 - loss: 1.4729 - val_accuracy: 0.5000 - val_loss: 1828.9956 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.8734 - loss: 0.3453 - val_accuracy: 0.5000 - val_loss: 395.3312 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9043 - loss: 0.2053 - val_accuracy: 0.4667 - val_loss: 21.4848 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9421 - loss: 0.1194 - val_accuracy: 0.4667 - val_loss: 9.5101 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9618 - loss: 0.1012 - val_accuracy: 0.5000 - val_loss: 14.7918 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9754 - loss: 0.0642 - val_accuracy: 0.5000 - val_loss: 9.0522 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9609 - loss: 0.0896 - val_accuracy: 0.5000 - val_loss: 6.7473 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9619 - loss: 0.1012 - val_accuracy: 0.5000 - val_loss: 7.4273 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9498 - loss: 0.1262 - val_accuracy: 0.5333 - val_loss: 2.8312 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9479 - loss: 0.1291 - val_accuracy: 0.5667 - val_loss: 2.3945 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9897 - loss: 0.0417 - val_accuracy: 0.6667 - val_loss: 2.7764 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9766 - loss: 0.0512 - val_accuracy: 0.8000 - val_loss: 0.5087 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9621 - loss: 0.0568 - val_accuracy: 0.8333 - val_loss: 0.6599 - learning_rate: 0.0100\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9826 - loss: 0.0531 - val_accuracy: 0.7000 - val_loss: 1.5904 - learning_rate: 0.0100\nEpoch 15/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9689 - loss: 0.0616\nEpoch 15: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9686 - loss: 0.0621 - val_accuracy: 0.8000 - val_loss: 0.8471 - learning_rate: 0.0100\nEpoch 16/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9731 - loss: 0.0648 - val_accuracy: 0.8333 - val_loss: 0.5881 - learning_rate: 1.0000e-03\nEpoch 17/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9791 - loss: 0.0609 - val_accuracy: 0.9333 - val_loss: 0.3583 - learning_rate: 1.0000e-03\nEpoch 18/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9942 - loss: 0.0182 - val_accuracy: 0.9333 - val_loss: 0.2859 - learning_rate: 1.0000e-03\nEpoch 19/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9876 - loss: 0.0258 - val_accuracy: 0.9333 - val_loss: 0.2677 - learning_rate: 1.0000e-03\nEpoch 20/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0127 - val_accuracy: 0.9333 - val_loss: 0.2502 - learning_rate: 1.0000e-03\nEpoch 21/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0133 - val_accuracy: 0.9333 - val_loss: 0.2628 - learning_rate: 1.0000e-03\nEpoch 22/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9996 - loss: 0.0094 - val_accuracy: 0.9333 - val_loss: 0.2519 - learning_rate: 1.0000e-03\nEpoch 23/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0068\nEpoch 23: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0069 - val_accuracy: 0.9333 - val_loss: 0.2771 - learning_rate: 1.0000e-03\nEpoch 24/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0052 - val_accuracy: 0.9333 - val_loss: 0.2549 - learning_rate: 1.0000e-04\nEpoch 25/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0100 - val_accuracy: 0.9333 - val_loss: 0.2358 - learning_rate: 1.0000e-04\nEpoch 26/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0105 - val_accuracy: 0.9333 - val_loss: 0.2153 - learning_rate: 1.0000e-04\nEpoch 27/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0063 - val_accuracy: 0.9333 - val_loss: 0.1977 - learning_rate: 1.0000e-04\nEpoch 28/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0133 - val_accuracy: 0.9333 - val_loss: 0.1837 - learning_rate: 1.0000e-04\nEpoch 29/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0089 - val_accuracy: 0.9333 - val_loss: 0.1695 - learning_rate: 1.0000e-04\nEpoch 30/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0066 - val_accuracy: 0.9333 - val_loss: 0.1531 - learning_rate: 1.0000e-04\nEpoch 31/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0092 - val_accuracy: 0.9333 - val_loss: 0.1401 - learning_rate: 1.0000e-04\nEpoch 32/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0080 - val_accuracy: 0.9333 - val_loss: 0.1251 - learning_rate: 1.0000e-04\nEpoch 33/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0072 - val_accuracy: 0.9333 - val_loss: 0.1170 - learning_rate: 1.0000e-04\nEpoch 34/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0133 - val_accuracy: 0.9333 - val_loss: 0.1132 - learning_rate: 1.0000e-04\nEpoch 35/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0077 - val_accuracy: 0.9333 - val_loss: 0.1072 - learning_rate: 1.0000e-04\nEpoch 36/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0101 - val_accuracy: 0.9333 - val_loss: 0.1052 - learning_rate: 1.0000e-04\nEpoch 37/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0047 - val_accuracy: 0.9667 - val_loss: 0.0985 - learning_rate: 1.0000e-04\nEpoch 38/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0076 - val_accuracy: 0.9667 - val_loss: 0.0917 - learning_rate: 1.0000e-04\nEpoch 39/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0078 - val_accuracy: 0.9667 - val_loss: 0.0854 - learning_rate: 1.0000e-04\nEpoch 40/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0054 - val_accuracy: 0.9667 - val_loss: 0.0815 - learning_rate: 1.0000e-04\nEpoch 41/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0053 - val_accuracy: 0.9667 - val_loss: 0.0798 - learning_rate: 1.0000e-04\nEpoch 42/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0067 - val_accuracy: 0.9667 - val_loss: 0.0769 - learning_rate: 1.0000e-04\nEpoch 43/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0102 - val_accuracy: 0.9667 - val_loss: 0.0745 - learning_rate: 1.0000e-04\nEpoch 44/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0058 - val_accuracy: 0.9667 - val_loss: 0.0715 - learning_rate: 1.0000e-04\nEpoch 45/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0067 - val_accuracy: 0.9667 - val_loss: 0.0689 - learning_rate: 1.0000e-04\nEpoch 46/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0056 - val_accuracy: 0.9667 - val_loss: 0.0682 - learning_rate: 1.0000e-04\nEpoch 47/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0056 - val_accuracy: 0.9667 - val_loss: 0.0676 - learning_rate: 1.0000e-04\nEpoch 48/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0054 - val_accuracy: 0.9667 - val_loss: 0.0653 - learning_rate: 1.0000e-04\nEpoch 49/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9983 - loss: 0.0089 - val_accuracy: 0.9667 - val_loss: 0.0611 - learning_rate: 1.0000e-04\nEpoch 50/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0050 - val_accuracy: 1.0000 - val_loss: 0.0577 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 50.\nFold 4 - Train Accuracy: 100.00%, Validation Accuracy: 100.00%\n\nTraining on Fold 5...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 423ms/step - accuracy: 0.6990 - loss: 1.2446 - val_accuracy: 0.5000 - val_loss: 1237.5651 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9193 - loss: 0.2319 - val_accuracy: 0.5333 - val_loss: 166.1831 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9337 - loss: 0.1625 - val_accuracy: 0.8333 - val_loss: 2.5185 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9600 - loss: 0.1153 - val_accuracy: 0.7333 - val_loss: 3.5519 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9911 - loss: 0.0593 - val_accuracy: 0.5333 - val_loss: 11.6510 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9928 - loss: 0.0556 - val_accuracy: 0.8333 - val_loss: 1.3852 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9489 - loss: 0.0982 - val_accuracy: 0.5333 - val_loss: 2.9601 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9256 - loss: 0.2129 - val_accuracy: 0.5333 - val_loss: 6.8811 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9548 - loss: 0.1226\nEpoch 9: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9560 - loss: 0.1205 - val_accuracy: 0.5333 - val_loss: 6.4764 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9865 - loss: 0.0600 - val_accuracy: 0.5333 - val_loss: 4.7822 - learning_rate: 1.0000e-03\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9964 - loss: 0.0372 - val_accuracy: 0.5667 - val_loss: 3.5388 - learning_rate: 1.0000e-03\nEpoch 11: early stopping\nRestoring model weights from the end of the best epoch: 6.\nFold 5 - Train Accuracy: 77.07%, Validation Accuracy: 83.33%\n\nTraining on Fold 6...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 413ms/step - accuracy: 0.6477 - loss: 1.1049 - val_accuracy: 0.5000 - val_loss: 860.3218 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9055 - loss: 0.2613 - val_accuracy: 0.5000 - val_loss: 438.2376 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9314 - loss: 0.1486 - val_accuracy: 0.5000 - val_loss: 37.5232 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9506 - loss: 0.1304 - val_accuracy: 0.5000 - val_loss: 20.6201 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9799 - loss: 0.0404 - val_accuracy: 0.5000 - val_loss: 14.1708 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9778 - loss: 0.0600 - val_accuracy: 0.5333 - val_loss: 10.0083 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9679 - loss: 0.0678 - val_accuracy: 0.7333 - val_loss: 1.9213 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9675 - loss: 0.1098 - val_accuracy: 0.5667 - val_loss: 4.5591 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9758 - loss: 0.0614 - val_accuracy: 0.7333 - val_loss: 1.9494 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9837 - loss: 0.0804\nEpoch 10: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9838 - loss: 0.0793 - val_accuracy: 0.5333 - val_loss: 5.3460 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9775 - loss: 0.0543 - val_accuracy: 0.5667 - val_loss: 4.1140 - learning_rate: 1.0000e-03\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9934 - loss: 0.0267 - val_accuracy: 0.5667 - val_loss: 3.2218 - learning_rate: 1.0000e-03\nEpoch 12: early stopping\nRestoring model weights from the end of the best epoch: 7.\nFold 6 - Train Accuracy: 75.56%, Validation Accuracy: 73.33%\n\nTraining on Fold 7...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 416ms/step - accuracy: 0.5898 - loss: 1.6001 - val_accuracy: 0.4828 - val_loss: 10373.5908 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8826 - loss: 0.3826 - val_accuracy: 0.4828 - val_loss: 347.1299 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.8908 - loss: 0.3242 - val_accuracy: 0.5172 - val_loss: 59.0188 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9244 - loss: 0.2437 - val_accuracy: 0.6207 - val_loss: 2.6299 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9624 - loss: 0.1577 - val_accuracy: 0.7241 - val_loss: 2.3157 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9587 - loss: 0.1400 - val_accuracy: 0.7586 - val_loss: 1.1810 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9695 - loss: 0.0926 - val_accuracy: 0.7931 - val_loss: 1.1927 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9791 - loss: 0.0606 - val_accuracy: 0.5517 - val_loss: 2.4751 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9570 - loss: 0.0854\nEpoch 9: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9564 - loss: 0.0879 - val_accuracy: 0.6897 - val_loss: 1.3100 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9579 - loss: 0.1240 - val_accuracy: 0.6897 - val_loss: 1.1538 - learning_rate: 1.0000e-03\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9649 - loss: 0.0595 - val_accuracy: 0.6552 - val_loss: 1.1769 - learning_rate: 1.0000e-03\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9968 - loss: 0.0262 - val_accuracy: 0.6552 - val_loss: 1.1874 - learning_rate: 1.0000e-03\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9928 - loss: 0.0225 - val_accuracy: 0.6552 - val_loss: 1.0847 - learning_rate: 1.0000e-03\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9945 - loss: 0.0238 - val_accuracy: 0.6897 - val_loss: 0.8498 - learning_rate: 1.0000e-03\nEpoch 15/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9968 - loss: 0.0196 - val_accuracy: 0.7586 - val_loss: 0.6946 - learning_rate: 1.0000e-03\nEpoch 16/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0189 - val_accuracy: 0.7586 - val_loss: 0.5939 - learning_rate: 1.0000e-03\nEpoch 17/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9949 - loss: 0.0214 - val_accuracy: 0.8621 - val_loss: 0.3781 - learning_rate: 1.0000e-03\nEpoch 18/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0186 - val_accuracy: 0.9310 - val_loss: 0.2531 - learning_rate: 1.0000e-03\nEpoch 19/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9968 - loss: 0.0126 - val_accuracy: 0.9310 - val_loss: 0.2332 - learning_rate: 1.0000e-03\nEpoch 20/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9968 - loss: 0.0149 - val_accuracy: 0.9310 - val_loss: 0.1606 - learning_rate: 1.0000e-03\nEpoch 21/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9977 - loss: 0.0144 - val_accuracy: 0.9655 - val_loss: 0.0758 - learning_rate: 1.0000e-03\nEpoch 22/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0150 - val_accuracy: 0.9655 - val_loss: 0.0643 - learning_rate: 1.0000e-03\nEpoch 23/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0091 - val_accuracy: 1.0000 - val_loss: 0.0451 - learning_rate: 1.0000e-03\nEpoch 24/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9968 - loss: 0.0129 - val_accuracy: 1.0000 - val_loss: 0.0384 - learning_rate: 1.0000e-03\nEpoch 25/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0089 - val_accuracy: 1.0000 - val_loss: 0.0291 - learning_rate: 1.0000e-03\nEpoch 26/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9968 - loss: 0.0128 - val_accuracy: 1.0000 - val_loss: 0.0207 - learning_rate: 1.0000e-03\nEpoch 27/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0084 - val_accuracy: 1.0000 - val_loss: 0.0151 - learning_rate: 1.0000e-03\nEpoch 28/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0111 - val_accuracy: 1.0000 - val_loss: 0.0094 - learning_rate: 1.0000e-03\nEpoch 29/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0055 - val_accuracy: 1.0000 - val_loss: 0.0073 - learning_rate: 1.0000e-03\nEpoch 30/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0076 - val_accuracy: 1.0000 - val_loss: 0.0065 - learning_rate: 1.0000e-03\nEpoch 31/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0063 - val_accuracy: 1.0000 - val_loss: 0.0053 - learning_rate: 1.0000e-03\nEpoch 32/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0082 - val_accuracy: 1.0000 - val_loss: 0.0064 - learning_rate: 1.0000e-03\nEpoch 33/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9968 - loss: 0.0115 - val_accuracy: 1.0000 - val_loss: 0.0115 - learning_rate: 1.0000e-03\nEpoch 34/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0131\nEpoch 34: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0130 - val_accuracy: 1.0000 - val_loss: 0.0053 - learning_rate: 1.0000e-03\nEpoch 35/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0053 - val_accuracy: 1.0000 - val_loss: 0.0050 - learning_rate: 1.0000e-04\nEpoch 36/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0065 - val_accuracy: 1.0000 - val_loss: 0.0050 - learning_rate: 1.0000e-04\nEpoch 37/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9968 - loss: 0.0087 - val_accuracy: 1.0000 - val_loss: 0.0052 - learning_rate: 1.0000e-04\nEpoch 38/50\n\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0052\nEpoch 38: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0055 - val_accuracy: 1.0000 - val_loss: 0.0053 - learning_rate: 1.0000e-04\nEpoch 39/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9968 - loss: 0.0106 - val_accuracy: 1.0000 - val_loss: 0.0052 - learning_rate: 1.0000e-05\nEpoch 40/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9968 - loss: 0.0080 - val_accuracy: 1.0000 - val_loss: 0.0053 - learning_rate: 1.0000e-05\nEpoch 40: early stopping\nRestoring model weights from the end of the best epoch: 35.\nFold 7 - Train Accuracy: 99.25%, Validation Accuracy: 100.00%\n\nTraining on Fold 8...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 414ms/step - accuracy: 0.7072 - loss: 0.9804 - val_accuracy: 0.4828 - val_loss: 8193.0967 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9124 - loss: 0.2735 - val_accuracy: 0.5172 - val_loss: 644.2912 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9527 - loss: 0.1119 - val_accuracy: 0.4483 - val_loss: 63.9924 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9589 - loss: 0.1060 - val_accuracy: 0.7931 - val_loss: 6.9687 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9874 - loss: 0.0366 - val_accuracy: 0.8621 - val_loss: 4.6259 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9567 - loss: 0.1358 - val_accuracy: 0.6207 - val_loss: 4.5336 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9414 - loss: 0.1406 - val_accuracy: 0.8276 - val_loss: 1.7141 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9736 - loss: 0.0643 - val_accuracy: 0.6552 - val_loss: 2.9824 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9814 - loss: 0.0546 - val_accuracy: 0.6897 - val_loss: 4.5087 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9842 - loss: 0.0657 - val_accuracy: 0.9310 - val_loss: 0.8086 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9666 - loss: 0.0834 - val_accuracy: 0.9310 - val_loss: 0.4333 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9980 - loss: 0.0084 - val_accuracy: 0.9655 - val_loss: 0.3347 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9855 - loss: 0.0205 - val_accuracy: 0.9655 - val_loss: 0.5005 - learning_rate: 0.0100\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9973 - loss: 0.0156 - val_accuracy: 0.8276 - val_loss: 1.1050 - learning_rate: 0.0100\nEpoch 15/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0056\nEpoch 15: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9996 - loss: 0.0066 - val_accuracy: 0.8621 - val_loss: 0.5412 - learning_rate: 0.0100\nEpoch 16/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 0.8966 - val_loss: 0.3990 - learning_rate: 1.0000e-03\nEpoch 17/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 0.8966 - val_loss: 0.3695 - learning_rate: 1.0000e-03\nEpoch 17: early stopping\nRestoring model weights from the end of the best epoch: 12.\nFold 8 - Train Accuracy: 92.88%, Validation Accuracy: 96.55%\n\nTraining on Fold 9...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 416ms/step - accuracy: 0.5721 - loss: 1.5033 - val_accuracy: 0.5172 - val_loss: 3025.3999 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8924 - loss: 0.3417 - val_accuracy: 0.5172 - val_loss: 161.9472 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9237 - loss: 0.1983 - val_accuracy: 0.5172 - val_loss: 38.1197 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9469 - loss: 0.1324 - val_accuracy: 0.5862 - val_loss: 12.3559 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9831 - loss: 0.0790 - val_accuracy: 0.5517 - val_loss: 8.9458 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9759 - loss: 0.0534 - val_accuracy: 0.7241 - val_loss: 3.1040 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9799 - loss: 0.0469 - val_accuracy: 0.5517 - val_loss: 8.9332 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9822 - loss: 0.0648 - val_accuracy: 0.6552 - val_loss: 6.1160 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9492 - loss: 0.1287\nEpoch 9: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9465 - loss: 0.1339 - val_accuracy: 0.7241 - val_loss: 3.9218 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9455 - loss: 0.2320 - val_accuracy: 0.8276 - val_loss: 1.0328 - learning_rate: 1.0000e-03\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9795 - loss: 0.1066 - val_accuracy: 0.9310 - val_loss: 0.7175 - learning_rate: 1.0000e-03\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9756 - loss: 0.0567 - val_accuracy: 0.8966 - val_loss: 0.6652 - learning_rate: 1.0000e-03\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9850 - loss: 0.0387 - val_accuracy: 0.8966 - val_loss: 0.6451 - learning_rate: 1.0000e-03\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9822 - loss: 0.0339 - val_accuracy: 0.8966 - val_loss: 0.6418 - learning_rate: 1.0000e-03\nEpoch 15/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9958 - loss: 0.0222 - val_accuracy: 0.9310 - val_loss: 0.5850 - learning_rate: 1.0000e-03\nEpoch 16/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0162 - val_accuracy: 0.9310 - val_loss: 0.5373 - learning_rate: 1.0000e-03\nEpoch 17/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0170 - val_accuracy: 0.9310 - val_loss: 0.5231 - learning_rate: 1.0000e-03\nEpoch 18/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9958 - loss: 0.0150 - val_accuracy: 0.9310 - val_loss: 0.5020 - learning_rate: 1.0000e-03\nEpoch 19/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9958 - loss: 0.0135 - val_accuracy: 0.9310 - val_loss: 0.4708 - learning_rate: 1.0000e-03\nEpoch 20/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9958 - loss: 0.0183 - val_accuracy: 0.9310 - val_loss: 0.4544 - learning_rate: 1.0000e-03\nEpoch 21/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0104 - val_accuracy: 0.9310 - val_loss: 0.4566 - learning_rate: 1.0000e-03\nEpoch 22/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9973 - loss: 0.0100 - val_accuracy: 0.9310 - val_loss: 0.4545 - learning_rate: 1.0000e-03\nEpoch 23/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0079 - val_accuracy: 0.9310 - val_loss: 0.4300 - learning_rate: 1.0000e-03\nEpoch 24/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0100 - val_accuracy: 0.9310 - val_loss: 0.4238 - learning_rate: 1.0000e-03\nEpoch 25/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0105 - val_accuracy: 0.9310 - val_loss: 0.3762 - learning_rate: 1.0000e-03\nEpoch 26/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0115 - val_accuracy: 0.9310 - val_loss: 0.3618 - learning_rate: 1.0000e-03\nEpoch 27/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0073 - val_accuracy: 0.9310 - val_loss: 0.3403 - learning_rate: 1.0000e-03\nEpoch 28/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0071 - val_accuracy: 0.9655 - val_loss: 0.3309 - learning_rate: 1.0000e-03\nEpoch 29/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0074 - val_accuracy: 0.9655 - val_loss: 0.3258 - learning_rate: 1.0000e-03\nEpoch 30/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0077 - val_accuracy: 0.9655 - val_loss: 0.3347 - learning_rate: 1.0000e-03\nEpoch 31/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0097 - val_accuracy: 0.9655 - val_loss: 0.3370 - learning_rate: 1.0000e-03\nEpoch 32/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0054 \nEpoch 32: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0056 - val_accuracy: 0.9655 - val_loss: 0.3326 - learning_rate: 1.0000e-03\nEpoch 33/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0061 - val_accuracy: 0.9655 - val_loss: 0.3273 - learning_rate: 1.0000e-04\nEpoch 34/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0044 - val_accuracy: 0.9655 - val_loss: 0.3234 - learning_rate: 1.0000e-04\nEpoch 35/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0042 - val_accuracy: 0.9655 - val_loss: 0.3207 - learning_rate: 1.0000e-04\nEpoch 36/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0075 - val_accuracy: 0.9655 - val_loss: 0.3196 - learning_rate: 1.0000e-04\nEpoch 37/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0055 - val_accuracy: 0.9655 - val_loss: 0.3169 - learning_rate: 1.0000e-04\nEpoch 38/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0045 - val_accuracy: 0.9655 - val_loss: 0.3138 - learning_rate: 1.0000e-04\nEpoch 39/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0045 - val_accuracy: 0.9655 - val_loss: 0.3130 - learning_rate: 1.0000e-04\nEpoch 40/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0072 - val_accuracy: 0.9655 - val_loss: 0.3127 - learning_rate: 1.0000e-04\nEpoch 41/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0032 - val_accuracy: 0.9655 - val_loss: 0.3125 - learning_rate: 1.0000e-04\nEpoch 42/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0062 - val_accuracy: 0.9655 - val_loss: 0.3144 - learning_rate: 1.0000e-04\nEpoch 43/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0055 - val_accuracy: 0.9655 - val_loss: 0.3157 - learning_rate: 1.0000e-04\nEpoch 44/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0053\nEpoch 44: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0056 - val_accuracy: 0.9655 - val_loss: 0.3131 - learning_rate: 1.0000e-04\nEpoch 45/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0041 - val_accuracy: 0.9655 - val_loss: 0.3120 - learning_rate: 1.0000e-05\nEpoch 46/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0042 - val_accuracy: 0.9655 - val_loss: 0.3123 - learning_rate: 1.0000e-05\nEpoch 47/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0060 - val_accuracy: 0.9655 - val_loss: 0.3108 - learning_rate: 1.0000e-05\nEpoch 48/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0041 - val_accuracy: 0.9655 - val_loss: 0.3117 - learning_rate: 1.0000e-05\nEpoch 49/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0054 - val_accuracy: 0.9655 - val_loss: 0.3113 - learning_rate: 1.0000e-05\nEpoch 50/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0027 \nEpoch 50: ReduceLROnPlateau reducing learning rate to 9.99999883788405e-07.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0030 - val_accuracy: 0.9655 - val_loss: 0.3111 - learning_rate: 1.0000e-05\nRestoring model weights from the end of the best epoch: 47.\nFold 9 - Train Accuracy: 100.00%, Validation Accuracy: 96.55%\n\nTraining on Fold 10...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 413ms/step - accuracy: 0.6130 - loss: 1.4028 - val_accuracy: 0.7241 - val_loss: 95.1961 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.8083 - loss: 0.4206 - val_accuracy: 0.4828 - val_loss: 1321.4591 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.8511 - loss: 0.3517 - val_accuracy: 0.4828 - val_loss: 90.4384 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9239 - loss: 0.1801 - val_accuracy: 0.5517 - val_loss: 7.5313 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9887 - loss: 0.0725 - val_accuracy: 0.4828 - val_loss: 8.6257 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9699 - loss: 0.0923 - val_accuracy: 0.4828 - val_loss: 5.7382 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9813 - loss: 0.0677 - val_accuracy: 0.6897 - val_loss: 2.3627 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9643 - loss: 0.0556 - val_accuracy: 0.5517 - val_loss: 3.4337 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9759 - loss: 0.0595 - val_accuracy: 0.7931 - val_loss: 1.7641 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9903 - loss: 0.0384 - val_accuracy: 0.8276 - val_loss: 1.0378 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9854 - loss: 0.0462 - val_accuracy: 0.8621 - val_loss: 0.5456 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0152 - val_accuracy: 0.8966 - val_loss: 0.4788 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0102 - val_accuracy: 0.8621 - val_loss: 0.5906 - learning_rate: 0.0100\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9973 - loss: 0.0098 - val_accuracy: 0.8966 - val_loss: 0.7417 - learning_rate: 0.0100\nEpoch 15/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0056\nEpoch 15: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0059 - val_accuracy: 0.7931 - val_loss: 1.4301 - learning_rate: 0.0100\nEpoch 16/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9986 - loss: 0.0072 - val_accuracy: 0.7931 - val_loss: 1.5227 - learning_rate: 1.0000e-03\nEpoch 17/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0053 - val_accuracy: 0.7931 - val_loss: 1.3540 - learning_rate: 1.0000e-03\nEpoch 17: early stopping\nRestoring model weights from the end of the best epoch: 12.\nFold 10 - Train Accuracy: 93.26%, Validation Accuracy: 89.66%\n\nAverage Training Accuracy: 92.56%\nAverage Validation Accuracy: 93.61%\n","output_type":"stream"}],"execution_count":93},{"cell_type":"markdown","source":"## 2.3 Rotating 180 degrees","metadata":{}},{"cell_type":"code","source":"X_train_rotated = np.rot180(X_train, k=2, axes=(1,2))\nX_test_rotated = np.rot180(X_test, k=2, axes=(1,2))\n\nX_train_augmented = np.concatenate((X_train, X_train_rotated), axis=0)\ny_train_augmented = np.concatenate((y_train, y_train), axis=0)\n\ntrain_evaluate_model_with_k_fold(\n    X_train=X_train_augmented,\n    y_train=y_train_augmented,\n    lr=0.01,\n    epochs=50,\n    batch_size=16)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T20:17:38.218503Z","iopub.execute_input":"2025-02-07T20:17:38.218730Z","iopub.status.idle":"2025-02-07T20:22:13.503580Z","shell.execute_reply.started":"2025-02-07T20:17:38.218711Z","shell.execute_reply":"2025-02-07T20:22:13.502774Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"\nTraining on Fold 1...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 417ms/step - accuracy: 0.7017 - loss: 1.0316 - val_accuracy: 0.5000 - val_loss: 5975.9946 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8575 - loss: 0.3144 - val_accuracy: 0.5000 - val_loss: 455.1063 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9435 - loss: 0.1664 - val_accuracy: 0.4333 - val_loss: 28.0014 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9273 - loss: 0.1367 - val_accuracy: 0.5000 - val_loss: 33.0817 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9306 - loss: 0.1428 - val_accuracy: 0.5000 - val_loss: 5.3856 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9832 - loss: 0.0499 - val_accuracy: 0.5333 - val_loss: 5.0419 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9804 - loss: 0.0385 - val_accuracy: 0.6000 - val_loss: 2.5874 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9908 - loss: 0.0273 - val_accuracy: 0.6333 - val_loss: 2.2090 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9973 - loss: 0.0205 - val_accuracy: 0.5333 - val_loss: 5.4682 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9903 - loss: 0.0513 - val_accuracy: 0.9000 - val_loss: 0.4326 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9742 - loss: 0.0478 - val_accuracy: 0.8667 - val_loss: 0.5168 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9863 - loss: 0.0452 - val_accuracy: 0.8667 - val_loss: 0.4239 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9888 - loss: 0.0562 - val_accuracy: 0.7667 - val_loss: 1.4342 - learning_rate: 0.0100\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9931 - loss: 0.0382 - val_accuracy: 0.5333 - val_loss: 9.0806 - learning_rate: 0.0100\nEpoch 15/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9916 - loss: 0.0320\nEpoch 15: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9917 - loss: 0.0331 - val_accuracy: 0.8333 - val_loss: 0.9574 - learning_rate: 0.0100\nEpoch 16/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9836 - loss: 0.0916 - val_accuracy: 0.8667 - val_loss: 0.2261 - learning_rate: 1.0000e-03\nEpoch 17/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9921 - loss: 0.0177 - val_accuracy: 0.9333 - val_loss: 0.1592 - learning_rate: 1.0000e-03\nEpoch 18/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0061 - val_accuracy: 0.9333 - val_loss: 0.1928 - learning_rate: 1.0000e-03\nEpoch 19/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0056 - val_accuracy: 0.9333 - val_loss: 0.2137 - learning_rate: 1.0000e-03\nEpoch 20/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0072\nEpoch 20: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0071 - val_accuracy: 0.9333 - val_loss: 0.2270 - learning_rate: 1.0000e-03\nEpoch 21/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0050 - val_accuracy: 0.9333 - val_loss: 0.2305 - learning_rate: 1.0000e-04\nEpoch 22/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0046 - val_accuracy: 0.9333 - val_loss: 0.2319 - learning_rate: 1.0000e-04\nEpoch 22: early stopping\nRestoring model weights from the end of the best epoch: 17.\nFold 1 - Train Accuracy: 96.99%, Validation Accuracy: 93.33%\n\nTraining on Fold 2...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 418ms/step - accuracy: 0.7745 - loss: 0.9139 - val_accuracy: 0.5000 - val_loss: 4913.1577 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.8492 - loss: 0.4177 - val_accuracy: 0.5000 - val_loss: 338.0827 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9464 - loss: 0.1657 - val_accuracy: 0.5000 - val_loss: 64.9230 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9775 - loss: 0.0927 - val_accuracy: 0.5000 - val_loss: 23.5754 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9717 - loss: 0.1017 - val_accuracy: 0.5000 - val_loss: 8.9480 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9865 - loss: 0.0536 - val_accuracy: 0.5333 - val_loss: 3.2759 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9916 - loss: 0.0325 - val_accuracy: 0.5000 - val_loss: 2.9125 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9902 - loss: 0.0299 - val_accuracy: 0.6333 - val_loss: 1.7526 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9964 - loss: 0.0155 - val_accuracy: 0.7000 - val_loss: 0.9210 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9919 - loss: 0.0208 - val_accuracy: 0.8000 - val_loss: 0.7837 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9824 - loss: 0.0395 - val_accuracy: 0.8667 - val_loss: 0.5440 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9738 - loss: 0.0673 - val_accuracy: 0.9333 - val_loss: 0.2188 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9858 - loss: 0.0407 - val_accuracy: 0.9667 - val_loss: 0.0528 - learning_rate: 0.0100\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9951 - loss: 0.0144 - val_accuracy: 1.0000 - val_loss: 0.0184 - learning_rate: 0.0100\nEpoch 15/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9975 - loss: 0.0092 - val_accuracy: 0.8667 - val_loss: 0.9539 - learning_rate: 0.0100\nEpoch 16/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9884 - loss: 0.0339 - val_accuracy: 0.8333 - val_loss: 0.6116 - learning_rate: 0.0100\nEpoch 17/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9686 - loss: 0.0941\nEpoch 17: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9675 - loss: 0.0972 - val_accuracy: 0.9333 - val_loss: 0.1411 - learning_rate: 0.0100\nEpoch 18/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9973 - loss: 0.0092 - val_accuracy: 0.9333 - val_loss: 0.0907 - learning_rate: 1.0000e-03\nEpoch 19/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9989 - loss: 0.0111 - val_accuracy: 0.9667 - val_loss: 0.0657 - learning_rate: 1.0000e-03\nEpoch 19: early stopping\nRestoring model weights from the end of the best epoch: 14.\nFold 2 - Train Accuracy: 90.98%, Validation Accuracy: 100.00%\n\nTraining on Fold 3...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 418ms/step - accuracy: 0.6891 - loss: 1.2126 - val_accuracy: 0.5000 - val_loss: 1655.2473 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8898 - loss: 0.2520 - val_accuracy: 0.5000 - val_loss: 239.2184 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9374 - loss: 0.1527 - val_accuracy: 0.5000 - val_loss: 59.6500 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9541 - loss: 0.1097 - val_accuracy: 0.5000 - val_loss: 26.0393 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9825 - loss: 0.0588 - val_accuracy: 0.5000 - val_loss: 17.2025 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9650 - loss: 0.0672 - val_accuracy: 0.5000 - val_loss: 8.5182 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9883 - loss: 0.0326 - val_accuracy: 0.8667 - val_loss: 1.0574 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9931 - loss: 0.0200 - val_accuracy: 0.9000 - val_loss: 1.3575 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9989 - loss: 0.0139 - val_accuracy: 0.7333 - val_loss: 1.8257 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9931 - loss: 0.0206 - val_accuracy: 0.9333 - val_loss: 0.8123 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9931 - loss: 0.0127 - val_accuracy: 0.8667 - val_loss: 1.1304 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9926 - loss: 0.0142 - val_accuracy: 0.7667 - val_loss: 2.1009 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9628 - loss: 0.0786 - val_accuracy: 1.0000 - val_loss: 0.0690 - learning_rate: 0.0100\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9335 - loss: 0.2664 - val_accuracy: 0.8333 - val_loss: 1.0223 - learning_rate: 0.0100\nEpoch 15/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9027 - loss: 0.2044 - val_accuracy: 0.9000 - val_loss: 0.8098 - learning_rate: 0.0100\nEpoch 16/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9458 - loss: 0.1195\nEpoch 16: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9472 - loss: 0.1167 - val_accuracy: 0.8667 - val_loss: 0.5661 - learning_rate: 0.0100\nEpoch 17/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9823 - loss: 0.0547 - val_accuracy: 0.9667 - val_loss: 0.2243 - learning_rate: 1.0000e-03\nEpoch 18/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9956 - loss: 0.0246 - val_accuracy: 0.9667 - val_loss: 0.1395 - learning_rate: 1.0000e-03\nEpoch 18: early stopping\nRestoring model weights from the end of the best epoch: 13.\nFold 3 - Train Accuracy: 86.09%, Validation Accuracy: 100.00%\n\nTraining on Fold 4...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 430ms/step - accuracy: 0.6960 - loss: 1.0019 - val_accuracy: 0.5000 - val_loss: 4317.1206 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.8996 - loss: 0.2990 - val_accuracy: 0.5000 - val_loss: 254.5440 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9215 - loss: 0.1582 - val_accuracy: 0.5000 - val_loss: 85.3654 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9441 - loss: 0.1239 - val_accuracy: 0.5000 - val_loss: 26.6385 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9584 - loss: 0.1286 - val_accuracy: 0.4667 - val_loss: 5.1537 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9745 - loss: 0.0950 - val_accuracy: 0.5000 - val_loss: 2.9723 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9878 - loss: 0.0515 - val_accuracy: 0.6667 - val_loss: 2.4927 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9972 - loss: 0.0428 - val_accuracy: 0.7000 - val_loss: 2.5103 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9711 - loss: 0.0701 - val_accuracy: 0.5000 - val_loss: 11.0729 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9394 - loss: 0.1779\nEpoch 10: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9413 - loss: 0.1710 - val_accuracy: 0.5000 - val_loss: 11.6218 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9675 - loss: 0.0797 - val_accuracy: 0.5333 - val_loss: 5.1762 - learning_rate: 1.0000e-03\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9855 - loss: 0.0562 - val_accuracy: 0.6333 - val_loss: 2.7255 - learning_rate: 1.0000e-03\nEpoch 12: early stopping\nRestoring model weights from the end of the best epoch: 7.\nFold 4 - Train Accuracy: 80.83%, Validation Accuracy: 66.67%\n\nTraining on Fold 5...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 419ms/step - accuracy: 0.7561 - loss: 0.9836 - val_accuracy: 0.5000 - val_loss: 8473.5664 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.8749 - loss: 0.3450 - val_accuracy: 0.5000 - val_loss: 491.8939 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9264 - loss: 0.1714 - val_accuracy: 0.5000 - val_loss: 281.4154 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9383 - loss: 0.1451 - val_accuracy: 0.5333 - val_loss: 52.4922 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9656 - loss: 0.0777 - val_accuracy: 0.4667 - val_loss: 10.5211 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9603 - loss: 0.0904 - val_accuracy: 0.5333 - val_loss: 17.2013 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9734 - loss: 0.0786 - val_accuracy: 0.5333 - val_loss: 2.3541 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9661 - loss: 0.0890 - val_accuracy: 0.5333 - val_loss: 13.0870 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9598 - loss: 0.0858 - val_accuracy: 0.6000 - val_loss: 6.7072 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9854 - loss: 0.0803 - val_accuracy: 0.8333 - val_loss: 0.7276 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9746 - loss: 0.0723 - val_accuracy: 0.8333 - val_loss: 1.2553 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9859 - loss: 0.0354 - val_accuracy: 1.0000 - val_loss: 0.0193 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9884 - loss: 0.0219 - val_accuracy: 1.0000 - val_loss: 0.0205 - learning_rate: 0.0100\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9994 - loss: 0.0164 - val_accuracy: 1.0000 - val_loss: 0.0045 - learning_rate: 0.0100\nEpoch 15/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9867 - loss: 0.0176 - val_accuracy: 0.9333 - val_loss: 0.4204 - learning_rate: 0.0100\nEpoch 16/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9696 - loss: 0.0725 - val_accuracy: 0.9667 - val_loss: 0.1100 - learning_rate: 0.0100\nEpoch 17/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9821 - loss: 0.0422\nEpoch 17: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9828 - loss: 0.0440 - val_accuracy: 0.9000 - val_loss: 0.3681 - learning_rate: 0.0100\nEpoch 18/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9888 - loss: 0.0254 - val_accuracy: 0.9333 - val_loss: 0.2652 - learning_rate: 1.0000e-03\nEpoch 19/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0039 - val_accuracy: 0.9333 - val_loss: 0.2003 - learning_rate: 1.0000e-03\nEpoch 19: early stopping\nRestoring model weights from the end of the best epoch: 14.\nFold 5 - Train Accuracy: 99.62%, Validation Accuracy: 100.00%\n\nTraining on Fold 6...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 413ms/step - accuracy: 0.7141 - loss: 0.8669 - val_accuracy: 0.5000 - val_loss: 3943.4517 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9002 - loss: 0.2789 - val_accuracy: 0.5000 - val_loss: 463.0600 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9200 - loss: 0.1524 - val_accuracy: 0.5000 - val_loss: 78.2061 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9669 - loss: 0.0886 - val_accuracy: 0.5000 - val_loss: 26.8919 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9850 - loss: 0.0573 - val_accuracy: 0.5333 - val_loss: 13.8055 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9811 - loss: 0.0620 - val_accuracy: 0.5000 - val_loss: 11.0175 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9458 - loss: 0.1246 - val_accuracy: 0.4667 - val_loss: 3.5129 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9656 - loss: 0.0952 - val_accuracy: 0.6667 - val_loss: 1.8429 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9830 - loss: 0.0702 - val_accuracy: 0.7000 - val_loss: 1.0742 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9941 - loss: 0.0260 - val_accuracy: 0.6667 - val_loss: 1.8015 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9862 - loss: 0.0206 - val_accuracy: 0.5667 - val_loss: 3.8432 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9828 - loss: 0.0613\nEpoch 12: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9830 - loss: 0.0595 - val_accuracy: 0.7000 - val_loss: 1.6844 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9839 - loss: 0.0192 - val_accuracy: 0.7000 - val_loss: 1.6471 - learning_rate: 1.0000e-03\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9983 - loss: 0.0057 - val_accuracy: 0.7000 - val_loss: 1.5585 - learning_rate: 1.0000e-03\nEpoch 14: early stopping\nRestoring model weights from the end of the best epoch: 9.\nFold 6 - Train Accuracy: 78.95%, Validation Accuracy: 70.00%\n\nTraining on Fold 7...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 418ms/step - accuracy: 0.6302 - loss: 1.4685 - val_accuracy: 0.4828 - val_loss: 5349.1885 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.8932 - loss: 0.3364 - val_accuracy: 0.5172 - val_loss: 348.2767 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9180 - loss: 0.2161 - val_accuracy: 0.5172 - val_loss: 65.4382 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9565 - loss: 0.1370 - val_accuracy: 0.5172 - val_loss: 38.4636 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9627 - loss: 0.0840 - val_accuracy: 0.5172 - val_loss: 3.8232 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9860 - loss: 0.0491 - val_accuracy: 0.5862 - val_loss: 1.5536 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9863 - loss: 0.0497 - val_accuracy: 0.5172 - val_loss: 1.3828 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9772 - loss: 0.0435 - val_accuracy: 0.5172 - val_loss: 4.9311 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9608 - loss: 0.1404 - val_accuracy: 0.6897 - val_loss: 1.6888 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9821 - loss: 0.0536 - val_accuracy: 0.8966 - val_loss: 0.7962 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9912 - loss: 0.0355 - val_accuracy: 0.6552 - val_loss: 2.2326 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9696 - loss: 0.0904 - val_accuracy: 0.8621 - val_loss: 0.7121 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9945 - loss: 0.0232 - val_accuracy: 0.7931 - val_loss: 1.2963 - learning_rate: 0.0100\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9994 - loss: 0.0201 - val_accuracy: 0.8966 - val_loss: 0.3900 - learning_rate: 0.0100\nEpoch 15/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0063 - val_accuracy: 0.8966 - val_loss: 0.3009 - learning_rate: 0.0100\nEpoch 16/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9930 - loss: 0.0171 - val_accuracy: 0.9655 - val_loss: 0.2858 - learning_rate: 0.0100\nEpoch 17/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9898 - loss: 0.0548 - val_accuracy: 0.9310 - val_loss: 0.1752 - learning_rate: 0.0100\nEpoch 18/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9800 - loss: 0.0743 - val_accuracy: 0.7931 - val_loss: 0.5794 - learning_rate: 0.0100\nEpoch 19/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9655 - loss: 0.0800 - val_accuracy: 0.9655 - val_loss: 0.1482 - learning_rate: 0.0100\nEpoch 20/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9721 - loss: 0.0635 - val_accuracy: 0.8621 - val_loss: 0.3304 - learning_rate: 0.0100\nEpoch 21/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9949 - loss: 0.0341 - val_accuracy: 0.9655 - val_loss: 0.1621 - learning_rate: 0.0100\nEpoch 22/50\n\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9964 - loss: 0.0167\nEpoch 22: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9964 - loss: 0.0172 - val_accuracy: 0.9310 - val_loss: 0.3409 - learning_rate: 0.0100\nEpoch 23/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9937 - loss: 0.0128 - val_accuracy: 0.9310 - val_loss: 0.2348 - learning_rate: 1.0000e-03\nEpoch 24/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9968 - loss: 0.0070 - val_accuracy: 0.8966 - val_loss: 0.1663 - learning_rate: 1.0000e-03\nEpoch 24: early stopping\nRestoring model weights from the end of the best epoch: 19.\nFold 7 - Train Accuracy: 96.63%, Validation Accuracy: 96.55%\n\nTraining on Fold 8...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 418ms/step - accuracy: 0.7429 - loss: 0.8838 - val_accuracy: 0.5172 - val_loss: 5825.9980 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.8936 - loss: 0.2312 - val_accuracy: 0.5172 - val_loss: 832.8497 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9421 - loss: 0.1480 - val_accuracy: 0.5172 - val_loss: 187.0098 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9684 - loss: 0.0676 - val_accuracy: 0.5172 - val_loss: 43.6305 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9915 - loss: 0.0326 - val_accuracy: 0.5172 - val_loss: 24.1279 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9950 - loss: 0.0273 - val_accuracy: 0.5517 - val_loss: 3.4707 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9882 - loss: 0.0333 - val_accuracy: 0.7241 - val_loss: 1.4773 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9845 - loss: 0.0453 - val_accuracy: 0.8276 - val_loss: 0.8537 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9820 - loss: 0.0596 - val_accuracy: 0.8621 - val_loss: 0.6129 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9819 - loss: 0.0572 - val_accuracy: 0.9310 - val_loss: 0.2385 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9749 - loss: 0.0796 - val_accuracy: 0.9310 - val_loss: 0.2174 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9977 - loss: 0.0159 - val_accuracy: 0.9655 - val_loss: 0.2459 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0187 - val_accuracy: 0.9655 - val_loss: 0.1548 - learning_rate: 0.0100\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0055 - val_accuracy: 0.9655 - val_loss: 0.1671 - learning_rate: 0.0100\nEpoch 15/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.9655 - val_loss: 0.2178 - learning_rate: 0.0100\nEpoch 16/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0015\nEpoch 16: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.9655 - val_loss: 0.2625 - learning_rate: 0.0100\nEpoch 17/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 6.8367e-04 - val_accuracy: 0.9655 - val_loss: 0.2706 - learning_rate: 1.0000e-03\nEpoch 18/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 8.6171e-04 - val_accuracy: 0.9655 - val_loss: 0.2703 - learning_rate: 1.0000e-03\nEpoch 18: early stopping\nRestoring model weights from the end of the best epoch: 13.\nFold 8 - Train Accuracy: 98.50%, Validation Accuracy: 96.55%\n\nTraining on Fold 9...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 409ms/step - accuracy: 0.6063 - loss: 1.3037 - val_accuracy: 0.5172 - val_loss: 4996.6655 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.8051 - loss: 0.3553 - val_accuracy: 0.4828 - val_loss: 163.2422 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9247 - loss: 0.1704 - val_accuracy: 0.4138 - val_loss: 40.9846 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9419 - loss: 0.1074 - val_accuracy: 0.6552 - val_loss: 9.7892 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9707 - loss: 0.0686 - val_accuracy: 0.4828 - val_loss: 27.5898 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9632 - loss: 0.1230 - val_accuracy: 0.6552 - val_loss: 1.8125 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9677 - loss: 0.0734 - val_accuracy: 0.6552 - val_loss: 5.7218 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9779 - loss: 0.0756 - val_accuracy: 0.7931 - val_loss: 1.4274 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9899 - loss: 0.0324 - val_accuracy: 0.8276 - val_loss: 1.4482 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9899 - loss: 0.0564 - val_accuracy: 0.9655 - val_loss: 0.4591 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9918 - loss: 0.0233 - val_accuracy: 0.9655 - val_loss: 0.7949 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9912 - loss: 0.0509 - val_accuracy: 0.8621 - val_loss: 0.8275 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9998 - loss: 0.0206\nEpoch 13: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9990 - loss: 0.0242 - val_accuracy: 0.9655 - val_loss: 0.6080 - learning_rate: 0.0100\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0137 - val_accuracy: 0.9655 - val_loss: 0.5542 - learning_rate: 1.0000e-03\nEpoch 15/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0085 - val_accuracy: 0.9655 - val_loss: 0.5096 - learning_rate: 1.0000e-03\nEpoch 15: early stopping\nRestoring model weights from the end of the best epoch: 10.\nFold 9 - Train Accuracy: 88.39%, Validation Accuracy: 96.55%\n\nTraining on Fold 10...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 419ms/step - accuracy: 0.6692 - loss: 0.9942 - val_accuracy: 0.5172 - val_loss: 2904.0464 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8662 - loss: 0.3959 - val_accuracy: 0.4828 - val_loss: 1011.5618 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9209 - loss: 0.2046 - val_accuracy: 0.4483 - val_loss: 16.3471 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9213 - loss: 0.1679 - val_accuracy: 0.3448 - val_loss: 15.2019 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9644 - loss: 0.0967 - val_accuracy: 0.4828 - val_loss: 7.3115 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9662 - loss: 0.0684 - val_accuracy: 0.6897 - val_loss: 4.4162 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9775 - loss: 0.0509 - val_accuracy: 0.7931 - val_loss: 1.5238 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9724 - loss: 0.0864 - val_accuracy: 0.7931 - val_loss: 2.0232 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9793 - loss: 0.0695 - val_accuracy: 0.8621 - val_loss: 1.8078 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9811 - loss: 0.0546\nEpoch 10: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9792 - loss: 0.0568 - val_accuracy: 0.8621 - val_loss: 1.6269 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0145 - val_accuracy: 0.8966 - val_loss: 1.2092 - learning_rate: 1.0000e-03\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0160 - val_accuracy: 0.8966 - val_loss: 1.0179 - learning_rate: 1.0000e-03\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9809 - loss: 0.0263 - val_accuracy: 0.8966 - val_loss: 0.8760 - learning_rate: 1.0000e-03\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9994 - loss: 0.0109 - val_accuracy: 0.8621 - val_loss: 0.7786 - learning_rate: 1.0000e-03\nEpoch 15/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0111 - val_accuracy: 0.8621 - val_loss: 0.7188 - learning_rate: 1.0000e-03\nEpoch 16/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9973 - loss: 0.0121 - val_accuracy: 0.8966 - val_loss: 0.6476 - learning_rate: 1.0000e-03\nEpoch 17/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0093 - val_accuracy: 0.8966 - val_loss: 0.6301 - learning_rate: 1.0000e-03\nEpoch 18/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0088 - val_accuracy: 0.8966 - val_loss: 0.6158 - learning_rate: 1.0000e-03\nEpoch 19/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0071 - val_accuracy: 0.8621 - val_loss: 0.5958 - learning_rate: 1.0000e-03\nEpoch 20/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0092 - val_accuracy: 0.8621 - val_loss: 0.5453 - learning_rate: 1.0000e-03\nEpoch 21/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0061 - val_accuracy: 0.8621 - val_loss: 0.4788 - learning_rate: 1.0000e-03\nEpoch 22/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0061 - val_accuracy: 0.8621 - val_loss: 0.4491 - learning_rate: 1.0000e-03\nEpoch 23/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0044 - val_accuracy: 0.8621 - val_loss: 0.4373 - learning_rate: 1.0000e-03\nEpoch 24/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0072 - val_accuracy: 0.8966 - val_loss: 0.4147 - learning_rate: 1.0000e-03\nEpoch 25/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0046 - val_accuracy: 0.8966 - val_loss: 0.4058 - learning_rate: 1.0000e-03\nEpoch 26/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0038 - val_accuracy: 0.8621 - val_loss: 0.4067 - learning_rate: 1.0000e-03\nEpoch 27/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0056 - val_accuracy: 0.8966 - val_loss: 0.3939 - learning_rate: 1.0000e-03\nEpoch 28/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0036 - val_accuracy: 0.8966 - val_loss: 0.3840 - learning_rate: 1.0000e-03\nEpoch 29/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0053 - val_accuracy: 0.8966 - val_loss: 0.3617 - learning_rate: 1.0000e-03\nEpoch 30/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0043 - val_accuracy: 0.8966 - val_loss: 0.3397 - learning_rate: 1.0000e-03\nEpoch 31/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0051 - val_accuracy: 0.9310 - val_loss: 0.3346 - learning_rate: 1.0000e-03\nEpoch 32/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.9310 - val_loss: 0.3313 - learning_rate: 1.0000e-03\nEpoch 33/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 0.9310 - val_loss: 0.3338 - learning_rate: 1.0000e-03\nEpoch 34/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 0.9310 - val_loss: 0.3431 - learning_rate: 1.0000e-03\nEpoch 35/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9998 - loss: 0.0033\nEpoch 35: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9994 - loss: 0.0039 - val_accuracy: 0.9310 - val_loss: 0.3466 - learning_rate: 1.0000e-03\nEpoch 36/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0023 - val_accuracy: 0.9310 - val_loss: 0.3444 - learning_rate: 1.0000e-04\nEpoch 37/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.9310 - val_loss: 0.3418 - learning_rate: 1.0000e-04\nEpoch 37: early stopping\nRestoring model weights from the end of the best epoch: 32.\nFold 10 - Train Accuracy: 98.50%, Validation Accuracy: 93.10%\n\nAverage Training Accuracy: 91.55%\nAverage Validation Accuracy: 91.28%\n","output_type":"stream"}],"execution_count":94},{"cell_type":"markdown","source":"## 2.4 Rotating 270 degrees","metadata":{}},{"cell_type":"code","source":"X_train_rotated = np.rot270(X_train, k=3, axes=(1,2))\nX_test_rotated = np.rot270(X_test, k=3, axes=(1,2))\n\nX_train_augmented = np.concatenate((X_train, X_train_rotated), axis=0)\ny_train_augmented = np.concatenate((y_train, y_train), axis=0)\n\ntrain_evaluate_model_with_k_fold(\n    X_train=X_train_augmented,\n    y_train=y_train_augmented,\n    lr=0.01,\n    epochs=50,\n    batch_size=16)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T20:22:13.504699Z","iopub.execute_input":"2025-02-07T20:22:13.504960Z","iopub.status.idle":"2025-02-07T20:26:48.252769Z","shell.execute_reply.started":"2025-02-07T20:22:13.504939Z","shell.execute_reply":"2025-02-07T20:26:48.251876Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"\nTraining on Fold 1...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 418ms/step - accuracy: 0.6981 - loss: 1.2505 - val_accuracy: 0.5000 - val_loss: 1607.7814 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.8862 - loss: 0.2480 - val_accuracy: 0.5000 - val_loss: 394.4673 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9394 - loss: 0.1392 - val_accuracy: 0.5000 - val_loss: 295.5130 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9551 - loss: 0.1141 - val_accuracy: 0.5000 - val_loss: 103.0436 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9614 - loss: 0.1062 - val_accuracy: 0.5333 - val_loss: 15.5523 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9463 - loss: 0.1305 - val_accuracy: 0.5333 - val_loss: 4.8851 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9949 - loss: 0.0614 - val_accuracy: 0.5667 - val_loss: 5.5517 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9921 - loss: 0.0364 - val_accuracy: 0.6667 - val_loss: 1.1213 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9716 - loss: 0.0636 - val_accuracy: 0.8667 - val_loss: 0.3657 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9796 - loss: 0.0567 - val_accuracy: 0.8667 - val_loss: 0.9205 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9958 - loss: 0.0421 - val_accuracy: 1.0000 - val_loss: 0.0221 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9740 - loss: 0.0734 - val_accuracy: 0.8000 - val_loss: 0.9972 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9668 - loss: 0.1015 - val_accuracy: 0.8333 - val_loss: 0.6611 - learning_rate: 0.0100\nEpoch 14/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9826 - loss: 0.0515\nEpoch 14: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9828 - loss: 0.0504 - val_accuracy: 0.9333 - val_loss: 0.0804 - learning_rate: 0.0100\nEpoch 15/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9888 - loss: 0.0265 - val_accuracy: 0.9667 - val_loss: 0.0486 - learning_rate: 1.0000e-03\nEpoch 16/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0099 - val_accuracy: 0.9667 - val_loss: 0.0579 - learning_rate: 1.0000e-03\nEpoch 16: early stopping\nRestoring model weights from the end of the best epoch: 11.\nFold 1 - Train Accuracy: 94.36%, Validation Accuracy: 100.00%\n\nTraining on Fold 2...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 423ms/step - accuracy: 0.6011 - loss: 1.5730 - val_accuracy: 0.5000 - val_loss: 1110.5763 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.7743 - loss: 0.4531 - val_accuracy: 0.5000 - val_loss: 332.4502 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9186 - loss: 0.2578 - val_accuracy: 0.5000 - val_loss: 207.2202 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9128 - loss: 0.2264 - val_accuracy: 0.5000 - val_loss: 79.8109 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9555 - loss: 0.1266 - val_accuracy: 0.5000 - val_loss: 37.6913 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9699 - loss: 0.0825 - val_accuracy: 0.5333 - val_loss: 17.5848 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9760 - loss: 0.0521 - val_accuracy: 0.5667 - val_loss: 10.7115 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9952 - loss: 0.0222 - val_accuracy: 0.5667 - val_loss: 4.4777 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0163 - val_accuracy: 0.5667 - val_loss: 4.1745 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9927 - loss: 0.0175 - val_accuracy: 0.7667 - val_loss: 1.2084 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9922 - loss: 0.0250 - val_accuracy: 0.6000 - val_loss: 3.7155 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9654 - loss: 0.1364 - val_accuracy: 0.5667 - val_loss: 5.3585 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9733 - loss: 0.0819\nEpoch 13: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9746 - loss: 0.0788 - val_accuracy: 0.7000 - val_loss: 2.6380 - learning_rate: 0.0100\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9893 - loss: 0.0385 - val_accuracy: 0.8333 - val_loss: 1.0495 - learning_rate: 1.0000e-03\nEpoch 15/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9951 - loss: 0.0292 - val_accuracy: 0.8667 - val_loss: 0.4811 - learning_rate: 1.0000e-03\nEpoch 16/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9893 - loss: 0.0318 - val_accuracy: 0.9000 - val_loss: 0.2367 - learning_rate: 1.0000e-03\nEpoch 17/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0174 - val_accuracy: 0.9333 - val_loss: 0.1616 - learning_rate: 1.0000e-03\nEpoch 18/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0165 - val_accuracy: 0.9333 - val_loss: 0.1470 - learning_rate: 1.0000e-03\nEpoch 19/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0128 - val_accuracy: 0.9333 - val_loss: 0.1270 - learning_rate: 1.0000e-03\nEpoch 20/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0072 - val_accuracy: 0.9333 - val_loss: 0.1001 - learning_rate: 1.0000e-03\nEpoch 21/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0079 - val_accuracy: 0.9667 - val_loss: 0.0971 - learning_rate: 1.0000e-03\nEpoch 22/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0075 - val_accuracy: 0.9667 - val_loss: 0.0941 - learning_rate: 1.0000e-03\nEpoch 23/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0067 - val_accuracy: 0.9667 - val_loss: 0.0819 - learning_rate: 1.0000e-03\nEpoch 24/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9964 - loss: 0.0102 - val_accuracy: 0.9667 - val_loss: 0.0858 - learning_rate: 1.0000e-03\nEpoch 25/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0062 - val_accuracy: 0.9667 - val_loss: 0.0880 - learning_rate: 1.0000e-03\nEpoch 26/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0066\nEpoch 26: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0070 - val_accuracy: 0.9667 - val_loss: 0.0890 - learning_rate: 1.0000e-03\nEpoch 27/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0087 - val_accuracy: 0.9667 - val_loss: 0.0710 - learning_rate: 1.0000e-04\nEpoch 28/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0053 - val_accuracy: 0.9667 - val_loss: 0.0558 - learning_rate: 1.0000e-04\nEpoch 29/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0047 - val_accuracy: 0.9667 - val_loss: 0.0452 - learning_rate: 1.0000e-04\nEpoch 30/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0073 - val_accuracy: 0.9667 - val_loss: 0.0376 - learning_rate: 1.0000e-04\nEpoch 31/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0067 - val_accuracy: 0.9667 - val_loss: 0.0305 - learning_rate: 1.0000e-04\nEpoch 32/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0061 - val_accuracy: 1.0000 - val_loss: 0.0256 - learning_rate: 1.0000e-04\nEpoch 33/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0043 - val_accuracy: 1.0000 - val_loss: 0.0226 - learning_rate: 1.0000e-04\nEpoch 34/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0060 - val_accuracy: 1.0000 - val_loss: 0.0212 - learning_rate: 1.0000e-04\nEpoch 35/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0041 - val_accuracy: 1.0000 - val_loss: 0.0201 - learning_rate: 1.0000e-04\nEpoch 36/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0047 - val_accuracy: 1.0000 - val_loss: 0.0205 - learning_rate: 1.0000e-04\nEpoch 37/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0051 - val_accuracy: 1.0000 - val_loss: 0.0213 - learning_rate: 1.0000e-04\nEpoch 38/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0046\nEpoch 38: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0047 - val_accuracy: 1.0000 - val_loss: 0.0229 - learning_rate: 1.0000e-04\nEpoch 39/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0053 - val_accuracy: 1.0000 - val_loss: 0.0246 - learning_rate: 1.0000e-05\nEpoch 40/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0051 - val_accuracy: 1.0000 - val_loss: 0.0271 - learning_rate: 1.0000e-05\nEpoch 40: early stopping\nRestoring model weights from the end of the best epoch: 35.\nFold 2 - Train Accuracy: 96.62%, Validation Accuracy: 100.00%\n\nTraining on Fold 3...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 412ms/step - accuracy: 0.6425 - loss: 1.2031 - val_accuracy: 0.5000 - val_loss: 694.2881 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.8560 - loss: 0.3356 - val_accuracy: 0.5000 - val_loss: 337.0931 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9321 - loss: 0.1507 - val_accuracy: 0.5000 - val_loss: 47.6345 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9599 - loss: 0.0628 - val_accuracy: 0.5000 - val_loss: 28.6129 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9914 - loss: 0.0387 - val_accuracy: 0.5000 - val_loss: 11.1439 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9690 - loss: 0.0484 - val_accuracy: 0.5000 - val_loss: 11.2283 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9816 - loss: 0.0390 - val_accuracy: 0.5000 - val_loss: 10.0405 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9727 - loss: 0.0583 - val_accuracy: 0.6333 - val_loss: 2.7623 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9889 - loss: 0.0373 - val_accuracy: 0.5000 - val_loss: 3.4841 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9880 - loss: 0.0476 - val_accuracy: 0.5000 - val_loss: 8.1388 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9947 - loss: 0.0258 - val_accuracy: 0.8000 - val_loss: 1.4421 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9820 - loss: 0.0558 - val_accuracy: 0.9000 - val_loss: 0.7105 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9834 - loss: 0.0423 - val_accuracy: 0.8667 - val_loss: 0.7354 - learning_rate: 0.0100\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9938 - loss: 0.0251 - val_accuracy: 0.6333 - val_loss: 2.0846 - learning_rate: 0.0100\nEpoch 15/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9919 - loss: 0.0180 - val_accuracy: 0.9333 - val_loss: 0.4055 - learning_rate: 0.0100\nEpoch 16/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9927 - loss: 0.0231 - val_accuracy: 0.9333 - val_loss: 0.1398 - learning_rate: 0.0100\nEpoch 17/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9989 - loss: 0.0057 - val_accuracy: 0.9333 - val_loss: 0.4577 - learning_rate: 0.0100\nEpoch 18/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9977 - loss: 0.0066 - val_accuracy: 0.8667 - val_loss: 0.6618 - learning_rate: 0.0100\nEpoch 19/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0035\nEpoch 19: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0035 - val_accuracy: 0.9000 - val_loss: 0.5838 - learning_rate: 0.0100\nEpoch 20/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.9000 - val_loss: 0.4478 - learning_rate: 1.0000e-03\nEpoch 21/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 9.7771e-04 - val_accuracy: 0.9333 - val_loss: 0.3185 - learning_rate: 1.0000e-03\nEpoch 21: early stopping\nRestoring model weights from the end of the best epoch: 16.\nFold 3 - Train Accuracy: 93.23%, Validation Accuracy: 93.33%\n\nTraining on Fold 4...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 433ms/step - accuracy: 0.6825 - loss: 1.3245 - val_accuracy: 0.5000 - val_loss: 1705.3313 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8954 - loss: 0.2588 - val_accuracy: 0.5000 - val_loss: 378.6555 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9290 - loss: 0.1495 - val_accuracy: 0.5000 - val_loss: 64.0954 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9482 - loss: 0.1147 - val_accuracy: 0.5000 - val_loss: 31.9703 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9752 - loss: 0.0813 - val_accuracy: 0.5333 - val_loss: 9.0170 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9802 - loss: 0.0608 - val_accuracy: 0.5667 - val_loss: 3.6397 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9902 - loss: 0.0383 - val_accuracy: 0.8667 - val_loss: 0.6848 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9996 - loss: 0.0301 - val_accuracy: 0.6000 - val_loss: 3.8618 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9861 - loss: 0.0320 - val_accuracy: 0.6667 - val_loss: 2.3868 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9737 - loss: 0.0982\nEpoch 10: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9745 - loss: 0.0958 - val_accuracy: 0.8000 - val_loss: 1.2716 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9848 - loss: 0.0508 - val_accuracy: 0.8667 - val_loss: 0.9117 - learning_rate: 1.0000e-03\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9977 - loss: 0.0196 - val_accuracy: 0.8333 - val_loss: 0.8873 - learning_rate: 1.0000e-03\nEpoch 12: early stopping\nRestoring model weights from the end of the best epoch: 7.\nFold 4 - Train Accuracy: 84.59%, Validation Accuracy: 86.67%\n\nTraining on Fold 5...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 416ms/step - accuracy: 0.7229 - loss: 0.8717 - val_accuracy: 0.5000 - val_loss: 3012.1289 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.8734 - loss: 0.3264 - val_accuracy: 0.5333 - val_loss: 197.7631 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9225 - loss: 0.2217 - val_accuracy: 0.7333 - val_loss: 25.7146 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9591 - loss: 0.1641 - val_accuracy: 0.5000 - val_loss: 46.0752 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9439 - loss: 0.1723 - val_accuracy: 0.6000 - val_loss: 4.9387 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9377 - loss: 0.1862 - val_accuracy: 0.5667 - val_loss: 2.6449 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9615 - loss: 0.1006 - val_accuracy: 0.8667 - val_loss: 0.4068 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9899 - loss: 0.0617 - val_accuracy: 0.7667 - val_loss: 1.1983 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9922 - loss: 0.0233 - val_accuracy: 0.7667 - val_loss: 0.9655 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9995 - loss: 0.0158\nEpoch 10: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9991 - loss: 0.0155 - val_accuracy: 0.8667 - val_loss: 0.5536 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0095 - val_accuracy: 0.9000 - val_loss: 0.4203 - learning_rate: 1.0000e-03\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9991 - loss: 0.0077 - val_accuracy: 0.9333 - val_loss: 0.3215 - learning_rate: 1.0000e-03\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0077 - val_accuracy: 0.9667 - val_loss: 0.2331 - learning_rate: 1.0000e-03\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9942 - loss: 0.0141 - val_accuracy: 0.9667 - val_loss: 0.1192 - learning_rate: 1.0000e-03\nEpoch 15/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0051 - val_accuracy: 0.9667 - val_loss: 0.0595 - learning_rate: 1.0000e-03\nEpoch 16/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0060 - val_accuracy: 0.9667 - val_loss: 0.0373 - learning_rate: 1.0000e-03\nEpoch 17/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0060 - val_accuracy: 1.0000 - val_loss: 0.0166 - learning_rate: 1.0000e-03\nEpoch 18/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0118 - val_accuracy: 1.0000 - val_loss: 0.0140 - learning_rate: 1.0000e-03\nEpoch 19/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0045 - val_accuracy: 1.0000 - val_loss: 0.0095 - learning_rate: 1.0000e-03\nEpoch 20/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0045 - val_accuracy: 1.0000 - val_loss: 0.0085 - learning_rate: 1.0000e-03\nEpoch 21/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0054 - val_accuracy: 1.0000 - val_loss: 0.0088 - learning_rate: 1.0000e-03\nEpoch 22/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0032 - val_accuracy: 1.0000 - val_loss: 0.0081 - learning_rate: 1.0000e-03\nEpoch 23/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 1.0000 - val_loss: 0.0083 - learning_rate: 1.0000e-03\nEpoch 24/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 1.0000 - val_loss: 0.0087 - learning_rate: 1.0000e-03\nEpoch 25/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0043\nEpoch 25: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0042 - val_accuracy: 1.0000 - val_loss: 0.0108 - learning_rate: 1.0000e-03\nEpoch 26/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0030 - val_accuracy: 1.0000 - val_loss: 0.0103 - learning_rate: 1.0000e-04\nEpoch 27/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0036 - val_accuracy: 1.0000 - val_loss: 0.0088 - learning_rate: 1.0000e-04\nEpoch 27: early stopping\nRestoring model weights from the end of the best epoch: 22.\nFold 5 - Train Accuracy: 96.62%, Validation Accuracy: 100.00%\n\nTraining on Fold 6...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 413ms/step - accuracy: 0.7139 - loss: 1.1981 - val_accuracy: 0.5000 - val_loss: 4125.4961 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8791 - loss: 0.2579 - val_accuracy: 0.5000 - val_loss: 1974.9471 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9413 - loss: 0.1494 - val_accuracy: 0.5000 - val_loss: 266.8892 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9461 - loss: 0.0966 - val_accuracy: 0.5000 - val_loss: 63.3284 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9900 - loss: 0.0508 - val_accuracy: 0.5000 - val_loss: 32.3055 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9842 - loss: 0.0409 - val_accuracy: 0.5333 - val_loss: 10.4338 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9701 - loss: 0.0573 - val_accuracy: 0.5000 - val_loss: 12.4102 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9814 - loss: 0.0565 - val_accuracy: 0.6000 - val_loss: 2.2547 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9842 - loss: 0.0425 - val_accuracy: 0.6667 - val_loss: 2.4281 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9955 - loss: 0.0193 - val_accuracy: 0.5667 - val_loss: 3.2786 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9964 - loss: 0.0127\nEpoch 11: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9964 - loss: 0.0128 - val_accuracy: 0.5667 - val_loss: 6.5748 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9878 - loss: 0.0319 - val_accuracy: 0.6000 - val_loss: 5.2052 - learning_rate: 1.0000e-03\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0089 - val_accuracy: 0.6333 - val_loss: 3.9770 - learning_rate: 1.0000e-03\nEpoch 13: early stopping\nRestoring model weights from the end of the best epoch: 8.\nFold 6 - Train Accuracy: 76.32%, Validation Accuracy: 60.00%\n\nTraining on Fold 7...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 416ms/step - accuracy: 0.6477 - loss: 1.3924 - val_accuracy: 0.5172 - val_loss: 3542.1450 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8597 - loss: 0.3562 - val_accuracy: 0.5172 - val_loss: 93.0478 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9029 - loss: 0.2885 - val_accuracy: 0.4828 - val_loss: 29.3248 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9031 - loss: 0.2610 - val_accuracy: 0.5172 - val_loss: 31.1105 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9258 - loss: 0.2901 - val_accuracy: 0.5172 - val_loss: 18.8935 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9350 - loss: 0.2433 - val_accuracy: 0.5172 - val_loss: 5.8304 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9656 - loss: 0.1492 - val_accuracy: 0.4828 - val_loss: 4.2173 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9577 - loss: 0.1214 - val_accuracy: 0.7586 - val_loss: 0.7264 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9886 - loss: 0.0560 - val_accuracy: 0.8276 - val_loss: 0.2833 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9798 - loss: 0.0756 - val_accuracy: 0.8276 - val_loss: 0.6233 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9192 - loss: 0.1994 - val_accuracy: 0.8621 - val_loss: 0.2611 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9827 - loss: 0.1144 - val_accuracy: 0.7586 - val_loss: 0.7053 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9804 - loss: 0.0775 - val_accuracy: 0.8621 - val_loss: 0.5064 - learning_rate: 0.0100\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9823 - loss: 0.0495 - val_accuracy: 0.9310 - val_loss: 0.0792 - learning_rate: 0.0100\nEpoch 15/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9672 - loss: 0.0634 - val_accuracy: 0.8276 - val_loss: 0.4928 - learning_rate: 0.0100\nEpoch 16/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9642 - loss: 0.1249 - val_accuracy: 0.7931 - val_loss: 0.4194 - learning_rate: 0.0100\nEpoch 17/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9748 - loss: 0.0481\nEpoch 17: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9756 - loss: 0.0473 - val_accuracy: 0.8276 - val_loss: 0.5563 - learning_rate: 0.0100\nEpoch 18/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9627 - loss: 0.0698 - val_accuracy: 0.8966 - val_loss: 0.4490 - learning_rate: 1.0000e-03\nEpoch 19/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9885 - loss: 0.0337 - val_accuracy: 0.8966 - val_loss: 0.3631 - learning_rate: 1.0000e-03\nEpoch 19: early stopping\nRestoring model weights from the end of the best epoch: 14.\nFold 7 - Train Accuracy: 96.25%, Validation Accuracy: 93.10%\n\nTraining on Fold 8...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 418ms/step - accuracy: 0.6973 - loss: 1.0603 - val_accuracy: 0.5172 - val_loss: 4163.1133 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.9244 - loss: 0.1771 - val_accuracy: 0.5172 - val_loss: 186.4009 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9575 - loss: 0.0950 - val_accuracy: 0.5172 - val_loss: 44.9895 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9729 - loss: 0.0633 - val_accuracy: 0.5172 - val_loss: 30.4228 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9983 - loss: 0.0203 - val_accuracy: 0.4828 - val_loss: 12.4293 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9914 - loss: 0.0265 - val_accuracy: 0.6552 - val_loss: 4.4827 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9816 - loss: 0.0584 - val_accuracy: 0.7931 - val_loss: 2.2414 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9795 - loss: 0.0728 - val_accuracy: 0.8621 - val_loss: 0.6880 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9621 - loss: 0.0723 - val_accuracy: 0.9655 - val_loss: 0.3013 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9936 - loss: 0.0252 - val_accuracy: 0.9310 - val_loss: 0.5482 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9980 - loss: 0.0128 - val_accuracy: 0.9310 - val_loss: 0.4954 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9964 - loss: 0.0100\nEpoch 12: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9964 - loss: 0.0102 - val_accuracy: 0.8966 - val_loss: 0.7211 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0055 - val_accuracy: 0.9310 - val_loss: 0.5810 - learning_rate: 1.0000e-03\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0073 - val_accuracy: 0.9310 - val_loss: 0.5368 - learning_rate: 1.0000e-03\nEpoch 14: early stopping\nRestoring model weights from the end of the best epoch: 9.\nFold 8 - Train Accuracy: 89.51%, Validation Accuracy: 96.55%\n\nTraining on Fold 9...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 414ms/step - accuracy: 0.7174 - loss: 1.3490 - val_accuracy: 0.4828 - val_loss: 1876.8817 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9287 - loss: 0.2070 - val_accuracy: 0.4828 - val_loss: 488.2412 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9511 - loss: 0.1647 - val_accuracy: 0.4828 - val_loss: 96.0055 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9573 - loss: 0.1189 - val_accuracy: 0.4828 - val_loss: 36.9367 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9730 - loss: 0.0796 - val_accuracy: 0.4828 - val_loss: 21.3071 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9827 - loss: 0.0489 - val_accuracy: 0.5517 - val_loss: 10.6873 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9914 - loss: 0.0314 - val_accuracy: 0.5862 - val_loss: 5.4800 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9866 - loss: 0.0393 - val_accuracy: 0.4828 - val_loss: 7.6419 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9605 - loss: 0.0844 - val_accuracy: 0.8276 - val_loss: 1.3974 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9837 - loss: 0.0328 - val_accuracy: 0.6897 - val_loss: 2.1386 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9716 - loss: 0.0658 - val_accuracy: 0.5862 - val_loss: 1.5871 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9852 - loss: 0.0390 - val_accuracy: 0.8621 - val_loss: 0.4886 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9831 - loss: 0.0438 - val_accuracy: 0.9655 - val_loss: 0.5529 - learning_rate: 0.0100\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0116 - val_accuracy: 0.8276 - val_loss: 0.9912 - learning_rate: 0.0100\nEpoch 15/50\n\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0056\nEpoch 15: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9994 - loss: 0.0068 - val_accuracy: 0.8966 - val_loss: 0.8267 - learning_rate: 0.0100\nEpoch 16/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 0.8966 - val_loss: 0.7150 - learning_rate: 1.0000e-03\nEpoch 17/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.8966 - val_loss: 0.6302 - learning_rate: 1.0000e-03\nEpoch 17: early stopping\nRestoring model weights from the end of the best epoch: 12.\nFold 9 - Train Accuracy: 82.02%, Validation Accuracy: 86.21%\n\nTraining on Fold 10...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 424ms/step - accuracy: 0.6254 - loss: 1.7405 - val_accuracy: 0.5172 - val_loss: 2932.0447 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.8466 - loss: 0.4071 - val_accuracy: 0.4828 - val_loss: 1634.8331 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8646 - loss: 0.3808 - val_accuracy: 0.4828 - val_loss: 261.8527 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9054 - loss: 0.2054 - val_accuracy: 0.4828 - val_loss: 35.9489 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9285 - loss: 0.1551 - val_accuracy: 0.4828 - val_loss: 18.1290 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9528 - loss: 0.0930 - val_accuracy: 0.5517 - val_loss: 11.5473 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9638 - loss: 0.0891 - val_accuracy: 0.5517 - val_loss: 7.9227 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9845 - loss: 0.0514 - val_accuracy: 0.5862 - val_loss: 4.6441 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9646 - loss: 0.0884 - val_accuracy: 0.8966 - val_loss: 1.2115 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9677 - loss: 0.0918 - val_accuracy: 0.8621 - val_loss: 0.4132 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9670 - loss: 0.1039 - val_accuracy: 0.8966 - val_loss: 0.7937 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9769 - loss: 0.0742 - val_accuracy: 0.9310 - val_loss: 0.3315 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9848 - loss: 0.0479 - val_accuracy: 0.8966 - val_loss: 0.5449 - learning_rate: 0.0100\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9781 - loss: 0.0613 - val_accuracy: 0.8621 - val_loss: 1.0021 - learning_rate: 0.0100\nEpoch 15/50\n\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9952 - loss: 0.0277\nEpoch 15: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9934 - loss: 0.0307 - val_accuracy: 0.9310 - val_loss: 0.4817 - learning_rate: 0.0100\nEpoch 16/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9915 - loss: 0.0325 - val_accuracy: 0.9310 - val_loss: 0.4130 - learning_rate: 1.0000e-03\nEpoch 17/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0156 - val_accuracy: 0.9310 - val_loss: 0.3575 - learning_rate: 1.0000e-03\nEpoch 17: early stopping\nRestoring model weights from the end of the best epoch: 12.\nFold 10 - Train Accuracy: 96.63%, Validation Accuracy: 93.10%\n\nAverage Training Accuracy: 90.61%\nAverage Validation Accuracy: 90.90%\n","output_type":"stream"}],"execution_count":95},{"cell_type":"markdown","source":"# 3 Network Training","metadata":{}},{"cell_type":"markdown","source":"## 3.1 Data Preparation","metadata":{}},{"cell_type":"code","source":"X_train_flipped = np.flip(X_train, axis=2)\nX_train_rotated_90 = np.rot90(X_train, k=1, axes=(1,2))\nX_train_rotated_180 = np.rot90(X_train, k=2, axes=(1,2))\nX_train_rotated_270 = np.rot90(X_train, k=3, axes=(1,2))\n\nX_train_augmented = np.concatenate((X_train, X_train_flipped, X_train_rotated_90, X_train_rotated_180, X_train_rotated_270), axis=0)\ny_train_augmented = np.concatenate((y_train, y_train, y_train, y_train, y_train), axis=0)\n\nindices = np.arange(X_train_augmented.shape[0])\nnp.random.shuffle(indices)\nX_train_augmented = X_train_augmented[indices]\ny_train_augmented = y_train_augmented[indices]\n\n# Split the data into training (80%) and validation (20%) sets\nX_train_final, X_val_final, y_train_final, y_val_final = train_test_split(X_train_augmented, y_train_augmented, test_size=0.5, random_state=33)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T23:05:19.879644Z","iopub.execute_input":"2025-02-07T23:05:19.879966Z","iopub.status.idle":"2025-02-07T23:05:20.363798Z","shell.execute_reply.started":"2025-02-07T23:05:19.879940Z","shell.execute_reply":"2025-02-07T23:05:20.362685Z"}},"outputs":[],"execution_count":33},{"cell_type":"markdown","source":"## 3.2 Training","metadata":{}},{"cell_type":"code","source":"model = define_model(\n    input_shape=(150,150,3),\n    lr=0.020\n)\n\nhistory = model.fit(\n    X_train_final, y_train_final,\n    validation_data=(X_val_final, y_val_final),\n    epochs=50,\n    batch_size=32,\n    callbacks=[\n        EarlyStopping(monitor=\"val_loss\", patience=15, restore_best_weights=True, verbose=1),\n        ReduceLROnPlateau(monitor='val_loss', factor=0.05, patience=3, verbose=1)\n    ],\n    verbose=1,\n    shuffle=True\n)\n\n# Extract loss & accuracy\nloss = history.history['loss']\nloss = np.log(loss)\nval_loss = history.history['val_loss']\nval_loss = np.log(val_loss)\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\n# Plot Loss\nplt.figure(figsize=(12, 5))\nplt.subplot(1, 2, 1)\nplt.plot(loss, label=\"Train Loss\")\nplt.plot(val_loss, label=\"Validation Loss\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Logarithmic loss\")\nplt.legend()\nplt.title(\"Logarithmic loss over epochs\")\n\n# Plot Accuracy\nplt.subplot(1, 2, 2)\nplt.plot(acc, label=\"Train Accuracy\")\nplt.plot(val_acc, label=\"Validation Accuracy\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Accuracy\")\nplt.legend()\nplt.title(\"Accuracy over epochs\")\n\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T23:05:22.097614Z","iopub.execute_input":"2025-02-07T23:05:22.097928Z","iopub.status.idle":"2025-02-07T23:06:02.284863Z","shell.execute_reply.started":"2025-02-07T23:05:22.097898Z","shell.execute_reply":"2025-02-07T23:06:02.283979Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/50\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 857ms/step - accuracy: 0.5702 - loss: 1.4343 - val_accuracy: 0.4757 - val_loss: 52885.6641 - learning_rate: 0.0200\nEpoch 2/50\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8792 - loss: 0.3175 - val_accuracy: 0.4757 - val_loss: 13876.8975 - learning_rate: 0.0200\nEpoch 3/50\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9179 - loss: 0.1725 - val_accuracy: 0.4757 - val_loss: 2842.7744 - learning_rate: 0.0200\nEpoch 4/50\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9409 - loss: 0.1424 - val_accuracy: 0.4054 - val_loss: 69.5927 - learning_rate: 0.0200\nEpoch 5/50\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9830 - loss: 0.0604 - val_accuracy: 0.4757 - val_loss: 431.8403 - learning_rate: 0.0200\nEpoch 6/50\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9877 - loss: 0.0477 - val_accuracy: 0.4757 - val_loss: 153.0395 - learning_rate: 0.0200\nEpoch 7/50\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0117\nEpoch 7: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0117 - val_accuracy: 0.4811 - val_loss: 82.3707 - learning_rate: 0.0200\nEpoch 8/50\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.0070 - val_accuracy: 0.4811 - val_loss: 55.3751 - learning_rate: 1.0000e-03\nEpoch 9/50\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.0080 - val_accuracy: 0.4757 - val_loss: 34.5208 - learning_rate: 1.0000e-03\nEpoch 10/50\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.0055 - val_accuracy: 0.4892 - val_loss: 22.2828 - learning_rate: 1.0000e-03\nEpoch 11/50\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9978 - loss: 0.0100 - val_accuracy: 0.5081 - val_loss: 14.7935 - learning_rate: 1.0000e-03\nEpoch 12/50\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 0.0054 - val_accuracy: 0.5297 - val_loss: 9.9458 - learning_rate: 1.0000e-03\nEpoch 13/50\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.0092 - val_accuracy: 0.5946 - val_loss: 6.7540 - learning_rate: 1.0000e-03\nEpoch 14/50\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9982 - loss: 0.0062 - val_accuracy: 0.6243 - val_loss: 4.5797 - learning_rate: 1.0000e-03\nEpoch 15/50\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.0039 - val_accuracy: 0.6649 - val_loss: 3.0256 - learning_rate: 1.0000e-03\nEpoch 16/50\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9991 - loss: 0.0081 - val_accuracy: 0.7405 - val_loss: 1.9749 - learning_rate: 1.0000e-03\nEpoch 17/50\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.0064 - val_accuracy: 0.7865 - val_loss: 1.3446 - learning_rate: 1.0000e-03\nEpoch 18/50\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.0062 - val_accuracy: 0.8514 - val_loss: 0.9054 - learning_rate: 1.0000e-03\nEpoch 19/50\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0065 - val_accuracy: 0.8703 - val_loss: 0.6922 - learning_rate: 1.0000e-03\nEpoch 20/50\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.0076 - val_accuracy: 0.8865 - val_loss: 0.5408 - learning_rate: 1.0000e-03\nEpoch 21/50\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0032 - val_accuracy: 0.9027 - val_loss: 0.4160 - learning_rate: 1.0000e-03\nEpoch 22/50\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9967 - loss: 0.0052 - val_accuracy: 0.9270 - val_loss: 0.3105 - learning_rate: 1.0000e-03\nEpoch 23/50\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.0035 - val_accuracy: 0.9351 - val_loss: 0.2632 - learning_rate: 1.0000e-03\nEpoch 24/50\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.0042 - val_accuracy: 0.9378 - val_loss: 0.2492 - learning_rate: 1.0000e-03\nEpoch 25/50\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.9351 - val_loss: 0.2448 - learning_rate: 1.0000e-03\nEpoch 26/50\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0033 - val_accuracy: 0.9405 - val_loss: 0.2404 - learning_rate: 1.0000e-03\nEpoch 27/50\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.0032 - val_accuracy: 0.9432 - val_loss: 0.2335 - learning_rate: 1.0000e-03\nEpoch 28/50\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.0035 - val_accuracy: 0.9486 - val_loss: 0.2324 - learning_rate: 1.0000e-03\nEpoch 29/50\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 0.9514 - val_loss: 0.2311 - learning_rate: 1.0000e-03\nEpoch 30/50\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9947 - loss: 0.0083 - val_accuracy: 0.9432 - val_loss: 0.2489 - learning_rate: 1.0000e-03\nEpoch 31/50\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.0046 - val_accuracy: 0.9405 - val_loss: 0.2497 - learning_rate: 1.0000e-03\nEpoch 32/50\n\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9979 - loss: 0.0034\nEpoch 32: ReduceLROnPlateau reducing learning rate to 4.9999996554106475e-05.\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9978 - loss: 0.0035 - val_accuracy: 0.9486 - val_loss: 0.2387 - learning_rate: 1.0000e-03\nEpoch 33/50\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.9486 - val_loss: 0.2356 - learning_rate: 5.0000e-05\nEpoch 34/50\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0032 - val_accuracy: 0.9486 - val_loss: 0.2333 - learning_rate: 5.0000e-05\nEpoch 35/50\n\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0030\nEpoch 35: ReduceLROnPlateau reducing learning rate to 2.499999754945748e-06.\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0030 - val_accuracy: 0.9514 - val_loss: 0.2324 - learning_rate: 5.0000e-05\nEpoch 36/50\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.9514 - val_loss: 0.2320 - learning_rate: 2.5000e-06\nEpoch 37/50\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 0.9514 - val_loss: 0.2325 - learning_rate: 2.5000e-06\nEpoch 38/50\n\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0027 \nEpoch 38: ReduceLROnPlateau reducing learning rate to 1.2499998547355062e-07.\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 0.9514 - val_loss: 0.2332 - learning_rate: 2.5000e-06\nEpoch 39/50\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0036 - val_accuracy: 0.9541 - val_loss: 0.2322 - learning_rate: 1.2500e-07\nEpoch 40/50\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0023 - val_accuracy: 0.9541 - val_loss: 0.2343 - learning_rate: 1.2500e-07\nEpoch 41/50\n\u001b[1m10/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0038 \nEpoch 41: ReduceLROnPlateau reducing learning rate to 6.249999273677532e-09.\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.0038 - val_accuracy: 0.9541 - val_loss: 0.2348 - learning_rate: 1.2500e-07\nEpoch 42/50\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.9541 - val_loss: 0.2373 - learning_rate: 6.2500e-09\nEpoch 43/50\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9989 - loss: 0.0037 - val_accuracy: 0.9541 - val_loss: 0.2377 - learning_rate: 6.2500e-09\nEpoch 44/50\n\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0032 \nEpoch 44: ReduceLROnPlateau reducing learning rate to 3.124999592429845e-10.\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0033 - val_accuracy: 0.9541 - val_loss: 0.2404 - learning_rate: 6.2500e-09\nEpoch 44: early stopping\nRestoring model weights from the end of the best epoch: 29.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1200x500 with 2 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":34},{"cell_type":"markdown","source":"# 4 Network Evaluation","metadata":{}},{"cell_type":"markdown","source":"## 4.1 Evaluation Metrics","metadata":{}},{"cell_type":"code","source":"y_pred = model.predict(X_test)\ny_pred_classes = (y_pred.reshape(-1) >= 0.5).astype(int)\n\n# Report the evaluation metrics\naccuracy = accuracy_score(y_test, y_pred_classes)\nprecision = precision_score(y_test, y_pred_classes, average='weighted')\nsensitivity = recall_score(y_test, y_pred_classes, average='weighted') # Sensitivity = Recall\nspecificity = recall_score(y_test, y_pred_classes, average='weighted') # Specificity is (1 - False Positive Rate)\nf1 = f1_score(y_test, y_pred_classes, average='weighted')\n\n# Print the classification report (for precision, recall, F1)\nprint(\"Classification Report:\")\nprint(classification_report(y_test, y_pred_classes))\n\n# Print the evaluation metrics\nprint(f\"Accuracy: {accuracy:.4f}\")\nprint(f\"Precision: {precision:.4f}\")\nprint(f\"Sensitivity: {sensitivity:.4f}\")\nprint(f\"Specificity: {specificity:.4f}\")\nprint(f\"F1 Score: {f1:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T23:06:49.504433Z","iopub.execute_input":"2025-02-07T23:06:49.504739Z","iopub.status.idle":"2025-02-07T23:06:50.554376Z","shell.execute_reply.started":"2025-02-07T23:06:49.504716Z","shell.execute_reply":"2025-02-07T23:06:50.553507Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 481ms/step\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.95      0.95      0.95        20\n           1       0.95      0.95      0.95        20\n\n    accuracy                           0.95        40\n   macro avg       0.95      0.95      0.95        40\nweighted avg       0.95      0.95      0.95        40\n\nAccuracy: 0.9500\nPrecision: 0.9500\nSensitivity: 0.9500\nSpecificity: 0.9500\nF1 Score: 0.9500\n","output_type":"stream"}],"execution_count":35},{"cell_type":"markdown","source":"## 4.2 Confusion Matrix","metadata":{}},{"cell_type":"code","source":"# Confusion Matrix\ncm = confusion_matrix(y_test, y_pred_classes)\n\n# Plot the confusion matrix\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=np.unique(y_test), yticklabels=np.unique(y_test))\nplt.title(\"Confusion Matrix\")\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T23:07:32.344687Z","iopub.execute_input":"2025-02-07T23:07:32.345010Z","iopub.status.idle":"2025-02-07T23:07:32.532878Z","shell.execute_reply.started":"2025-02-07T23:07:32.344982Z","shell.execute_reply":"2025-02-07T23:07:32.532061Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 800x600 with 2 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":36},{"cell_type":"markdown","source":"# All in Once","metadata":{}},{"cell_type":"code","source":"lr = 0.004\nbatch_size = 26\nlr_factor_reduce = 0.2\nlr_patience_reduce = 7\ntest_size = 0.3\nepochs = 100\n\n\nX_train_flipped = np.flip(X_train, axis=2)\nX_train_rotated_90 = np.rot90(X_train, k=1, axes=(1,2))\nX_train_rotated_180 = np.rot90(X_train, k=2, axes=(1,2))\nX_train_rotated_270 = np.rot90(X_train, k=3, axes=(1,2))\n\nX_train_augmented = np.concatenate((X_train, X_train_flipped, X_train_rotated_90, X_train_rotated_180, X_train_rotated_270), axis=0)\ny_train_augmented = np.concatenate((y_train, y_train, y_train, y_train, y_train), axis=0)\n\nindices = np.arange(X_train_augmented.shape[0])\nnp.random.shuffle(indices)\nX_train_augmented = X_train_augmented[indices]\ny_train_augmented = y_train_augmented[indices]\n\n# Split the data into training (80%) and validation (20%) sets\nX_train_final, X_val_final, y_train_final, y_val_final = train_test_split(X_train_augmented, y_train_augmented, test_size=test_size, random_state=33)\n\nmodel = define_model(\n    input_shape=(150,150,3),\n    lr=lr\n)\n\nhistory = model.fit(\n    X_train_final, y_train_final,\n    validation_data=(X_val_final, y_val_final),\n    epochs=epochs,\n    batch_size=batch_size,\n    callbacks=[\n        EarlyStopping(monitor=\"val_loss\", patience=15, restore_best_weights=True, verbose=1),\n        ReduceLROnPlateau(monitor='val_loss', factor=lr_factor_reduce, patience=lr_patience_reduce, verbose=1)\n    ],\n    verbose=1,\n    shuffle=True\n)\n\n# Extract loss & accuracy\nloss = history.history['loss']\nloss = np.log(loss)\nval_loss = history.history['val_loss']\nval_loss = np.log(val_loss)\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\n# Plot Loss\nplt.figure(figsize=(12, 5))\nplt.subplot(1, 2, 1)\nplt.plot(loss, label=\"Train Loss\")\nplt.plot(val_loss, label=\"Validation Loss\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Logarithmic loss\")\nplt.legend()\nplt.title(\"Logarithmic loss over epochs\")\n\n# Plot Accuracy\nplt.subplot(1, 2, 2)\nplt.plot(acc, label=\"Train Accuracy\")\nplt.plot(val_acc, label=\"Validation Accuracy\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Accuracy\")\nplt.legend()\nplt.title(\"Accuracy over epochs\")\n\nplt.show()\n\ny_pred = model.predict(X_test)\ny_pred_classes = (y_pred.reshape(-1) >= 0.5).astype(int)\n\n# Report the evaluation metrics\naccuracy = accuracy_score(y_test, y_pred_classes)\nprecision = precision_score(y_test, y_pred_classes, average='weighted')\nsensitivity = recall_score(y_test, y_pred_classes, average='weighted') # Sensitivity = Recall\nspecificity = recall_score(y_test, y_pred_classes, average='weighted') # Specificity is (1 - False Positive Rate)\nf1 = f1_score(y_test, y_pred_classes, average='weighted')\n\n# Print the classification report (for precision, recall, F1)\nprint(\"Classification Report:\")\nprint(classification_report(y_test, y_pred_classes))\n\n# Print the evaluation metrics\nprint(f\"Accuracy: {accuracy:.4f}\")\nprint(f\"Precision: {precision:.4f}\")\nprint(f\"Sensitivity: {sensitivity:.4f}\")\nprint(f\"Specificity: {specificity:.4f}\")\nprint(f\"F1 Score: {f1:.4f}\")\n\n# Confusion Matrix\ncm = confusion_matrix(y_test, y_pred_classes)\n\n# Plot the confusion matrix\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=np.unique(y_test), yticklabels=np.unique(y_test))\nplt.title(\"Confusion Matrix\")\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T23:34:42.664913Z","iopub.execute_input":"2025-02-07T23:34:42.665203Z","iopub.status.idle":"2025-02-07T23:35:40.912200Z","shell.execute_reply.started":"2025-02-07T23:34:42.665181Z","shell.execute_reply":"2025-02-07T23:35:40.911409Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 500ms/step - accuracy: 0.7067 - loss: 0.7654 - val_accuracy: 0.4775 - val_loss: 60.1343 - learning_rate: 0.0040\nEpoch 2/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.9218 - loss: 0.2116 - val_accuracy: 0.6126 - val_loss: 5.7718 - learning_rate: 0.0040\nEpoch 3/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9439 - loss: 0.1339 - val_accuracy: 0.4820 - val_loss: 13.1562 - learning_rate: 0.0040\nEpoch 4/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9661 - loss: 0.0766 - val_accuracy: 0.4775 - val_loss: 10.7406 - learning_rate: 0.0040\nEpoch 5/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.9859 - loss: 0.0346 - val_accuracy: 0.4775 - val_loss: 8.9596 - learning_rate: 0.0040\nEpoch 6/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9807 - loss: 0.0382 - val_accuracy: 0.4775 - val_loss: 11.2367 - learning_rate: 0.0040\nEpoch 7/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9922 - loss: 0.0265 - val_accuracy: 0.4775 - val_loss: 9.8428 - learning_rate: 0.0040\nEpoch 8/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.9961 - loss: 0.0137 - val_accuracy: 0.4775 - val_loss: 7.8684 - learning_rate: 0.0040\nEpoch 9/100\n\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0064\nEpoch 9: ReduceLROnPlateau reducing learning rate to 0.000800000037997961.\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0063 - val_accuracy: 0.4775 - val_loss: 9.7433 - learning_rate: 0.0040\nEpoch 10/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0061 - val_accuracy: 0.4775 - val_loss: 9.5339 - learning_rate: 8.0000e-04\nEpoch 11/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0040 - val_accuracy: 0.4775 - val_loss: 9.2521 - learning_rate: 8.0000e-04\nEpoch 12/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0023 - val_accuracy: 0.4775 - val_loss: 8.7894 - learning_rate: 8.0000e-04\nEpoch 13/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0043 - val_accuracy: 0.4775 - val_loss: 7.8174 - learning_rate: 8.0000e-04\nEpoch 14/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0037 - val_accuracy: 0.4775 - val_loss: 7.4391 - learning_rate: 8.0000e-04\nEpoch 15/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.4775 - val_loss: 6.6073 - learning_rate: 8.0000e-04\nEpoch 16/100\n\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0016\nEpoch 16: ReduceLROnPlateau reducing learning rate to 0.00016000000759959222.\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.4775 - val_loss: 5.9972 - learning_rate: 8.0000e-04\nEpoch 17/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.4820 - val_loss: 5.5594 - learning_rate: 1.6000e-04\nEpoch 18/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.4820 - val_loss: 5.0712 - learning_rate: 1.6000e-04\nEpoch 19/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.4955 - val_loss: 4.5788 - learning_rate: 1.6000e-04\nEpoch 20/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.4955 - val_loss: 3.9763 - learning_rate: 1.6000e-04\nEpoch 21/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.5180 - val_loss: 3.3078 - learning_rate: 1.6000e-04\nEpoch 22/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 8.6263e-04 - val_accuracy: 0.5721 - val_loss: 2.7043 - learning_rate: 1.6000e-04\nEpoch 23/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.6261 - val_loss: 2.2830 - learning_rate: 1.6000e-04\nEpoch 24/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.6802 - val_loss: 1.9333 - learning_rate: 1.6000e-04\nEpoch 25/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.7297 - val_loss: 1.5626 - learning_rate: 1.6000e-04\nEpoch 26/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 8.6292e-04 - val_accuracy: 0.7658 - val_loss: 1.2396 - learning_rate: 1.6000e-04\nEpoch 27/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 8.7005e-04 - val_accuracy: 0.8063 - val_loss: 1.0007 - learning_rate: 1.6000e-04\nEpoch 28/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.8514 - val_loss: 0.8347 - learning_rate: 1.6000e-04\nEpoch 29/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 8.4257e-04 - val_accuracy: 0.8559 - val_loss: 0.7061 - learning_rate: 1.6000e-04\nEpoch 30/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.8784 - val_loss: 0.5926 - learning_rate: 1.6000e-04\nEpoch 31/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 9.8912e-04 - val_accuracy: 0.8919 - val_loss: 0.5091 - learning_rate: 1.6000e-04\nEpoch 32/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 9.9800e-04 - val_accuracy: 0.9009 - val_loss: 0.4412 - learning_rate: 1.6000e-04\nEpoch 33/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.9099 - val_loss: 0.3649 - learning_rate: 1.6000e-04\nEpoch 34/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.9144 - val_loss: 0.3478 - learning_rate: 1.6000e-04\nEpoch 35/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 7.5903e-04 - val_accuracy: 0.9324 - val_loss: 0.3217 - learning_rate: 1.6000e-04\nEpoch 36/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.9324 - val_loss: 0.2976 - learning_rate: 1.6000e-04\nEpoch 37/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 8.4841e-04 - val_accuracy: 0.9324 - val_loss: 0.2922 - learning_rate: 1.6000e-04\nEpoch 38/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.9324 - val_loss: 0.2760 - learning_rate: 1.6000e-04\nEpoch 39/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 6.0770e-04 - val_accuracy: 0.9324 - val_loss: 0.2617 - learning_rate: 1.6000e-04\nEpoch 40/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 6.6985e-04 - val_accuracy: 0.9279 - val_loss: 0.2480 - learning_rate: 1.6000e-04\nEpoch 41/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.9279 - val_loss: 0.2499 - learning_rate: 1.6000e-04\nEpoch 42/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.9369 - val_loss: 0.2346 - learning_rate: 1.6000e-04\nEpoch 43/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.9414 - val_loss: 0.1998 - learning_rate: 1.6000e-04\nEpoch 44/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 9.6379e-04 - val_accuracy: 0.9414 - val_loss: 0.2006 - learning_rate: 1.6000e-04\nEpoch 45/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.9505 - val_loss: 0.1912 - learning_rate: 1.6000e-04\nEpoch 46/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 7.7933e-04 - val_accuracy: 0.9505 - val_loss: 0.1940 - learning_rate: 1.6000e-04\nEpoch 47/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.9505 - val_loss: 0.1962 - learning_rate: 1.6000e-04\nEpoch 48/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 6.8516e-04 - val_accuracy: 0.9459 - val_loss: 0.1992 - learning_rate: 1.6000e-04\nEpoch 49/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.9459 - val_loss: 0.2083 - learning_rate: 1.6000e-04\nEpoch 50/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 9.6625e-04 - val_accuracy: 0.9459 - val_loss: 0.2007 - learning_rate: 1.6000e-04\nEpoch 51/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 6.2154e-04 - val_accuracy: 0.9459 - val_loss: 0.1979 - learning_rate: 1.6000e-04\nEpoch 52/100\n\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 6.6615e-04\nEpoch 52: ReduceLROnPlateau reducing learning rate to 3.200000210199505e-05.\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 6.7547e-04 - val_accuracy: 0.9459 - val_loss: 0.1968 - learning_rate: 1.6000e-04\nEpoch 53/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 9.8396e-04 - val_accuracy: 0.9459 - val_loss: 0.1965 - learning_rate: 3.2000e-05\nEpoch 54/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.9505 - val_loss: 0.1900 - learning_rate: 3.2000e-05\nEpoch 55/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.9505 - val_loss: 0.1903 - learning_rate: 3.2000e-05\nEpoch 56/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 8.9863e-04 - val_accuracy: 0.9505 - val_loss: 0.1914 - learning_rate: 3.2000e-05\nEpoch 57/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.9459 - val_loss: 0.1946 - learning_rate: 3.2000e-05\nEpoch 58/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 7.3690e-04 - val_accuracy: 0.9459 - val_loss: 0.1955 - learning_rate: 3.2000e-05\nEpoch 59/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 8.2088e-04 - val_accuracy: 0.9505 - val_loss: 0.1956 - learning_rate: 3.2000e-05\nEpoch 60/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 8.1844e-04 - val_accuracy: 0.9459 - val_loss: 0.1969 - learning_rate: 3.2000e-05\nEpoch 61/100\n\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 7.2358e-04\nEpoch 61: ReduceLROnPlateau reducing learning rate to 6.400000711437315e-06.\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 7.2920e-04 - val_accuracy: 0.9459 - val_loss: 0.1993 - learning_rate: 3.2000e-05\nEpoch 62/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.9459 - val_loss: 0.1989 - learning_rate: 6.4000e-06\nEpoch 63/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.9459 - val_loss: 0.2032 - learning_rate: 6.4000e-06\nEpoch 64/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.9459 - val_loss: 0.2045 - learning_rate: 6.4000e-06\nEpoch 65/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.9459 - val_loss: 0.2043 - learning_rate: 6.4000e-06\nEpoch 66/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.9459 - val_loss: 0.2027 - learning_rate: 6.4000e-06\nEpoch 67/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 5.8626e-04 - val_accuracy: 0.9459 - val_loss: 0.2010 - learning_rate: 6.4000e-06\nEpoch 68/100\n\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0012\nEpoch 68: ReduceLROnPlateau reducing learning rate to 1.2800001059076749e-06.\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.9459 - val_loss: 0.2026 - learning_rate: 6.4000e-06\nEpoch 69/100\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 5.8719e-04 - val_accuracy: 0.9459 - val_loss: 0.2008 - learning_rate: 1.2800e-06\nEpoch 69: early stopping\nRestoring model weights from the end of the best epoch: 54.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1200x500 with 2 Axes>","image/png":"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\n"},"metadata":{}},{"name":"stdout","text":"\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 480ms/step\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       1.00      0.65      0.79        20\n           1       0.74      1.00      0.85        20\n\n    accuracy                           0.82        40\n   macro avg       0.87      0.82      0.82        40\nweighted avg       0.87      0.82      0.82        40\n\nAccuracy: 0.8250\nPrecision: 0.8704\nSensitivity: 0.8250\nSpecificity: 0.8250\nF1 Score: 0.8195\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 800x600 with 2 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":54},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}