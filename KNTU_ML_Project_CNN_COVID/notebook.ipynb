{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 1 Prerequisites","metadata":{}},{"cell_type":"code","source":"import gdown\nfrom pickle import dump, load\nimport shutil\nimport os\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, Input\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\nimport seaborn as sns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T22:02:28.747192Z","iopub.execute_input":"2025-02-07T22:02:28.747566Z","iopub.status.idle":"2025-02-07T22:02:28.752600Z","shell.execute_reply.started":"2025-02-07T22:02:28.747535Z","shell.execute_reply":"2025-02-07T22:02:28.751789Z"}},"outputs":[],"execution_count":148},{"cell_type":"code","source":"np.random.seed(33)\ntf.random.set_seed(33)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T19:56:35.815294Z","iopub.execute_input":"2025-02-07T19:56:35.816200Z","iopub.status.idle":"2025-02-07T19:56:35.853994Z","shell.execute_reply.started":"2025-02-07T19:56:35.816169Z","shell.execute_reply":"2025-02-07T19:56:35.852916Z"}},"outputs":[],"execution_count":89},{"cell_type":"markdown","source":"## 1.1 Required global functions","metadata":{}},{"cell_type":"code","source":"def download_from_drive(filename, file_id):\n    url = f\"https://drive.google.com/uc?export=download&id={file_id}\"\n    gdown.download(url, filename, quiet=False)\n\ndef load_dataset(image_size=(150, 150)):\n\n    categories = [\"NORMAL\", \"COVID\"]\n    datasets_name_list = [\"test\", \"train\"]\n    X = [[], []] # 0 for test & 1 for train\n    y = [[], []] # 0 for test & 1 for train\n\n    for i, dataset_name in enumerate(datasets_name_list):\n        for label, category in enumerate(categories):\n            dir_path = \"/kaggle/working/dataset1/\" + dataset_name + '/' + category + '/'\n            for filename in os.listdir(dir_path):\n                img_path = os.path.join(dir_path, filename)\n                img = Image.open(img_path).convert(\"RGB\")\n                img = img.resize(image_size)\n                img_array = np.array(img)\n                X[i].append(img_array)\n                y[i].append(label) # NORMAL = 0, COVID = 1\n\n    X_train = np.array(X[1]) / 255.0\n    y_train = np.array(y[1])\n    X_test = np.array(X[0]) / 255.0\n    y_test = np.array(y[0])\n\n    indices = np.arange(X_train.shape[0])\n    np.random.shuffle(indices)\n    X_train = X_train[indices]\n    y_train = y_train[indices]\n\n    return X_train, y_train, X_test, y_test\n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T19:17:50.392967Z","iopub.execute_input":"2025-02-07T19:17:50.393302Z","iopub.status.idle":"2025-02-07T19:17:50.400320Z","shell.execute_reply.started":"2025-02-07T19:17:50.393278Z","shell.execute_reply":"2025-02-07T19:17:50.399503Z"}},"outputs":[],"execution_count":71},{"cell_type":"markdown","source":"## 1.2 Downloading & Loading the dataset","metadata":{}},{"cell_type":"code","source":"download_from_drive(\n    filename=\"Datasets.rar\",\n    file_id=\"1wM1NufVrRtbHuLmeBjiOls_e80Qrsoy-\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T09:59:56.327216Z","iopub.execute_input":"2025-02-07T09:59:56.327604Z","iopub.status.idle":"2025-02-07T10:00:02.919933Z","shell.execute_reply.started":"2025-02-07T09:59:56.327571Z","shell.execute_reply":"2025-02-07T10:00:02.918908Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stderr","text":"Downloading...\nFrom (original): https://drive.google.com/uc?export=download&id=1wM1NufVrRtbHuLmeBjiOls_e80Qrsoy-\nFrom (redirected): https://drive.google.com/uc?export=download&id=1wM1NufVrRtbHuLmeBjiOls_e80Qrsoy-&confirm=t&uuid=4c6dd7af-157c-41c9-bdd4-0caa4dc59bae\nTo: /kaggle/working/Datasets.rar\n100%|██████████| 220M/220M [00:02<00:00, 81.0MB/s] \n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# Extract the Datasets.rar file in the current directory\n!unrar x \"Datasets.rar\" ./","metadata":{"trusted":true,"_kg_hide-output":true,"scrolled":true,"execution":{"iopub.status.busy":"2025-02-07T10:00:02.921204Z","iopub.execute_input":"2025-02-07T10:00:02.921494Z","iopub.status.idle":"2025-02-07T10:00:05.358943Z","shell.execute_reply.started":"2025-02-07T10:00:02.921468Z","shell.execute_reply":"2025-02-07T10:00:05.357315Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"\nUNRAR 6.11 beta 1 freeware      Copyright (c) 1993-2022 Alexander Roshal\n\n\nExtracting from Datasets.rar\n\nCreating    ./dataset2                                                OK\nCreating    ./dataset2/test                                           OK\nCreating    ./dataset2/test/NORMAL                                    OK\nExtracting  ./dataset2/test/NORMAL/NORMAL(1266).jpg                      0  OK \nExtracting  ./dataset2/test/NORMAL/NORMAL(1267).jpg                      0  OK \nExtracting  ./dataset2/test/NORMAL/NORMAL(1268).jpg                      0  OK \nExtracting  ./dataset2/test/NORMAL/NORMAL(1269).jpg                      1  OK \nExtracting  ./dataset2/test/NORMAL/NORMAL(1270).jpg                      1  OK \nExtracting  ./dataset2/test/NORMAL/NORMAL(1271).jpg                      1  OK \nExtracting  ./dataset2/test/NORMAL/NORMAL(1272).jpg                      2  OK \nExtracting  ./dataset2/test/NORMAL/NORMAL(1273).jpg                      2  OK \nExtracting  ./dataset2/test/NORMAL/NORMAL(1274).jpg                      2  OK \nExtracting  ./dataset2/test/NORMAL/NORMAL(1275).jpg                      2  OK \nExtracting  ./dataset2/test/NORMAL/NORMAL(1276).jpg                      3  OK \nExtracting  ./dataset2/test/NORMAL/NORMAL(1277).jpg                      3  OK \nExtracting  ./dataset2/test/NORMAL/NORMAL(1278).jpg                      3  OK \nExtracting  ./dataset2/test/NORMAL/NORMAL(1279).jpg                      3  OK \nExtracting  ./dataset2/test/NORMAL/NORMAL(1280).jpg                      4  OK \nExtracting  ./dataset2/test/NORMAL/NORMAL(1281).jpg                      4  OK \nExtracting  ./dataset2/test/NORMAL/NORMAL(1282).jpg                      4  OK \nExtracting  ./dataset2/test/NORMAL/NORMAL(1283).jpg                      5  OK \nExtracting  ./dataset2/test/NORMAL/NORMAL(1284).jpg                      5  OK \nExtracting  ./dataset2/test/NORMAL/NORMAL(1285).jpg                      6  OK \nExtracting  ./dataset2/test/NORMAL/NORMAL(1286).jpg                      6  OK \nExtracting  ./dataset2/test/NORMAL/NORMAL(1287).jpg                      6  OK \nExtracting  ./dataset2/test/NORMAL/NORMAL(1288).jpg                      7  OK \nExtracting  ./dataset2/test/NORMAL/NORMAL(1289).jpg                      7  OK \nExtracting  ./dataset2/test/NORMAL/NORMAL(1290).jpg                      7  OK \nExtracting  ./dataset2/test/NORMAL/NORMAL(1291).jpg                      8  OK \nExtracting  ./dataset2/test/NORMAL/NORMAL(1292).jpg                      8  OK \nExtracting  ./dataset2/test/NORMAL/NORMAL(1293).jpg                      8  OK \nExtracting  ./dataset2/test/NORMAL/NORMAL(1294).jpg                      9  OK \nExtracting  ./dataset2/test/NORMAL/NORMAL(1295).jpg                      9  OK \nExtracting  ./dataset2/test/NORMAL/NORMAL(1296).jpg                      9  OK \nExtracting  ./dataset2/test/NORMAL/NORMAL(1297).jpg                      9  OK \nExtracting  ./dataset2/test/NORMAL/NORMAL(1298).jpg                     10  OK \nExtracting  ./dataset2/test/NORMAL/NORMAL(1299).jpg                     1 11  OK \nExtracting  ./dataset2/test/NORMAL/NORMAL(1300).jpg                     11  OK \nExtracting  ./dataset2/test/NORMAL/NORMAL(1301).jpg                     11  OK \nExtracting  ./dataset2/test/NORMAL/NORMAL(1302).jpg                     11  OK \nExtracting  ./dataset2/test/NORMAL/NORMAL(1303).jpg                     12  OK \nExtracting  ./dataset2/test/NORMAL/NORMAL(1304).jpg                     12  OK \nExtracting  ./dataset2/test/NORMAL/NORMAL(1305).jpg                     12  OK \nCreating    ./dataset2/test/PNEUMONIA                                 OK\nExtracting  ./dataset2/test/PNEUMONIA/PNEUMONIA(3418).jpg               12  OK \nExtracting  ./dataset2/test/PNEUMONIA/PNEUMONIA(3419).jpg               12  OK \nExtracting  ./dataset2/test/PNEUMONIA/PNEUMONIA(3420).jpg               12  OK \nExtracting  ./dataset2/test/PNEUMONIA/PNEUMONIA(3421).jpg               12  OK \nExtracting  ./dataset2/test/PNEUMONIA/PNEUMONIA(3422).jpg               12  OK \nExtracting  ./dataset2/test/PNEUMONIA/PNEUMONIA(3423).jpg               12  OK \nExtracting  ./dataset2/test/PNEUMONIA/PNEUMONIA(3424).jpg               13  OK \nExtracting  ./dataset2/test/PNEUMONIA/PNEUMONIA(3425).jpg               13  OK \nExtracting  ./dataset2/test/PNEUMONIA/PNEUMONIA(3426).jpg               13  OK \nExtracting  ./dataset2/test/PNEUMONIA/PNEUMONIA(3427).jpg               13  OK \nExtracting  ./dataset2/test/PNEUMONIA/PNEUMONIA(3428).jpg               13  OK \nExtracting  ./dataset2/test/PNEUMONIA/PNEUMONIA(3429).jpg               13  OK \nExtracting  ./dataset2/test/PNEUMONIA/PNEUMONIA(3430).jpg               13  OK \nExtracting  ./dataset2/test/PNEUMONIA/PNEUMONIA(3431).jpg               13  OK \nExtracting  ./dataset2/test/PNEUMONIA/PNEUMONIA(3432).jpg               13  OK \nExtracting  ./dataset2/test/PNEUMONIA/PNEUMONIA(3433).jpg               13  OK \nExtracting  ./dataset2/test/PNEUMONIA/PNEUMONIA(3434).jpg               13  OK \nExtracting  ./dataset2/test/PNEUMONIA/PNEUMONIA(3435).jpg               13  OK \nExtracting  ./dataset2/test/PNEUMONIA/PNEUMONIA(3436).jpg               13  OK \nExtracting  ./dataset2/test/PNEUMONIA/PNEUMONIA(3437).jpg               13  OK \nExtracting  ./dataset2/test/PNEUMONIA/PNEUMONIA(3438).jpg               13  OK \nExtracting  ./dataset2/test/PNEUMONIA/PNEUMONIA(3439).jpg               13  OK \nExtracting  ./dataset2/test/PNEUMONIA/PNEUMONIA(3440).jpg               13  OK \nExtracting  ./dataset2/test/PNEUMONIA/PNEUMONIA(3441).jpg               14  OK \nExtracting  ./dataset2/test/PNEUMONIA/PNEUMONIA(3442).jpg               14  OK \nExtracting  ./dataset2/test/PNEUMONIA/PNEUMONIA(3443).jpg               14  OK \nExtracting  ./dataset2/test/PNEUMONIA/PNEUMONIA(3444).jpg               14  OK \nExtracting  ./dataset2/test/PNEUMONIA/PNEUMONIA(3445).jpg               14  OK \nExtracting  ./dataset2/test/PNEUMONIA/PNEUMONIA(3446).jpg               14  OK \nExtracting  ./dataset2/test/PNEUMONIA/PNEUMONIA(3447).jpg               14  OK \nExtracting  ./dataset2/test/PNEUMONIA/PNEUMONIA(3448).jpg               14  OK \nExtracting  ./dataset2/test/PNEUMONIA/PNEUMONIA(3449).jpg               14  OK \nExtracting  ./dataset2/test/PNEUMONIA/PNEUMONIA(3450).jpg               14  OK \nExtracting  ./dataset2/test/PNEUMONIA/PNEUMONIA(3451).jpg               14  OK \nExtracting  ./dataset2/test/PNEUMONIA/PNEUMONIA(3452).jpg               14  OK \nExtracting  ./dataset2/test/PNEUMONIA/PNEUMONIA(3453).jpg               14  OK \nExtracting  ./dataset2/test/PNEUMONIA/PNEUMONIA(3454).jpg               15  OK \nExtracting  ./dataset2/test/PNEUMONIA/PNEUMONIA(3455).jpg               15  OK \nExtracting  ./dataset2/test/PNEUMONIA/PNEUMONIA(3456).jpg               15  OK \nExtracting  ./dataset2/test/PNEUMONIA/PNEUMONIA(3457).jpg               15  OK \nCreating    ./dataset2/train                                          OK\nCreating    ./dataset2/train/NORMAL                                   OK\nExtracting  ./dataset2/train/NORMAL/NORMAL(0).jpg                       15  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(1).jpg                       15  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(10).jpg                      16  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(11).jpg                      16  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(12).jpg                      17  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(13).jpg                      17  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(14).jpg                      17  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(15).jpg                      18  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(16).jpg                      18  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(17).jpg                      18  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(18).jpg                      19  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(19).jpg                      20  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(2).jpg                       20  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(20).jpg                      21  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(21).jpg                      21  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(22).jpg                      21  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(23).jpg                      22  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(24).jpg                      22  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(25).jpg                      23  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(26).jpg                      23  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(27).jpg                      24  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(28).jpg                      24  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(29).jpg                      24  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(3).jpg                       24  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(30).jpg                      25  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(31).jpg                      25  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(32).jpg                      26  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(33).jpg                      27  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(34).jpg                      27  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(35).jpg                      27  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(36).jpg                      28  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(37).jpg                      28  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(38).jpg                      28  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(39).jpg                      28  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(4).jpg                       29  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(40).jpg                      29  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(41).jpg                      29  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(42).jpg                      29  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(43).jpg                      30  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(44).jpg                      30  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(45).jpg                      30  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(46).jpg                      30  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(47).jpg                      30  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(48).jpg                      30  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(49).jpg                      31  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(5).jpg                       31  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(50).jpg                      31  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(51).jpg                      31  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(52).jpg                      31  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(53).jpg                      31  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(54).jpg                      32  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(55).jpg                      32  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(56).jpg                      32  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(57).jpg                      32  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(58).jpg                      32  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(59).jpg                      32  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(6).jpg                       33  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(60).jpg                      33  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(61).jpg                      33  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(62).jpg                      33  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(63).jpg                      34  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(64).jpg                      34  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(65).jpg                      34  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(66).jpg                      34  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(67).jpg                      34  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(68).jpg                      34  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(69).jpg                      35  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(7).jpg                       35  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(70).jpg                      36  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(71).jpg                      36  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(72).jpg                      36  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(73).jpg                      36  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(74).jpg                      37  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(75).jpg                      37  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(76).jpg                      37  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(77).jpg                      37  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(78).jpg                      37  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(79).jpg                      38  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(8).jpg                       38  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(80).jpg                      38  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(81).jpg                      39  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(82).jpg                      39  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(83).jpg                      39  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(84).jpg                      40  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(85).jpg                      40  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(86).jpg                      40  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(87).jpg                      41  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(88).jpg                      41  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(89).jpg                      41  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(9).jpg                       41  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(90).jpg                      42  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(91).jpg                      42  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(92).jpg                      42  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(93).jpg                      42  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(94).jpg                      42  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(95).jpg                      43  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(96).jpg                      43  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(97).jpg                      43  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(98).jpg                      44  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(99).jpg                      44  OK \nCreating    ./dataset2/train/PNEUMONIA                                OK\nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(0).jpg                 44  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(1).jpg                 44  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(10).jpg                44  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(100).jpg               45  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(101).jpg               45  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(102).jpg               45  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(103).jpg               45  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(104).jpg               45  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(105).jpg               45  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(106).jpg               45  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(107).jpg               45  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(108).jpg               45  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(109).jpg               45  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(11).jpg                45  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(110).jpg               45  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(111).jpg               45  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(112).jpg               46  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(113).jpg               46  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(114).jpg               46  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(115).jpg               46  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(116).jpg               46  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(117).jpg               46  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(118).jpg               46  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(119).jpg               46  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(12).jpg                46  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(120).jpg               46  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(121).jpg               46  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(122).jpg               46  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(123).jpg               46  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(124).jpg               46  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(125).jpg               46  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(126).jpg               47  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(127).jpg               47  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(128).jpg               47  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(129).jpg               47  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(13).jpg                47  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(130).jpg               47  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(131).jpg               47  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(132).jpg               47  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(133).jpg               47  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(134).jpg               47  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(135).jpg               47  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(136).jpg               47  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(137).jpg               48  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(138).jpg               48  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(139).jpg               48  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(14).jpg                48  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(140).jpg               48  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(141).jpg               48  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(142).jpg               48  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(143).jpg               48  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(144).jpg               48  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(145).jpg               48  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(146).jpg               48  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(147).jpg               48  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(148).jpg               48  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(149).jpg               49  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(15).jpg                49  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(150).jpg               49  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(151).jpg               49  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(152).jpg               49  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(153).jpg               49  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(154).jpg               49  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(155).jpg               49  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(156).jpg               49  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(157).jpg               49  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(158).jpg               49  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(159).jpg               49  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(16).jpg                49  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(160).jpg               50  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(161).jpg               50  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(162).jpg               50  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(163).jpg               50  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(164).jpg               50  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(165).jpg               50  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(166).jpg               50  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(167).jpg               50  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(168).jpg               50  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(169).jpg               50  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(17).jpg                50  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(170).jpg               50  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(171).jpg               50  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(172).jpg               50  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(173).jpg               51  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(174).jpg               51  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(175).jpg               51  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(176).jpg               51  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(177).jpg               51  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(178).jpg               51  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(179).jpg               51  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(18).jpg                51  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(180).jpg               51  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(181).jpg               51  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(182).jpg               51  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(183).jpg               52  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(184).jpg               52  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(185).jpg               52  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(186).jpg               52  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(187).jpg               52  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(188).jpg               52  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(189).jpg               52  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(19).jpg                52  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(190).jpg               52  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(191).jpg               52  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(192).jpg               52  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(193).jpg               52  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(194).jpg               52  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(195).jpg               52  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(196).jpg               52  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(197).jpg               52  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(198).jpg               53  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(199).jpg               53  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(2).jpg                 53  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(20).jpg                53  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(21).jpg                53  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(22).jpg                53  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(23).jpg                53  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(24).jpg                53  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(25).jpg                53  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(26).jpg                53  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(27).jpg                53  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(28).jpg                53  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(29).jpg                53  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(3).jpg                 53  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(30).jpg                54  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(31).jpg                54  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(32).jpg                54  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(33).jpg                54  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(34).jpg                54  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(35).jpg                54  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(36).jpg                54  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(37).jpg                54  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(38).jpg                54  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(39).jpg                54  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(4).jpg                 55  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(40).jpg                55  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(41).jpg                55  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(42).jpg                55  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(43).jpg                55  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(44).jpg                55  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(45).jpg                55  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(46).jpg                55  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(47).jpg                55  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(48).jpg                55  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(49).jpg                55  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(5).jpg                 55  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(50).jpg                56  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(51).jpg                56  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(52).jpg                56  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(53).jpg                56  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(54).jpg                56  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(55).jpg                56  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(56).jpg                56  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(57).jpg                56  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(58).jpg                56  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(59).jpg                56  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(6).jpg                 56  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(60).jpg                56  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(61).jpg                56  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(62).jpg                57  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(63).jpg                57  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(64).jpg                57  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(65).jpg                57  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(66).jpg                57  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(67).jpg                57  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(68).jpg                57  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(69).jpg                57  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(7).jpg                 57  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(70).jpg                57  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(71).jpg                57  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(72).jpg                57  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(73).jpg                57  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(74).jpg                57  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(75).jpg                57  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(76).jpg                58  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(77).jpg                58  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(78).jpg                58  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(79).jpg                58  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(8).jpg                 58  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(80).jpg                58  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(81).jpg                58  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(82).jpg                58  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(83).jpg                58  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(84).jpg                58  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(85).jpg                58  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(86).jpg                58  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(87).jpg                58  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(88).jpg                58  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(89).jpg                59  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(9).jpg                 59  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(90).jpg                59  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(91).jpg                59  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(92).jpg                59  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(93).jpg                59  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(94).jpg                59  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(95).jpg                59  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(96).jpg                59  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(97).jpg                59  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(98).jpg                59  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(99).jpg                59  OK \nCreating    ./dataset1                                                OK\nCreating    ./dataset1/test                                           OK\nCreating    ./dataset1/test/COVID                                     OK\nExtracting  ./dataset1/test/COVID/ryct.2020200034.fig2.jpeg             59  OK \nExtracting  ./dataset1/test/COVID/ryct.2020200034.fig5-day0.jpeg        59  OK \nExtracting  ./dataset1/test/COVID/ryct.2020200034.fig5-day4.jpeg        60  OK \nExtracting  ./dataset1/test/COVID/ryct.2020200034.fig5-day7.jpeg        60  OK \nExtracting  ./dataset1/test/COVID/SARS-10.1148rg.242035193-g04mr34g0-Fig8a-day0.jpeg    60  OK \nExtracting  ./dataset1/test/COVID/SARS-10.1148rg.242035193-g04mr34g0-Fig8b-day5.jpeg    60  OK \nExtracting  ./dataset1/test/COVID/SARS-10.1148rg.242035193-g04mr34g0-Fig8c-day10.jpeg    60  OK \nExtracting  ./dataset1/test/COVID/SARS-10.1148rg.242035193-g04mr34g04a-Fig4a-day7.jpeg    60  OK \nExtracting  ./dataset1/test/COVID/SARS-10.1148rg.242035193-g04mr34g04b-Fig4b-day12.jpeg    61  OK \nExtracting  ./dataset1/test/COVID/SARS-10.1148rg.242035193-g04mr34g05x-Fig5-day9.jpeg    61  OK \nExtracting  ./dataset1/test/COVID/SARS-10.1148rg.242035193-g04mr34g07a-Fig7a-day5.jpeg    61  OK \nExtracting  ./dataset1/test/COVID/SARS-10.1148rg.242035193-g04mr34g07b-Fig7b-day12.jpeg    61  OK \nExtracting  ./dataset1/test/COVID/SARS-10.1148rg.242035193-g04mr34g09a-Fig9a-day17.jpeg    61  OK \nExtracting  ./dataset1/test/COVID/SARS-10.1148rg.242035193-g04mr34g09b-Fig9b-day19.jpeg    61  OK \nExtracting  ./dataset1/test/COVID/SARS-10.1148rg.242035193-g04mr34g09c-Fig9c-day27.jpeg    61  OK \nExtracting  ./dataset1/test/COVID/streptococcus-pneumoniae-pneumonia-1.jpg    62  OK \nExtracting  ./dataset1/test/COVID/streptococcus-pneumoniae-pneumonia-temporal-evolution-1-day0.jpg    62  OK \nExtracting  ./dataset1/test/COVID/streptococcus-pneumoniae-pneumonia-temporal-evolution-1-day1.jpg    62  OK \nExtracting  ./dataset1/test/COVID/streptococcus-pneumoniae-pneumonia-temporal-evolution-1-day2.jpg    62  OK \nExtracting  ./dataset1/test/COVID/streptococcus-pneumoniae-pneumonia-temporal-evolution-1-day3.jpg    62  OK \nCreating    ./dataset1/test/NORMAL                                    OK\nExtracting  ./dataset1/test/NORMAL/NORMAL2-IM-0035-0001.jpeg            62  OK \nExtracting  ./dataset1/test/NORMAL/NORMAL2-IM-0052-0001.jpeg            62  OK \nExtracting  ./dataset1/test/NORMAL/NORMAL2-IM-0058-0001.jpeg            62  OK \nExtracting  ./dataset1/test/NORMAL/NORMAL2-IM-0059-0001.jpeg            62  OK \nExtracting  ./dataset1/test/NORMAL/NORMAL2-IM-0072-0001.jpeg            62  OK \nExtracting  ./dataset1/test/NORMAL/NORMAL2-IM-0073-0001.jpeg            63  OK \nExtracting  ./dataset1/test/NORMAL/NORMAL2-IM-0092-0001.jpeg            63  OK \nExtracting  ./dataset1/test/NORMAL/NORMAL2-IM-0105-0001.jpeg            63  OK \nExtracting  ./dataset1/test/NORMAL/NORMAL2-IM-0110-0001.jpeg            63  OK \nExtracting  ./dataset1/test/NORMAL/NORMAL2-IM-0111-0001.jpeg            63  OK \nExtracting  ./dataset1/test/NORMAL/NORMAL2-IM-0112-0001.jpeg            63  OK \nExtracting  ./dataset1/test/NORMAL/NORMAL2-IM-0117-0001.jpeg            63  OK \nExtracting  ./dataset1/test/NORMAL/NORMAL2-IM-0120-0001.jpeg            63  OK \nExtracting  ./dataset1/test/NORMAL/NORMAL2-IM-0123-0001.jpeg            63  OK \nExtracting  ./dataset1/test/NORMAL/NORMAL2-IM-0130-0001.jpeg            63  OK \nExtracting  ./dataset1/test/NORMAL/NORMAL2-IM-0131-0001.jpeg            63  OK \nExtracting  ./dataset1/test/NORMAL/NORMAL2-IM-0132-0001.jpeg            64  OK \nExtracting  ./dataset1/test/NORMAL/NORMAL2-IM-0139-0001.jpeg            64  OK \nExtracting  ./dataset1/test/NORMAL/NORMAL2-IM-0145-0001.jpeg            64  OK \nExtracting  ./dataset1/test/NORMAL/NORMAL2-IM-0171-0001.jpeg            64  OK \nCreating    ./dataset1/train                                          OK\nCreating    ./dataset1/train/COVID                                    OK\nExtracting  ./dataset1/train/COVID/01E392EE-69F9-4E33-BFCE-E5C968654078.jpeg    64  OK \nExtracting  ./dataset1/train/COVID/1-s2.0-S0140673620303706-fx1_lrg.jpg    64  OK \nExtracting  ./dataset1/train/COVID/1-s2.0-S1684118220300608-main.pdf-001.jpg    64  OK \nExtracting  ./dataset1/train/COVID/1-s2.0-S1684118220300608-main.pdf-002.jpg    64  OK \nExtracting  ./dataset1/train/COVID/1-s2.0-S1684118220300682-main.pdf-002-a1.png    64  OK \nExtracting  ./dataset1/train/COVID/1-s2.0-S1684118220300682-main.pdf-002-a2.png    64  OK \nExtracting  ./dataset1/train/COVID/1-s2.0-S1684118220300682-main.pdf-003-b1.png    64  OK \nExtracting  ./dataset1/train/COVID/1-s2.0-S1684118220300682-main.pdf-003-b2.png    65  OK \nExtracting  ./dataset1/train/COVID/1312A392-67A3-4EBF-9319-810CF6DA5EF6.jpeg    65  OK \nExtracting  ./dataset1/train/COVID/171CB377-62FF-4B76-906C-F3787A01CB2E.jpeg    65  OK \nExtracting  ./dataset1/train/COVID/1B734A89-A1BF-49A8-A1D3-66FAFA4FAC5D.jpeg    65  OK \nExtracting  ./dataset1/train/COVID/23E99E2E-447C-46E5-8EB2-D35D12473C39.png    66  OK \nExtracting  ./dataset1/train/COVID/2C10A413-AABE-4807-8CCE-6A2025594067.jpeg    6 70  OK \nExtracting  ./dataset1/train/COVID/2C26F453-AF3B-4517-BB9E-802CF2179543.jpeg    70  OK \nExtracting  ./dataset1/train/COVID/31BA3780-2323-493F-8AED-62081B9C383B.jpeg    70  OK \nExtracting  ./dataset1/train/COVID/39EE8E69-5801-48DE-B6E3-BE7D1BCF3092.jpeg    70  OK \nExtracting  ./dataset1/train/COVID/41591_2020_819_Fig1_HTML.webp-day10.png    70  OK \nExtracting  ./dataset1/train/COVID/41591_2020_819_Fig1_HTML.webp-day5.png    70  OK \nExtracting  ./dataset1/train/COVID/446B2CB6-B572-40AB-B01F-1910CA07086A.jpeg    71  OK \nExtracting  ./dataset1/train/COVID/5931B64A-7B97-485D-BE60-3F1EA76BC4F0.jpeg    71  OK \nExtracting  ./dataset1/train/COVID/5CBC2E94-D358-401E-8928-965CCD965C5C.jpeg    72  OK \nExtracting  ./dataset1/train/COVID/5e6dd879fde9502400e58b2f.jpeg        72  OK \nExtracting  ./dataset1/train/COVID/6CB4EFC6-68FA-4CD5-940C-BEFA8DAFE9A7.jpeg    73  OK \nExtracting  ./dataset1/train/COVID/7AF6C1AF-D249-4BD2-8C26-449304105D03.jpeg    73  OK \nExtracting  ./dataset1/train/COVID/7C69C012-7479-493F-8722-ABC29C60A2DD.jpeg    73  OK \nExtracting  ./dataset1/train/COVID/7D2CF6CE-F529-4470-8356-D33FFAF98600.jpeg    73  OK \nExtracting  ./dataset1/train/COVID/7E335538-2F86-424E-A0AB-6397783A38D0.jpeg    7 76  OK \nExtracting  ./dataset1/train/COVID/7EF28E12-F628-4BEC-A8C5-E6277C2E4F60.png    76  OK \nExtracting  ./dataset1/train/COVID/80446565-E090-4187-A031-9D3CEAA586C8.jpeg    76  OK \nExtracting  ./dataset1/train/COVID/85E52EB3-56E9-4D67-82DA-DEA247C82886.jpeg    77  OK \nExtracting  ./dataset1/train/COVID/8FDE8DBA-CFBD-4B4C-B1A4-6F36A93B7E87.jpeg    77  OK \nExtracting  ./dataset1/train/COVID/93FE0BB1-022D-4F24-9727-987A07975FFB.jpeg    77  OK \nExtracting  ./dataset1/train/COVID/9C34AF49-E589-44D5-92D3-168B3B04E4A6.jpeg    77  OK \nExtracting  ./dataset1/train/COVID/acute-respiratory-distress-syndrome-ards-1.jpg    77  OK \nExtracting  ./dataset1/train/COVID/all14238-fig-0001-m-b.jpg            77  OK \nExtracting  ./dataset1/train/COVID/all14238-fig-0001-m-c.jpg            77  OK \nExtracting  ./dataset1/train/COVID/all14238-fig-0002-m-e.jpg            77  OK \nExtracting  ./dataset1/train/COVID/ards-secondary-to-tiger-snake-bite.png    78  OK \nExtracting  ./dataset1/train/COVID/ARDSSevere.png                       78  OK \nExtracting  ./dataset1/train/COVID/auntminnie-2020_01_31_20_24_2322_2020_01_31_x-ray_coronavirus_US.jpg    78  OK \nExtracting  ./dataset1/train/COVID/auntminnie-b-2020_01_28_23_51_6665_2020_01_28_Vietnam_coronavirus.jpeg    78  OK \nExtracting  ./dataset1/train/COVID/auntminnie-c-2020_01_28_23_51_6665_2020_01_28_Vietnam_coronavirus.jpeg    78  OK \nExtracting  ./dataset1/train/COVID/auntminnie-d-2020_01_28_23_51_6665_2020_01_28_Vietnam_coronavirus.jpeg    78  OK \nExtracting  ./dataset1/train/COVID/B59DD164-51D5-40DF-A926-6A42DD52EBE8.jpeg    78  OK \nExtracting  ./dataset1/train/COVID/C6EA0BE5-B01E-4113-B194-18D956675E25.jpeg    79  OK \nExtracting  ./dataset1/train/COVID/CD50BA96-6982-4C80-AE7B-5F67ACDBFA56.jpeg    79  OK \nExtracting  ./dataset1/train/COVID/covid-19-pneumonia-12.jpg            80  OK \nExtracting  ./dataset1/train/COVID/covid-19-pneumonia-14-PA.png         82  OK \nExtracting  ./dataset1/train/COVID/covid-19-pneumonia-15-PA.jpg         83  OK \nExtracting  ./dataset1/train/COVID/covid-19-pneumonia-7-PA.jpg          83  OK \nExtracting  ./dataset1/train/COVID/E1724330-1866-4581-8CD8-CEC9B8AFEDDE.jpeg    8 87  OK \nExtracting  ./dataset1/train/COVID/E63574A7-4188-4C8D-8D17-9D67A18A1AFA.jpeg    87  OK \nExtracting  ./dataset1/train/COVID/F051E018-DAD1-4506-AD43-BE4CA29E960B.jpeg    87  OK \nExtracting  ./dataset1/train/COVID/F4341CE7-73C9-45C6-99C8-8567A5484B63.jpeg    87  OK \nExtracting  ./dataset1/train/COVID/F63AB6CE-1968-4154-A70F-913AF154F53D.jpeg    87  OK \nExtracting  ./dataset1/train/COVID/jkms-35-e79-g001-l-a.jpg             88  OK \nExtracting  ./dataset1/train/COVID/jkms-35-e79-g001-l-b.jpg             88  OK \nExtracting  ./dataset1/train/COVID/jkms-35-e79-g001-l-c.jpg             88  OK \nExtracting  ./dataset1/train/COVID/kjr-21-e24-g001-l-a.jpg              88  OK \nExtracting  ./dataset1/train/COVID/kjr-21-e24-g002-l-a.jpg              88  OK \nExtracting  ./dataset1/train/COVID/kjr-21-e24-g003-l-a.jpg              88  OK \nExtracting  ./dataset1/train/COVID/kjr-21-e25-g001-l-a.jpg              88  OK \nExtracting  ./dataset1/train/COVID/lancet-case2a.jpg                    88  OK \nExtracting  ./dataset1/train/COVID/MERS-CoV-1-s2.0-S0378603X1500248X-gr4e.jpg    88  OK \nExtracting  ./dataset1/train/COVID/nCoV-radiol.2020200269.fig1-day7.jpeg    88  OK \nExtracting  ./dataset1/train/COVID/nCoV-Snohomish-20382862_web1_M1-Lungs-EDH-200201-640x300@2x.jpg    88  OK \nExtracting  ./dataset1/train/COVID/nejmc2001573_f1a.jpeg                88  OK \nExtracting  ./dataset1/train/COVID/nejmc2001573_f1b.jpeg                88  OK \nExtracting  ./dataset1/train/COVID/nejmoa2001191_f1-PA.jpeg             88  OK \nExtracting  ./dataset1/train/COVID/nejmoa2001191_f3-PA.jpeg             88  OK \nExtracting  ./dataset1/train/COVID/nejmoa2001191_f4.jpeg                89  OK \nExtracting  ./dataset1/train/COVID/nejmoa2001191_f5-PA.jpeg             89  OK \nExtracting  ./dataset1/train/COVID/pneumocystis-pneumonia-2-PA.png      89  OK \nExtracting  ./dataset1/train/COVID/ryct.2020200028.fig1a.jpeg           90  OK \nCreating    ./dataset1/train/NORMAL                                   OK\nExtracting  ./dataset1/train/NORMAL/IM-0001-0001.jpeg                   90  OK \nExtracting  ./dataset1/train/NORMAL/IM-0003-0001.jpeg                   90  OK \nExtracting  ./dataset1/train/NORMAL/IM-0005-0001.jpeg                   90  OK \nExtracting  ./dataset1/train/NORMAL/IM-0006-0001.jpeg                   90  OK \nExtracting  ./dataset1/train/NORMAL/IM-0007-0001.jpeg                   91  OK \nExtracting  ./dataset1/train/NORMAL/IM-0009-0001.jpeg                   91  OK \nExtracting  ./dataset1/train/NORMAL/IM-0010-0001.jpeg                   91  OK \nExtracting  ./dataset1/train/NORMAL/IM-0011-0001-0001.jpeg              91  OK \nExtracting  ./dataset1/train/NORMAL/IM-0011-0001-0002.jpeg              91  OK \nExtracting  ./dataset1/train/NORMAL/IM-0011-0001.jpeg                   91  OK \nExtracting  ./dataset1/train/NORMAL/IM-0013-0001.jpeg                   92  OK \nExtracting  ./dataset1/train/NORMAL/IM-0015-0001.jpeg                   92  OK \nExtracting  ./dataset1/train/NORMAL/IM-0016-0001.jpeg                   92  OK \nExtracting  ./dataset1/train/NORMAL/IM-0017-0001.jpeg                   92  OK \nExtracting  ./dataset1/train/NORMAL/IM-0019-0001.jpeg                   92  OK \nExtracting  ./dataset1/train/NORMAL/IM-0021-0001.jpeg                   93  OK \nExtracting  ./dataset1/train/NORMAL/IM-0022-0001.jpeg                   93  OK \nExtracting  ./dataset1/train/NORMAL/IM-0023-0001.jpeg                   93  OK \nExtracting  ./dataset1/train/NORMAL/IM-0025-0001.jpeg                   93  OK \nExtracting  ./dataset1/train/NORMAL/IM-0027-0001.jpeg                   93  OK \nExtracting  ./dataset1/train/NORMAL/IM-0029-0001.jpeg                   94  OK \nExtracting  ./dataset1/train/NORMAL/IM-0030-0001.jpeg                   94  OK \nExtracting  ./dataset1/train/NORMAL/IM-0031-0001.jpeg                   94  OK \nExtracting  ./dataset1/train/NORMAL/IM-0033-0001-0001.jpeg              94  OK \nExtracting  ./dataset1/train/NORMAL/IM-0033-0001-0002.jpeg              94  OK \nExtracting  ./dataset1/train/NORMAL/IM-0033-0001.jpeg                   94  OK \nExtracting  ./dataset1/train/NORMAL/IM-0035-0001.jpeg                   95  OK \nExtracting  ./dataset1/train/NORMAL/IM-0036-0001.jpeg                   95  OK \nExtracting  ./dataset1/train/NORMAL/IM-0037-0001.jpeg                   95  OK \nExtracting  ./dataset1/train/NORMAL/IM-0039-0001.jpeg                   95  OK \nExtracting  ./dataset1/train/NORMAL/IM-0041-0001.jpeg                   95  OK \nExtracting  ./dataset1/train/NORMAL/IM-0043-0001.jpeg                   96  OK \nExtracting  ./dataset1/train/NORMAL/IM-0045-0001.jpeg                   96  OK \nExtracting  ./dataset1/train/NORMAL/IM-0046-0001.jpeg                   96  OK \nExtracting  ./dataset1/train/NORMAL/IM-0049-0001.jpeg                   96  OK \nExtracting  ./dataset1/train/NORMAL/IM-0050-0001.jpeg                   96  OK \nExtracting  ./dataset1/train/NORMAL/IM-0059-0001.jpeg                   96  OK \nExtracting  ./dataset1/train/NORMAL/IM-0061-0001.jpeg                   96  OK \nExtracting  ./dataset1/train/NORMAL/IM-0063-0001.jpeg                   97  OK \nExtracting  ./dataset1/train/NORMAL/IM-0069-0001.jpeg                   97  OK \nExtracting  ./dataset1/train/NORMAL/IM-0070-0001.jpeg                   97  OK \nExtracting  ./dataset1/train/NORMAL/IM-0071-0001.jpeg                   97  OK \nExtracting  ./dataset1/train/NORMAL/IM-0073-0001.jpeg                   97  OK \nExtracting  ./dataset1/train/NORMAL/IM-0075-0001.jpeg                   97  OK \nExtracting  ./dataset1/train/NORMAL/IM-0077-0001.jpeg                   97  OK \nExtracting  ./dataset1/train/NORMAL/IM-0079-0001.jpeg                   97  OK \nExtracting  ./dataset1/train/NORMAL/IM-0081-0001.jpeg                   97  OK \nExtracting  ./dataset1/train/NORMAL/IM-0083-0001.jpeg                   97  OK \nExtracting  ./dataset1/train/NORMAL/IM-0084-0001.jpeg                   97  OK \nExtracting  ./dataset1/train/NORMAL/IM-0085-0001.jpeg                   97  OK \nExtracting  ./dataset1/train/NORMAL/IM-0086-0001.jpeg                   97  OK \nExtracting  ./dataset1/train/NORMAL/IM-0087-0001.jpeg                   98  OK \nExtracting  ./dataset1/train/NORMAL/IM-0089-0001.jpeg                   98  OK \nExtracting  ./dataset1/train/NORMAL/IM-0091-0001.jpeg                   98  OK \nExtracting  ./dataset1/train/NORMAL/IM-0093-0001.jpeg                   98  OK \nExtracting  ./dataset1/train/NORMAL/IM-0095-0001.jpeg                   98  OK \nExtracting  ./dataset1/train/NORMAL/IM-0097-0001.jpeg                   98  OK \nExtracting  ./dataset1/train/NORMAL/IM-0099-0001.jpeg                   98  OK \nExtracting  ./dataset1/train/NORMAL/IM-0101-0001.jpeg                   98  OK \nExtracting  ./dataset1/train/NORMAL/IM-0102-0001.jpeg                   98  OK \nExtracting  ./dataset1/train/NORMAL/IM-0103-0001.jpeg                   98  OK \nExtracting  ./dataset1/train/NORMAL/IM-0105-0001.jpeg                   98  OK \nExtracting  ./dataset1/train/NORMAL/IM-0107-0001.jpeg                   98  OK \nExtracting  ./dataset1/train/NORMAL/IM-0110-0001.jpeg                   98  OK \nExtracting  ./dataset1/train/NORMAL/IM-0111-0001.jpeg                   99  OK \nExtracting  ./dataset1/train/NORMAL/NORMAL2-IM-0007-0001.jpeg           99  OK \nExtracting  ./dataset1/train/NORMAL/NORMAL2-IM-0012-0001.jpeg           99  OK \nExtracting  ./dataset1/train/NORMAL/NORMAL2-IM-0013-0001.jpeg           99  OK \nExtracting  ./dataset1/train/NORMAL/NORMAL2-IM-0023-0001.jpeg           99  OK \nExtracting  ./dataset1/train/NORMAL/NORMAL2-IM-0027-0001.jpeg           99  OK \nExtracting  ./dataset1/train/NORMAL/NORMAL2-IM-0028-0001.jpeg           99  OK \nExtracting  ./dataset1/train/NORMAL/NORMAL2-IM-0029-0001.jpeg           99  OK \nExtracting  ./dataset1/train/NORMAL/NORMAL2-IM-0030-0001.jpeg           99  OK \nExtracting  ./dataset1/train/NORMAL/NORMAL2-IM-0033-0001.jpeg           99  OK \nAll OK\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"X_train, y_train, X_test, y_test = load_dataset()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T19:19:08.513774Z","iopub.execute_input":"2025-02-07T19:19:08.514069Z","iopub.status.idle":"2025-02-07T19:19:15.847123Z","shell.execute_reply.started":"2025-02-07T19:19:08.514047Z","shell.execute_reply":"2025-02-07T19:19:15.846471Z"}},"outputs":[],"execution_count":74},{"cell_type":"code","source":"num_train = X_train.shape[0]\nnum_test = X_test.shape[0]\nnum_covid = sum(y_train[y_train==1]) + sum(y_test[y_test==1])\nprint(f\"Number of Training Samples: {num_train}\\nNumber of Test Samples: {num_test}\\nNumber of COVID samples: {num_covid}\\nNumber of Normal samples: {num_train + num_test - num_covid}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T22:00:31.978741Z","iopub.execute_input":"2025-02-07T22:00:31.979018Z","iopub.status.idle":"2025-02-07T22:00:31.983648Z","shell.execute_reply.started":"2025-02-07T22:00:31.978996Z","shell.execute_reply":"2025-02-07T22:00:31.982783Z"}},"outputs":[{"name":"stdout","text":"Number of Training Samples: 148\nNumber of Test Samples: 40\nNumber of COVID samples: 94\nNumber of Normal samples: 94\n","output_type":"stream"}],"execution_count":147},{"cell_type":"markdown","source":"## 1.3 CNN Architecture","metadata":{}},{"cell_type":"code","source":"def define_model(input_shape=(150,150,3), lr=0.001):\n    model = Sequential(\n        [\n            # Input\n            Input(shape=input_shape),\n            \n            # Conv1\n            Conv2D(64, kernel_size=(3,3), activation='relu', padding='same'),\n            BatchNormalization(axis=-1),\n            MaxPooling2D(pool_size=(2,2)),\n            Dropout(0.2),\n\n            # Conv2\n            Conv2D(64, kernel_size=(3,3), activation='relu', padding='same'),\n            BatchNormalization(axis=-1),\n            MaxPooling2D(pool_size=(2,2)),\n            Dropout(0.2),\n\n            # Conv3\n            Conv2D(128, kernel_size=(3,3), activation='relu', padding='same'),\n            BatchNormalization(axis=-1),\n            MaxPooling2D(pool_size=(2,2)),\n            Dropout(0.2),\n\n            # Conv4\n            Conv2D(128, kernel_size=(3,3), activation='relu', padding='same'),\n            BatchNormalization(axis=-1),\n            MaxPooling2D(pool_size=(2,2)),\n            Dropout(0.2),\n\n            # Conv5\n            Conv2D(256, kernel_size=(3,3), activation='relu', padding='same'),\n            BatchNormalization(axis=-1),\n            MaxPooling2D(pool_size=(2,2)),\n            Dropout(0.2),\n\n            # Conv6\n            Conv2D(256, kernel_size=(3,3), activation='relu', padding='same'),\n            BatchNormalization(axis=-1),\n            MaxPooling2D(pool_size=(2,2)),\n            Dropout(0.2),\n\n            # Flatten Layer\n            Flatten(),\n\n            # FCL\n            Dense(512, activation='relu'),\n            BatchNormalization(axis=-1),\n            Dense(256, activation='relu'),\n            BatchNormalization(axis=-1),\n\n            # Output\n            Dense(1, activation='sigmoid')\n        ]\n    )\n\n    model.compile(\n        optimizer=Adam(learning_rate=lr),\n        loss='binary_crossentropy',\n        metrics=['accuracy']\n    )\n\n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T17:14:44.193916Z","iopub.execute_input":"2025-02-07T17:14:44.194341Z","iopub.status.idle":"2025-02-07T17:14:44.203562Z","shell.execute_reply.started":"2025-02-07T17:14:44.194310Z","shell.execute_reply":"2025-02-07T17:14:44.202478Z"}},"outputs":[],"execution_count":44},{"cell_type":"markdown","source":"## 1.4 Train & Evaluation of model with k-fold cross-validation","metadata":{}},{"cell_type":"code","source":"def train_evaluate_model_with_k_fold(X_train, y_train, lr=0.01, epochs=50, batch_size=16, output_model=False):\n    \n    kf = KFold(n_splits=10, shuffle=True, random_state=33)\n\n    fold_no = 1\n    train_acc_scores = []\n    val_acc_scores = []\n    \n    for train_index, val_index in kf.split(X_train, y_train):\n        print(f\"\\nTraining on Fold {fold_no}...\")\n        \n        X_tr, X_val = X_train[train_index], X_train[val_index]\n        y_tr, y_val = y_train[train_index], y_train[val_index]\n        \n        # Recreate a fresh model for each fold\n        model = define_model(input_shape=(150,150,3), lr=lr)\n        \n        history = model.fit(\n            X_tr, y_tr,\n            validation_data=(X_val, y_val),\n            epochs=epochs,\n            batch_size=batch_size,\n            callbacks=[\n                EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True, verbose=1),\n                ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1)\n            ],\n            verbose=1,\n            shuffle=True\n        )\n        \n        # Evaluate the model on the fold's training and validation sets\n        train_loss, train_acc = model.evaluate(X_tr, y_tr, verbose=0)\n        val_loss, val_acc = model.evaluate(X_val, y_val, verbose=0)\n        \n        print(f\"Fold {fold_no} - Train Accuracy: {train_acc*100:.2f}%, Validation Accuracy: {val_acc*100:.2f}%\")\n        train_acc_scores.append(train_acc)\n        val_acc_scores.append(val_acc)\n        \n        fold_no += 1\n    \n    print(\"\\nAverage Training Accuracy: {:.2f}%\".format(np.mean(train_acc_scores)*100))\n    print(\"Average Validation Accuracy: {:.2f}%\".format(np.mean(val_acc_scores)*100))\n\n    if output_model:\n        return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T22:02:54.905974Z","iopub.execute_input":"2025-02-07T22:02:54.906270Z","iopub.status.idle":"2025-02-07T22:02:54.913499Z","shell.execute_reply.started":"2025-02-07T22:02:54.906244Z","shell.execute_reply":"2025-02-07T22:02:54.912468Z"}},"outputs":[],"execution_count":149},{"cell_type":"markdown","source":"# 2 Data Collection and Image Preprocessing","metadata":{}},{"cell_type":"markdown","source":"## 2.0 Evaluation before adding augmented dataset","metadata":{}},{"cell_type":"code","source":"train_evaluate_model_with_k_fold(X_train, y_train, lr=0.01, epochs=50, batch_size=16)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T20:01:36.341934Z","iopub.execute_input":"2025-02-07T20:01:36.342226Z","iopub.status.idle":"2025-02-07T20:05:41.528033Z","shell.execute_reply.started":"2025-02-07T20:01:36.342203Z","shell.execute_reply":"2025-02-07T20:05:41.527262Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"\nTraining on Fold 1...\nEpoch 1/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 885ms/step - accuracy: 0.6716 - loss: 1.1087 - val_accuracy: 0.4667 - val_loss: 12465.7129 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8765 - loss: 0.4161 - val_accuracy: 0.4667 - val_loss: 883.4987 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9377 - loss: 0.1560 - val_accuracy: 0.4667 - val_loss: 1059.7609 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9854 - loss: 0.0820 - val_accuracy: 0.4667 - val_loss: 206.0867 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9867 - loss: 0.0418 - val_accuracy: 0.4667 - val_loss: 31.8108 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0326 - val_accuracy: 0.5333 - val_loss: 38.1015 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0107 - val_accuracy: 0.5333 - val_loss: 18.0174 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0040 - val_accuracy: 0.6000 - val_loss: 6.1719 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0050 - val_accuracy: 0.6000 - val_loss: 6.2366 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0046 - val_accuracy: 0.6000 - val_loss: 3.7785 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0033 - val_accuracy: 0.8000 - val_loss: 1.1556 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.7333 - val_loss: 1.2924 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.6667 - val_loss: 1.5341 - learning_rate: 0.0100\nEpoch 14/50\n\u001b[1m7/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 6.9206e-04\nEpoch 14: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 7.2345e-04 - val_accuracy: 0.6000 - val_loss: 1.8807 - learning_rate: 0.0100\nEpoch 15/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.6000 - val_loss: 1.8409 - learning_rate: 1.0000e-03\nEpoch 16/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 8.0861e-04 - val_accuracy: 0.6667 - val_loss: 1.7107 - learning_rate: 1.0000e-03\nEpoch 16: early stopping\nRestoring model weights from the end of the best epoch: 11.\nFold 1 - Train Accuracy: 60.15%, Validation Accuracy: 80.00%\n\nTraining on Fold 2...\nEpoch 1/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 754ms/step - accuracy: 0.7375 - loss: 0.6620 - val_accuracy: 0.5333 - val_loss: 7886.8574 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8837 - loss: 0.3516 - val_accuracy: 0.6000 - val_loss: 915.2784 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9080 - loss: 0.2801 - val_accuracy: 0.5333 - val_loss: 386.3588 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9592 - loss: 0.1436 - val_accuracy: 0.5333 - val_loss: 340.5612 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9444 - loss: 0.0915 - val_accuracy: 0.5333 - val_loss: 131.0680 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9495 - loss: 0.0913 - val_accuracy: 0.5333 - val_loss: 56.9932 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9715 - loss: 0.0744 - val_accuracy: 0.5333 - val_loss: 22.0873 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9958 - loss: 0.0242 - val_accuracy: 0.5333 - val_loss: 10.5532 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9792 - loss: 0.0467 - val_accuracy: 0.6000 - val_loss: 5.6033 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9815 - loss: 0.0402 - val_accuracy: 0.6000 - val_loss: 6.3514 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0110 - val_accuracy: 0.6000 - val_loss: 5.1115 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0078 - val_accuracy: 0.8000 - val_loss: 2.0723 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9977 - loss: 0.0107 - val_accuracy: 0.8000 - val_loss: 1.9418 - learning_rate: 0.0100\nEpoch 14/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9954 - loss: 0.0196 - val_accuracy: 0.6000 - val_loss: 4.4229 - learning_rate: 0.0100\nEpoch 15/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9903 - loss: 0.0539 - val_accuracy: 0.8000 - val_loss: 1.6030 - learning_rate: 0.0100\nEpoch 16/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9838 - loss: 0.0498 - val_accuracy: 0.7333 - val_loss: 2.1197 - learning_rate: 0.0100\nEpoch 17/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9977 - loss: 0.0225 - val_accuracy: 0.6667 - val_loss: 3.7783 - learning_rate: 0.0100\nEpoch 18/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9815 - loss: 0.0389 - val_accuracy: 0.9333 - val_loss: 0.2081 - learning_rate: 0.0100\nEpoch 19/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9560 - loss: 0.0847 - val_accuracy: 0.8667 - val_loss: 0.3722 - learning_rate: 0.0100\nEpoch 20/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0127 - val_accuracy: 0.8667 - val_loss: 0.4019 - learning_rate: 0.0100\nEpoch 21/50\n\u001b[1m7/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0035\nEpoch 21: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0048 - val_accuracy: 0.8000 - val_loss: 0.3173 - learning_rate: 0.0100\nEpoch 22/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0051 - val_accuracy: 0.8000 - val_loss: 0.4566 - learning_rate: 1.0000e-03\nEpoch 23/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0049 - val_accuracy: 0.8000 - val_loss: 0.5684 - learning_rate: 1.0000e-03\nEpoch 23: early stopping\nRestoring model weights from the end of the best epoch: 18.\nFold 2 - Train Accuracy: 94.74%, Validation Accuracy: 93.33%\n\nTraining on Fold 3...\nEpoch 1/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 765ms/step - accuracy: 0.6695 - loss: 1.4414 - val_accuracy: 0.5333 - val_loss: 301.3988 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9007 - loss: 0.2649 - val_accuracy: 0.4667 - val_loss: 1160.6516 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9750 - loss: 0.0983 - val_accuracy: 0.5333 - val_loss: 135.2151 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9775 - loss: 0.0699 - val_accuracy: 0.5333 - val_loss: 74.2654 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9958 - loss: 0.0306 - val_accuracy: 0.5333 - val_loss: 63.1838 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9871 - loss: 0.0378 - val_accuracy: 0.6667 - val_loss: 5.2567 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9958 - loss: 0.0225 - val_accuracy: 0.5333 - val_loss: 18.2138 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9930 - loss: 0.0199 - val_accuracy: 0.5333 - val_loss: 23.8600 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m7/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9902 - loss: 0.0215\nEpoch 9: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9909 - loss: 0.0215 - val_accuracy: 0.6000 - val_loss: 11.2142 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0088 - val_accuracy: 0.5333 - val_loss: 6.4387 - learning_rate: 1.0000e-03\nEpoch 11/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0114 - val_accuracy: 0.5333 - val_loss: 3.6848 - learning_rate: 1.0000e-03\nEpoch 12/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9958 - loss: 0.0130 - val_accuracy: 0.6000 - val_loss: 2.0157 - learning_rate: 1.0000e-03\nEpoch 13/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0081 - val_accuracy: 0.6667 - val_loss: 1.0853 - learning_rate: 1.0000e-03\nEpoch 14/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0063 - val_accuracy: 0.7333 - val_loss: 0.6190 - learning_rate: 1.0000e-03\nEpoch 15/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0046 - val_accuracy: 0.8000 - val_loss: 0.3415 - learning_rate: 1.0000e-03\nEpoch 16/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0061 - val_accuracy: 0.8667 - val_loss: 0.2312 - learning_rate: 1.0000e-03\nEpoch 17/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9958 - loss: 0.0089 - val_accuracy: 0.9333 - val_loss: 0.1432 - learning_rate: 1.0000e-03\nEpoch 18/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9977 - loss: 0.0059 - val_accuracy: 1.0000 - val_loss: 0.0724 - learning_rate: 1.0000e-03\nEpoch 19/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0049 - val_accuracy: 1.0000 - val_loss: 0.0775 - learning_rate: 1.0000e-03\nEpoch 20/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0044 - val_accuracy: 0.9333 - val_loss: 0.1076 - learning_rate: 1.0000e-03\nEpoch 21/50\n\u001b[1m7/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0041\nEpoch 21: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0043 - val_accuracy: 0.9333 - val_loss: 0.1341 - learning_rate: 1.0000e-03\nEpoch 22/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0032 - val_accuracy: 0.9333 - val_loss: 0.1508 - learning_rate: 1.0000e-04\nEpoch 23/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0032 - val_accuracy: 0.9333 - val_loss: 0.1602 - learning_rate: 1.0000e-04\nEpoch 23: early stopping\nRestoring model weights from the end of the best epoch: 18.\nFold 3 - Train Accuracy: 81.95%, Validation Accuracy: 100.00%\n\nTraining on Fold 4...\nEpoch 1/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 758ms/step - accuracy: 0.6544 - loss: 0.9348 - val_accuracy: 0.5333 - val_loss: 387.9161 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9537 - loss: 0.2127 - val_accuracy: 0.4667 - val_loss: 643.5619 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9328 - loss: 0.1788 - val_accuracy: 0.4667 - val_loss: 3484.5117 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9739 - loss: 0.0805 - val_accuracy: 0.4667 - val_loss: 377.8097 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9903 - loss: 0.0458 - val_accuracy: 0.4667 - val_loss: 139.7285 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9916 - loss: 0.0230 - val_accuracy: 0.4667 - val_loss: 46.0601 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9958 - loss: 0.0214 - val_accuracy: 0.5333 - val_loss: 18.4508 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0085 - val_accuracy: 0.7333 - val_loss: 7.7101 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0034 - val_accuracy: 0.8000 - val_loss: 5.9020 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9985 - loss: 0.0100 - val_accuracy: 0.7333 - val_loss: 6.5947 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9935 - loss: 0.0162 - val_accuracy: 0.7333 - val_loss: 6.5569 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m7/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9902 - loss: 0.0346\nEpoch 12: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9909 - loss: 0.0330 - val_accuracy: 0.5333 - val_loss: 7.4810 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9854 - loss: 0.0274 - val_accuracy: 0.5333 - val_loss: 5.5711 - learning_rate: 1.0000e-03\nEpoch 14/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9945 - loss: 0.0243 - val_accuracy: 0.6000 - val_loss: 3.2783 - learning_rate: 1.0000e-03\nEpoch 15/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0095 - val_accuracy: 0.6000 - val_loss: 1.7324 - learning_rate: 1.0000e-03\nEpoch 16/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9909 - loss: 0.0201 - val_accuracy: 0.6667 - val_loss: 1.1653 - learning_rate: 1.0000e-03\nEpoch 17/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0035 - val_accuracy: 0.8000 - val_loss: 0.5294 - learning_rate: 1.0000e-03\nEpoch 18/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9878 - loss: 0.0129 - val_accuracy: 0.9333 - val_loss: 0.1498 - learning_rate: 1.0000e-03\nEpoch 19/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 1.0000 - val_loss: 0.0464 - learning_rate: 1.0000e-03\nEpoch 20/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0036 - val_accuracy: 1.0000 - val_loss: 0.0214 - learning_rate: 1.0000e-03\nEpoch 21/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 1.0000 - val_loss: 0.0483 - learning_rate: 1.0000e-03\nEpoch 22/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0044 - val_accuracy: 0.9333 - val_loss: 0.0909 - learning_rate: 1.0000e-03\nEpoch 23/50\n\u001b[1m7/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0012    \nEpoch 23: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.9333 - val_loss: 0.1089 - learning_rate: 1.0000e-03\nEpoch 24/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.9333 - val_loss: 0.1164 - learning_rate: 1.0000e-04\nEpoch 25/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.9333 - val_loss: 0.1159 - learning_rate: 1.0000e-04\nEpoch 25: early stopping\nRestoring model weights from the end of the best epoch: 20.\nFold 4 - Train Accuracy: 94.74%, Validation Accuracy: 100.00%\n\nTraining on Fold 5...\nEpoch 1/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 779ms/step - accuracy: 0.6810 - loss: 1.0574 - val_accuracy: 0.5333 - val_loss: 17272.9395 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9064 - loss: 0.2461 - val_accuracy: 0.4667 - val_loss: 354.2272 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9583 - loss: 0.1495 - val_accuracy: 0.4667 - val_loss: 189.4381 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9876 - loss: 0.0625 - val_accuracy: 0.6000 - val_loss: 29.6793 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0312 - val_accuracy: 0.4667 - val_loss: 292.3539 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9922 - loss: 0.0512 - val_accuracy: 0.4667 - val_loss: 259.6829 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m7/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9723 - loss: 0.0404\nEpoch 7: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9760 - loss: 0.0363 - val_accuracy: 0.4667 - val_loss: 59.4705 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0158 - val_accuracy: 0.4667 - val_loss: 34.3677 - learning_rate: 1.0000e-03\nEpoch 9/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9855 - loss: 0.0222 - val_accuracy: 0.4667 - val_loss: 24.2294 - learning_rate: 1.0000e-03\nEpoch 10/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0088 - val_accuracy: 0.4667 - val_loss: 17.2175 - learning_rate: 1.0000e-03\nEpoch 11/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0070 - val_accuracy: 0.5333 - val_loss: 11.6263 - learning_rate: 1.0000e-03\nEpoch 12/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0105 - val_accuracy: 0.5333 - val_loss: 7.5757 - learning_rate: 1.0000e-03\nEpoch 13/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0079 - val_accuracy: 0.5333 - val_loss: 4.6189 - learning_rate: 1.0000e-03\nEpoch 14/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0052 - val_accuracy: 0.5333 - val_loss: 2.8495 - learning_rate: 1.0000e-03\nEpoch 15/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0039 - val_accuracy: 0.6667 - val_loss: 2.0877 - learning_rate: 1.0000e-03\nEpoch 16/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0061 - val_accuracy: 0.6667 - val_loss: 1.7129 - learning_rate: 1.0000e-03\nEpoch 17/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0083 - val_accuracy: 0.6667 - val_loss: 1.6493 - learning_rate: 1.0000e-03\nEpoch 18/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0039 - val_accuracy: 0.6667 - val_loss: 1.4460 - learning_rate: 1.0000e-03\nEpoch 19/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0094 - val_accuracy: 0.7333 - val_loss: 1.2664 - learning_rate: 1.0000e-03\nEpoch 20/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0094 - val_accuracy: 0.7333 - val_loss: 0.9668 - learning_rate: 1.0000e-03\nEpoch 21/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9878 - loss: 0.0180 - val_accuracy: 0.8000 - val_loss: 0.8645 - learning_rate: 1.0000e-03\nEpoch 22/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 0.8667 - val_loss: 0.7771 - learning_rate: 1.0000e-03\nEpoch 23/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9945 - loss: 0.0122 - val_accuracy: 0.8667 - val_loss: 0.7016 - learning_rate: 1.0000e-03\nEpoch 24/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0023 - val_accuracy: 0.8667 - val_loss: 0.6534 - learning_rate: 1.0000e-03\nEpoch 25/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0050 - val_accuracy: 0.9333 - val_loss: 0.6208 - learning_rate: 1.0000e-03\nEpoch 26/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.9333 - val_loss: 0.6016 - learning_rate: 1.0000e-03\nEpoch 27/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0039 - val_accuracy: 0.9333 - val_loss: 0.5841 - learning_rate: 1.0000e-03\nEpoch 28/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.9333 - val_loss: 0.5646 - learning_rate: 1.0000e-03\nEpoch 29/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 0.9333 - val_loss: 0.5463 - learning_rate: 1.0000e-03\nEpoch 30/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0036 - val_accuracy: 0.9333 - val_loss: 0.5281 - learning_rate: 1.0000e-03\nEpoch 31/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.9333 - val_loss: 0.5151 - learning_rate: 1.0000e-03\nEpoch 32/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.9333 - val_loss: 0.5078 - learning_rate: 1.0000e-03\nEpoch 33/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.9333 - val_loss: 0.5055 - learning_rate: 1.0000e-03\nEpoch 34/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0023 - val_accuracy: 0.9333 - val_loss: 0.5016 - learning_rate: 1.0000e-03\nEpoch 35/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.9333 - val_loss: 0.5007 - learning_rate: 1.0000e-03\nEpoch 36/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.9333 - val_loss: 0.4971 - learning_rate: 1.0000e-03\nEpoch 37/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 0.9333 - val_loss: 0.4922 - learning_rate: 1.0000e-03\nEpoch 38/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.9333 - val_loss: 0.4893 - learning_rate: 1.0000e-03\nEpoch 39/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.9333 - val_loss: 0.4871 - learning_rate: 1.0000e-03\nEpoch 40/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.9333 - val_loss: 0.4864 - learning_rate: 1.0000e-03\nEpoch 41/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 9.5835e-04 - val_accuracy: 0.9333 - val_loss: 0.4850 - learning_rate: 1.0000e-03\nEpoch 42/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.9333 - val_loss: 0.4825 - learning_rate: 1.0000e-03\nEpoch 43/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.9333 - val_loss: 0.4811 - learning_rate: 1.0000e-03\nEpoch 44/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.9333 - val_loss: 0.4785 - learning_rate: 1.0000e-03\nEpoch 45/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 8.3462e-04 - val_accuracy: 0.9333 - val_loss: 0.4753 - learning_rate: 1.0000e-03\nEpoch 46/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 0.9333 - val_loss: 0.4681 - learning_rate: 1.0000e-03\nEpoch 47/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 8.4460e-04 - val_accuracy: 0.9333 - val_loss: 0.4626 - learning_rate: 1.0000e-03\nEpoch 48/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.9333 - val_loss: 0.4552 - learning_rate: 1.0000e-03\nEpoch 49/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.9333 - val_loss: 0.4494 - learning_rate: 1.0000e-03\nEpoch 50/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 9.2122e-04 - val_accuracy: 0.9333 - val_loss: 0.4498 - learning_rate: 1.0000e-03\nRestoring model weights from the end of the best epoch: 49.\nFold 5 - Train Accuracy: 100.00%, Validation Accuracy: 93.33%\n\nTraining on Fold 6...\nEpoch 1/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 762ms/step - accuracy: 0.6717 - loss: 1.1966 - val_accuracy: 0.4667 - val_loss: 3614.4275 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8561 - loss: 0.4010 - val_accuracy: 0.2667 - val_loss: 345.6579 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9098 - loss: 0.2026 - val_accuracy: 0.5333 - val_loss: 167.4444 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9624 - loss: 0.1183 - val_accuracy: 0.5333 - val_loss: 95.4086 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9668 - loss: 0.0754 - val_accuracy: 0.5333 - val_loss: 35.4747 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9842 - loss: 0.0530 - val_accuracy: 0.5333 - val_loss: 10.2827 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9777 - loss: 0.0627 - val_accuracy: 0.5333 - val_loss: 6.3157 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9977 - loss: 0.0384 - val_accuracy: 0.3333 - val_loss: 2.2337 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9977 - loss: 0.0174 - val_accuracy: 0.4000 - val_loss: 2.2173 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0141 - val_accuracy: 0.4667 - val_loss: 3.2752 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9783 - loss: 0.0352 - val_accuracy: 0.5333 - val_loss: 4.3769 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m7/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0068\nEpoch 12: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9977 - loss: 0.0120 - val_accuracy: 0.7333 - val_loss: 2.4426 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0062 - val_accuracy: 0.7333 - val_loss: 1.7223 - learning_rate: 1.0000e-03\nEpoch 14/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0058 - val_accuracy: 0.8667 - val_loss: 1.3436 - learning_rate: 1.0000e-03\nEpoch 15/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0076 - val_accuracy: 0.8667 - val_loss: 1.0805 - learning_rate: 1.0000e-03\nEpoch 16/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0067 - val_accuracy: 0.9333 - val_loss: 0.8693 - learning_rate: 1.0000e-03\nEpoch 17/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0043 - val_accuracy: 0.9333 - val_loss: 0.7113 - learning_rate: 1.0000e-03\nEpoch 18/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0046 - val_accuracy: 0.9333 - val_loss: 0.5562 - learning_rate: 1.0000e-03\nEpoch 19/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0031 - val_accuracy: 0.9333 - val_loss: 0.4615 - learning_rate: 1.0000e-03\nEpoch 20/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0043 - val_accuracy: 0.9333 - val_loss: 0.3651 - learning_rate: 1.0000e-03\nEpoch 21/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.9333 - val_loss: 0.2712 - learning_rate: 1.0000e-03\nEpoch 22/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0049 - val_accuracy: 0.9333 - val_loss: 0.2093 - learning_rate: 1.0000e-03\nEpoch 23/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.9333 - val_loss: 0.1486 - learning_rate: 1.0000e-03\nEpoch 24/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.9333 - val_loss: 0.0671 - learning_rate: 1.0000e-03\nEpoch 25/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 1.0000 - val_loss: 0.0307 - learning_rate: 1.0000e-03\nEpoch 26/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 1.0000 - val_loss: 0.0125 - learning_rate: 1.0000e-03\nEpoch 27/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 1.0000 - val_loss: 0.0056 - learning_rate: 1.0000e-03\nEpoch 28/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 1.0000 - val_loss: 0.0035 - learning_rate: 1.0000e-03\nEpoch 29/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 1.0000 - val_loss: 0.0028 - learning_rate: 1.0000e-03\nEpoch 30/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 1.0000 - val_loss: 0.0025 - learning_rate: 1.0000e-03\nEpoch 31/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 1.0000 - val_loss: 0.0022 - learning_rate: 1.0000e-03\nEpoch 32/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 1.0000 - val_loss: 0.0021 - learning_rate: 1.0000e-03\nEpoch 33/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 1.0000 - val_loss: 0.0022 - learning_rate: 1.0000e-03\nEpoch 34/50\n\u001b[1m7/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0013    \nEpoch 34: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0023 - val_accuracy: 1.0000 - val_loss: 0.0025 - learning_rate: 1.0000e-03\nEpoch 35/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 1.0000 - val_loss: 0.0030 - learning_rate: 1.0000e-04\nEpoch 36/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0035 - val_accuracy: 1.0000 - val_loss: 0.0036 - learning_rate: 1.0000e-04\nEpoch 37/50\n\u001b[1m7/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 9.4305e-04\nEpoch 37: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 1.0000 - val_loss: 0.0048 - learning_rate: 1.0000e-04\nEpoch 37: early stopping\nRestoring model weights from the end of the best epoch: 32.\nFold 6 - Train Accuracy: 97.74%, Validation Accuracy: 100.00%\n\nTraining on Fold 7...\nEpoch 1/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 767ms/step - accuracy: 0.7689 - loss: 0.9487 - val_accuracy: 0.5333 - val_loss: 3646.8135 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8375 - loss: 0.4361 - val_accuracy: 0.5333 - val_loss: 1631.9688 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9443 - loss: 0.1562 - val_accuracy: 0.5333 - val_loss: 95.2392 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9630 - loss: 0.0992 - val_accuracy: 0.4667 - val_loss: 229.8753 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9844 - loss: 0.0453 - val_accuracy: 0.4667 - val_loss: 80.3652 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0268 - val_accuracy: 0.4667 - val_loss: 56.1819 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0219 - val_accuracy: 0.4667 - val_loss: 39.8879 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0078 - val_accuracy: 0.4667 - val_loss: 32.3757 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0060 - val_accuracy: 0.5333 - val_loss: 11.9778 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0049 - val_accuracy: 0.6000 - val_loss: 4.1707 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.6000 - val_loss: 3.2083 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.7333 - val_loss: 2.0536 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9783 - loss: 0.0275 - val_accuracy: 0.6667 - val_loss: 2.4578 - learning_rate: 0.0100\nEpoch 14/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9777 - loss: 0.0407 - val_accuracy: 0.7333 - val_loss: 1.0755 - learning_rate: 0.0100\nEpoch 15/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9768 - loss: 0.0966 - val_accuracy: 0.6000 - val_loss: 5.5854 - learning_rate: 0.0100\nEpoch 16/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9379 - loss: 0.1863 - val_accuracy: 1.0000 - val_loss: 0.0299 - learning_rate: 0.0100\nEpoch 17/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9977 - loss: 0.0243 - val_accuracy: 0.6000 - val_loss: 4.1563 - learning_rate: 0.0100\nEpoch 18/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9945 - loss: 0.0270 - val_accuracy: 0.7333 - val_loss: 1.7820 - learning_rate: 0.0100\nEpoch 19/50\n\u001b[1m7/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0102\nEpoch 19: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0104 - val_accuracy: 0.8667 - val_loss: 0.6349 - learning_rate: 0.0100\nEpoch 20/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0100 - val_accuracy: 0.8667 - val_loss: 0.3338 - learning_rate: 1.0000e-03\nEpoch 21/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0086 - val_accuracy: 0.8667 - val_loss: 0.1670 - learning_rate: 1.0000e-03\nEpoch 21: early stopping\nRestoring model weights from the end of the best epoch: 16.\nFold 7 - Train Accuracy: 90.23%, Validation Accuracy: 100.00%\n\nTraining on Fold 8...\nEpoch 1/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 768ms/step - accuracy: 0.6014 - loss: 1.0826 - val_accuracy: 0.5333 - val_loss: 5205.0156 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9170 - loss: 0.2904 - val_accuracy: 0.4667 - val_loss: 3072.7756 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9564 - loss: 0.1106 - val_accuracy: 0.4667 - val_loss: 1160.0426 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9839 - loss: 0.0364 - val_accuracy: 0.4667 - val_loss: 485.4072 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9909 - loss: 0.0326 - val_accuracy: 0.4667 - val_loss: 289.2257 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9909 - loss: 0.0319 - val_accuracy: 0.4667 - val_loss: 143.5277 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9792 - loss: 0.0295 - val_accuracy: 0.4000 - val_loss: 40.3450 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0054 - val_accuracy: 0.4667 - val_loss: 27.2909 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 0.4667 - val_loss: 17.5357 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.5333 - val_loss: 7.8722 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 0.6000 - val_loss: 4.4673 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.6667 - val_loss: 2.5986 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.7333 - val_loss: 1.6147 - learning_rate: 0.0100\nEpoch 14/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 7.9640e-04 - val_accuracy: 0.8667 - val_loss: 1.2343 - learning_rate: 0.0100\nEpoch 15/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 8.4428e-04 - val_accuracy: 0.8667 - val_loss: 1.0670 - learning_rate: 0.0100\nEpoch 16/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 4.3774e-04 - val_accuracy: 0.8000 - val_loss: 1.0612 - learning_rate: 0.0100\nEpoch 17/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 0.8000 - val_loss: 0.9809 - learning_rate: 0.0100\nEpoch 18/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 4.5988e-04 - val_accuracy: 0.8000 - val_loss: 0.8816 - learning_rate: 0.0100\nEpoch 19/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 5.1100e-04 - val_accuracy: 0.8667 - val_loss: 0.8135 - learning_rate: 0.0100\nEpoch 20/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 2.2611e-04 - val_accuracy: 0.8667 - val_loss: 0.7517 - learning_rate: 0.0100\nEpoch 21/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 1.8408e-04 - val_accuracy: 0.8667 - val_loss: 0.6913 - learning_rate: 0.0100\nEpoch 22/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 4.9305e-04 - val_accuracy: 0.8667 - val_loss: 0.6622 - learning_rate: 0.0100\nEpoch 23/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 2.1483e-04 - val_accuracy: 0.8667 - val_loss: 0.6940 - learning_rate: 0.0100\nEpoch 24/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 1.8932e-04 - val_accuracy: 0.8667 - val_loss: 0.7638 - learning_rate: 0.0100\nEpoch 25/50\n\u001b[1m7/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 3.8096e-04\nEpoch 25: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 3.6251e-04 - val_accuracy: 0.8667 - val_loss: 0.7981 - learning_rate: 0.0100\nEpoch 26/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 7.2794e-04 - val_accuracy: 0.8667 - val_loss: 0.7881 - learning_rate: 1.0000e-03\nEpoch 27/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 1.9483e-04 - val_accuracy: 0.8667 - val_loss: 0.7578 - learning_rate: 1.0000e-03\nEpoch 27: early stopping\nRestoring model weights from the end of the best epoch: 22.\nFold 8 - Train Accuracy: 97.74%, Validation Accuracy: 86.67%\n\nTraining on Fold 9...\nEpoch 1/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1s/step - accuracy: 0.7010 - loss: 0.8866 - val_accuracy: 0.5000 - val_loss: 9161.7529 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8778 - loss: 0.4616 - val_accuracy: 0.5000 - val_loss: 4503.3022 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9670 - loss: 0.1262 - val_accuracy: 0.5000 - val_loss: 2504.0261 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9945 - loss: 0.0366 - val_accuracy: 0.5000 - val_loss: 951.7460 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9815 - loss: 0.0248 - val_accuracy: 0.5000 - val_loss: 435.9248 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0056 - val_accuracy: 0.5000 - val_loss: 225.2595 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0105 - val_accuracy: 0.5000 - val_loss: 124.2107 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0107 - val_accuracy: 0.5000 - val_loss: 66.5899 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0097 - val_accuracy: 0.5000 - val_loss: 40.0657 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 0.5000 - val_loss: 24.4561 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0043 - val_accuracy: 0.5714 - val_loss: 15.1804 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0123 - val_accuracy: 0.5714 - val_loss: 7.9592 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.6429 - val_loss: 3.7053 - learning_rate: 0.0100\nEpoch 14/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 9.0752e-04 - val_accuracy: 0.7143 - val_loss: 1.0451 - learning_rate: 0.0100\nEpoch 15/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0042 - val_accuracy: 0.7857 - val_loss: 0.4552 - learning_rate: 0.0100\nEpoch 16/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 8.7988e-04 - val_accuracy: 0.7143 - val_loss: 0.7438 - learning_rate: 0.0100\nEpoch 17/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 4.3384e-04 - val_accuracy: 0.7143 - val_loss: 1.0599 - learning_rate: 0.0100\nEpoch 18/50\n\u001b[1m7/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0026\nEpoch 18: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.7143 - val_loss: 0.8423 - learning_rate: 0.0100\nEpoch 19/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 2.2718e-04 - val_accuracy: 0.7143 - val_loss: 0.8245 - learning_rate: 1.0000e-03\nEpoch 20/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 2.7886e-04 - val_accuracy: 0.7857 - val_loss: 0.7708 - learning_rate: 1.0000e-03\nEpoch 20: early stopping\nRestoring model weights from the end of the best epoch: 15.\nFold 9 - Train Accuracy: 65.67%, Validation Accuracy: 78.57%\n\nTraining on Fold 10...\nEpoch 1/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 802ms/step - accuracy: 0.7340 - loss: 0.8674 - val_accuracy: 0.5000 - val_loss: 11946.4775 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8347 - loss: 0.5087 - val_accuracy: 0.5000 - val_loss: 11255.2051 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9245 - loss: 0.1939 - val_accuracy: 0.5000 - val_loss: 2254.7307 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9536 - loss: 0.0743 - val_accuracy: 0.5000 - val_loss: 364.9631 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9945 - loss: 0.0298 - val_accuracy: 0.5714 - val_loss: 23.3272 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9945 - loss: 0.0193 - val_accuracy: 0.5000 - val_loss: 57.5167 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0113 - val_accuracy: 0.5000 - val_loss: 47.2059 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0052 - val_accuracy: 0.5000 - val_loss: 20.3296 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0038 - val_accuracy: 0.5000 - val_loss: 8.7200 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0051 - val_accuracy: 0.5000 - val_loss: 3.2984 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0039 - val_accuracy: 0.5000 - val_loss: 2.2810 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 9.1255e-04 - val_accuracy: 0.6429 - val_loss: 1.4279 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.7857 - val_loss: 0.9072 - learning_rate: 0.0100\nEpoch 14/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9945 - loss: 0.0068 - val_accuracy: 0.7857 - val_loss: 0.5153 - learning_rate: 0.0100\nEpoch 15/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.8571 - val_loss: 0.4462 - learning_rate: 0.0100\nEpoch 16/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9909 - loss: 0.0110 - val_accuracy: 0.7143 - val_loss: 0.7698 - learning_rate: 0.0100\nEpoch 17/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 7.1177e-04 - val_accuracy: 0.6429 - val_loss: 1.0951 - learning_rate: 0.0100\nEpoch 18/50\n\u001b[1m7/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0043\nEpoch 18: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0043 - val_accuracy: 0.7857 - val_loss: 0.7033 - learning_rate: 0.0100\nEpoch 19/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.7857 - val_loss: 0.6231 - learning_rate: 1.0000e-03\nEpoch 20/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0060 - val_accuracy: 0.8571 - val_loss: 0.5632 - learning_rate: 1.0000e-03\nEpoch 20: early stopping\nRestoring model weights from the end of the best epoch: 15.\nFold 10 - Train Accuracy: 90.30%, Validation Accuracy: 85.71%\n\nAverage Training Accuracy: 87.33%\nAverage Validation Accuracy: 91.76%\n","output_type":"stream"}],"execution_count":91},{"cell_type":"markdown","source":"## 2.1 Flipping","metadata":{}},{"cell_type":"code","source":"X_train_flipped = np.flip(X_train, axis=2)\nX_test_flipped = np.flip(X_test, axis=2)\n\nX_train_augmented = np.concatenate((X_train, X_train_flipped), axis=0)\ny_train_augmented = np.concatenate((y_train, y_train), axis=0)\n\ntrain_evaluate_model_with_k_fold(\n    X_train=X_train_augmented,\n    y_train=y_train_augmented,\n    lr=0.01,\n    epochs=50,\n    batch_size=16)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T20:07:32.726250Z","iopub.execute_input":"2025-02-07T20:07:32.726603Z","iopub.status.idle":"2025-02-07T20:12:27.809953Z","shell.execute_reply.started":"2025-02-07T20:07:32.726574Z","shell.execute_reply":"2025-02-07T20:12:27.809138Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"\nTraining on Fold 1...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 587ms/step - accuracy: 0.7027 - loss: 1.3310 - val_accuracy: 0.5000 - val_loss: 16620.5059 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8934 - loss: 0.3664 - val_accuracy: 0.5000 - val_loss: 427.3303 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9478 - loss: 0.1739 - val_accuracy: 0.7667 - val_loss: 6.4587 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9412 - loss: 0.1210 - val_accuracy: 0.5000 - val_loss: 30.9617 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9833 - loss: 0.0664 - val_accuracy: 0.5333 - val_loss: 6.3170 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9857 - loss: 0.0385 - val_accuracy: 0.6333 - val_loss: 2.1121 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9832 - loss: 0.0373 - val_accuracy: 0.5667 - val_loss: 4.1205 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9958 - loss: 0.0289 - val_accuracy: 0.7667 - val_loss: 1.2864 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9813 - loss: 0.0309 - val_accuracy: 0.7333 - val_loss: 2.1451 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9751 - loss: 0.0596 - val_accuracy: 0.8000 - val_loss: 1.3798 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9888 - loss: 0.0416 - val_accuracy: 0.8000 - val_loss: 1.0002 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9821 - loss: 0.0496 - val_accuracy: 0.8000 - val_loss: 0.9705 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9828 - loss: 0.0752 - val_accuracy: 0.9000 - val_loss: 0.4471 - learning_rate: 0.0100\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9873 - loss: 0.0291 - val_accuracy: 0.8333 - val_loss: 0.5800 - learning_rate: 0.0100\nEpoch 15/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9715 - loss: 0.0484 - val_accuracy: 0.9333 - val_loss: 0.6710 - learning_rate: 0.0100\nEpoch 16/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9958 - loss: 0.0176 - val_accuracy: 0.9000 - val_loss: 0.3724 - learning_rate: 0.0100\nEpoch 17/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9915 - loss: 0.0285 - val_accuracy: 0.9333 - val_loss: 0.6232 - learning_rate: 0.0100\nEpoch 18/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9958 - loss: 0.0137 - val_accuracy: 0.9333 - val_loss: 0.4389 - learning_rate: 0.0100\nEpoch 19/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0066 - val_accuracy: 0.9667 - val_loss: 0.3089 - learning_rate: 0.0100\nEpoch 20/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 0.9333 - val_loss: 0.3173 - learning_rate: 0.0100\nEpoch 21/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 0.9333 - val_loss: 0.3239 - learning_rate: 0.0100\nEpoch 22/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.9333 - val_loss: 0.2683 - learning_rate: 0.0100\nEpoch 23/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 8.7328e-04 - val_accuracy: 0.9333 - val_loss: 0.2182 - learning_rate: 0.0100\nEpoch 24/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 8.0141e-04 - val_accuracy: 0.9333 - val_loss: 0.1689 - learning_rate: 0.0100\nEpoch 25/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 8.6493e-04 - val_accuracy: 0.9667 - val_loss: 0.1346 - learning_rate: 0.0100\nEpoch 26/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 7.8507e-04 - val_accuracy: 0.9667 - val_loss: 0.1179 - learning_rate: 0.0100\nEpoch 27/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0070 - val_accuracy: 0.9667 - val_loss: 0.4106 - learning_rate: 0.0100\nEpoch 28/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9937 - loss: 0.0173 - val_accuracy: 0.9333 - val_loss: 0.8180 - learning_rate: 0.0100\nEpoch 29/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9989 - loss: 0.0123\nEpoch 29: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9986 - loss: 0.0130 - val_accuracy: 0.9000 - val_loss: 1.2867 - learning_rate: 0.0100\nEpoch 30/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9931 - loss: 0.0312 - val_accuracy: 0.9333 - val_loss: 0.7785 - learning_rate: 1.0000e-03\nEpoch 31/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0051 - val_accuracy: 0.9333 - val_loss: 0.6175 - learning_rate: 1.0000e-03\nEpoch 31: early stopping\nRestoring model weights from the end of the best epoch: 26.\nFold 1 - Train Accuracy: 98.87%, Validation Accuracy: 96.67%\n\nTraining on Fold 2...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 419ms/step - accuracy: 0.7275 - loss: 0.9014 - val_accuracy: 0.5000 - val_loss: 1960.6597 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.9259 - loss: 0.2505 - val_accuracy: 0.5000 - val_loss: 193.4128 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9415 - loss: 0.1260 - val_accuracy: 0.5000 - val_loss: 108.3874 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9838 - loss: 0.0479 - val_accuracy: 0.8333 - val_loss: 3.5453 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9797 - loss: 0.0386 - val_accuracy: 0.8667 - val_loss: 1.4603 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9798 - loss: 0.0434 - val_accuracy: 0.6333 - val_loss: 4.1378 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9655 - loss: 0.0892 - val_accuracy: 0.9000 - val_loss: 1.3894 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9856 - loss: 0.0304 - val_accuracy: 0.6667 - val_loss: 3.2065 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9972 - loss: 0.0251 - val_accuracy: 0.6333 - val_loss: 2.4322 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9821 - loss: 0.0364\nEpoch 10: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9819 - loss: 0.0384 - val_accuracy: 0.6000 - val_loss: 4.5285 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9687 - loss: 0.1192 - val_accuracy: 0.7667 - val_loss: 1.5679 - learning_rate: 1.0000e-03\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9980 - loss: 0.0236 - val_accuracy: 0.8333 - val_loss: 0.6830 - learning_rate: 1.0000e-03\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0067 - val_accuracy: 0.8333 - val_loss: 0.3972 - learning_rate: 1.0000e-03\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0061 - val_accuracy: 0.8667 - val_loss: 0.2768 - learning_rate: 1.0000e-03\nEpoch 15/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0059 - val_accuracy: 0.9000 - val_loss: 0.2063 - learning_rate: 1.0000e-03\nEpoch 16/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 0.9000 - val_loss: 0.1504 - learning_rate: 1.0000e-03\nEpoch 17/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0039 - val_accuracy: 0.9333 - val_loss: 0.1183 - learning_rate: 1.0000e-03\nEpoch 18/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0036 - val_accuracy: 0.9333 - val_loss: 0.0973 - learning_rate: 1.0000e-03\nEpoch 19/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0031 - val_accuracy: 0.9333 - val_loss: 0.0758 - learning_rate: 1.0000e-03\nEpoch 20/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 0.9333 - val_loss: 0.0575 - learning_rate: 1.0000e-03\nEpoch 21/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 1.0000 - val_loss: 0.0472 - learning_rate: 1.0000e-03\nEpoch 22/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 1.0000 - val_loss: 0.0383 - learning_rate: 1.0000e-03\nEpoch 23/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 1.0000 - val_loss: 0.0297 - learning_rate: 1.0000e-03\nEpoch 24/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 1.0000 - val_loss: 0.0236 - learning_rate: 1.0000e-03\nEpoch 25/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0035 - val_accuracy: 1.0000 - val_loss: 0.0199 - learning_rate: 1.0000e-03\nEpoch 26/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0032 - val_accuracy: 1.0000 - val_loss: 0.0171 - learning_rate: 1.0000e-03\nEpoch 27/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 1.0000 - val_loss: 0.0164 - learning_rate: 1.0000e-03\nEpoch 28/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 1.0000 - val_loss: 0.0159 - learning_rate: 1.0000e-03\nEpoch 29/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 1.0000 - val_loss: 0.0147 - learning_rate: 1.0000e-03\nEpoch 30/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 1.0000 - val_loss: 0.0145 - learning_rate: 1.0000e-03\nEpoch 31/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 1.0000 - val_loss: 0.0150 - learning_rate: 1.0000e-03\nEpoch 32/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 1.0000 - val_loss: 0.0154 - learning_rate: 1.0000e-03\nEpoch 33/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0010    \nEpoch 33: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 1.0000 - val_loss: 0.0160 - learning_rate: 1.0000e-03\nEpoch 34/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 1.0000 - val_loss: 0.0166 - learning_rate: 1.0000e-04\nEpoch 35/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0023 - val_accuracy: 1.0000 - val_loss: 0.0168 - learning_rate: 1.0000e-04\nEpoch 35: early stopping\nRestoring model weights from the end of the best epoch: 30.\nFold 2 - Train Accuracy: 100.00%, Validation Accuracy: 100.00%\n\nTraining on Fold 3...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 416ms/step - accuracy: 0.7413 - loss: 1.0052 - val_accuracy: 0.5000 - val_loss: 321.9003 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9111 - loss: 0.2235 - val_accuracy: 0.4667 - val_loss: 53.7540 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9571 - loss: 0.1889 - val_accuracy: 0.3000 - val_loss: 11.3137 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9834 - loss: 0.0471 - val_accuracy: 0.6667 - val_loss: 3.8711 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9698 - loss: 0.0582 - val_accuracy: 0.6333 - val_loss: 4.9022 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9844 - loss: 0.0311 - val_accuracy: 0.7333 - val_loss: 1.2166 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9959 - loss: 0.0187 - val_accuracy: 0.7667 - val_loss: 1.0136 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9919 - loss: 0.0219 - val_accuracy: 0.8333 - val_loss: 0.7915 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9952 - loss: 0.0118 - val_accuracy: 0.8667 - val_loss: 0.5879 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9895 - loss: 0.0780 - val_accuracy: 0.9333 - val_loss: 0.6822 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9934 - loss: 0.0147 - val_accuracy: 1.0000 - val_loss: 0.0256 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9783 - loss: 0.0459 - val_accuracy: 0.7667 - val_loss: 1.4888 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9837 - loss: 0.0308 - val_accuracy: 0.8333 - val_loss: 0.9383 - learning_rate: 0.0100\nEpoch 14/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9718 - loss: 0.0585\nEpoch 14: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9728 - loss: 0.0568 - val_accuracy: 0.9333 - val_loss: 0.4212 - learning_rate: 0.0100\nEpoch 15/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9779 - loss: 0.0230 - val_accuracy: 0.9333 - val_loss: 0.1815 - learning_rate: 1.0000e-03\nEpoch 16/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9983 - loss: 0.0078 - val_accuracy: 0.9667 - val_loss: 0.0497 - learning_rate: 1.0000e-03\nEpoch 16: early stopping\nRestoring model weights from the end of the best epoch: 11.\nFold 3 - Train Accuracy: 83.83%, Validation Accuracy: 100.00%\n\nTraining on Fold 4...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 411ms/step - accuracy: 0.7313 - loss: 0.9982 - val_accuracy: 0.5000 - val_loss: 1036.3601 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.8500 - loss: 0.3436 - val_accuracy: 0.5000 - val_loss: 282.9016 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9068 - loss: 0.2196 - val_accuracy: 0.5000 - val_loss: 79.3200 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9374 - loss: 0.1556 - val_accuracy: 0.5000 - val_loss: 47.8281 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9532 - loss: 0.1009 - val_accuracy: 0.5000 - val_loss: 40.5223 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9639 - loss: 0.0695 - val_accuracy: 0.5333 - val_loss: 41.6773 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9593 - loss: 0.0971 - val_accuracy: 0.5333 - val_loss: 10.7694 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9830 - loss: 0.0859 - val_accuracy: 0.8333 - val_loss: 0.4875 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9609 - loss: 0.0855 - val_accuracy: 0.8000 - val_loss: 0.8538 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9747 - loss: 0.0511 - val_accuracy: 0.7667 - val_loss: 0.7994 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9943 - loss: 0.0277\nEpoch 11: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9941 - loss: 0.0275 - val_accuracy: 0.7667 - val_loss: 1.2644 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9728 - loss: 0.0605 - val_accuracy: 0.8667 - val_loss: 0.5261 - learning_rate: 1.0000e-03\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9977 - loss: 0.0144 - val_accuracy: 0.9000 - val_loss: 0.3659 - learning_rate: 1.0000e-03\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9942 - loss: 0.0165 - val_accuracy: 0.9000 - val_loss: 0.3638 - learning_rate: 1.0000e-03\nEpoch 15/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0099 - val_accuracy: 0.9000 - val_loss: 0.3791 - learning_rate: 1.0000e-03\nEpoch 16/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0102 - val_accuracy: 0.9000 - val_loss: 0.3636 - learning_rate: 1.0000e-03\nEpoch 17/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0065 - val_accuracy: 0.9000 - val_loss: 0.3450 - learning_rate: 1.0000e-03\nEpoch 18/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9977 - loss: 0.0114 - val_accuracy: 0.9000 - val_loss: 0.4096 - learning_rate: 1.0000e-03\nEpoch 19/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0069 - val_accuracy: 0.8667 - val_loss: 0.4033 - learning_rate: 1.0000e-03\nEpoch 20/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0083 - val_accuracy: 0.8667 - val_loss: 0.3299 - learning_rate: 1.0000e-03\nEpoch 21/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0076 - val_accuracy: 0.8667 - val_loss: 0.3043 - learning_rate: 1.0000e-03\nEpoch 22/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0069 - val_accuracy: 0.8667 - val_loss: 0.2867 - learning_rate: 1.0000e-03\nEpoch 23/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0037 - val_accuracy: 0.9000 - val_loss: 0.2860 - learning_rate: 1.0000e-03\nEpoch 24/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0040 - val_accuracy: 0.9000 - val_loss: 0.3214 - learning_rate: 1.0000e-03\nEpoch 25/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0071 - val_accuracy: 0.9000 - val_loss: 0.3017 - learning_rate: 1.0000e-03\nEpoch 26/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0060\nEpoch 26: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0060 - val_accuracy: 0.9000 - val_loss: 0.3307 - learning_rate: 1.0000e-03\nEpoch 27/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0041 - val_accuracy: 0.9000 - val_loss: 0.3310 - learning_rate: 1.0000e-04\nEpoch 28/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0046 - val_accuracy: 0.9000 - val_loss: 0.3431 - learning_rate: 1.0000e-04\nEpoch 28: early stopping\nRestoring model weights from the end of the best epoch: 23.\nFold 4 - Train Accuracy: 98.50%, Validation Accuracy: 90.00%\n\nTraining on Fold 5...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 414ms/step - accuracy: 0.7724 - loss: 0.7265 - val_accuracy: 0.5000 - val_loss: 852.1312 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8633 - loss: 0.2694 - val_accuracy: 0.5000 - val_loss: 538.6650 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9373 - loss: 0.1387 - val_accuracy: 0.5667 - val_loss: 43.1859 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9753 - loss: 0.0790 - val_accuracy: 0.5333 - val_loss: 18.3740 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9846 - loss: 0.0568 - val_accuracy: 0.8333 - val_loss: 1.7281 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9769 - loss: 0.0569 - val_accuracy: 0.7667 - val_loss: 1.5927 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9798 - loss: 0.0437 - val_accuracy: 0.7333 - val_loss: 1.5111 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9789 - loss: 0.0568 - val_accuracy: 0.7000 - val_loss: 1.8700 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9938 - loss: 0.0458 - val_accuracy: 0.9333 - val_loss: 0.3278 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9983 - loss: 0.0316 - val_accuracy: 0.9000 - val_loss: 0.4695 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9765 - loss: 0.0696 - val_accuracy: 0.7333 - val_loss: 1.4645 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9938 - loss: 0.0188 - val_accuracy: 0.9333 - val_loss: 0.2075 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9693 - loss: 0.1357 - val_accuracy: 0.8000 - val_loss: 1.2899 - learning_rate: 0.0100\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9728 - loss: 0.0582 - val_accuracy: 0.9333 - val_loss: 0.1870 - learning_rate: 0.0100\nEpoch 15/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9815 - loss: 0.0478 - val_accuracy: 0.9333 - val_loss: 0.1246 - learning_rate: 0.0100\nEpoch 16/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9906 - loss: 0.0189 - val_accuracy: 0.9000 - val_loss: 0.3572 - learning_rate: 0.0100\nEpoch 17/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0048 - val_accuracy: 0.9667 - val_loss: 0.1284 - learning_rate: 0.0100\nEpoch 18/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0039\nEpoch 18: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0038 - val_accuracy: 0.9667 - val_loss: 0.1486 - learning_rate: 0.0100\nEpoch 19/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.9667 - val_loss: 0.1392 - learning_rate: 1.0000e-03\nEpoch 20/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.9667 - val_loss: 0.1319 - learning_rate: 1.0000e-03\nEpoch 20: early stopping\nRestoring model weights from the end of the best epoch: 15.\nFold 5 - Train Accuracy: 95.86%, Validation Accuracy: 93.33%\n\nTraining on Fold 6...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 410ms/step - accuracy: 0.7035 - loss: 0.8208 - val_accuracy: 0.5000 - val_loss: 1159.8646 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.9384 - loss: 0.1623 - val_accuracy: 0.5000 - val_loss: 460.0631 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9614 - loss: 0.0878 - val_accuracy: 0.7333 - val_loss: 4.9971 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9890 - loss: 0.0451 - val_accuracy: 0.5000 - val_loss: 25.8830 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9459 - loss: 0.1100 - val_accuracy: 0.6000 - val_loss: 9.7861 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9743 - loss: 0.1125\nEpoch 6: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9730 - loss: 0.1152 - val_accuracy: 0.5333 - val_loss: 19.2874 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9848 - loss: 0.0422 - val_accuracy: 0.5333 - val_loss: 6.6809 - learning_rate: 1.0000e-03\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9934 - loss: 0.0291 - val_accuracy: 0.6000 - val_loss: 2.5047 - learning_rate: 1.0000e-03\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9940 - loss: 0.0237 - val_accuracy: 0.8000 - val_loss: 1.0468 - learning_rate: 1.0000e-03\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9951 - loss: 0.0211 - val_accuracy: 0.8667 - val_loss: 0.4761 - learning_rate: 1.0000e-03\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9983 - loss: 0.0149 - val_accuracy: 0.8667 - val_loss: 0.3204 - learning_rate: 1.0000e-03\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9969 - loss: 0.0126 - val_accuracy: 0.9000 - val_loss: 0.3143 - learning_rate: 1.0000e-03\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0086 - val_accuracy: 0.9000 - val_loss: 0.3760 - learning_rate: 1.0000e-03\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0075 - val_accuracy: 0.9000 - val_loss: 0.4447 - learning_rate: 1.0000e-03\nEpoch 15/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0052\nEpoch 15: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0055 - val_accuracy: 0.9000 - val_loss: 0.4761 - learning_rate: 1.0000e-03\nEpoch 16/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0072 - val_accuracy: 0.9000 - val_loss: 0.4825 - learning_rate: 1.0000e-04\nEpoch 17/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9986 - loss: 0.0088 - val_accuracy: 0.9000 - val_loss: 0.4765 - learning_rate: 1.0000e-04\nEpoch 17: early stopping\nRestoring model weights from the end of the best epoch: 12.\nFold 6 - Train Accuracy: 96.62%, Validation Accuracy: 90.00%\n\nTraining on Fold 7...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 648ms/step - accuracy: 0.6803 - loss: 1.3878 - val_accuracy: 0.4828 - val_loss: 14831.5273 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8948 - loss: 0.3442 - val_accuracy: 0.5172 - val_loss: 543.3107 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9290 - loss: 0.2448 - val_accuracy: 0.5172 - val_loss: 186.9715 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9188 - loss: 0.1818 - val_accuracy: 0.5172 - val_loss: 40.1445 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9538 - loss: 0.1089 - val_accuracy: 0.5172 - val_loss: 25.0545 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9945 - loss: 0.0501 - val_accuracy: 0.4828 - val_loss: 9.1966 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9983 - loss: 0.0276 - val_accuracy: 0.4828 - val_loss: 6.9879 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9901 - loss: 0.0321 - val_accuracy: 0.5862 - val_loss: 3.4000 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9890 - loss: 0.0354 - val_accuracy: 0.6207 - val_loss: 4.4053 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9787 - loss: 0.0649 - val_accuracy: 0.7241 - val_loss: 2.6660 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9620 - loss: 0.0997 - val_accuracy: 0.5172 - val_loss: 8.6096 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9604 - loss: 0.1355 - val_accuracy: 0.7586 - val_loss: 1.8325 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9760 - loss: 0.0591 - val_accuracy: 0.7931 - val_loss: 0.9336 - learning_rate: 0.0100\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9878 - loss: 0.0529 - val_accuracy: 0.7241 - val_loss: 2.0851 - learning_rate: 0.0100\nEpoch 15/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0252 - val_accuracy: 1.0000 - val_loss: 0.0270 - learning_rate: 0.0100\nEpoch 16/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9964 - loss: 0.0176 - val_accuracy: 0.7931 - val_loss: 1.1161 - learning_rate: 0.0100\nEpoch 17/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9914 - loss: 0.0221 - val_accuracy: 1.0000 - val_loss: 0.0236 - learning_rate: 0.0100\nEpoch 18/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9808 - loss: 0.0434 - val_accuracy: 0.8621 - val_loss: 0.6437 - learning_rate: 0.0100\nEpoch 19/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9888 - loss: 0.0280 - val_accuracy: 0.8621 - val_loss: 0.3904 - learning_rate: 0.0100\nEpoch 20/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9826 - loss: 0.0392\nEpoch 20: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9820 - loss: 0.0395 - val_accuracy: 0.8621 - val_loss: 0.3324 - learning_rate: 0.0100\nEpoch 21/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9968 - loss: 0.0078 - val_accuracy: 0.8966 - val_loss: 0.2192 - learning_rate: 1.0000e-03\nEpoch 22/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9931 - loss: 0.0118 - val_accuracy: 0.9310 - val_loss: 0.1293 - learning_rate: 1.0000e-03\nEpoch 22: early stopping\nRestoring model weights from the end of the best epoch: 17.\nFold 7 - Train Accuracy: 98.13%, Validation Accuracy: 100.00%\n\nTraining on Fold 8...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 415ms/step - accuracy: 0.7922 - loss: 0.6227 - val_accuracy: 0.4138 - val_loss: 252.6774 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.9411 - loss: 0.1330 - val_accuracy: 0.4828 - val_loss: 329.9691 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9778 - loss: 0.0476 - val_accuracy: 0.5172 - val_loss: 62.8196 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9916 - loss: 0.0287 - val_accuracy: 0.5172 - val_loss: 18.7114 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9930 - loss: 0.0268 - val_accuracy: 0.6207 - val_loss: 2.8108 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9964 - loss: 0.0113 - val_accuracy: 0.5517 - val_loss: 5.5355 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9931 - loss: 0.0154 - val_accuracy: 0.5517 - val_loss: 3.8799 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0063 - val_accuracy: 0.7931 - val_loss: 1.1057 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0041 - val_accuracy: 0.7241 - val_loss: 2.2098 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.6897 - val_loss: 2.1121 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9925 - loss: 0.0175\nEpoch 11: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9921 - loss: 0.0178 - val_accuracy: 0.8621 - val_loss: 1.9091 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9983 - loss: 0.0139 - val_accuracy: 0.8276 - val_loss: 1.8961 - learning_rate: 1.0000e-03\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9983 - loss: 0.0060 - val_accuracy: 0.8276 - val_loss: 1.8547 - learning_rate: 1.0000e-03\nEpoch 13: early stopping\nRestoring model weights from the end of the best epoch: 8.\nFold 8 - Train Accuracy: 61.80%, Validation Accuracy: 79.31%\n\nTraining on Fold 9...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 417ms/step - accuracy: 0.7600 - loss: 0.8179 - val_accuracy: 0.5172 - val_loss: 677.0947 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9319 - loss: 0.1718 - val_accuracy: 0.5172 - val_loss: 127.7192 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9569 - loss: 0.1074 - val_accuracy: 0.4828 - val_loss: 10.7426 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9724 - loss: 0.0581 - val_accuracy: 0.4828 - val_loss: 5.0490 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9883 - loss: 0.0379 - val_accuracy: 0.4828 - val_loss: 5.2252 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9973 - loss: 0.0191 - val_accuracy: 0.5517 - val_loss: 2.6785 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9854 - loss: 0.0229 - val_accuracy: 0.7931 - val_loss: 1.5825 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9881 - loss: 0.0262 - val_accuracy: 0.7931 - val_loss: 0.7501 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9881 - loss: 0.0306 - val_accuracy: 0.8276 - val_loss: 0.9315 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9932 - loss: 0.0357 - val_accuracy: 0.9310 - val_loss: 0.6435 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9845 - loss: 0.0297 - val_accuracy: 0.8276 - val_loss: 1.0861 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9973 - loss: 0.0149 - val_accuracy: 0.8966 - val_loss: 0.6240 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9960 - loss: 0.0249 - val_accuracy: 0.9310 - val_loss: 0.8474 - learning_rate: 0.0100\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9938 - loss: 0.0103 - val_accuracy: 0.9310 - val_loss: 0.2575 - learning_rate: 0.0100\nEpoch 15/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9969 - loss: 0.0142 - val_accuracy: 0.9310 - val_loss: 0.4247 - learning_rate: 0.0100\nEpoch 16/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9915 - loss: 0.0201 - val_accuracy: 0.9310 - val_loss: 0.2878 - learning_rate: 0.0100\nEpoch 17/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9961 - loss: 0.0073 \nEpoch 17: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9957 - loss: 0.0089 - val_accuracy: 0.9310 - val_loss: 0.4483 - learning_rate: 0.0100\nEpoch 18/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0051 - val_accuracy: 0.9310 - val_loss: 0.3753 - learning_rate: 1.0000e-03\nEpoch 19/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.9655 - val_loss: 0.3142 - learning_rate: 1.0000e-03\nEpoch 19: early stopping\nRestoring model weights from the end of the best epoch: 14.\nFold 9 - Train Accuracy: 98.13%, Validation Accuracy: 93.10%\n\nTraining on Fold 10...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 410ms/step - accuracy: 0.7854 - loss: 0.7082 - val_accuracy: 0.4828 - val_loss: 9705.5928 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.8391 - loss: 0.3779 - val_accuracy: 0.5172 - val_loss: 161.1179 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9239 - loss: 0.1830 - val_accuracy: 0.4828 - val_loss: 76.9329 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9700 - loss: 0.0868 - val_accuracy: 0.5172 - val_loss: 8.8986 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9783 - loss: 0.0718 - val_accuracy: 0.4828 - val_loss: 7.0644 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0244 - val_accuracy: 0.5172 - val_loss: 8.1642 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0130 - val_accuracy: 0.5517 - val_loss: 4.2839 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9898 - loss: 0.0388 - val_accuracy: 0.8621 - val_loss: 1.4607 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9732 - loss: 0.0834 - val_accuracy: 0.7241 - val_loss: 1.8758 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9670 - loss: 0.0889 - val_accuracy: 0.6897 - val_loss: 2.3471 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9859 - loss: 0.0627 - val_accuracy: 0.7586 - val_loss: 1.0156 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9822 - loss: 0.0474 - val_accuracy: 0.8621 - val_loss: 0.2683 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9894 - loss: 0.0499 - val_accuracy: 0.8966 - val_loss: 0.4822 - learning_rate: 0.0100\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9812 - loss: 0.0437 - val_accuracy: 0.9655 - val_loss: 0.4538 - learning_rate: 0.0100\nEpoch 15/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9901 - loss: 0.0343\nEpoch 15: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9899 - loss: 0.0345 - val_accuracy: 0.8966 - val_loss: 0.5675 - learning_rate: 0.0100\nEpoch 16/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9983 - loss: 0.0126 - val_accuracy: 0.9655 - val_loss: 0.1227 - learning_rate: 1.0000e-03\nEpoch 17/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0079 - val_accuracy: 0.9655 - val_loss: 0.0568 - learning_rate: 1.0000e-03\nEpoch 18/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0082 - val_accuracy: 0.9655 - val_loss: 0.0758 - learning_rate: 1.0000e-03\nEpoch 19/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0073 - val_accuracy: 0.9655 - val_loss: 0.0869 - learning_rate: 1.0000e-03\nEpoch 20/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0053\nEpoch 20: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0053 - val_accuracy: 0.9655 - val_loss: 0.0862 - learning_rate: 1.0000e-03\nEpoch 21/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0046 - val_accuracy: 0.9655 - val_loss: 0.0766 - learning_rate: 1.0000e-04\nEpoch 22/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0039 - val_accuracy: 0.9655 - val_loss: 0.0684 - learning_rate: 1.0000e-04\nEpoch 22: early stopping\nRestoring model weights from the end of the best epoch: 17.\nFold 10 - Train Accuracy: 100.00%, Validation Accuracy: 96.55%\n\nAverage Training Accuracy: 93.17%\nAverage Validation Accuracy: 93.90%\n","output_type":"stream"}],"execution_count":92},{"cell_type":"markdown","source":"## 2.2 Rotating 90 degrees","metadata":{}},{"cell_type":"code","source":"X_train_rotated = np.rot90(X_train, k=1, axes=(1,2))\nX_test_rotated = np.rot90(X_test, k=1, axes=(1,2))\n\nX_train_augmented = np.concatenate((X_train, X_train_rotated), axis=0)\ny_train_augmented = np.concatenate((y_train, y_train), axis=0)\n\ntrain_evaluate_model_with_k_fold(\n    X_train=X_train_augmented,\n    y_train=y_train_augmented,\n    lr=0.01,\n    epochs=50,\n    batch_size=16)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T20:12:27.811225Z","iopub.execute_input":"2025-02-07T20:12:27.811503Z","iopub.status.idle":"2025-02-07T20:17:38.216602Z","shell.execute_reply.started":"2025-02-07T20:12:27.811481Z","shell.execute_reply":"2025-02-07T20:17:38.215799Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"\nTraining on Fold 1...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 417ms/step - accuracy: 0.6361 - loss: 1.2447 - val_accuracy: 0.5000 - val_loss: 4839.6313 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8952 - loss: 0.2765 - val_accuracy: 0.5000 - val_loss: 1245.4366 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9409 - loss: 0.1635 - val_accuracy: 0.5000 - val_loss: 204.4291 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9410 - loss: 0.1255 - val_accuracy: 0.5000 - val_loss: 54.3854 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9684 - loss: 0.0888 - val_accuracy: 0.5000 - val_loss: 22.5367 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9722 - loss: 0.0923 - val_accuracy: 0.5333 - val_loss: 13.4147 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9915 - loss: 0.0482 - val_accuracy: 0.7333 - val_loss: 1.8227 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9838 - loss: 0.0417 - val_accuracy: 0.8000 - val_loss: 1.8836 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9828 - loss: 0.0449 - val_accuracy: 0.9667 - val_loss: 0.0355 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9757 - loss: 0.0798 - val_accuracy: 0.8000 - val_loss: 1.1263 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9653 - loss: 0.0690 - val_accuracy: 0.9000 - val_loss: 0.8889 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9856 - loss: 0.0492\nEpoch 12: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9839 - loss: 0.0527 - val_accuracy: 0.9000 - val_loss: 0.5334 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9595 - loss: 0.1061 - val_accuracy: 0.7000 - val_loss: 1.0600 - learning_rate: 1.0000e-03\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9718 - loss: 0.0459 - val_accuracy: 0.8333 - val_loss: 0.5079 - learning_rate: 1.0000e-03\nEpoch 14: early stopping\nRestoring model weights from the end of the best epoch: 9.\nFold 1 - Train Accuracy: 89.85%, Validation Accuracy: 96.67%\n\nTraining on Fold 2...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 417ms/step - accuracy: 0.7120 - loss: 0.9730 - val_accuracy: 0.5000 - val_loss: 1991.7644 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.8461 - loss: 0.3232 - val_accuracy: 0.5000 - val_loss: 292.3757 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9233 - loss: 0.2093 - val_accuracy: 0.5000 - val_loss: 157.4633 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9392 - loss: 0.1256 - val_accuracy: 0.5000 - val_loss: 41.4227 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9580 - loss: 0.0870 - val_accuracy: 0.5667 - val_loss: 11.3872 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9810 - loss: 0.0445 - val_accuracy: 0.5667 - val_loss: 14.0562 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9899 - loss: 0.0279 - val_accuracy: 0.7000 - val_loss: 1.8718 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9648 - loss: 0.0848 - val_accuracy: 0.8333 - val_loss: 1.0863 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9810 - loss: 0.0515 - val_accuracy: 0.9333 - val_loss: 0.0832 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9739 - loss: 0.1116 - val_accuracy: 0.8667 - val_loss: 0.6277 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9482 - loss: 0.1277 - val_accuracy: 0.9667 - val_loss: 0.0526 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9839 - loss: 0.0492 - val_accuracy: 0.9667 - val_loss: 0.0544 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9834 - loss: 0.0485 - val_accuracy: 1.0000 - val_loss: 0.0428 - learning_rate: 0.0100\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9810 - loss: 0.0522 - val_accuracy: 0.9667 - val_loss: 0.1681 - learning_rate: 0.0100\nEpoch 15/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9747 - loss: 0.0528 - val_accuracy: 0.9667 - val_loss: 0.6010 - learning_rate: 0.0100\nEpoch 16/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9956 - loss: 0.0235\nEpoch 16: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9952 - loss: 0.0233 - val_accuracy: 0.9667 - val_loss: 0.2127 - learning_rate: 0.0100\nEpoch 17/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0087 - val_accuracy: 0.9667 - val_loss: 0.2069 - learning_rate: 1.0000e-03\nEpoch 18/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0051 - val_accuracy: 0.9667 - val_loss: 0.2055 - learning_rate: 1.0000e-03\nEpoch 18: early stopping\nRestoring model weights from the end of the best epoch: 13.\nFold 2 - Train Accuracy: 98.12%, Validation Accuracy: 100.00%\n\nTraining on Fold 3...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 414ms/step - accuracy: 0.6849 - loss: 1.0669 - val_accuracy: 0.5000 - val_loss: 1187.1964 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8933 - loss: 0.3032 - val_accuracy: 0.5000 - val_loss: 233.9431 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9563 - loss: 0.1137 - val_accuracy: 0.5000 - val_loss: 73.1968 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9598 - loss: 0.0986 - val_accuracy: 0.5000 - val_loss: 36.9917 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9652 - loss: 0.1139 - val_accuracy: 0.5000 - val_loss: 20.9795 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9783 - loss: 0.0566 - val_accuracy: 0.7333 - val_loss: 3.4409 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9859 - loss: 0.0337 - val_accuracy: 0.6000 - val_loss: 7.8507 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9825 - loss: 0.0628 - val_accuracy: 0.6000 - val_loss: 2.8036 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9904 - loss: 0.0335 - val_accuracy: 0.6333 - val_loss: 7.5293 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9896 - loss: 0.0300 - val_accuracy: 0.7667 - val_loss: 3.1352 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9899 - loss: 0.0406\nEpoch 11: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9898 - loss: 0.0412 - val_accuracy: 0.6333 - val_loss: 4.2462 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9851 - loss: 0.0329 - val_accuracy: 0.7333 - val_loss: 2.5814 - learning_rate: 1.0000e-03\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0122 - val_accuracy: 0.8000 - val_loss: 1.3988 - learning_rate: 1.0000e-03\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9986 - loss: 0.0109 - val_accuracy: 0.8667 - val_loss: 0.8145 - learning_rate: 1.0000e-03\nEpoch 15/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0078 - val_accuracy: 0.9000 - val_loss: 0.4846 - learning_rate: 1.0000e-03\nEpoch 16/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0055 - val_accuracy: 0.9000 - val_loss: 0.2851 - learning_rate: 1.0000e-03\nEpoch 17/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0035 - val_accuracy: 0.9000 - val_loss: 0.1879 - learning_rate: 1.0000e-03\nEpoch 18/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0043 - val_accuracy: 0.9333 - val_loss: 0.1264 - learning_rate: 1.0000e-03\nEpoch 19/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0031 - val_accuracy: 0.9667 - val_loss: 0.0825 - learning_rate: 1.0000e-03\nEpoch 20/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0034 - val_accuracy: 0.9667 - val_loss: 0.0620 - learning_rate: 1.0000e-03\nEpoch 21/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 1.0000 - val_loss: 0.0437 - learning_rate: 1.0000e-03\nEpoch 22/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 1.0000 - val_loss: 0.0285 - learning_rate: 1.0000e-03\nEpoch 23/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9983 - loss: 0.0035 - val_accuracy: 1.0000 - val_loss: 0.0282 - learning_rate: 1.0000e-03\nEpoch 24/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 1.0000 - val_loss: 0.0319 - learning_rate: 1.0000e-03\nEpoch 25/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0053 - val_accuracy: 1.0000 - val_loss: 0.0326 - learning_rate: 1.0000e-03\nEpoch 26/50\n\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0019\nEpoch 26: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 1.0000 - val_loss: 0.0285 - learning_rate: 1.0000e-03\nEpoch 27/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 1.0000 - val_loss: 0.0271 - learning_rate: 1.0000e-04\nEpoch 28/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 1.0000 - val_loss: 0.0257 - learning_rate: 1.0000e-04\nEpoch 29/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 1.0000 - val_loss: 0.0239 - learning_rate: 1.0000e-04\nEpoch 30/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 1.0000 - val_loss: 0.0219 - learning_rate: 1.0000e-04\nEpoch 31/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 1.0000 - val_loss: 0.0215 - learning_rate: 1.0000e-04\nEpoch 32/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 1.0000 - val_loss: 0.0214 - learning_rate: 1.0000e-04\nEpoch 33/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 1.0000 - val_loss: 0.0212 - learning_rate: 1.0000e-04\nEpoch 34/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 1.0000 - val_loss: 0.0210 - learning_rate: 1.0000e-04\nEpoch 35/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 1.0000 - val_loss: 0.0215 - learning_rate: 1.0000e-04\nEpoch 36/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 1.0000 - val_loss: 0.0214 - learning_rate: 1.0000e-04\nEpoch 37/50\n\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0011    \nEpoch 37: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 1.0000 - val_loss: 0.0210 - learning_rate: 1.0000e-04\nEpoch 38/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 1.0000 - val_loss: 0.0209 - learning_rate: 1.0000e-05\nEpoch 39/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 1.0000 - val_loss: 0.0210 - learning_rate: 1.0000e-05\nEpoch 40/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 1.0000 - val_loss: 0.0207 - learning_rate: 1.0000e-05\nEpoch 41/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 1.0000 - val_loss: 0.0203 - learning_rate: 1.0000e-05\nEpoch 42/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 1.0000 - val_loss: 0.0208 - learning_rate: 1.0000e-05\nEpoch 43/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 1.0000 - val_loss: 0.0209 - learning_rate: 1.0000e-05\nEpoch 44/50\n\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0014  \nEpoch 44: ReduceLROnPlateau reducing learning rate to 9.99999883788405e-07.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 1.0000 - val_loss: 0.0208 - learning_rate: 1.0000e-05\nEpoch 45/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 1.0000 - val_loss: 0.0209 - learning_rate: 1.0000e-06\nEpoch 46/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 1.0000 - val_loss: 0.0209 - learning_rate: 1.0000e-06\nEpoch 46: early stopping\nRestoring model weights from the end of the best epoch: 41.\nFold 3 - Train Accuracy: 99.62%, Validation Accuracy: 100.00%\n\nTraining on Fold 4...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 414ms/step - accuracy: 0.6296 - loss: 1.4729 - val_accuracy: 0.5000 - val_loss: 1828.9956 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.8734 - loss: 0.3453 - val_accuracy: 0.5000 - val_loss: 395.3312 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9043 - loss: 0.2053 - val_accuracy: 0.4667 - val_loss: 21.4848 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9421 - loss: 0.1194 - val_accuracy: 0.4667 - val_loss: 9.5101 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9618 - loss: 0.1012 - val_accuracy: 0.5000 - val_loss: 14.7918 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9754 - loss: 0.0642 - val_accuracy: 0.5000 - val_loss: 9.0522 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9609 - loss: 0.0896 - val_accuracy: 0.5000 - val_loss: 6.7473 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9619 - loss: 0.1012 - val_accuracy: 0.5000 - val_loss: 7.4273 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9498 - loss: 0.1262 - val_accuracy: 0.5333 - val_loss: 2.8312 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9479 - loss: 0.1291 - val_accuracy: 0.5667 - val_loss: 2.3945 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9897 - loss: 0.0417 - val_accuracy: 0.6667 - val_loss: 2.7764 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9766 - loss: 0.0512 - val_accuracy: 0.8000 - val_loss: 0.5087 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9621 - loss: 0.0568 - val_accuracy: 0.8333 - val_loss: 0.6599 - learning_rate: 0.0100\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9826 - loss: 0.0531 - val_accuracy: 0.7000 - val_loss: 1.5904 - learning_rate: 0.0100\nEpoch 15/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9689 - loss: 0.0616\nEpoch 15: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9686 - loss: 0.0621 - val_accuracy: 0.8000 - val_loss: 0.8471 - learning_rate: 0.0100\nEpoch 16/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9731 - loss: 0.0648 - val_accuracy: 0.8333 - val_loss: 0.5881 - learning_rate: 1.0000e-03\nEpoch 17/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9791 - loss: 0.0609 - val_accuracy: 0.9333 - val_loss: 0.3583 - learning_rate: 1.0000e-03\nEpoch 18/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9942 - loss: 0.0182 - val_accuracy: 0.9333 - val_loss: 0.2859 - learning_rate: 1.0000e-03\nEpoch 19/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9876 - loss: 0.0258 - val_accuracy: 0.9333 - val_loss: 0.2677 - learning_rate: 1.0000e-03\nEpoch 20/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0127 - val_accuracy: 0.9333 - val_loss: 0.2502 - learning_rate: 1.0000e-03\nEpoch 21/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0133 - val_accuracy: 0.9333 - val_loss: 0.2628 - learning_rate: 1.0000e-03\nEpoch 22/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9996 - loss: 0.0094 - val_accuracy: 0.9333 - val_loss: 0.2519 - learning_rate: 1.0000e-03\nEpoch 23/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0068\nEpoch 23: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0069 - val_accuracy: 0.9333 - val_loss: 0.2771 - learning_rate: 1.0000e-03\nEpoch 24/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0052 - val_accuracy: 0.9333 - val_loss: 0.2549 - learning_rate: 1.0000e-04\nEpoch 25/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0100 - val_accuracy: 0.9333 - val_loss: 0.2358 - learning_rate: 1.0000e-04\nEpoch 26/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0105 - val_accuracy: 0.9333 - val_loss: 0.2153 - learning_rate: 1.0000e-04\nEpoch 27/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0063 - val_accuracy: 0.9333 - val_loss: 0.1977 - learning_rate: 1.0000e-04\nEpoch 28/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0133 - val_accuracy: 0.9333 - val_loss: 0.1837 - learning_rate: 1.0000e-04\nEpoch 29/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0089 - val_accuracy: 0.9333 - val_loss: 0.1695 - learning_rate: 1.0000e-04\nEpoch 30/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0066 - val_accuracy: 0.9333 - val_loss: 0.1531 - learning_rate: 1.0000e-04\nEpoch 31/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0092 - val_accuracy: 0.9333 - val_loss: 0.1401 - learning_rate: 1.0000e-04\nEpoch 32/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0080 - val_accuracy: 0.9333 - val_loss: 0.1251 - learning_rate: 1.0000e-04\nEpoch 33/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0072 - val_accuracy: 0.9333 - val_loss: 0.1170 - learning_rate: 1.0000e-04\nEpoch 34/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0133 - val_accuracy: 0.9333 - val_loss: 0.1132 - learning_rate: 1.0000e-04\nEpoch 35/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0077 - val_accuracy: 0.9333 - val_loss: 0.1072 - learning_rate: 1.0000e-04\nEpoch 36/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0101 - val_accuracy: 0.9333 - val_loss: 0.1052 - learning_rate: 1.0000e-04\nEpoch 37/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0047 - val_accuracy: 0.9667 - val_loss: 0.0985 - learning_rate: 1.0000e-04\nEpoch 38/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0076 - val_accuracy: 0.9667 - val_loss: 0.0917 - learning_rate: 1.0000e-04\nEpoch 39/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0078 - val_accuracy: 0.9667 - val_loss: 0.0854 - learning_rate: 1.0000e-04\nEpoch 40/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0054 - val_accuracy: 0.9667 - val_loss: 0.0815 - learning_rate: 1.0000e-04\nEpoch 41/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0053 - val_accuracy: 0.9667 - val_loss: 0.0798 - learning_rate: 1.0000e-04\nEpoch 42/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0067 - val_accuracy: 0.9667 - val_loss: 0.0769 - learning_rate: 1.0000e-04\nEpoch 43/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0102 - val_accuracy: 0.9667 - val_loss: 0.0745 - learning_rate: 1.0000e-04\nEpoch 44/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0058 - val_accuracy: 0.9667 - val_loss: 0.0715 - learning_rate: 1.0000e-04\nEpoch 45/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0067 - val_accuracy: 0.9667 - val_loss: 0.0689 - learning_rate: 1.0000e-04\nEpoch 46/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0056 - val_accuracy: 0.9667 - val_loss: 0.0682 - learning_rate: 1.0000e-04\nEpoch 47/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0056 - val_accuracy: 0.9667 - val_loss: 0.0676 - learning_rate: 1.0000e-04\nEpoch 48/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0054 - val_accuracy: 0.9667 - val_loss: 0.0653 - learning_rate: 1.0000e-04\nEpoch 49/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9983 - loss: 0.0089 - val_accuracy: 0.9667 - val_loss: 0.0611 - learning_rate: 1.0000e-04\nEpoch 50/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0050 - val_accuracy: 1.0000 - val_loss: 0.0577 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 50.\nFold 4 - Train Accuracy: 100.00%, Validation Accuracy: 100.00%\n\nTraining on Fold 5...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 423ms/step - accuracy: 0.6990 - loss: 1.2446 - val_accuracy: 0.5000 - val_loss: 1237.5651 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9193 - loss: 0.2319 - val_accuracy: 0.5333 - val_loss: 166.1831 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9337 - loss: 0.1625 - val_accuracy: 0.8333 - val_loss: 2.5185 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9600 - loss: 0.1153 - val_accuracy: 0.7333 - val_loss: 3.5519 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9911 - loss: 0.0593 - val_accuracy: 0.5333 - val_loss: 11.6510 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9928 - loss: 0.0556 - val_accuracy: 0.8333 - val_loss: 1.3852 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9489 - loss: 0.0982 - val_accuracy: 0.5333 - val_loss: 2.9601 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9256 - loss: 0.2129 - val_accuracy: 0.5333 - val_loss: 6.8811 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9548 - loss: 0.1226\nEpoch 9: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9560 - loss: 0.1205 - val_accuracy: 0.5333 - val_loss: 6.4764 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9865 - loss: 0.0600 - val_accuracy: 0.5333 - val_loss: 4.7822 - learning_rate: 1.0000e-03\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9964 - loss: 0.0372 - val_accuracy: 0.5667 - val_loss: 3.5388 - learning_rate: 1.0000e-03\nEpoch 11: early stopping\nRestoring model weights from the end of the best epoch: 6.\nFold 5 - Train Accuracy: 77.07%, Validation Accuracy: 83.33%\n\nTraining on Fold 6...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 413ms/step - accuracy: 0.6477 - loss: 1.1049 - val_accuracy: 0.5000 - val_loss: 860.3218 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9055 - loss: 0.2613 - val_accuracy: 0.5000 - val_loss: 438.2376 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9314 - loss: 0.1486 - val_accuracy: 0.5000 - val_loss: 37.5232 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9506 - loss: 0.1304 - val_accuracy: 0.5000 - val_loss: 20.6201 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9799 - loss: 0.0404 - val_accuracy: 0.5000 - val_loss: 14.1708 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9778 - loss: 0.0600 - val_accuracy: 0.5333 - val_loss: 10.0083 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9679 - loss: 0.0678 - val_accuracy: 0.7333 - val_loss: 1.9213 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9675 - loss: 0.1098 - val_accuracy: 0.5667 - val_loss: 4.5591 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9758 - loss: 0.0614 - val_accuracy: 0.7333 - val_loss: 1.9494 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9837 - loss: 0.0804\nEpoch 10: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9838 - loss: 0.0793 - val_accuracy: 0.5333 - val_loss: 5.3460 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9775 - loss: 0.0543 - val_accuracy: 0.5667 - val_loss: 4.1140 - learning_rate: 1.0000e-03\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9934 - loss: 0.0267 - val_accuracy: 0.5667 - val_loss: 3.2218 - learning_rate: 1.0000e-03\nEpoch 12: early stopping\nRestoring model weights from the end of the best epoch: 7.\nFold 6 - Train Accuracy: 75.56%, Validation Accuracy: 73.33%\n\nTraining on Fold 7...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 416ms/step - accuracy: 0.5898 - loss: 1.6001 - val_accuracy: 0.4828 - val_loss: 10373.5908 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8826 - loss: 0.3826 - val_accuracy: 0.4828 - val_loss: 347.1299 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.8908 - loss: 0.3242 - val_accuracy: 0.5172 - val_loss: 59.0188 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9244 - loss: 0.2437 - val_accuracy: 0.6207 - val_loss: 2.6299 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9624 - loss: 0.1577 - val_accuracy: 0.7241 - val_loss: 2.3157 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9587 - loss: 0.1400 - val_accuracy: 0.7586 - val_loss: 1.1810 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9695 - loss: 0.0926 - val_accuracy: 0.7931 - val_loss: 1.1927 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9791 - loss: 0.0606 - val_accuracy: 0.5517 - val_loss: 2.4751 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9570 - loss: 0.0854\nEpoch 9: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9564 - loss: 0.0879 - val_accuracy: 0.6897 - val_loss: 1.3100 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9579 - loss: 0.1240 - val_accuracy: 0.6897 - val_loss: 1.1538 - learning_rate: 1.0000e-03\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9649 - loss: 0.0595 - val_accuracy: 0.6552 - val_loss: 1.1769 - learning_rate: 1.0000e-03\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9968 - loss: 0.0262 - val_accuracy: 0.6552 - val_loss: 1.1874 - learning_rate: 1.0000e-03\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9928 - loss: 0.0225 - val_accuracy: 0.6552 - val_loss: 1.0847 - learning_rate: 1.0000e-03\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9945 - loss: 0.0238 - val_accuracy: 0.6897 - val_loss: 0.8498 - learning_rate: 1.0000e-03\nEpoch 15/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9968 - loss: 0.0196 - val_accuracy: 0.7586 - val_loss: 0.6946 - learning_rate: 1.0000e-03\nEpoch 16/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0189 - val_accuracy: 0.7586 - val_loss: 0.5939 - learning_rate: 1.0000e-03\nEpoch 17/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9949 - loss: 0.0214 - val_accuracy: 0.8621 - val_loss: 0.3781 - learning_rate: 1.0000e-03\nEpoch 18/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0186 - val_accuracy: 0.9310 - val_loss: 0.2531 - learning_rate: 1.0000e-03\nEpoch 19/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9968 - loss: 0.0126 - val_accuracy: 0.9310 - val_loss: 0.2332 - learning_rate: 1.0000e-03\nEpoch 20/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9968 - loss: 0.0149 - val_accuracy: 0.9310 - val_loss: 0.1606 - learning_rate: 1.0000e-03\nEpoch 21/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9977 - loss: 0.0144 - val_accuracy: 0.9655 - val_loss: 0.0758 - learning_rate: 1.0000e-03\nEpoch 22/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0150 - val_accuracy: 0.9655 - val_loss: 0.0643 - learning_rate: 1.0000e-03\nEpoch 23/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0091 - val_accuracy: 1.0000 - val_loss: 0.0451 - learning_rate: 1.0000e-03\nEpoch 24/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9968 - loss: 0.0129 - val_accuracy: 1.0000 - val_loss: 0.0384 - learning_rate: 1.0000e-03\nEpoch 25/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0089 - val_accuracy: 1.0000 - val_loss: 0.0291 - learning_rate: 1.0000e-03\nEpoch 26/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9968 - loss: 0.0128 - val_accuracy: 1.0000 - val_loss: 0.0207 - learning_rate: 1.0000e-03\nEpoch 27/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0084 - val_accuracy: 1.0000 - val_loss: 0.0151 - learning_rate: 1.0000e-03\nEpoch 28/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0111 - val_accuracy: 1.0000 - val_loss: 0.0094 - learning_rate: 1.0000e-03\nEpoch 29/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0055 - val_accuracy: 1.0000 - val_loss: 0.0073 - learning_rate: 1.0000e-03\nEpoch 30/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0076 - val_accuracy: 1.0000 - val_loss: 0.0065 - learning_rate: 1.0000e-03\nEpoch 31/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0063 - val_accuracy: 1.0000 - val_loss: 0.0053 - learning_rate: 1.0000e-03\nEpoch 32/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0082 - val_accuracy: 1.0000 - val_loss: 0.0064 - learning_rate: 1.0000e-03\nEpoch 33/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9968 - loss: 0.0115 - val_accuracy: 1.0000 - val_loss: 0.0115 - learning_rate: 1.0000e-03\nEpoch 34/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0131\nEpoch 34: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0130 - val_accuracy: 1.0000 - val_loss: 0.0053 - learning_rate: 1.0000e-03\nEpoch 35/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0053 - val_accuracy: 1.0000 - val_loss: 0.0050 - learning_rate: 1.0000e-04\nEpoch 36/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0065 - val_accuracy: 1.0000 - val_loss: 0.0050 - learning_rate: 1.0000e-04\nEpoch 37/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9968 - loss: 0.0087 - val_accuracy: 1.0000 - val_loss: 0.0052 - learning_rate: 1.0000e-04\nEpoch 38/50\n\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0052\nEpoch 38: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0055 - val_accuracy: 1.0000 - val_loss: 0.0053 - learning_rate: 1.0000e-04\nEpoch 39/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9968 - loss: 0.0106 - val_accuracy: 1.0000 - val_loss: 0.0052 - learning_rate: 1.0000e-05\nEpoch 40/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9968 - loss: 0.0080 - val_accuracy: 1.0000 - val_loss: 0.0053 - learning_rate: 1.0000e-05\nEpoch 40: early stopping\nRestoring model weights from the end of the best epoch: 35.\nFold 7 - Train Accuracy: 99.25%, Validation Accuracy: 100.00%\n\nTraining on Fold 8...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 414ms/step - accuracy: 0.7072 - loss: 0.9804 - val_accuracy: 0.4828 - val_loss: 8193.0967 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9124 - loss: 0.2735 - val_accuracy: 0.5172 - val_loss: 644.2912 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9527 - loss: 0.1119 - val_accuracy: 0.4483 - val_loss: 63.9924 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9589 - loss: 0.1060 - val_accuracy: 0.7931 - val_loss: 6.9687 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9874 - loss: 0.0366 - val_accuracy: 0.8621 - val_loss: 4.6259 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9567 - loss: 0.1358 - val_accuracy: 0.6207 - val_loss: 4.5336 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9414 - loss: 0.1406 - val_accuracy: 0.8276 - val_loss: 1.7141 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9736 - loss: 0.0643 - val_accuracy: 0.6552 - val_loss: 2.9824 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9814 - loss: 0.0546 - val_accuracy: 0.6897 - val_loss: 4.5087 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9842 - loss: 0.0657 - val_accuracy: 0.9310 - val_loss: 0.8086 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9666 - loss: 0.0834 - val_accuracy: 0.9310 - val_loss: 0.4333 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9980 - loss: 0.0084 - val_accuracy: 0.9655 - val_loss: 0.3347 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9855 - loss: 0.0205 - val_accuracy: 0.9655 - val_loss: 0.5005 - learning_rate: 0.0100\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9973 - loss: 0.0156 - val_accuracy: 0.8276 - val_loss: 1.1050 - learning_rate: 0.0100\nEpoch 15/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0056\nEpoch 15: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9996 - loss: 0.0066 - val_accuracy: 0.8621 - val_loss: 0.5412 - learning_rate: 0.0100\nEpoch 16/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 0.8966 - val_loss: 0.3990 - learning_rate: 1.0000e-03\nEpoch 17/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 0.8966 - val_loss: 0.3695 - learning_rate: 1.0000e-03\nEpoch 17: early stopping\nRestoring model weights from the end of the best epoch: 12.\nFold 8 - Train Accuracy: 92.88%, Validation Accuracy: 96.55%\n\nTraining on Fold 9...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 416ms/step - accuracy: 0.5721 - loss: 1.5033 - val_accuracy: 0.5172 - val_loss: 3025.3999 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8924 - loss: 0.3417 - val_accuracy: 0.5172 - val_loss: 161.9472 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9237 - loss: 0.1983 - val_accuracy: 0.5172 - val_loss: 38.1197 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9469 - loss: 0.1324 - val_accuracy: 0.5862 - val_loss: 12.3559 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9831 - loss: 0.0790 - val_accuracy: 0.5517 - val_loss: 8.9458 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9759 - loss: 0.0534 - val_accuracy: 0.7241 - val_loss: 3.1040 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9799 - loss: 0.0469 - val_accuracy: 0.5517 - val_loss: 8.9332 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9822 - loss: 0.0648 - val_accuracy: 0.6552 - val_loss: 6.1160 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9492 - loss: 0.1287\nEpoch 9: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9465 - loss: 0.1339 - val_accuracy: 0.7241 - val_loss: 3.9218 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9455 - loss: 0.2320 - val_accuracy: 0.8276 - val_loss: 1.0328 - learning_rate: 1.0000e-03\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9795 - loss: 0.1066 - val_accuracy: 0.9310 - val_loss: 0.7175 - learning_rate: 1.0000e-03\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9756 - loss: 0.0567 - val_accuracy: 0.8966 - val_loss: 0.6652 - learning_rate: 1.0000e-03\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9850 - loss: 0.0387 - val_accuracy: 0.8966 - val_loss: 0.6451 - learning_rate: 1.0000e-03\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9822 - loss: 0.0339 - val_accuracy: 0.8966 - val_loss: 0.6418 - learning_rate: 1.0000e-03\nEpoch 15/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9958 - loss: 0.0222 - val_accuracy: 0.9310 - val_loss: 0.5850 - learning_rate: 1.0000e-03\nEpoch 16/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0162 - val_accuracy: 0.9310 - val_loss: 0.5373 - learning_rate: 1.0000e-03\nEpoch 17/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0170 - val_accuracy: 0.9310 - val_loss: 0.5231 - learning_rate: 1.0000e-03\nEpoch 18/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9958 - loss: 0.0150 - val_accuracy: 0.9310 - val_loss: 0.5020 - learning_rate: 1.0000e-03\nEpoch 19/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9958 - loss: 0.0135 - val_accuracy: 0.9310 - val_loss: 0.4708 - learning_rate: 1.0000e-03\nEpoch 20/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9958 - loss: 0.0183 - val_accuracy: 0.9310 - val_loss: 0.4544 - learning_rate: 1.0000e-03\nEpoch 21/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0104 - val_accuracy: 0.9310 - val_loss: 0.4566 - learning_rate: 1.0000e-03\nEpoch 22/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9973 - loss: 0.0100 - val_accuracy: 0.9310 - val_loss: 0.4545 - learning_rate: 1.0000e-03\nEpoch 23/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0079 - val_accuracy: 0.9310 - val_loss: 0.4300 - learning_rate: 1.0000e-03\nEpoch 24/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0100 - val_accuracy: 0.9310 - val_loss: 0.4238 - learning_rate: 1.0000e-03\nEpoch 25/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0105 - val_accuracy: 0.9310 - val_loss: 0.3762 - learning_rate: 1.0000e-03\nEpoch 26/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0115 - val_accuracy: 0.9310 - val_loss: 0.3618 - learning_rate: 1.0000e-03\nEpoch 27/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0073 - val_accuracy: 0.9310 - val_loss: 0.3403 - learning_rate: 1.0000e-03\nEpoch 28/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0071 - val_accuracy: 0.9655 - val_loss: 0.3309 - learning_rate: 1.0000e-03\nEpoch 29/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0074 - val_accuracy: 0.9655 - val_loss: 0.3258 - learning_rate: 1.0000e-03\nEpoch 30/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0077 - val_accuracy: 0.9655 - val_loss: 0.3347 - learning_rate: 1.0000e-03\nEpoch 31/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0097 - val_accuracy: 0.9655 - val_loss: 0.3370 - learning_rate: 1.0000e-03\nEpoch 32/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0054 \nEpoch 32: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0056 - val_accuracy: 0.9655 - val_loss: 0.3326 - learning_rate: 1.0000e-03\nEpoch 33/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0061 - val_accuracy: 0.9655 - val_loss: 0.3273 - learning_rate: 1.0000e-04\nEpoch 34/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0044 - val_accuracy: 0.9655 - val_loss: 0.3234 - learning_rate: 1.0000e-04\nEpoch 35/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0042 - val_accuracy: 0.9655 - val_loss: 0.3207 - learning_rate: 1.0000e-04\nEpoch 36/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0075 - val_accuracy: 0.9655 - val_loss: 0.3196 - learning_rate: 1.0000e-04\nEpoch 37/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0055 - val_accuracy: 0.9655 - val_loss: 0.3169 - learning_rate: 1.0000e-04\nEpoch 38/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0045 - val_accuracy: 0.9655 - val_loss: 0.3138 - learning_rate: 1.0000e-04\nEpoch 39/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0045 - val_accuracy: 0.9655 - val_loss: 0.3130 - learning_rate: 1.0000e-04\nEpoch 40/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0072 - val_accuracy: 0.9655 - val_loss: 0.3127 - learning_rate: 1.0000e-04\nEpoch 41/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0032 - val_accuracy: 0.9655 - val_loss: 0.3125 - learning_rate: 1.0000e-04\nEpoch 42/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0062 - val_accuracy: 0.9655 - val_loss: 0.3144 - learning_rate: 1.0000e-04\nEpoch 43/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0055 - val_accuracy: 0.9655 - val_loss: 0.3157 - learning_rate: 1.0000e-04\nEpoch 44/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0053\nEpoch 44: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0056 - val_accuracy: 0.9655 - val_loss: 0.3131 - learning_rate: 1.0000e-04\nEpoch 45/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0041 - val_accuracy: 0.9655 - val_loss: 0.3120 - learning_rate: 1.0000e-05\nEpoch 46/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0042 - val_accuracy: 0.9655 - val_loss: 0.3123 - learning_rate: 1.0000e-05\nEpoch 47/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0060 - val_accuracy: 0.9655 - val_loss: 0.3108 - learning_rate: 1.0000e-05\nEpoch 48/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0041 - val_accuracy: 0.9655 - val_loss: 0.3117 - learning_rate: 1.0000e-05\nEpoch 49/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0054 - val_accuracy: 0.9655 - val_loss: 0.3113 - learning_rate: 1.0000e-05\nEpoch 50/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0027 \nEpoch 50: ReduceLROnPlateau reducing learning rate to 9.99999883788405e-07.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0030 - val_accuracy: 0.9655 - val_loss: 0.3111 - learning_rate: 1.0000e-05\nRestoring model weights from the end of the best epoch: 47.\nFold 9 - Train Accuracy: 100.00%, Validation Accuracy: 96.55%\n\nTraining on Fold 10...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 413ms/step - accuracy: 0.6130 - loss: 1.4028 - val_accuracy: 0.7241 - val_loss: 95.1961 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.8083 - loss: 0.4206 - val_accuracy: 0.4828 - val_loss: 1321.4591 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.8511 - loss: 0.3517 - val_accuracy: 0.4828 - val_loss: 90.4384 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9239 - loss: 0.1801 - val_accuracy: 0.5517 - val_loss: 7.5313 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9887 - loss: 0.0725 - val_accuracy: 0.4828 - val_loss: 8.6257 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9699 - loss: 0.0923 - val_accuracy: 0.4828 - val_loss: 5.7382 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9813 - loss: 0.0677 - val_accuracy: 0.6897 - val_loss: 2.3627 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9643 - loss: 0.0556 - val_accuracy: 0.5517 - val_loss: 3.4337 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9759 - loss: 0.0595 - val_accuracy: 0.7931 - val_loss: 1.7641 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9903 - loss: 0.0384 - val_accuracy: 0.8276 - val_loss: 1.0378 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9854 - loss: 0.0462 - val_accuracy: 0.8621 - val_loss: 0.5456 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0152 - val_accuracy: 0.8966 - val_loss: 0.4788 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0102 - val_accuracy: 0.8621 - val_loss: 0.5906 - learning_rate: 0.0100\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9973 - loss: 0.0098 - val_accuracy: 0.8966 - val_loss: 0.7417 - learning_rate: 0.0100\nEpoch 15/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0056\nEpoch 15: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0059 - val_accuracy: 0.7931 - val_loss: 1.4301 - learning_rate: 0.0100\nEpoch 16/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9986 - loss: 0.0072 - val_accuracy: 0.7931 - val_loss: 1.5227 - learning_rate: 1.0000e-03\nEpoch 17/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0053 - val_accuracy: 0.7931 - val_loss: 1.3540 - learning_rate: 1.0000e-03\nEpoch 17: early stopping\nRestoring model weights from the end of the best epoch: 12.\nFold 10 - Train Accuracy: 93.26%, Validation Accuracy: 89.66%\n\nAverage Training Accuracy: 92.56%\nAverage Validation Accuracy: 93.61%\n","output_type":"stream"}],"execution_count":93},{"cell_type":"markdown","source":"## 2.3 Rotating 180 degrees","metadata":{}},{"cell_type":"code","source":"X_train_rotated = np.rot180(X_train, k=2, axes=(1,2))\nX_test_rotated = np.rot180(X_test, k=2, axes=(1,2))\n\nX_train_augmented = np.concatenate((X_train, X_train_rotated), axis=0)\ny_train_augmented = np.concatenate((y_train, y_train), axis=0)\n\ntrain_evaluate_model_with_k_fold(\n    X_train=X_train_augmented,\n    y_train=y_train_augmented,\n    lr=0.01,\n    epochs=50,\n    batch_size=16)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T20:17:38.218503Z","iopub.execute_input":"2025-02-07T20:17:38.218730Z","iopub.status.idle":"2025-02-07T20:22:13.503580Z","shell.execute_reply.started":"2025-02-07T20:17:38.218711Z","shell.execute_reply":"2025-02-07T20:22:13.502774Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"\nTraining on Fold 1...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 417ms/step - accuracy: 0.7017 - loss: 1.0316 - val_accuracy: 0.5000 - val_loss: 5975.9946 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8575 - loss: 0.3144 - val_accuracy: 0.5000 - val_loss: 455.1063 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9435 - loss: 0.1664 - val_accuracy: 0.4333 - val_loss: 28.0014 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9273 - loss: 0.1367 - val_accuracy: 0.5000 - val_loss: 33.0817 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9306 - loss: 0.1428 - val_accuracy: 0.5000 - val_loss: 5.3856 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9832 - loss: 0.0499 - val_accuracy: 0.5333 - val_loss: 5.0419 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9804 - loss: 0.0385 - val_accuracy: 0.6000 - val_loss: 2.5874 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9908 - loss: 0.0273 - val_accuracy: 0.6333 - val_loss: 2.2090 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9973 - loss: 0.0205 - val_accuracy: 0.5333 - val_loss: 5.4682 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9903 - loss: 0.0513 - val_accuracy: 0.9000 - val_loss: 0.4326 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9742 - loss: 0.0478 - val_accuracy: 0.8667 - val_loss: 0.5168 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9863 - loss: 0.0452 - val_accuracy: 0.8667 - val_loss: 0.4239 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9888 - loss: 0.0562 - val_accuracy: 0.7667 - val_loss: 1.4342 - learning_rate: 0.0100\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9931 - loss: 0.0382 - val_accuracy: 0.5333 - val_loss: 9.0806 - learning_rate: 0.0100\nEpoch 15/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9916 - loss: 0.0320\nEpoch 15: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9917 - loss: 0.0331 - val_accuracy: 0.8333 - val_loss: 0.9574 - learning_rate: 0.0100\nEpoch 16/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9836 - loss: 0.0916 - val_accuracy: 0.8667 - val_loss: 0.2261 - learning_rate: 1.0000e-03\nEpoch 17/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9921 - loss: 0.0177 - val_accuracy: 0.9333 - val_loss: 0.1592 - learning_rate: 1.0000e-03\nEpoch 18/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0061 - val_accuracy: 0.9333 - val_loss: 0.1928 - learning_rate: 1.0000e-03\nEpoch 19/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0056 - val_accuracy: 0.9333 - val_loss: 0.2137 - learning_rate: 1.0000e-03\nEpoch 20/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0072\nEpoch 20: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0071 - val_accuracy: 0.9333 - val_loss: 0.2270 - learning_rate: 1.0000e-03\nEpoch 21/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0050 - val_accuracy: 0.9333 - val_loss: 0.2305 - learning_rate: 1.0000e-04\nEpoch 22/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0046 - val_accuracy: 0.9333 - val_loss: 0.2319 - learning_rate: 1.0000e-04\nEpoch 22: early stopping\nRestoring model weights from the end of the best epoch: 17.\nFold 1 - Train Accuracy: 96.99%, Validation Accuracy: 93.33%\n\nTraining on Fold 2...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 418ms/step - accuracy: 0.7745 - loss: 0.9139 - val_accuracy: 0.5000 - val_loss: 4913.1577 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.8492 - loss: 0.4177 - val_accuracy: 0.5000 - val_loss: 338.0827 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9464 - loss: 0.1657 - val_accuracy: 0.5000 - val_loss: 64.9230 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9775 - loss: 0.0927 - val_accuracy: 0.5000 - val_loss: 23.5754 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9717 - loss: 0.1017 - val_accuracy: 0.5000 - val_loss: 8.9480 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9865 - loss: 0.0536 - val_accuracy: 0.5333 - val_loss: 3.2759 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9916 - loss: 0.0325 - val_accuracy: 0.5000 - val_loss: 2.9125 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9902 - loss: 0.0299 - val_accuracy: 0.6333 - val_loss: 1.7526 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9964 - loss: 0.0155 - val_accuracy: 0.7000 - val_loss: 0.9210 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9919 - loss: 0.0208 - val_accuracy: 0.8000 - val_loss: 0.7837 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9824 - loss: 0.0395 - val_accuracy: 0.8667 - val_loss: 0.5440 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9738 - loss: 0.0673 - val_accuracy: 0.9333 - val_loss: 0.2188 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9858 - loss: 0.0407 - val_accuracy: 0.9667 - val_loss: 0.0528 - learning_rate: 0.0100\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9951 - loss: 0.0144 - val_accuracy: 1.0000 - val_loss: 0.0184 - learning_rate: 0.0100\nEpoch 15/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9975 - loss: 0.0092 - val_accuracy: 0.8667 - val_loss: 0.9539 - learning_rate: 0.0100\nEpoch 16/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9884 - loss: 0.0339 - val_accuracy: 0.8333 - val_loss: 0.6116 - learning_rate: 0.0100\nEpoch 17/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9686 - loss: 0.0941\nEpoch 17: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9675 - loss: 0.0972 - val_accuracy: 0.9333 - val_loss: 0.1411 - learning_rate: 0.0100\nEpoch 18/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9973 - loss: 0.0092 - val_accuracy: 0.9333 - val_loss: 0.0907 - learning_rate: 1.0000e-03\nEpoch 19/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9989 - loss: 0.0111 - val_accuracy: 0.9667 - val_loss: 0.0657 - learning_rate: 1.0000e-03\nEpoch 19: early stopping\nRestoring model weights from the end of the best epoch: 14.\nFold 2 - Train Accuracy: 90.98%, Validation Accuracy: 100.00%\n\nTraining on Fold 3...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 418ms/step - accuracy: 0.6891 - loss: 1.2126 - val_accuracy: 0.5000 - val_loss: 1655.2473 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8898 - loss: 0.2520 - val_accuracy: 0.5000 - val_loss: 239.2184 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9374 - loss: 0.1527 - val_accuracy: 0.5000 - val_loss: 59.6500 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9541 - loss: 0.1097 - val_accuracy: 0.5000 - val_loss: 26.0393 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9825 - loss: 0.0588 - val_accuracy: 0.5000 - val_loss: 17.2025 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9650 - loss: 0.0672 - val_accuracy: 0.5000 - val_loss: 8.5182 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9883 - loss: 0.0326 - val_accuracy: 0.8667 - val_loss: 1.0574 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9931 - loss: 0.0200 - val_accuracy: 0.9000 - val_loss: 1.3575 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9989 - loss: 0.0139 - val_accuracy: 0.7333 - val_loss: 1.8257 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9931 - loss: 0.0206 - val_accuracy: 0.9333 - val_loss: 0.8123 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9931 - loss: 0.0127 - val_accuracy: 0.8667 - val_loss: 1.1304 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9926 - loss: 0.0142 - val_accuracy: 0.7667 - val_loss: 2.1009 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9628 - loss: 0.0786 - val_accuracy: 1.0000 - val_loss: 0.0690 - learning_rate: 0.0100\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9335 - loss: 0.2664 - val_accuracy: 0.8333 - val_loss: 1.0223 - learning_rate: 0.0100\nEpoch 15/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9027 - loss: 0.2044 - val_accuracy: 0.9000 - val_loss: 0.8098 - learning_rate: 0.0100\nEpoch 16/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9458 - loss: 0.1195\nEpoch 16: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9472 - loss: 0.1167 - val_accuracy: 0.8667 - val_loss: 0.5661 - learning_rate: 0.0100\nEpoch 17/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9823 - loss: 0.0547 - val_accuracy: 0.9667 - val_loss: 0.2243 - learning_rate: 1.0000e-03\nEpoch 18/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9956 - loss: 0.0246 - val_accuracy: 0.9667 - val_loss: 0.1395 - learning_rate: 1.0000e-03\nEpoch 18: early stopping\nRestoring model weights from the end of the best epoch: 13.\nFold 3 - Train Accuracy: 86.09%, Validation Accuracy: 100.00%\n\nTraining on Fold 4...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 430ms/step - accuracy: 0.6960 - loss: 1.0019 - val_accuracy: 0.5000 - val_loss: 4317.1206 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.8996 - loss: 0.2990 - val_accuracy: 0.5000 - val_loss: 254.5440 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9215 - loss: 0.1582 - val_accuracy: 0.5000 - val_loss: 85.3654 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9441 - loss: 0.1239 - val_accuracy: 0.5000 - val_loss: 26.6385 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9584 - loss: 0.1286 - val_accuracy: 0.4667 - val_loss: 5.1537 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9745 - loss: 0.0950 - val_accuracy: 0.5000 - val_loss: 2.9723 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9878 - loss: 0.0515 - val_accuracy: 0.6667 - val_loss: 2.4927 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9972 - loss: 0.0428 - val_accuracy: 0.7000 - val_loss: 2.5103 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9711 - loss: 0.0701 - val_accuracy: 0.5000 - val_loss: 11.0729 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9394 - loss: 0.1779\nEpoch 10: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9413 - loss: 0.1710 - val_accuracy: 0.5000 - val_loss: 11.6218 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9675 - loss: 0.0797 - val_accuracy: 0.5333 - val_loss: 5.1762 - learning_rate: 1.0000e-03\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9855 - loss: 0.0562 - val_accuracy: 0.6333 - val_loss: 2.7255 - learning_rate: 1.0000e-03\nEpoch 12: early stopping\nRestoring model weights from the end of the best epoch: 7.\nFold 4 - Train Accuracy: 80.83%, Validation Accuracy: 66.67%\n\nTraining on Fold 5...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 419ms/step - accuracy: 0.7561 - loss: 0.9836 - val_accuracy: 0.5000 - val_loss: 8473.5664 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.8749 - loss: 0.3450 - val_accuracy: 0.5000 - val_loss: 491.8939 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9264 - loss: 0.1714 - val_accuracy: 0.5000 - val_loss: 281.4154 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9383 - loss: 0.1451 - val_accuracy: 0.5333 - val_loss: 52.4922 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9656 - loss: 0.0777 - val_accuracy: 0.4667 - val_loss: 10.5211 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9603 - loss: 0.0904 - val_accuracy: 0.5333 - val_loss: 17.2013 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9734 - loss: 0.0786 - val_accuracy: 0.5333 - val_loss: 2.3541 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9661 - loss: 0.0890 - val_accuracy: 0.5333 - val_loss: 13.0870 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9598 - loss: 0.0858 - val_accuracy: 0.6000 - val_loss: 6.7072 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9854 - loss: 0.0803 - val_accuracy: 0.8333 - val_loss: 0.7276 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9746 - loss: 0.0723 - val_accuracy: 0.8333 - val_loss: 1.2553 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9859 - loss: 0.0354 - val_accuracy: 1.0000 - val_loss: 0.0193 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9884 - loss: 0.0219 - val_accuracy: 1.0000 - val_loss: 0.0205 - learning_rate: 0.0100\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9994 - loss: 0.0164 - val_accuracy: 1.0000 - val_loss: 0.0045 - learning_rate: 0.0100\nEpoch 15/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9867 - loss: 0.0176 - val_accuracy: 0.9333 - val_loss: 0.4204 - learning_rate: 0.0100\nEpoch 16/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9696 - loss: 0.0725 - val_accuracy: 0.9667 - val_loss: 0.1100 - learning_rate: 0.0100\nEpoch 17/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9821 - loss: 0.0422\nEpoch 17: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9828 - loss: 0.0440 - val_accuracy: 0.9000 - val_loss: 0.3681 - learning_rate: 0.0100\nEpoch 18/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9888 - loss: 0.0254 - val_accuracy: 0.9333 - val_loss: 0.2652 - learning_rate: 1.0000e-03\nEpoch 19/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0039 - val_accuracy: 0.9333 - val_loss: 0.2003 - learning_rate: 1.0000e-03\nEpoch 19: early stopping\nRestoring model weights from the end of the best epoch: 14.\nFold 5 - Train Accuracy: 99.62%, Validation Accuracy: 100.00%\n\nTraining on Fold 6...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 413ms/step - accuracy: 0.7141 - loss: 0.8669 - val_accuracy: 0.5000 - val_loss: 3943.4517 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9002 - loss: 0.2789 - val_accuracy: 0.5000 - val_loss: 463.0600 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9200 - loss: 0.1524 - val_accuracy: 0.5000 - val_loss: 78.2061 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9669 - loss: 0.0886 - val_accuracy: 0.5000 - val_loss: 26.8919 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9850 - loss: 0.0573 - val_accuracy: 0.5333 - val_loss: 13.8055 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9811 - loss: 0.0620 - val_accuracy: 0.5000 - val_loss: 11.0175 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9458 - loss: 0.1246 - val_accuracy: 0.4667 - val_loss: 3.5129 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9656 - loss: 0.0952 - val_accuracy: 0.6667 - val_loss: 1.8429 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9830 - loss: 0.0702 - val_accuracy: 0.7000 - val_loss: 1.0742 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9941 - loss: 0.0260 - val_accuracy: 0.6667 - val_loss: 1.8015 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9862 - loss: 0.0206 - val_accuracy: 0.5667 - val_loss: 3.8432 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9828 - loss: 0.0613\nEpoch 12: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9830 - loss: 0.0595 - val_accuracy: 0.7000 - val_loss: 1.6844 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9839 - loss: 0.0192 - val_accuracy: 0.7000 - val_loss: 1.6471 - learning_rate: 1.0000e-03\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9983 - loss: 0.0057 - val_accuracy: 0.7000 - val_loss: 1.5585 - learning_rate: 1.0000e-03\nEpoch 14: early stopping\nRestoring model weights from the end of the best epoch: 9.\nFold 6 - Train Accuracy: 78.95%, Validation Accuracy: 70.00%\n\nTraining on Fold 7...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 418ms/step - accuracy: 0.6302 - loss: 1.4685 - val_accuracy: 0.4828 - val_loss: 5349.1885 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.8932 - loss: 0.3364 - val_accuracy: 0.5172 - val_loss: 348.2767 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9180 - loss: 0.2161 - val_accuracy: 0.5172 - val_loss: 65.4382 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9565 - loss: 0.1370 - val_accuracy: 0.5172 - val_loss: 38.4636 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9627 - loss: 0.0840 - val_accuracy: 0.5172 - val_loss: 3.8232 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9860 - loss: 0.0491 - val_accuracy: 0.5862 - val_loss: 1.5536 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9863 - loss: 0.0497 - val_accuracy: 0.5172 - val_loss: 1.3828 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9772 - loss: 0.0435 - val_accuracy: 0.5172 - val_loss: 4.9311 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9608 - loss: 0.1404 - val_accuracy: 0.6897 - val_loss: 1.6888 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9821 - loss: 0.0536 - val_accuracy: 0.8966 - val_loss: 0.7962 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9912 - loss: 0.0355 - val_accuracy: 0.6552 - val_loss: 2.2326 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9696 - loss: 0.0904 - val_accuracy: 0.8621 - val_loss: 0.7121 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9945 - loss: 0.0232 - val_accuracy: 0.7931 - val_loss: 1.2963 - learning_rate: 0.0100\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9994 - loss: 0.0201 - val_accuracy: 0.8966 - val_loss: 0.3900 - learning_rate: 0.0100\nEpoch 15/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0063 - val_accuracy: 0.8966 - val_loss: 0.3009 - learning_rate: 0.0100\nEpoch 16/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9930 - loss: 0.0171 - val_accuracy: 0.9655 - val_loss: 0.2858 - learning_rate: 0.0100\nEpoch 17/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9898 - loss: 0.0548 - val_accuracy: 0.9310 - val_loss: 0.1752 - learning_rate: 0.0100\nEpoch 18/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9800 - loss: 0.0743 - val_accuracy: 0.7931 - val_loss: 0.5794 - learning_rate: 0.0100\nEpoch 19/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9655 - loss: 0.0800 - val_accuracy: 0.9655 - val_loss: 0.1482 - learning_rate: 0.0100\nEpoch 20/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9721 - loss: 0.0635 - val_accuracy: 0.8621 - val_loss: 0.3304 - learning_rate: 0.0100\nEpoch 21/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9949 - loss: 0.0341 - val_accuracy: 0.9655 - val_loss: 0.1621 - learning_rate: 0.0100\nEpoch 22/50\n\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9964 - loss: 0.0167\nEpoch 22: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9964 - loss: 0.0172 - val_accuracy: 0.9310 - val_loss: 0.3409 - learning_rate: 0.0100\nEpoch 23/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9937 - loss: 0.0128 - val_accuracy: 0.9310 - val_loss: 0.2348 - learning_rate: 1.0000e-03\nEpoch 24/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9968 - loss: 0.0070 - val_accuracy: 0.8966 - val_loss: 0.1663 - learning_rate: 1.0000e-03\nEpoch 24: early stopping\nRestoring model weights from the end of the best epoch: 19.\nFold 7 - Train Accuracy: 96.63%, Validation Accuracy: 96.55%\n\nTraining on Fold 8...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 418ms/step - accuracy: 0.7429 - loss: 0.8838 - val_accuracy: 0.5172 - val_loss: 5825.9980 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.8936 - loss: 0.2312 - val_accuracy: 0.5172 - val_loss: 832.8497 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9421 - loss: 0.1480 - val_accuracy: 0.5172 - val_loss: 187.0098 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9684 - loss: 0.0676 - val_accuracy: 0.5172 - val_loss: 43.6305 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9915 - loss: 0.0326 - val_accuracy: 0.5172 - val_loss: 24.1279 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9950 - loss: 0.0273 - val_accuracy: 0.5517 - val_loss: 3.4707 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9882 - loss: 0.0333 - val_accuracy: 0.7241 - val_loss: 1.4773 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9845 - loss: 0.0453 - val_accuracy: 0.8276 - val_loss: 0.8537 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9820 - loss: 0.0596 - val_accuracy: 0.8621 - val_loss: 0.6129 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9819 - loss: 0.0572 - val_accuracy: 0.9310 - val_loss: 0.2385 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9749 - loss: 0.0796 - val_accuracy: 0.9310 - val_loss: 0.2174 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9977 - loss: 0.0159 - val_accuracy: 0.9655 - val_loss: 0.2459 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0187 - val_accuracy: 0.9655 - val_loss: 0.1548 - learning_rate: 0.0100\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0055 - val_accuracy: 0.9655 - val_loss: 0.1671 - learning_rate: 0.0100\nEpoch 15/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.9655 - val_loss: 0.2178 - learning_rate: 0.0100\nEpoch 16/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0015\nEpoch 16: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.9655 - val_loss: 0.2625 - learning_rate: 0.0100\nEpoch 17/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 6.8367e-04 - val_accuracy: 0.9655 - val_loss: 0.2706 - learning_rate: 1.0000e-03\nEpoch 18/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 8.6171e-04 - val_accuracy: 0.9655 - val_loss: 0.2703 - learning_rate: 1.0000e-03\nEpoch 18: early stopping\nRestoring model weights from the end of the best epoch: 13.\nFold 8 - Train Accuracy: 98.50%, Validation Accuracy: 96.55%\n\nTraining on Fold 9...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 409ms/step - accuracy: 0.6063 - loss: 1.3037 - val_accuracy: 0.5172 - val_loss: 4996.6655 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.8051 - loss: 0.3553 - val_accuracy: 0.4828 - val_loss: 163.2422 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9247 - loss: 0.1704 - val_accuracy: 0.4138 - val_loss: 40.9846 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9419 - loss: 0.1074 - val_accuracy: 0.6552 - val_loss: 9.7892 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9707 - loss: 0.0686 - val_accuracy: 0.4828 - val_loss: 27.5898 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9632 - loss: 0.1230 - val_accuracy: 0.6552 - val_loss: 1.8125 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9677 - loss: 0.0734 - val_accuracy: 0.6552 - val_loss: 5.7218 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9779 - loss: 0.0756 - val_accuracy: 0.7931 - val_loss: 1.4274 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9899 - loss: 0.0324 - val_accuracy: 0.8276 - val_loss: 1.4482 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9899 - loss: 0.0564 - val_accuracy: 0.9655 - val_loss: 0.4591 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9918 - loss: 0.0233 - val_accuracy: 0.9655 - val_loss: 0.7949 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9912 - loss: 0.0509 - val_accuracy: 0.8621 - val_loss: 0.8275 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9998 - loss: 0.0206\nEpoch 13: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9990 - loss: 0.0242 - val_accuracy: 0.9655 - val_loss: 0.6080 - learning_rate: 0.0100\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0137 - val_accuracy: 0.9655 - val_loss: 0.5542 - learning_rate: 1.0000e-03\nEpoch 15/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0085 - val_accuracy: 0.9655 - val_loss: 0.5096 - learning_rate: 1.0000e-03\nEpoch 15: early stopping\nRestoring model weights from the end of the best epoch: 10.\nFold 9 - Train Accuracy: 88.39%, Validation Accuracy: 96.55%\n\nTraining on Fold 10...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 419ms/step - accuracy: 0.6692 - loss: 0.9942 - val_accuracy: 0.5172 - val_loss: 2904.0464 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8662 - loss: 0.3959 - val_accuracy: 0.4828 - val_loss: 1011.5618 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9209 - loss: 0.2046 - val_accuracy: 0.4483 - val_loss: 16.3471 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9213 - loss: 0.1679 - val_accuracy: 0.3448 - val_loss: 15.2019 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9644 - loss: 0.0967 - val_accuracy: 0.4828 - val_loss: 7.3115 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9662 - loss: 0.0684 - val_accuracy: 0.6897 - val_loss: 4.4162 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9775 - loss: 0.0509 - val_accuracy: 0.7931 - val_loss: 1.5238 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9724 - loss: 0.0864 - val_accuracy: 0.7931 - val_loss: 2.0232 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9793 - loss: 0.0695 - val_accuracy: 0.8621 - val_loss: 1.8078 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9811 - loss: 0.0546\nEpoch 10: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9792 - loss: 0.0568 - val_accuracy: 0.8621 - val_loss: 1.6269 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0145 - val_accuracy: 0.8966 - val_loss: 1.2092 - learning_rate: 1.0000e-03\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0160 - val_accuracy: 0.8966 - val_loss: 1.0179 - learning_rate: 1.0000e-03\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9809 - loss: 0.0263 - val_accuracy: 0.8966 - val_loss: 0.8760 - learning_rate: 1.0000e-03\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9994 - loss: 0.0109 - val_accuracy: 0.8621 - val_loss: 0.7786 - learning_rate: 1.0000e-03\nEpoch 15/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0111 - val_accuracy: 0.8621 - val_loss: 0.7188 - learning_rate: 1.0000e-03\nEpoch 16/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9973 - loss: 0.0121 - val_accuracy: 0.8966 - val_loss: 0.6476 - learning_rate: 1.0000e-03\nEpoch 17/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0093 - val_accuracy: 0.8966 - val_loss: 0.6301 - learning_rate: 1.0000e-03\nEpoch 18/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0088 - val_accuracy: 0.8966 - val_loss: 0.6158 - learning_rate: 1.0000e-03\nEpoch 19/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0071 - val_accuracy: 0.8621 - val_loss: 0.5958 - learning_rate: 1.0000e-03\nEpoch 20/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0092 - val_accuracy: 0.8621 - val_loss: 0.5453 - learning_rate: 1.0000e-03\nEpoch 21/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0061 - val_accuracy: 0.8621 - val_loss: 0.4788 - learning_rate: 1.0000e-03\nEpoch 22/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0061 - val_accuracy: 0.8621 - val_loss: 0.4491 - learning_rate: 1.0000e-03\nEpoch 23/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0044 - val_accuracy: 0.8621 - val_loss: 0.4373 - learning_rate: 1.0000e-03\nEpoch 24/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0072 - val_accuracy: 0.8966 - val_loss: 0.4147 - learning_rate: 1.0000e-03\nEpoch 25/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0046 - val_accuracy: 0.8966 - val_loss: 0.4058 - learning_rate: 1.0000e-03\nEpoch 26/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0038 - val_accuracy: 0.8621 - val_loss: 0.4067 - learning_rate: 1.0000e-03\nEpoch 27/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0056 - val_accuracy: 0.8966 - val_loss: 0.3939 - learning_rate: 1.0000e-03\nEpoch 28/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0036 - val_accuracy: 0.8966 - val_loss: 0.3840 - learning_rate: 1.0000e-03\nEpoch 29/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0053 - val_accuracy: 0.8966 - val_loss: 0.3617 - learning_rate: 1.0000e-03\nEpoch 30/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0043 - val_accuracy: 0.8966 - val_loss: 0.3397 - learning_rate: 1.0000e-03\nEpoch 31/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0051 - val_accuracy: 0.9310 - val_loss: 0.3346 - learning_rate: 1.0000e-03\nEpoch 32/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.9310 - val_loss: 0.3313 - learning_rate: 1.0000e-03\nEpoch 33/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 0.9310 - val_loss: 0.3338 - learning_rate: 1.0000e-03\nEpoch 34/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 0.9310 - val_loss: 0.3431 - learning_rate: 1.0000e-03\nEpoch 35/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9998 - loss: 0.0033\nEpoch 35: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9994 - loss: 0.0039 - val_accuracy: 0.9310 - val_loss: 0.3466 - learning_rate: 1.0000e-03\nEpoch 36/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0023 - val_accuracy: 0.9310 - val_loss: 0.3444 - learning_rate: 1.0000e-04\nEpoch 37/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.9310 - val_loss: 0.3418 - learning_rate: 1.0000e-04\nEpoch 37: early stopping\nRestoring model weights from the end of the best epoch: 32.\nFold 10 - Train Accuracy: 98.50%, Validation Accuracy: 93.10%\n\nAverage Training Accuracy: 91.55%\nAverage Validation Accuracy: 91.28%\n","output_type":"stream"}],"execution_count":94},{"cell_type":"markdown","source":"## 2.4 Rotating 270 degrees","metadata":{}},{"cell_type":"code","source":"X_train_rotated = np.rot270(X_train, k=3, axes=(1,2))\nX_test_rotated = np.rot270(X_test, k=3, axes=(1,2))\n\nX_train_augmented = np.concatenate((X_train, X_train_rotated), axis=0)\ny_train_augmented = np.concatenate((y_train, y_train), axis=0)\n\ntrain_evaluate_model_with_k_fold(\n    X_train=X_train_augmented,\n    y_train=y_train_augmented,\n    lr=0.01,\n    epochs=50,\n    batch_size=16)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T20:22:13.504699Z","iopub.execute_input":"2025-02-07T20:22:13.504960Z","iopub.status.idle":"2025-02-07T20:26:48.252769Z","shell.execute_reply.started":"2025-02-07T20:22:13.504939Z","shell.execute_reply":"2025-02-07T20:26:48.251876Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"\nTraining on Fold 1...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 418ms/step - accuracy: 0.6981 - loss: 1.2505 - val_accuracy: 0.5000 - val_loss: 1607.7814 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.8862 - loss: 0.2480 - val_accuracy: 0.5000 - val_loss: 394.4673 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9394 - loss: 0.1392 - val_accuracy: 0.5000 - val_loss: 295.5130 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9551 - loss: 0.1141 - val_accuracy: 0.5000 - val_loss: 103.0436 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9614 - loss: 0.1062 - val_accuracy: 0.5333 - val_loss: 15.5523 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9463 - loss: 0.1305 - val_accuracy: 0.5333 - val_loss: 4.8851 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9949 - loss: 0.0614 - val_accuracy: 0.5667 - val_loss: 5.5517 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9921 - loss: 0.0364 - val_accuracy: 0.6667 - val_loss: 1.1213 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9716 - loss: 0.0636 - val_accuracy: 0.8667 - val_loss: 0.3657 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9796 - loss: 0.0567 - val_accuracy: 0.8667 - val_loss: 0.9205 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9958 - loss: 0.0421 - val_accuracy: 1.0000 - val_loss: 0.0221 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9740 - loss: 0.0734 - val_accuracy: 0.8000 - val_loss: 0.9972 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9668 - loss: 0.1015 - val_accuracy: 0.8333 - val_loss: 0.6611 - learning_rate: 0.0100\nEpoch 14/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9826 - loss: 0.0515\nEpoch 14: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9828 - loss: 0.0504 - val_accuracy: 0.9333 - val_loss: 0.0804 - learning_rate: 0.0100\nEpoch 15/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9888 - loss: 0.0265 - val_accuracy: 0.9667 - val_loss: 0.0486 - learning_rate: 1.0000e-03\nEpoch 16/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0099 - val_accuracy: 0.9667 - val_loss: 0.0579 - learning_rate: 1.0000e-03\nEpoch 16: early stopping\nRestoring model weights from the end of the best epoch: 11.\nFold 1 - Train Accuracy: 94.36%, Validation Accuracy: 100.00%\n\nTraining on Fold 2...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 423ms/step - accuracy: 0.6011 - loss: 1.5730 - val_accuracy: 0.5000 - val_loss: 1110.5763 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.7743 - loss: 0.4531 - val_accuracy: 0.5000 - val_loss: 332.4502 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9186 - loss: 0.2578 - val_accuracy: 0.5000 - val_loss: 207.2202 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9128 - loss: 0.2264 - val_accuracy: 0.5000 - val_loss: 79.8109 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9555 - loss: 0.1266 - val_accuracy: 0.5000 - val_loss: 37.6913 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9699 - loss: 0.0825 - val_accuracy: 0.5333 - val_loss: 17.5848 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9760 - loss: 0.0521 - val_accuracy: 0.5667 - val_loss: 10.7115 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9952 - loss: 0.0222 - val_accuracy: 0.5667 - val_loss: 4.4777 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0163 - val_accuracy: 0.5667 - val_loss: 4.1745 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9927 - loss: 0.0175 - val_accuracy: 0.7667 - val_loss: 1.2084 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9922 - loss: 0.0250 - val_accuracy: 0.6000 - val_loss: 3.7155 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9654 - loss: 0.1364 - val_accuracy: 0.5667 - val_loss: 5.3585 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9733 - loss: 0.0819\nEpoch 13: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9746 - loss: 0.0788 - val_accuracy: 0.7000 - val_loss: 2.6380 - learning_rate: 0.0100\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9893 - loss: 0.0385 - val_accuracy: 0.8333 - val_loss: 1.0495 - learning_rate: 1.0000e-03\nEpoch 15/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9951 - loss: 0.0292 - val_accuracy: 0.8667 - val_loss: 0.4811 - learning_rate: 1.0000e-03\nEpoch 16/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9893 - loss: 0.0318 - val_accuracy: 0.9000 - val_loss: 0.2367 - learning_rate: 1.0000e-03\nEpoch 17/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0174 - val_accuracy: 0.9333 - val_loss: 0.1616 - learning_rate: 1.0000e-03\nEpoch 18/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0165 - val_accuracy: 0.9333 - val_loss: 0.1470 - learning_rate: 1.0000e-03\nEpoch 19/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0128 - val_accuracy: 0.9333 - val_loss: 0.1270 - learning_rate: 1.0000e-03\nEpoch 20/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0072 - val_accuracy: 0.9333 - val_loss: 0.1001 - learning_rate: 1.0000e-03\nEpoch 21/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0079 - val_accuracy: 0.9667 - val_loss: 0.0971 - learning_rate: 1.0000e-03\nEpoch 22/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0075 - val_accuracy: 0.9667 - val_loss: 0.0941 - learning_rate: 1.0000e-03\nEpoch 23/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0067 - val_accuracy: 0.9667 - val_loss: 0.0819 - learning_rate: 1.0000e-03\nEpoch 24/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9964 - loss: 0.0102 - val_accuracy: 0.9667 - val_loss: 0.0858 - learning_rate: 1.0000e-03\nEpoch 25/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0062 - val_accuracy: 0.9667 - val_loss: 0.0880 - learning_rate: 1.0000e-03\nEpoch 26/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0066\nEpoch 26: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0070 - val_accuracy: 0.9667 - val_loss: 0.0890 - learning_rate: 1.0000e-03\nEpoch 27/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0087 - val_accuracy: 0.9667 - val_loss: 0.0710 - learning_rate: 1.0000e-04\nEpoch 28/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0053 - val_accuracy: 0.9667 - val_loss: 0.0558 - learning_rate: 1.0000e-04\nEpoch 29/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0047 - val_accuracy: 0.9667 - val_loss: 0.0452 - learning_rate: 1.0000e-04\nEpoch 30/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0073 - val_accuracy: 0.9667 - val_loss: 0.0376 - learning_rate: 1.0000e-04\nEpoch 31/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0067 - val_accuracy: 0.9667 - val_loss: 0.0305 - learning_rate: 1.0000e-04\nEpoch 32/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0061 - val_accuracy: 1.0000 - val_loss: 0.0256 - learning_rate: 1.0000e-04\nEpoch 33/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0043 - val_accuracy: 1.0000 - val_loss: 0.0226 - learning_rate: 1.0000e-04\nEpoch 34/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0060 - val_accuracy: 1.0000 - val_loss: 0.0212 - learning_rate: 1.0000e-04\nEpoch 35/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0041 - val_accuracy: 1.0000 - val_loss: 0.0201 - learning_rate: 1.0000e-04\nEpoch 36/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0047 - val_accuracy: 1.0000 - val_loss: 0.0205 - learning_rate: 1.0000e-04\nEpoch 37/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0051 - val_accuracy: 1.0000 - val_loss: 0.0213 - learning_rate: 1.0000e-04\nEpoch 38/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0046\nEpoch 38: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0047 - val_accuracy: 1.0000 - val_loss: 0.0229 - learning_rate: 1.0000e-04\nEpoch 39/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0053 - val_accuracy: 1.0000 - val_loss: 0.0246 - learning_rate: 1.0000e-05\nEpoch 40/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0051 - val_accuracy: 1.0000 - val_loss: 0.0271 - learning_rate: 1.0000e-05\nEpoch 40: early stopping\nRestoring model weights from the end of the best epoch: 35.\nFold 2 - Train Accuracy: 96.62%, Validation Accuracy: 100.00%\n\nTraining on Fold 3...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 412ms/step - accuracy: 0.6425 - loss: 1.2031 - val_accuracy: 0.5000 - val_loss: 694.2881 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.8560 - loss: 0.3356 - val_accuracy: 0.5000 - val_loss: 337.0931 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9321 - loss: 0.1507 - val_accuracy: 0.5000 - val_loss: 47.6345 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9599 - loss: 0.0628 - val_accuracy: 0.5000 - val_loss: 28.6129 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9914 - loss: 0.0387 - val_accuracy: 0.5000 - val_loss: 11.1439 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9690 - loss: 0.0484 - val_accuracy: 0.5000 - val_loss: 11.2283 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9816 - loss: 0.0390 - val_accuracy: 0.5000 - val_loss: 10.0405 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9727 - loss: 0.0583 - val_accuracy: 0.6333 - val_loss: 2.7623 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9889 - loss: 0.0373 - val_accuracy: 0.5000 - val_loss: 3.4841 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9880 - loss: 0.0476 - val_accuracy: 0.5000 - val_loss: 8.1388 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9947 - loss: 0.0258 - val_accuracy: 0.8000 - val_loss: 1.4421 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9820 - loss: 0.0558 - val_accuracy: 0.9000 - val_loss: 0.7105 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9834 - loss: 0.0423 - val_accuracy: 0.8667 - val_loss: 0.7354 - learning_rate: 0.0100\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9938 - loss: 0.0251 - val_accuracy: 0.6333 - val_loss: 2.0846 - learning_rate: 0.0100\nEpoch 15/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9919 - loss: 0.0180 - val_accuracy: 0.9333 - val_loss: 0.4055 - learning_rate: 0.0100\nEpoch 16/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9927 - loss: 0.0231 - val_accuracy: 0.9333 - val_loss: 0.1398 - learning_rate: 0.0100\nEpoch 17/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9989 - loss: 0.0057 - val_accuracy: 0.9333 - val_loss: 0.4577 - learning_rate: 0.0100\nEpoch 18/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9977 - loss: 0.0066 - val_accuracy: 0.8667 - val_loss: 0.6618 - learning_rate: 0.0100\nEpoch 19/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0035\nEpoch 19: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0035 - val_accuracy: 0.9000 - val_loss: 0.5838 - learning_rate: 0.0100\nEpoch 20/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.9000 - val_loss: 0.4478 - learning_rate: 1.0000e-03\nEpoch 21/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 9.7771e-04 - val_accuracy: 0.9333 - val_loss: 0.3185 - learning_rate: 1.0000e-03\nEpoch 21: early stopping\nRestoring model weights from the end of the best epoch: 16.\nFold 3 - Train Accuracy: 93.23%, Validation Accuracy: 93.33%\n\nTraining on Fold 4...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 433ms/step - accuracy: 0.6825 - loss: 1.3245 - val_accuracy: 0.5000 - val_loss: 1705.3313 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8954 - loss: 0.2588 - val_accuracy: 0.5000 - val_loss: 378.6555 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9290 - loss: 0.1495 - val_accuracy: 0.5000 - val_loss: 64.0954 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9482 - loss: 0.1147 - val_accuracy: 0.5000 - val_loss: 31.9703 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9752 - loss: 0.0813 - val_accuracy: 0.5333 - val_loss: 9.0170 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9802 - loss: 0.0608 - val_accuracy: 0.5667 - val_loss: 3.6397 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9902 - loss: 0.0383 - val_accuracy: 0.8667 - val_loss: 0.6848 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9996 - loss: 0.0301 - val_accuracy: 0.6000 - val_loss: 3.8618 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9861 - loss: 0.0320 - val_accuracy: 0.6667 - val_loss: 2.3868 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9737 - loss: 0.0982\nEpoch 10: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9745 - loss: 0.0958 - val_accuracy: 0.8000 - val_loss: 1.2716 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9848 - loss: 0.0508 - val_accuracy: 0.8667 - val_loss: 0.9117 - learning_rate: 1.0000e-03\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9977 - loss: 0.0196 - val_accuracy: 0.8333 - val_loss: 0.8873 - learning_rate: 1.0000e-03\nEpoch 12: early stopping\nRestoring model weights from the end of the best epoch: 7.\nFold 4 - Train Accuracy: 84.59%, Validation Accuracy: 86.67%\n\nTraining on Fold 5...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 416ms/step - accuracy: 0.7229 - loss: 0.8717 - val_accuracy: 0.5000 - val_loss: 3012.1289 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.8734 - loss: 0.3264 - val_accuracy: 0.5333 - val_loss: 197.7631 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9225 - loss: 0.2217 - val_accuracy: 0.7333 - val_loss: 25.7146 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9591 - loss: 0.1641 - val_accuracy: 0.5000 - val_loss: 46.0752 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9439 - loss: 0.1723 - val_accuracy: 0.6000 - val_loss: 4.9387 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9377 - loss: 0.1862 - val_accuracy: 0.5667 - val_loss: 2.6449 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9615 - loss: 0.1006 - val_accuracy: 0.8667 - val_loss: 0.4068 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9899 - loss: 0.0617 - val_accuracy: 0.7667 - val_loss: 1.1983 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9922 - loss: 0.0233 - val_accuracy: 0.7667 - val_loss: 0.9655 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9995 - loss: 0.0158\nEpoch 10: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9991 - loss: 0.0155 - val_accuracy: 0.8667 - val_loss: 0.5536 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0095 - val_accuracy: 0.9000 - val_loss: 0.4203 - learning_rate: 1.0000e-03\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9991 - loss: 0.0077 - val_accuracy: 0.9333 - val_loss: 0.3215 - learning_rate: 1.0000e-03\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0077 - val_accuracy: 0.9667 - val_loss: 0.2331 - learning_rate: 1.0000e-03\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9942 - loss: 0.0141 - val_accuracy: 0.9667 - val_loss: 0.1192 - learning_rate: 1.0000e-03\nEpoch 15/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0051 - val_accuracy: 0.9667 - val_loss: 0.0595 - learning_rate: 1.0000e-03\nEpoch 16/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0060 - val_accuracy: 0.9667 - val_loss: 0.0373 - learning_rate: 1.0000e-03\nEpoch 17/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0060 - val_accuracy: 1.0000 - val_loss: 0.0166 - learning_rate: 1.0000e-03\nEpoch 18/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0118 - val_accuracy: 1.0000 - val_loss: 0.0140 - learning_rate: 1.0000e-03\nEpoch 19/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0045 - val_accuracy: 1.0000 - val_loss: 0.0095 - learning_rate: 1.0000e-03\nEpoch 20/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0045 - val_accuracy: 1.0000 - val_loss: 0.0085 - learning_rate: 1.0000e-03\nEpoch 21/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0054 - val_accuracy: 1.0000 - val_loss: 0.0088 - learning_rate: 1.0000e-03\nEpoch 22/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0032 - val_accuracy: 1.0000 - val_loss: 0.0081 - learning_rate: 1.0000e-03\nEpoch 23/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 1.0000 - val_loss: 0.0083 - learning_rate: 1.0000e-03\nEpoch 24/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 1.0000 - val_loss: 0.0087 - learning_rate: 1.0000e-03\nEpoch 25/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0043\nEpoch 25: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0042 - val_accuracy: 1.0000 - val_loss: 0.0108 - learning_rate: 1.0000e-03\nEpoch 26/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0030 - val_accuracy: 1.0000 - val_loss: 0.0103 - learning_rate: 1.0000e-04\nEpoch 27/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0036 - val_accuracy: 1.0000 - val_loss: 0.0088 - learning_rate: 1.0000e-04\nEpoch 27: early stopping\nRestoring model weights from the end of the best epoch: 22.\nFold 5 - Train Accuracy: 96.62%, Validation Accuracy: 100.00%\n\nTraining on Fold 6...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 413ms/step - accuracy: 0.7139 - loss: 1.1981 - val_accuracy: 0.5000 - val_loss: 4125.4961 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8791 - loss: 0.2579 - val_accuracy: 0.5000 - val_loss: 1974.9471 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9413 - loss: 0.1494 - val_accuracy: 0.5000 - val_loss: 266.8892 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9461 - loss: 0.0966 - val_accuracy: 0.5000 - val_loss: 63.3284 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9900 - loss: 0.0508 - val_accuracy: 0.5000 - val_loss: 32.3055 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9842 - loss: 0.0409 - val_accuracy: 0.5333 - val_loss: 10.4338 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9701 - loss: 0.0573 - val_accuracy: 0.5000 - val_loss: 12.4102 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9814 - loss: 0.0565 - val_accuracy: 0.6000 - val_loss: 2.2547 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9842 - loss: 0.0425 - val_accuracy: 0.6667 - val_loss: 2.4281 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9955 - loss: 0.0193 - val_accuracy: 0.5667 - val_loss: 3.2786 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9964 - loss: 0.0127\nEpoch 11: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9964 - loss: 0.0128 - val_accuracy: 0.5667 - val_loss: 6.5748 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9878 - loss: 0.0319 - val_accuracy: 0.6000 - val_loss: 5.2052 - learning_rate: 1.0000e-03\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0089 - val_accuracy: 0.6333 - val_loss: 3.9770 - learning_rate: 1.0000e-03\nEpoch 13: early stopping\nRestoring model weights from the end of the best epoch: 8.\nFold 6 - Train Accuracy: 76.32%, Validation Accuracy: 60.00%\n\nTraining on Fold 7...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 416ms/step - accuracy: 0.6477 - loss: 1.3924 - val_accuracy: 0.5172 - val_loss: 3542.1450 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8597 - loss: 0.3562 - val_accuracy: 0.5172 - val_loss: 93.0478 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9029 - loss: 0.2885 - val_accuracy: 0.4828 - val_loss: 29.3248 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9031 - loss: 0.2610 - val_accuracy: 0.5172 - val_loss: 31.1105 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9258 - loss: 0.2901 - val_accuracy: 0.5172 - val_loss: 18.8935 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9350 - loss: 0.2433 - val_accuracy: 0.5172 - val_loss: 5.8304 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9656 - loss: 0.1492 - val_accuracy: 0.4828 - val_loss: 4.2173 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9577 - loss: 0.1214 - val_accuracy: 0.7586 - val_loss: 0.7264 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9886 - loss: 0.0560 - val_accuracy: 0.8276 - val_loss: 0.2833 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9798 - loss: 0.0756 - val_accuracy: 0.8276 - val_loss: 0.6233 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9192 - loss: 0.1994 - val_accuracy: 0.8621 - val_loss: 0.2611 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9827 - loss: 0.1144 - val_accuracy: 0.7586 - val_loss: 0.7053 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9804 - loss: 0.0775 - val_accuracy: 0.8621 - val_loss: 0.5064 - learning_rate: 0.0100\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9823 - loss: 0.0495 - val_accuracy: 0.9310 - val_loss: 0.0792 - learning_rate: 0.0100\nEpoch 15/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9672 - loss: 0.0634 - val_accuracy: 0.8276 - val_loss: 0.4928 - learning_rate: 0.0100\nEpoch 16/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9642 - loss: 0.1249 - val_accuracy: 0.7931 - val_loss: 0.4194 - learning_rate: 0.0100\nEpoch 17/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9748 - loss: 0.0481\nEpoch 17: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9756 - loss: 0.0473 - val_accuracy: 0.8276 - val_loss: 0.5563 - learning_rate: 0.0100\nEpoch 18/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9627 - loss: 0.0698 - val_accuracy: 0.8966 - val_loss: 0.4490 - learning_rate: 1.0000e-03\nEpoch 19/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9885 - loss: 0.0337 - val_accuracy: 0.8966 - val_loss: 0.3631 - learning_rate: 1.0000e-03\nEpoch 19: early stopping\nRestoring model weights from the end of the best epoch: 14.\nFold 7 - Train Accuracy: 96.25%, Validation Accuracy: 93.10%\n\nTraining on Fold 8...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 418ms/step - accuracy: 0.6973 - loss: 1.0603 - val_accuracy: 0.5172 - val_loss: 4163.1133 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.9244 - loss: 0.1771 - val_accuracy: 0.5172 - val_loss: 186.4009 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9575 - loss: 0.0950 - val_accuracy: 0.5172 - val_loss: 44.9895 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9729 - loss: 0.0633 - val_accuracy: 0.5172 - val_loss: 30.4228 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9983 - loss: 0.0203 - val_accuracy: 0.4828 - val_loss: 12.4293 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9914 - loss: 0.0265 - val_accuracy: 0.6552 - val_loss: 4.4827 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9816 - loss: 0.0584 - val_accuracy: 0.7931 - val_loss: 2.2414 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9795 - loss: 0.0728 - val_accuracy: 0.8621 - val_loss: 0.6880 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9621 - loss: 0.0723 - val_accuracy: 0.9655 - val_loss: 0.3013 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9936 - loss: 0.0252 - val_accuracy: 0.9310 - val_loss: 0.5482 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9980 - loss: 0.0128 - val_accuracy: 0.9310 - val_loss: 0.4954 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9964 - loss: 0.0100\nEpoch 12: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9964 - loss: 0.0102 - val_accuracy: 0.8966 - val_loss: 0.7211 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0055 - val_accuracy: 0.9310 - val_loss: 0.5810 - learning_rate: 1.0000e-03\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0073 - val_accuracy: 0.9310 - val_loss: 0.5368 - learning_rate: 1.0000e-03\nEpoch 14: early stopping\nRestoring model weights from the end of the best epoch: 9.\nFold 8 - Train Accuracy: 89.51%, Validation Accuracy: 96.55%\n\nTraining on Fold 9...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 414ms/step - accuracy: 0.7174 - loss: 1.3490 - val_accuracy: 0.4828 - val_loss: 1876.8817 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9287 - loss: 0.2070 - val_accuracy: 0.4828 - val_loss: 488.2412 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9511 - loss: 0.1647 - val_accuracy: 0.4828 - val_loss: 96.0055 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9573 - loss: 0.1189 - val_accuracy: 0.4828 - val_loss: 36.9367 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9730 - loss: 0.0796 - val_accuracy: 0.4828 - val_loss: 21.3071 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9827 - loss: 0.0489 - val_accuracy: 0.5517 - val_loss: 10.6873 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9914 - loss: 0.0314 - val_accuracy: 0.5862 - val_loss: 5.4800 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9866 - loss: 0.0393 - val_accuracy: 0.4828 - val_loss: 7.6419 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9605 - loss: 0.0844 - val_accuracy: 0.8276 - val_loss: 1.3974 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9837 - loss: 0.0328 - val_accuracy: 0.6897 - val_loss: 2.1386 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9716 - loss: 0.0658 - val_accuracy: 0.5862 - val_loss: 1.5871 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9852 - loss: 0.0390 - val_accuracy: 0.8621 - val_loss: 0.4886 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9831 - loss: 0.0438 - val_accuracy: 0.9655 - val_loss: 0.5529 - learning_rate: 0.0100\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0116 - val_accuracy: 0.8276 - val_loss: 0.9912 - learning_rate: 0.0100\nEpoch 15/50\n\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0056\nEpoch 15: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9994 - loss: 0.0068 - val_accuracy: 0.8966 - val_loss: 0.8267 - learning_rate: 0.0100\nEpoch 16/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 0.8966 - val_loss: 0.7150 - learning_rate: 1.0000e-03\nEpoch 17/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.8966 - val_loss: 0.6302 - learning_rate: 1.0000e-03\nEpoch 17: early stopping\nRestoring model weights from the end of the best epoch: 12.\nFold 9 - Train Accuracy: 82.02%, Validation Accuracy: 86.21%\n\nTraining on Fold 10...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 424ms/step - accuracy: 0.6254 - loss: 1.7405 - val_accuracy: 0.5172 - val_loss: 2932.0447 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.8466 - loss: 0.4071 - val_accuracy: 0.4828 - val_loss: 1634.8331 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8646 - loss: 0.3808 - val_accuracy: 0.4828 - val_loss: 261.8527 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9054 - loss: 0.2054 - val_accuracy: 0.4828 - val_loss: 35.9489 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9285 - loss: 0.1551 - val_accuracy: 0.4828 - val_loss: 18.1290 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9528 - loss: 0.0930 - val_accuracy: 0.5517 - val_loss: 11.5473 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9638 - loss: 0.0891 - val_accuracy: 0.5517 - val_loss: 7.9227 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9845 - loss: 0.0514 - val_accuracy: 0.5862 - val_loss: 4.6441 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9646 - loss: 0.0884 - val_accuracy: 0.8966 - val_loss: 1.2115 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9677 - loss: 0.0918 - val_accuracy: 0.8621 - val_loss: 0.4132 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9670 - loss: 0.1039 - val_accuracy: 0.8966 - val_loss: 0.7937 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9769 - loss: 0.0742 - val_accuracy: 0.9310 - val_loss: 0.3315 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9848 - loss: 0.0479 - val_accuracy: 0.8966 - val_loss: 0.5449 - learning_rate: 0.0100\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9781 - loss: 0.0613 - val_accuracy: 0.8621 - val_loss: 1.0021 - learning_rate: 0.0100\nEpoch 15/50\n\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9952 - loss: 0.0277\nEpoch 15: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9934 - loss: 0.0307 - val_accuracy: 0.9310 - val_loss: 0.4817 - learning_rate: 0.0100\nEpoch 16/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9915 - loss: 0.0325 - val_accuracy: 0.9310 - val_loss: 0.4130 - learning_rate: 1.0000e-03\nEpoch 17/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0156 - val_accuracy: 0.9310 - val_loss: 0.3575 - learning_rate: 1.0000e-03\nEpoch 17: early stopping\nRestoring model weights from the end of the best epoch: 12.\nFold 10 - Train Accuracy: 96.63%, Validation Accuracy: 93.10%\n\nAverage Training Accuracy: 90.61%\nAverage Validation Accuracy: 90.90%\n","output_type":"stream"}],"execution_count":95},{"cell_type":"markdown","source":"# 3 Network Training","metadata":{}},{"cell_type":"markdown","source":"## 3.1 Data Preparation","metadata":{}},{"cell_type":"code","source":"X_train_flipped = np.flip(X_train, axis=2)\nX_train_rotated_90 = np.rot90(X_train, k=1, axes=(1,2))\nX_train_rotated_180 = np.rot90(X_train, k=2, axes=(1,2))\nX_train_rotated_270 = np.rot90(X_train, k=3, axes=(1,2))\n\nX_train_augmented = np.concatenate((X_train, X_train_flipped, X_train_rotated_90, X_train_rotated_180, X_train_rotated_270), axis=0)\ny_train_augmented = np.concatenate((y_train, y_train, y_train, y_train, y_train), axis=0)\n\nindices = np.arange(X_train_augmented.shape[0])\nnp.random.shuffle(indices)\nX_train_augmented = X_train_augmented[indices]\ny_train_augmented = y_train_augmented[indices]\n\n# Split the data into training (80%) and validation (20%) sets\nX_train_final, X_val_final, y_train_final, y_val_final = train_test_split(X_train_augmented, y_train_augmented, test_size=0.8, random_state=33)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 3.2 Training","metadata":{}},{"cell_type":"code","source":"model = define_model(\n    input_shape=(150,150,3),\n    lr=0.01\n)\n\nhistory = model.fit(\n    X_train_final, y_train_final,\n    validation_data=(X_val_final, y_val_final),\n    epochs=100,\n    batch_size=16,\n    callbacks=[\n        EarlyStopping(monitor=\"val_loss\", patience=15, restore_best_weights=True, verbose=1),\n        ReduceLROnPlateau(monitor='val_loss', factor=0.8, patience=3, verbose=1)\n    ],\n    verbose=1,\n    shuffle=True\n)\n\n# Extract loss & accuracy\nloss = history.history['loss']\nloss = np.log(loss)\nval_loss = history.history['val_loss']\nval_loss = np.log(val_loss)\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\n# Plot Loss\nplt.figure(figsize=(12, 5))\nplt.subplot(1, 2, 1)\nplt.plot(loss, label=\"Train Loss\")\nplt.plot(val_loss, label=\"Validation Loss\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Logarithmic loss\")\nplt.legend()\nplt.title(\"Logarithmic loss over epochs\")\n\n# Plot Accuracy\nplt.subplot(1, 2, 2)\nplt.plot(acc, label=\"Train Accuracy\")\nplt.plot(val_acc, label=\"Validation Accuracy\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Accuracy\")\nplt.legend()\nplt.title(\"Accuracy over epochs\")\n\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 4 Network Evaluation","metadata":{}},{"cell_type":"markdown","source":"## 4.1 Evaluation Metrics","metadata":{}},{"cell_type":"code","source":"y_pred = model.predict(X_test)\ny_pred_classes = (y_pred.reshape(-1) >= 0.5).astype(int)\n\n# Report the evaluation metrics\naccuracy = accuracy_score(y_test, y_pred_classes)\nprecision = precision_score(y_test, y_pred_classes, average='weighted')\nsensitivity = recall_score(y_test, y_pred_classes, average='weighted') # Sensitivity = Recall\nspecificity = recall_score(y_test, y_pred_classes, average='weighted') # Specificity is (1 - False Positive Rate)\nf1 = f1_score(y_test, y_pred_classes, average='weighted')\n\n# Print the classification report (for precision, recall, F1)\nprint(\"Classification Report:\")\nprint(classification_report(y_test, y_pred_classes))\n\n# Print the evaluation metrics\nprint(f\"Accuracy: {accuracy:.4f}\")\nprint(f\"Precision: {precision:.4f}\")\nprint(f\"Sensitivity: {sensitivity:.4f}\")\nprint(f\"Specificity: {specificity:.4f}\")\nprint(f\"F1 Score: {f1:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T22:11:36.566558Z","iopub.execute_input":"2025-02-07T22:11:36.566855Z","iopub.status.idle":"2025-02-07T22:11:36.669718Z","shell.execute_reply.started":"2025-02-07T22:11:36.566831Z","shell.execute_reply":"2025-02-07T22:11:36.669056Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       1.00      0.70      0.82        20\n           1       0.77      1.00      0.87        20\n\n    accuracy                           0.85        40\n   macro avg       0.88      0.85      0.85        40\nweighted avg       0.88      0.85      0.85        40\n\nAccuracy: 0.8500\nPrecision: 0.8846\nSensitivity: 0.8500\nSpecificity: 0.8500\nF1 Score: 0.8465\n","output_type":"stream"}],"execution_count":164},{"cell_type":"markdown","source":"## 4.2 Confusion Matrix","metadata":{}},{"cell_type":"code","source":"# Confusion Matrix\ncm = confusion_matrix(y_test, y_pred_classes)\n\n# Plot the confusion matrix\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=np.unique(y_test), yticklabels=np.unique(y_test))\nplt.title(\"Confusion Matrix\")\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T22:10:15.974025Z","iopub.execute_input":"2025-02-07T22:10:15.974323Z","iopub.status.idle":"2025-02-07T22:10:16.161762Z","shell.execute_reply.started":"2025-02-07T22:10:15.974299Z","shell.execute_reply":"2025-02-07T22:10:16.161060Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 800x600 with 2 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":163},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}