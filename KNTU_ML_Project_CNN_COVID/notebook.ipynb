{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 1 Prerequisites","metadata":{}},{"cell_type":"code","source":"import gdown\nfrom pickle import dump, load\nimport shutil\nimport os\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, Input\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\nimport seaborn as sns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T21:42:41.205155Z","iopub.execute_input":"2025-02-07T21:42:41.205542Z","iopub.status.idle":"2025-02-07T21:42:41.582710Z","shell.execute_reply.started":"2025-02-07T21:42:41.205508Z","shell.execute_reply":"2025-02-07T21:42:41.581930Z"}},"outputs":[],"execution_count":127},{"cell_type":"code","source":"np.random.seed(33)\ntf.random.set_seed(33)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T19:56:35.815294Z","iopub.execute_input":"2025-02-07T19:56:35.816200Z","iopub.status.idle":"2025-02-07T19:56:35.853994Z","shell.execute_reply.started":"2025-02-07T19:56:35.816169Z","shell.execute_reply":"2025-02-07T19:56:35.852916Z"}},"outputs":[],"execution_count":89},{"cell_type":"markdown","source":"## 1.1 Required global functions","metadata":{}},{"cell_type":"code","source":"def download_from_drive(filename, file_id):\n    url = f\"https://drive.google.com/uc?export=download&id={file_id}\"\n    gdown.download(url, filename, quiet=False)\n\ndef load_dataset(image_size=(150, 150)):\n\n    categories = [\"NORMAL\", \"COVID\"]\n    datasets_name_list = [\"test\", \"train\"]\n    X = [[], []] # 0 for test & 1 for train\n    y = [[], []] # 0 for test & 1 for train\n\n    for i, dataset_name in enumerate(datasets_name_list):\n        for label, category in enumerate(categories):\n            dir_path = \"/kaggle/working/dataset1/\" + dataset_name + '/' + category + '/'\n            for filename in os.listdir(dir_path):\n                img_path = os.path.join(dir_path, filename)\n                img = Image.open(img_path).convert(\"RGB\")\n                img = img.resize(image_size)\n                img_array = np.array(img)\n                X[i].append(img_array)\n                y[i].append(label) # NORMAL = 0, COVID = 1\n\n    X_train = np.array(X[1]) / 255.0\n    y_train = np.array(y[1])\n    X_test = np.array(X[0]) / 255.0\n    y_test = np.array(y[0])\n\n    indices = np.arange(X_train.shape[0])\n    np.random.shuffle(indices)\n    X_train = X_train[indices]\n    y_train = y_train[indices]\n\n    return X_train, y_train, X_test, y_test\n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T19:17:50.392967Z","iopub.execute_input":"2025-02-07T19:17:50.393302Z","iopub.status.idle":"2025-02-07T19:17:50.400320Z","shell.execute_reply.started":"2025-02-07T19:17:50.393278Z","shell.execute_reply":"2025-02-07T19:17:50.399503Z"}},"outputs":[],"execution_count":71},{"cell_type":"markdown","source":"## 1.2 Downloading & Loading the dataset","metadata":{}},{"cell_type":"code","source":"download_from_drive(\n    filename=\"Datasets.rar\",\n    file_id=\"1wM1NufVrRtbHuLmeBjiOls_e80Qrsoy-\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T09:59:56.327216Z","iopub.execute_input":"2025-02-07T09:59:56.327604Z","iopub.status.idle":"2025-02-07T10:00:02.919933Z","shell.execute_reply.started":"2025-02-07T09:59:56.327571Z","shell.execute_reply":"2025-02-07T10:00:02.918908Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stderr","text":"Downloading...\nFrom (original): https://drive.google.com/uc?export=download&id=1wM1NufVrRtbHuLmeBjiOls_e80Qrsoy-\nFrom (redirected): https://drive.google.com/uc?export=download&id=1wM1NufVrRtbHuLmeBjiOls_e80Qrsoy-&confirm=t&uuid=4c6dd7af-157c-41c9-bdd4-0caa4dc59bae\nTo: /kaggle/working/Datasets.rar\n100%|██████████| 220M/220M [00:02<00:00, 81.0MB/s] \n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# Extract the Datasets.rar file in the current directory\n!unrar x \"Datasets.rar\" ./","metadata":{"trusted":true,"_kg_hide-output":true,"scrolled":true,"execution":{"iopub.status.busy":"2025-02-07T10:00:02.921204Z","iopub.execute_input":"2025-02-07T10:00:02.921494Z","iopub.status.idle":"2025-02-07T10:00:05.358943Z","shell.execute_reply.started":"2025-02-07T10:00:02.921468Z","shell.execute_reply":"2025-02-07T10:00:05.357315Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"\nUNRAR 6.11 beta 1 freeware      Copyright (c) 1993-2022 Alexander Roshal\n\n\nExtracting from Datasets.rar\n\nCreating    ./dataset2                                                OK\nCreating    ./dataset2/test                                           OK\nCreating    ./dataset2/test/NORMAL                                    OK\nExtracting  ./dataset2/test/NORMAL/NORMAL(1266).jpg                      0  OK \nExtracting  ./dataset2/test/NORMAL/NORMAL(1267).jpg                      0  OK \nExtracting  ./dataset2/test/NORMAL/NORMAL(1268).jpg                      0  OK \nExtracting  ./dataset2/test/NORMAL/NORMAL(1269).jpg                      1  OK \nExtracting  ./dataset2/test/NORMAL/NORMAL(1270).jpg                      1  OK \nExtracting  ./dataset2/test/NORMAL/NORMAL(1271).jpg                      1  OK \nExtracting  ./dataset2/test/NORMAL/NORMAL(1272).jpg                      2  OK \nExtracting  ./dataset2/test/NORMAL/NORMAL(1273).jpg                      2  OK \nExtracting  ./dataset2/test/NORMAL/NORMAL(1274).jpg                      2  OK \nExtracting  ./dataset2/test/NORMAL/NORMAL(1275).jpg                      2  OK \nExtracting  ./dataset2/test/NORMAL/NORMAL(1276).jpg                      3  OK \nExtracting  ./dataset2/test/NORMAL/NORMAL(1277).jpg                      3  OK \nExtracting  ./dataset2/test/NORMAL/NORMAL(1278).jpg                      3  OK \nExtracting  ./dataset2/test/NORMAL/NORMAL(1279).jpg                      3  OK \nExtracting  ./dataset2/test/NORMAL/NORMAL(1280).jpg                      4  OK \nExtracting  ./dataset2/test/NORMAL/NORMAL(1281).jpg                      4  OK \nExtracting  ./dataset2/test/NORMAL/NORMAL(1282).jpg                      4  OK \nExtracting  ./dataset2/test/NORMAL/NORMAL(1283).jpg                      5  OK \nExtracting  ./dataset2/test/NORMAL/NORMAL(1284).jpg                      5  OK \nExtracting  ./dataset2/test/NORMAL/NORMAL(1285).jpg                      6  OK \nExtracting  ./dataset2/test/NORMAL/NORMAL(1286).jpg                      6  OK \nExtracting  ./dataset2/test/NORMAL/NORMAL(1287).jpg                      6  OK \nExtracting  ./dataset2/test/NORMAL/NORMAL(1288).jpg                      7  OK \nExtracting  ./dataset2/test/NORMAL/NORMAL(1289).jpg                      7  OK \nExtracting  ./dataset2/test/NORMAL/NORMAL(1290).jpg                      7  OK \nExtracting  ./dataset2/test/NORMAL/NORMAL(1291).jpg                      8  OK \nExtracting  ./dataset2/test/NORMAL/NORMAL(1292).jpg                      8  OK \nExtracting  ./dataset2/test/NORMAL/NORMAL(1293).jpg                      8  OK \nExtracting  ./dataset2/test/NORMAL/NORMAL(1294).jpg                      9  OK \nExtracting  ./dataset2/test/NORMAL/NORMAL(1295).jpg                      9  OK \nExtracting  ./dataset2/test/NORMAL/NORMAL(1296).jpg                      9  OK \nExtracting  ./dataset2/test/NORMAL/NORMAL(1297).jpg                      9  OK \nExtracting  ./dataset2/test/NORMAL/NORMAL(1298).jpg                     10  OK \nExtracting  ./dataset2/test/NORMAL/NORMAL(1299).jpg                     1 11  OK \nExtracting  ./dataset2/test/NORMAL/NORMAL(1300).jpg                     11  OK \nExtracting  ./dataset2/test/NORMAL/NORMAL(1301).jpg                     11  OK \nExtracting  ./dataset2/test/NORMAL/NORMAL(1302).jpg                     11  OK \nExtracting  ./dataset2/test/NORMAL/NORMAL(1303).jpg                     12  OK \nExtracting  ./dataset2/test/NORMAL/NORMAL(1304).jpg                     12  OK \nExtracting  ./dataset2/test/NORMAL/NORMAL(1305).jpg                     12  OK \nCreating    ./dataset2/test/PNEUMONIA                                 OK\nExtracting  ./dataset2/test/PNEUMONIA/PNEUMONIA(3418).jpg               12  OK \nExtracting  ./dataset2/test/PNEUMONIA/PNEUMONIA(3419).jpg               12  OK \nExtracting  ./dataset2/test/PNEUMONIA/PNEUMONIA(3420).jpg               12  OK \nExtracting  ./dataset2/test/PNEUMONIA/PNEUMONIA(3421).jpg               12  OK \nExtracting  ./dataset2/test/PNEUMONIA/PNEUMONIA(3422).jpg               12  OK \nExtracting  ./dataset2/test/PNEUMONIA/PNEUMONIA(3423).jpg               12  OK \nExtracting  ./dataset2/test/PNEUMONIA/PNEUMONIA(3424).jpg               13  OK \nExtracting  ./dataset2/test/PNEUMONIA/PNEUMONIA(3425).jpg               13  OK \nExtracting  ./dataset2/test/PNEUMONIA/PNEUMONIA(3426).jpg               13  OK \nExtracting  ./dataset2/test/PNEUMONIA/PNEUMONIA(3427).jpg               13  OK \nExtracting  ./dataset2/test/PNEUMONIA/PNEUMONIA(3428).jpg               13  OK \nExtracting  ./dataset2/test/PNEUMONIA/PNEUMONIA(3429).jpg               13  OK \nExtracting  ./dataset2/test/PNEUMONIA/PNEUMONIA(3430).jpg               13  OK \nExtracting  ./dataset2/test/PNEUMONIA/PNEUMONIA(3431).jpg               13  OK \nExtracting  ./dataset2/test/PNEUMONIA/PNEUMONIA(3432).jpg               13  OK \nExtracting  ./dataset2/test/PNEUMONIA/PNEUMONIA(3433).jpg               13  OK \nExtracting  ./dataset2/test/PNEUMONIA/PNEUMONIA(3434).jpg               13  OK \nExtracting  ./dataset2/test/PNEUMONIA/PNEUMONIA(3435).jpg               13  OK \nExtracting  ./dataset2/test/PNEUMONIA/PNEUMONIA(3436).jpg               13  OK \nExtracting  ./dataset2/test/PNEUMONIA/PNEUMONIA(3437).jpg               13  OK \nExtracting  ./dataset2/test/PNEUMONIA/PNEUMONIA(3438).jpg               13  OK \nExtracting  ./dataset2/test/PNEUMONIA/PNEUMONIA(3439).jpg               13  OK \nExtracting  ./dataset2/test/PNEUMONIA/PNEUMONIA(3440).jpg               13  OK \nExtracting  ./dataset2/test/PNEUMONIA/PNEUMONIA(3441).jpg               14  OK \nExtracting  ./dataset2/test/PNEUMONIA/PNEUMONIA(3442).jpg               14  OK \nExtracting  ./dataset2/test/PNEUMONIA/PNEUMONIA(3443).jpg               14  OK \nExtracting  ./dataset2/test/PNEUMONIA/PNEUMONIA(3444).jpg               14  OK \nExtracting  ./dataset2/test/PNEUMONIA/PNEUMONIA(3445).jpg               14  OK \nExtracting  ./dataset2/test/PNEUMONIA/PNEUMONIA(3446).jpg               14  OK \nExtracting  ./dataset2/test/PNEUMONIA/PNEUMONIA(3447).jpg               14  OK \nExtracting  ./dataset2/test/PNEUMONIA/PNEUMONIA(3448).jpg               14  OK \nExtracting  ./dataset2/test/PNEUMONIA/PNEUMONIA(3449).jpg               14  OK \nExtracting  ./dataset2/test/PNEUMONIA/PNEUMONIA(3450).jpg               14  OK \nExtracting  ./dataset2/test/PNEUMONIA/PNEUMONIA(3451).jpg               14  OK \nExtracting  ./dataset2/test/PNEUMONIA/PNEUMONIA(3452).jpg               14  OK \nExtracting  ./dataset2/test/PNEUMONIA/PNEUMONIA(3453).jpg               14  OK \nExtracting  ./dataset2/test/PNEUMONIA/PNEUMONIA(3454).jpg               15  OK \nExtracting  ./dataset2/test/PNEUMONIA/PNEUMONIA(3455).jpg               15  OK \nExtracting  ./dataset2/test/PNEUMONIA/PNEUMONIA(3456).jpg               15  OK \nExtracting  ./dataset2/test/PNEUMONIA/PNEUMONIA(3457).jpg               15  OK \nCreating    ./dataset2/train                                          OK\nCreating    ./dataset2/train/NORMAL                                   OK\nExtracting  ./dataset2/train/NORMAL/NORMAL(0).jpg                       15  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(1).jpg                       15  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(10).jpg                      16  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(11).jpg                      16  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(12).jpg                      17  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(13).jpg                      17  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(14).jpg                      17  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(15).jpg                      18  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(16).jpg                      18  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(17).jpg                      18  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(18).jpg                      19  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(19).jpg                      20  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(2).jpg                       20  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(20).jpg                      21  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(21).jpg                      21  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(22).jpg                      21  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(23).jpg                      22  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(24).jpg                      22  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(25).jpg                      23  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(26).jpg                      23  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(27).jpg                      24  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(28).jpg                      24  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(29).jpg                      24  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(3).jpg                       24  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(30).jpg                      25  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(31).jpg                      25  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(32).jpg                      26  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(33).jpg                      27  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(34).jpg                      27  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(35).jpg                      27  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(36).jpg                      28  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(37).jpg                      28  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(38).jpg                      28  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(39).jpg                      28  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(4).jpg                       29  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(40).jpg                      29  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(41).jpg                      29  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(42).jpg                      29  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(43).jpg                      30  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(44).jpg                      30  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(45).jpg                      30  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(46).jpg                      30  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(47).jpg                      30  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(48).jpg                      30  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(49).jpg                      31  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(5).jpg                       31  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(50).jpg                      31  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(51).jpg                      31  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(52).jpg                      31  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(53).jpg                      31  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(54).jpg                      32  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(55).jpg                      32  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(56).jpg                      32  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(57).jpg                      32  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(58).jpg                      32  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(59).jpg                      32  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(6).jpg                       33  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(60).jpg                      33  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(61).jpg                      33  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(62).jpg                      33  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(63).jpg                      34  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(64).jpg                      34  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(65).jpg                      34  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(66).jpg                      34  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(67).jpg                      34  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(68).jpg                      34  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(69).jpg                      35  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(7).jpg                       35  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(70).jpg                      36  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(71).jpg                      36  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(72).jpg                      36  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(73).jpg                      36  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(74).jpg                      37  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(75).jpg                      37  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(76).jpg                      37  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(77).jpg                      37  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(78).jpg                      37  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(79).jpg                      38  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(8).jpg                       38  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(80).jpg                      38  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(81).jpg                      39  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(82).jpg                      39  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(83).jpg                      39  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(84).jpg                      40  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(85).jpg                      40  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(86).jpg                      40  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(87).jpg                      41  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(88).jpg                      41  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(89).jpg                      41  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(9).jpg                       41  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(90).jpg                      42  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(91).jpg                      42  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(92).jpg                      42  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(93).jpg                      42  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(94).jpg                      42  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(95).jpg                      43  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(96).jpg                      43  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(97).jpg                      43  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(98).jpg                      44  OK \nExtracting  ./dataset2/train/NORMAL/NORMAL(99).jpg                      44  OK \nCreating    ./dataset2/train/PNEUMONIA                                OK\nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(0).jpg                 44  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(1).jpg                 44  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(10).jpg                44  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(100).jpg               45  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(101).jpg               45  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(102).jpg               45  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(103).jpg               45  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(104).jpg               45  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(105).jpg               45  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(106).jpg               45  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(107).jpg               45  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(108).jpg               45  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(109).jpg               45  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(11).jpg                45  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(110).jpg               45  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(111).jpg               45  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(112).jpg               46  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(113).jpg               46  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(114).jpg               46  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(115).jpg               46  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(116).jpg               46  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(117).jpg               46  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(118).jpg               46  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(119).jpg               46  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(12).jpg                46  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(120).jpg               46  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(121).jpg               46  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(122).jpg               46  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(123).jpg               46  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(124).jpg               46  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(125).jpg               46  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(126).jpg               47  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(127).jpg               47  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(128).jpg               47  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(129).jpg               47  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(13).jpg                47  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(130).jpg               47  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(131).jpg               47  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(132).jpg               47  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(133).jpg               47  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(134).jpg               47  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(135).jpg               47  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(136).jpg               47  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(137).jpg               48  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(138).jpg               48  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(139).jpg               48  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(14).jpg                48  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(140).jpg               48  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(141).jpg               48  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(142).jpg               48  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(143).jpg               48  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(144).jpg               48  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(145).jpg               48  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(146).jpg               48  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(147).jpg               48  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(148).jpg               48  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(149).jpg               49  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(15).jpg                49  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(150).jpg               49  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(151).jpg               49  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(152).jpg               49  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(153).jpg               49  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(154).jpg               49  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(155).jpg               49  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(156).jpg               49  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(157).jpg               49  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(158).jpg               49  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(159).jpg               49  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(16).jpg                49  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(160).jpg               50  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(161).jpg               50  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(162).jpg               50  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(163).jpg               50  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(164).jpg               50  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(165).jpg               50  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(166).jpg               50  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(167).jpg               50  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(168).jpg               50  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(169).jpg               50  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(17).jpg                50  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(170).jpg               50  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(171).jpg               50  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(172).jpg               50  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(173).jpg               51  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(174).jpg               51  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(175).jpg               51  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(176).jpg               51  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(177).jpg               51  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(178).jpg               51  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(179).jpg               51  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(18).jpg                51  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(180).jpg               51  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(181).jpg               51  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(182).jpg               51  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(183).jpg               52  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(184).jpg               52  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(185).jpg               52  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(186).jpg               52  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(187).jpg               52  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(188).jpg               52  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(189).jpg               52  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(19).jpg                52  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(190).jpg               52  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(191).jpg               52  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(192).jpg               52  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(193).jpg               52  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(194).jpg               52  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(195).jpg               52  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(196).jpg               52  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(197).jpg               52  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(198).jpg               53  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(199).jpg               53  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(2).jpg                 53  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(20).jpg                53  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(21).jpg                53  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(22).jpg                53  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(23).jpg                53  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(24).jpg                53  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(25).jpg                53  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(26).jpg                53  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(27).jpg                53  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(28).jpg                53  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(29).jpg                53  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(3).jpg                 53  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(30).jpg                54  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(31).jpg                54  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(32).jpg                54  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(33).jpg                54  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(34).jpg                54  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(35).jpg                54  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(36).jpg                54  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(37).jpg                54  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(38).jpg                54  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(39).jpg                54  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(4).jpg                 55  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(40).jpg                55  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(41).jpg                55  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(42).jpg                55  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(43).jpg                55  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(44).jpg                55  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(45).jpg                55  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(46).jpg                55  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(47).jpg                55  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(48).jpg                55  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(49).jpg                55  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(5).jpg                 55  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(50).jpg                56  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(51).jpg                56  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(52).jpg                56  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(53).jpg                56  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(54).jpg                56  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(55).jpg                56  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(56).jpg                56  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(57).jpg                56  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(58).jpg                56  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(59).jpg                56  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(6).jpg                 56  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(60).jpg                56  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(61).jpg                56  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(62).jpg                57  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(63).jpg                57  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(64).jpg                57  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(65).jpg                57  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(66).jpg                57  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(67).jpg                57  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(68).jpg                57  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(69).jpg                57  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(7).jpg                 57  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(70).jpg                57  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(71).jpg                57  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(72).jpg                57  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(73).jpg                57  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(74).jpg                57  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(75).jpg                57  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(76).jpg                58  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(77).jpg                58  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(78).jpg                58  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(79).jpg                58  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(8).jpg                 58  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(80).jpg                58  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(81).jpg                58  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(82).jpg                58  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(83).jpg                58  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(84).jpg                58  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(85).jpg                58  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(86).jpg                58  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(87).jpg                58  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(88).jpg                58  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(89).jpg                59  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(9).jpg                 59  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(90).jpg                59  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(91).jpg                59  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(92).jpg                59  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(93).jpg                59  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(94).jpg                59  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(95).jpg                59  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(96).jpg                59  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(97).jpg                59  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(98).jpg                59  OK \nExtracting  ./dataset2/train/PNEUMONIA/PNEUMONIA(99).jpg                59  OK \nCreating    ./dataset1                                                OK\nCreating    ./dataset1/test                                           OK\nCreating    ./dataset1/test/COVID                                     OK\nExtracting  ./dataset1/test/COVID/ryct.2020200034.fig2.jpeg             59  OK \nExtracting  ./dataset1/test/COVID/ryct.2020200034.fig5-day0.jpeg        59  OK \nExtracting  ./dataset1/test/COVID/ryct.2020200034.fig5-day4.jpeg        60  OK \nExtracting  ./dataset1/test/COVID/ryct.2020200034.fig5-day7.jpeg        60  OK \nExtracting  ./dataset1/test/COVID/SARS-10.1148rg.242035193-g04mr34g0-Fig8a-day0.jpeg    60  OK \nExtracting  ./dataset1/test/COVID/SARS-10.1148rg.242035193-g04mr34g0-Fig8b-day5.jpeg    60  OK \nExtracting  ./dataset1/test/COVID/SARS-10.1148rg.242035193-g04mr34g0-Fig8c-day10.jpeg    60  OK \nExtracting  ./dataset1/test/COVID/SARS-10.1148rg.242035193-g04mr34g04a-Fig4a-day7.jpeg    60  OK \nExtracting  ./dataset1/test/COVID/SARS-10.1148rg.242035193-g04mr34g04b-Fig4b-day12.jpeg    61  OK \nExtracting  ./dataset1/test/COVID/SARS-10.1148rg.242035193-g04mr34g05x-Fig5-day9.jpeg    61  OK \nExtracting  ./dataset1/test/COVID/SARS-10.1148rg.242035193-g04mr34g07a-Fig7a-day5.jpeg    61  OK \nExtracting  ./dataset1/test/COVID/SARS-10.1148rg.242035193-g04mr34g07b-Fig7b-day12.jpeg    61  OK \nExtracting  ./dataset1/test/COVID/SARS-10.1148rg.242035193-g04mr34g09a-Fig9a-day17.jpeg    61  OK \nExtracting  ./dataset1/test/COVID/SARS-10.1148rg.242035193-g04mr34g09b-Fig9b-day19.jpeg    61  OK \nExtracting  ./dataset1/test/COVID/SARS-10.1148rg.242035193-g04mr34g09c-Fig9c-day27.jpeg    61  OK \nExtracting  ./dataset1/test/COVID/streptococcus-pneumoniae-pneumonia-1.jpg    62  OK \nExtracting  ./dataset1/test/COVID/streptococcus-pneumoniae-pneumonia-temporal-evolution-1-day0.jpg    62  OK \nExtracting  ./dataset1/test/COVID/streptococcus-pneumoniae-pneumonia-temporal-evolution-1-day1.jpg    62  OK \nExtracting  ./dataset1/test/COVID/streptococcus-pneumoniae-pneumonia-temporal-evolution-1-day2.jpg    62  OK \nExtracting  ./dataset1/test/COVID/streptococcus-pneumoniae-pneumonia-temporal-evolution-1-day3.jpg    62  OK \nCreating    ./dataset1/test/NORMAL                                    OK\nExtracting  ./dataset1/test/NORMAL/NORMAL2-IM-0035-0001.jpeg            62  OK \nExtracting  ./dataset1/test/NORMAL/NORMAL2-IM-0052-0001.jpeg            62  OK \nExtracting  ./dataset1/test/NORMAL/NORMAL2-IM-0058-0001.jpeg            62  OK \nExtracting  ./dataset1/test/NORMAL/NORMAL2-IM-0059-0001.jpeg            62  OK \nExtracting  ./dataset1/test/NORMAL/NORMAL2-IM-0072-0001.jpeg            62  OK \nExtracting  ./dataset1/test/NORMAL/NORMAL2-IM-0073-0001.jpeg            63  OK \nExtracting  ./dataset1/test/NORMAL/NORMAL2-IM-0092-0001.jpeg            63  OK \nExtracting  ./dataset1/test/NORMAL/NORMAL2-IM-0105-0001.jpeg            63  OK \nExtracting  ./dataset1/test/NORMAL/NORMAL2-IM-0110-0001.jpeg            63  OK \nExtracting  ./dataset1/test/NORMAL/NORMAL2-IM-0111-0001.jpeg            63  OK \nExtracting  ./dataset1/test/NORMAL/NORMAL2-IM-0112-0001.jpeg            63  OK \nExtracting  ./dataset1/test/NORMAL/NORMAL2-IM-0117-0001.jpeg            63  OK \nExtracting  ./dataset1/test/NORMAL/NORMAL2-IM-0120-0001.jpeg            63  OK \nExtracting  ./dataset1/test/NORMAL/NORMAL2-IM-0123-0001.jpeg            63  OK \nExtracting  ./dataset1/test/NORMAL/NORMAL2-IM-0130-0001.jpeg            63  OK \nExtracting  ./dataset1/test/NORMAL/NORMAL2-IM-0131-0001.jpeg            63  OK \nExtracting  ./dataset1/test/NORMAL/NORMAL2-IM-0132-0001.jpeg            64  OK \nExtracting  ./dataset1/test/NORMAL/NORMAL2-IM-0139-0001.jpeg            64  OK \nExtracting  ./dataset1/test/NORMAL/NORMAL2-IM-0145-0001.jpeg            64  OK \nExtracting  ./dataset1/test/NORMAL/NORMAL2-IM-0171-0001.jpeg            64  OK \nCreating    ./dataset1/train                                          OK\nCreating    ./dataset1/train/COVID                                    OK\nExtracting  ./dataset1/train/COVID/01E392EE-69F9-4E33-BFCE-E5C968654078.jpeg    64  OK \nExtracting  ./dataset1/train/COVID/1-s2.0-S0140673620303706-fx1_lrg.jpg    64  OK \nExtracting  ./dataset1/train/COVID/1-s2.0-S1684118220300608-main.pdf-001.jpg    64  OK \nExtracting  ./dataset1/train/COVID/1-s2.0-S1684118220300608-main.pdf-002.jpg    64  OK \nExtracting  ./dataset1/train/COVID/1-s2.0-S1684118220300682-main.pdf-002-a1.png    64  OK \nExtracting  ./dataset1/train/COVID/1-s2.0-S1684118220300682-main.pdf-002-a2.png    64  OK \nExtracting  ./dataset1/train/COVID/1-s2.0-S1684118220300682-main.pdf-003-b1.png    64  OK \nExtracting  ./dataset1/train/COVID/1-s2.0-S1684118220300682-main.pdf-003-b2.png    65  OK \nExtracting  ./dataset1/train/COVID/1312A392-67A3-4EBF-9319-810CF6DA5EF6.jpeg    65  OK \nExtracting  ./dataset1/train/COVID/171CB377-62FF-4B76-906C-F3787A01CB2E.jpeg    65  OK \nExtracting  ./dataset1/train/COVID/1B734A89-A1BF-49A8-A1D3-66FAFA4FAC5D.jpeg    65  OK \nExtracting  ./dataset1/train/COVID/23E99E2E-447C-46E5-8EB2-D35D12473C39.png    66  OK \nExtracting  ./dataset1/train/COVID/2C10A413-AABE-4807-8CCE-6A2025594067.jpeg    6 70  OK \nExtracting  ./dataset1/train/COVID/2C26F453-AF3B-4517-BB9E-802CF2179543.jpeg    70  OK \nExtracting  ./dataset1/train/COVID/31BA3780-2323-493F-8AED-62081B9C383B.jpeg    70  OK \nExtracting  ./dataset1/train/COVID/39EE8E69-5801-48DE-B6E3-BE7D1BCF3092.jpeg    70  OK \nExtracting  ./dataset1/train/COVID/41591_2020_819_Fig1_HTML.webp-day10.png    70  OK \nExtracting  ./dataset1/train/COVID/41591_2020_819_Fig1_HTML.webp-day5.png    70  OK \nExtracting  ./dataset1/train/COVID/446B2CB6-B572-40AB-B01F-1910CA07086A.jpeg    71  OK \nExtracting  ./dataset1/train/COVID/5931B64A-7B97-485D-BE60-3F1EA76BC4F0.jpeg    71  OK \nExtracting  ./dataset1/train/COVID/5CBC2E94-D358-401E-8928-965CCD965C5C.jpeg    72  OK \nExtracting  ./dataset1/train/COVID/5e6dd879fde9502400e58b2f.jpeg        72  OK \nExtracting  ./dataset1/train/COVID/6CB4EFC6-68FA-4CD5-940C-BEFA8DAFE9A7.jpeg    73  OK \nExtracting  ./dataset1/train/COVID/7AF6C1AF-D249-4BD2-8C26-449304105D03.jpeg    73  OK \nExtracting  ./dataset1/train/COVID/7C69C012-7479-493F-8722-ABC29C60A2DD.jpeg    73  OK \nExtracting  ./dataset1/train/COVID/7D2CF6CE-F529-4470-8356-D33FFAF98600.jpeg    73  OK \nExtracting  ./dataset1/train/COVID/7E335538-2F86-424E-A0AB-6397783A38D0.jpeg    7 76  OK \nExtracting  ./dataset1/train/COVID/7EF28E12-F628-4BEC-A8C5-E6277C2E4F60.png    76  OK \nExtracting  ./dataset1/train/COVID/80446565-E090-4187-A031-9D3CEAA586C8.jpeg    76  OK \nExtracting  ./dataset1/train/COVID/85E52EB3-56E9-4D67-82DA-DEA247C82886.jpeg    77  OK \nExtracting  ./dataset1/train/COVID/8FDE8DBA-CFBD-4B4C-B1A4-6F36A93B7E87.jpeg    77  OK \nExtracting  ./dataset1/train/COVID/93FE0BB1-022D-4F24-9727-987A07975FFB.jpeg    77  OK \nExtracting  ./dataset1/train/COVID/9C34AF49-E589-44D5-92D3-168B3B04E4A6.jpeg    77  OK \nExtracting  ./dataset1/train/COVID/acute-respiratory-distress-syndrome-ards-1.jpg    77  OK \nExtracting  ./dataset1/train/COVID/all14238-fig-0001-m-b.jpg            77  OK \nExtracting  ./dataset1/train/COVID/all14238-fig-0001-m-c.jpg            77  OK \nExtracting  ./dataset1/train/COVID/all14238-fig-0002-m-e.jpg            77  OK \nExtracting  ./dataset1/train/COVID/ards-secondary-to-tiger-snake-bite.png    78  OK \nExtracting  ./dataset1/train/COVID/ARDSSevere.png                       78  OK \nExtracting  ./dataset1/train/COVID/auntminnie-2020_01_31_20_24_2322_2020_01_31_x-ray_coronavirus_US.jpg    78  OK \nExtracting  ./dataset1/train/COVID/auntminnie-b-2020_01_28_23_51_6665_2020_01_28_Vietnam_coronavirus.jpeg    78  OK \nExtracting  ./dataset1/train/COVID/auntminnie-c-2020_01_28_23_51_6665_2020_01_28_Vietnam_coronavirus.jpeg    78  OK \nExtracting  ./dataset1/train/COVID/auntminnie-d-2020_01_28_23_51_6665_2020_01_28_Vietnam_coronavirus.jpeg    78  OK \nExtracting  ./dataset1/train/COVID/B59DD164-51D5-40DF-A926-6A42DD52EBE8.jpeg    78  OK \nExtracting  ./dataset1/train/COVID/C6EA0BE5-B01E-4113-B194-18D956675E25.jpeg    79  OK \nExtracting  ./dataset1/train/COVID/CD50BA96-6982-4C80-AE7B-5F67ACDBFA56.jpeg    79  OK \nExtracting  ./dataset1/train/COVID/covid-19-pneumonia-12.jpg            80  OK \nExtracting  ./dataset1/train/COVID/covid-19-pneumonia-14-PA.png         82  OK \nExtracting  ./dataset1/train/COVID/covid-19-pneumonia-15-PA.jpg         83  OK \nExtracting  ./dataset1/train/COVID/covid-19-pneumonia-7-PA.jpg          83  OK \nExtracting  ./dataset1/train/COVID/E1724330-1866-4581-8CD8-CEC9B8AFEDDE.jpeg    8 87  OK \nExtracting  ./dataset1/train/COVID/E63574A7-4188-4C8D-8D17-9D67A18A1AFA.jpeg    87  OK \nExtracting  ./dataset1/train/COVID/F051E018-DAD1-4506-AD43-BE4CA29E960B.jpeg    87  OK \nExtracting  ./dataset1/train/COVID/F4341CE7-73C9-45C6-99C8-8567A5484B63.jpeg    87  OK \nExtracting  ./dataset1/train/COVID/F63AB6CE-1968-4154-A70F-913AF154F53D.jpeg    87  OK \nExtracting  ./dataset1/train/COVID/jkms-35-e79-g001-l-a.jpg             88  OK \nExtracting  ./dataset1/train/COVID/jkms-35-e79-g001-l-b.jpg             88  OK \nExtracting  ./dataset1/train/COVID/jkms-35-e79-g001-l-c.jpg             88  OK \nExtracting  ./dataset1/train/COVID/kjr-21-e24-g001-l-a.jpg              88  OK \nExtracting  ./dataset1/train/COVID/kjr-21-e24-g002-l-a.jpg              88  OK \nExtracting  ./dataset1/train/COVID/kjr-21-e24-g003-l-a.jpg              88  OK \nExtracting  ./dataset1/train/COVID/kjr-21-e25-g001-l-a.jpg              88  OK \nExtracting  ./dataset1/train/COVID/lancet-case2a.jpg                    88  OK \nExtracting  ./dataset1/train/COVID/MERS-CoV-1-s2.0-S0378603X1500248X-gr4e.jpg    88  OK \nExtracting  ./dataset1/train/COVID/nCoV-radiol.2020200269.fig1-day7.jpeg    88  OK \nExtracting  ./dataset1/train/COVID/nCoV-Snohomish-20382862_web1_M1-Lungs-EDH-200201-640x300@2x.jpg    88  OK \nExtracting  ./dataset1/train/COVID/nejmc2001573_f1a.jpeg                88  OK \nExtracting  ./dataset1/train/COVID/nejmc2001573_f1b.jpeg                88  OK \nExtracting  ./dataset1/train/COVID/nejmoa2001191_f1-PA.jpeg             88  OK \nExtracting  ./dataset1/train/COVID/nejmoa2001191_f3-PA.jpeg             88  OK \nExtracting  ./dataset1/train/COVID/nejmoa2001191_f4.jpeg                89  OK \nExtracting  ./dataset1/train/COVID/nejmoa2001191_f5-PA.jpeg             89  OK \nExtracting  ./dataset1/train/COVID/pneumocystis-pneumonia-2-PA.png      89  OK \nExtracting  ./dataset1/train/COVID/ryct.2020200028.fig1a.jpeg           90  OK \nCreating    ./dataset1/train/NORMAL                                   OK\nExtracting  ./dataset1/train/NORMAL/IM-0001-0001.jpeg                   90  OK \nExtracting  ./dataset1/train/NORMAL/IM-0003-0001.jpeg                   90  OK \nExtracting  ./dataset1/train/NORMAL/IM-0005-0001.jpeg                   90  OK \nExtracting  ./dataset1/train/NORMAL/IM-0006-0001.jpeg                   90  OK \nExtracting  ./dataset1/train/NORMAL/IM-0007-0001.jpeg                   91  OK \nExtracting  ./dataset1/train/NORMAL/IM-0009-0001.jpeg                   91  OK \nExtracting  ./dataset1/train/NORMAL/IM-0010-0001.jpeg                   91  OK \nExtracting  ./dataset1/train/NORMAL/IM-0011-0001-0001.jpeg              91  OK \nExtracting  ./dataset1/train/NORMAL/IM-0011-0001-0002.jpeg              91  OK \nExtracting  ./dataset1/train/NORMAL/IM-0011-0001.jpeg                   91  OK \nExtracting  ./dataset1/train/NORMAL/IM-0013-0001.jpeg                   92  OK \nExtracting  ./dataset1/train/NORMAL/IM-0015-0001.jpeg                   92  OK \nExtracting  ./dataset1/train/NORMAL/IM-0016-0001.jpeg                   92  OK \nExtracting  ./dataset1/train/NORMAL/IM-0017-0001.jpeg                   92  OK \nExtracting  ./dataset1/train/NORMAL/IM-0019-0001.jpeg                   92  OK \nExtracting  ./dataset1/train/NORMAL/IM-0021-0001.jpeg                   93  OK \nExtracting  ./dataset1/train/NORMAL/IM-0022-0001.jpeg                   93  OK \nExtracting  ./dataset1/train/NORMAL/IM-0023-0001.jpeg                   93  OK \nExtracting  ./dataset1/train/NORMAL/IM-0025-0001.jpeg                   93  OK \nExtracting  ./dataset1/train/NORMAL/IM-0027-0001.jpeg                   93  OK \nExtracting  ./dataset1/train/NORMAL/IM-0029-0001.jpeg                   94  OK \nExtracting  ./dataset1/train/NORMAL/IM-0030-0001.jpeg                   94  OK \nExtracting  ./dataset1/train/NORMAL/IM-0031-0001.jpeg                   94  OK \nExtracting  ./dataset1/train/NORMAL/IM-0033-0001-0001.jpeg              94  OK \nExtracting  ./dataset1/train/NORMAL/IM-0033-0001-0002.jpeg              94  OK \nExtracting  ./dataset1/train/NORMAL/IM-0033-0001.jpeg                   94  OK \nExtracting  ./dataset1/train/NORMAL/IM-0035-0001.jpeg                   95  OK \nExtracting  ./dataset1/train/NORMAL/IM-0036-0001.jpeg                   95  OK \nExtracting  ./dataset1/train/NORMAL/IM-0037-0001.jpeg                   95  OK \nExtracting  ./dataset1/train/NORMAL/IM-0039-0001.jpeg                   95  OK \nExtracting  ./dataset1/train/NORMAL/IM-0041-0001.jpeg                   95  OK \nExtracting  ./dataset1/train/NORMAL/IM-0043-0001.jpeg                   96  OK \nExtracting  ./dataset1/train/NORMAL/IM-0045-0001.jpeg                   96  OK \nExtracting  ./dataset1/train/NORMAL/IM-0046-0001.jpeg                   96  OK \nExtracting  ./dataset1/train/NORMAL/IM-0049-0001.jpeg                   96  OK \nExtracting  ./dataset1/train/NORMAL/IM-0050-0001.jpeg                   96  OK \nExtracting  ./dataset1/train/NORMAL/IM-0059-0001.jpeg                   96  OK \nExtracting  ./dataset1/train/NORMAL/IM-0061-0001.jpeg                   96  OK \nExtracting  ./dataset1/train/NORMAL/IM-0063-0001.jpeg                   97  OK \nExtracting  ./dataset1/train/NORMAL/IM-0069-0001.jpeg                   97  OK \nExtracting  ./dataset1/train/NORMAL/IM-0070-0001.jpeg                   97  OK \nExtracting  ./dataset1/train/NORMAL/IM-0071-0001.jpeg                   97  OK \nExtracting  ./dataset1/train/NORMAL/IM-0073-0001.jpeg                   97  OK \nExtracting  ./dataset1/train/NORMAL/IM-0075-0001.jpeg                   97  OK \nExtracting  ./dataset1/train/NORMAL/IM-0077-0001.jpeg                   97  OK \nExtracting  ./dataset1/train/NORMAL/IM-0079-0001.jpeg                   97  OK \nExtracting  ./dataset1/train/NORMAL/IM-0081-0001.jpeg                   97  OK \nExtracting  ./dataset1/train/NORMAL/IM-0083-0001.jpeg                   97  OK \nExtracting  ./dataset1/train/NORMAL/IM-0084-0001.jpeg                   97  OK \nExtracting  ./dataset1/train/NORMAL/IM-0085-0001.jpeg                   97  OK \nExtracting  ./dataset1/train/NORMAL/IM-0086-0001.jpeg                   97  OK \nExtracting  ./dataset1/train/NORMAL/IM-0087-0001.jpeg                   98  OK \nExtracting  ./dataset1/train/NORMAL/IM-0089-0001.jpeg                   98  OK \nExtracting  ./dataset1/train/NORMAL/IM-0091-0001.jpeg                   98  OK \nExtracting  ./dataset1/train/NORMAL/IM-0093-0001.jpeg                   98  OK \nExtracting  ./dataset1/train/NORMAL/IM-0095-0001.jpeg                   98  OK \nExtracting  ./dataset1/train/NORMAL/IM-0097-0001.jpeg                   98  OK \nExtracting  ./dataset1/train/NORMAL/IM-0099-0001.jpeg                   98  OK \nExtracting  ./dataset1/train/NORMAL/IM-0101-0001.jpeg                   98  OK \nExtracting  ./dataset1/train/NORMAL/IM-0102-0001.jpeg                   98  OK \nExtracting  ./dataset1/train/NORMAL/IM-0103-0001.jpeg                   98  OK \nExtracting  ./dataset1/train/NORMAL/IM-0105-0001.jpeg                   98  OK \nExtracting  ./dataset1/train/NORMAL/IM-0107-0001.jpeg                   98  OK \nExtracting  ./dataset1/train/NORMAL/IM-0110-0001.jpeg                   98  OK \nExtracting  ./dataset1/train/NORMAL/IM-0111-0001.jpeg                   99  OK \nExtracting  ./dataset1/train/NORMAL/NORMAL2-IM-0007-0001.jpeg           99  OK \nExtracting  ./dataset1/train/NORMAL/NORMAL2-IM-0012-0001.jpeg           99  OK \nExtracting  ./dataset1/train/NORMAL/NORMAL2-IM-0013-0001.jpeg           99  OK \nExtracting  ./dataset1/train/NORMAL/NORMAL2-IM-0023-0001.jpeg           99  OK \nExtracting  ./dataset1/train/NORMAL/NORMAL2-IM-0027-0001.jpeg           99  OK \nExtracting  ./dataset1/train/NORMAL/NORMAL2-IM-0028-0001.jpeg           99  OK \nExtracting  ./dataset1/train/NORMAL/NORMAL2-IM-0029-0001.jpeg           99  OK \nExtracting  ./dataset1/train/NORMAL/NORMAL2-IM-0030-0001.jpeg           99  OK \nExtracting  ./dataset1/train/NORMAL/NORMAL2-IM-0033-0001.jpeg           99  OK \nAll OK\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"X_train, y_train, X_test, y_test = load_dataset()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T19:19:08.513774Z","iopub.execute_input":"2025-02-07T19:19:08.514069Z","iopub.status.idle":"2025-02-07T19:19:15.847123Z","shell.execute_reply.started":"2025-02-07T19:19:08.514047Z","shell.execute_reply":"2025-02-07T19:19:15.846471Z"}},"outputs":[],"execution_count":74},{"cell_type":"code","source":"num_train = X_train.shape[0]\nnum_test = X_test.shape[0]\nnum_covid = sum(y_train[y_train==1]) + sum(y_test[y_test==1])\nprint(f\"Number of Training Samples: {num_train}\\nNumber of Test Samples: {num_test}\\nNumber of COVID samples: {num_covid}\\nNumber of Normal samples: {num_train + num_test - num_covid}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T22:00:31.978741Z","iopub.execute_input":"2025-02-07T22:00:31.979018Z","iopub.status.idle":"2025-02-07T22:00:31.983648Z","shell.execute_reply.started":"2025-02-07T22:00:31.978996Z","shell.execute_reply":"2025-02-07T22:00:31.982783Z"}},"outputs":[{"name":"stdout","text":"Number of Training Samples: 148\nNumber of Test Samples: 40\nNumber of COVID samples: 94\nNumber of Normal samples: 94\n","output_type":"stream"}],"execution_count":147},{"cell_type":"markdown","source":"## 1.3 CNN Architecture","metadata":{}},{"cell_type":"code","source":"def define_model(input_shape=(150,150,3), lr=0.001):\n    model = Sequential(\n        [\n            # Input\n            Input(shape=input_shape),\n            \n            # Conv1\n            Conv2D(64, kernel_size=(3,3), activation='relu', padding='same'),\n            BatchNormalization(axis=-1),\n            MaxPooling2D(pool_size=(2,2)),\n            Dropout(0.2),\n\n            # Conv2\n            Conv2D(64, kernel_size=(3,3), activation='relu', padding='same'),\n            BatchNormalization(axis=-1),\n            MaxPooling2D(pool_size=(2,2)),\n            Dropout(0.2),\n\n            # Conv3\n            Conv2D(128, kernel_size=(3,3), activation='relu', padding='same'),\n            BatchNormalization(axis=-1),\n            MaxPooling2D(pool_size=(2,2)),\n            Dropout(0.2),\n\n            # Conv4\n            Conv2D(128, kernel_size=(3,3), activation='relu', padding='same'),\n            BatchNormalization(axis=-1),\n            MaxPooling2D(pool_size=(2,2)),\n            Dropout(0.2),\n\n            # Conv5\n            Conv2D(256, kernel_size=(3,3), activation='relu', padding='same'),\n            BatchNormalization(axis=-1),\n            MaxPooling2D(pool_size=(2,2)),\n            Dropout(0.2),\n\n            # Conv6\n            Conv2D(256, kernel_size=(3,3), activation='relu', padding='same'),\n            BatchNormalization(axis=-1),\n            MaxPooling2D(pool_size=(2,2)),\n            Dropout(0.2),\n\n            # Flatten Layer\n            Flatten(),\n\n            # FCL\n            Dense(512, activation='relu'),\n            BatchNormalization(axis=-1),\n            Dense(256, activation='relu'),\n            BatchNormalization(axis=-1),\n\n            # Output\n            Dense(1, activation='sigmoid')\n        ]\n    )\n\n    model.compile(\n        optimizer=Adam(learning_rate=lr),\n        loss='binary_crossentropy',\n        metrics=['accuracy']\n    )\n\n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T17:14:44.193916Z","iopub.execute_input":"2025-02-07T17:14:44.194341Z","iopub.status.idle":"2025-02-07T17:14:44.203562Z","shell.execute_reply.started":"2025-02-07T17:14:44.194310Z","shell.execute_reply":"2025-02-07T17:14:44.202478Z"}},"outputs":[],"execution_count":44},{"cell_type":"markdown","source":"## 1.4 Train & Evaluation of model with k-fold cross-validation","metadata":{}},{"cell_type":"code","source":"def train_evaluate_model_with_k_fold(X_train, y_train, lr=0.01, epochs=50, batch_size=16, output_model=False):\n    \n    skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=33)\n\n    fold_no = 1\n    train_acc_scores = []\n    val_acc_scores = []\n    \n    for train_index, val_index in skf.split(X_train, y_train):\n        print(f\"\\nTraining on Fold {fold_no}...\")\n        \n        X_tr, X_val = X_train[train_index], X_train[val_index]\n        y_tr, y_val = y_train[train_index], y_train[val_index]\n        \n        # Recreate a fresh model for each fold\n        model = define_model(input_shape=(150,150,3), lr=lr)\n        \n        history = model.fit(\n            X_tr, y_tr,\n            validation_data=(X_val, y_val),\n            epochs=epochs,\n            batch_size=batch_size,\n            callbacks=[\n                EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True, verbose=1),\n                ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1)\n            ],\n            verbose=1,\n            shuffle=True\n        )\n        \n        # Evaluate the model on the fold's training and validation sets\n        train_loss, train_acc = model.evaluate(X_tr, y_tr, verbose=0)\n        val_loss, val_acc = model.evaluate(X_val, y_val, verbose=0)\n        \n        print(f\"Fold {fold_no} - Train Accuracy: {train_acc*100:.2f}%, Validation Accuracy: {val_acc*100:.2f}%\")\n        train_acc_scores.append(train_acc)\n        val_acc_scores.append(val_acc)\n        \n        fold_no += 1\n    \n    print(\"\\nAverage Training Accuracy: {:.2f}%\".format(np.mean(train_acc_scores)*100))\n    print(\"Average Validation Accuracy: {:.2f}%\".format(np.mean(val_acc_scores)*100))\n\n    if output_model:\n        return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T21:32:07.591730Z","iopub.execute_input":"2025-02-07T21:32:07.592030Z","iopub.status.idle":"2025-02-07T21:32:07.599370Z","shell.execute_reply.started":"2025-02-07T21:32:07.592007Z","shell.execute_reply":"2025-02-07T21:32:07.598490Z"}},"outputs":[],"execution_count":123},{"cell_type":"markdown","source":"# 2 Data Collection and Image Preprocessing","metadata":{}},{"cell_type":"markdown","source":"## 2.0 Evaluation before adding augmented dataset","metadata":{}},{"cell_type":"code","source":"train_evaluate_model_with_k_fold(X_train, y_train, lr=0.01, epochs=50, batch_size=16)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T20:01:36.341934Z","iopub.execute_input":"2025-02-07T20:01:36.342226Z","iopub.status.idle":"2025-02-07T20:05:41.528033Z","shell.execute_reply.started":"2025-02-07T20:01:36.342203Z","shell.execute_reply":"2025-02-07T20:05:41.527262Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"\nTraining on Fold 1...\nEpoch 1/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 885ms/step - accuracy: 0.6716 - loss: 1.1087 - val_accuracy: 0.4667 - val_loss: 12465.7129 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8765 - loss: 0.4161 - val_accuracy: 0.4667 - val_loss: 883.4987 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9377 - loss: 0.1560 - val_accuracy: 0.4667 - val_loss: 1059.7609 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9854 - loss: 0.0820 - val_accuracy: 0.4667 - val_loss: 206.0867 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9867 - loss: 0.0418 - val_accuracy: 0.4667 - val_loss: 31.8108 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0326 - val_accuracy: 0.5333 - val_loss: 38.1015 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0107 - val_accuracy: 0.5333 - val_loss: 18.0174 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0040 - val_accuracy: 0.6000 - val_loss: 6.1719 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0050 - val_accuracy: 0.6000 - val_loss: 6.2366 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0046 - val_accuracy: 0.6000 - val_loss: 3.7785 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0033 - val_accuracy: 0.8000 - val_loss: 1.1556 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.7333 - val_loss: 1.2924 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.6667 - val_loss: 1.5341 - learning_rate: 0.0100\nEpoch 14/50\n\u001b[1m7/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 6.9206e-04\nEpoch 14: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 7.2345e-04 - val_accuracy: 0.6000 - val_loss: 1.8807 - learning_rate: 0.0100\nEpoch 15/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.6000 - val_loss: 1.8409 - learning_rate: 1.0000e-03\nEpoch 16/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 8.0861e-04 - val_accuracy: 0.6667 - val_loss: 1.7107 - learning_rate: 1.0000e-03\nEpoch 16: early stopping\nRestoring model weights from the end of the best epoch: 11.\nFold 1 - Train Accuracy: 60.15%, Validation Accuracy: 80.00%\n\nTraining on Fold 2...\nEpoch 1/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 754ms/step - accuracy: 0.7375 - loss: 0.6620 - val_accuracy: 0.5333 - val_loss: 7886.8574 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8837 - loss: 0.3516 - val_accuracy: 0.6000 - val_loss: 915.2784 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9080 - loss: 0.2801 - val_accuracy: 0.5333 - val_loss: 386.3588 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9592 - loss: 0.1436 - val_accuracy: 0.5333 - val_loss: 340.5612 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9444 - loss: 0.0915 - val_accuracy: 0.5333 - val_loss: 131.0680 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9495 - loss: 0.0913 - val_accuracy: 0.5333 - val_loss: 56.9932 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9715 - loss: 0.0744 - val_accuracy: 0.5333 - val_loss: 22.0873 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9958 - loss: 0.0242 - val_accuracy: 0.5333 - val_loss: 10.5532 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9792 - loss: 0.0467 - val_accuracy: 0.6000 - val_loss: 5.6033 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9815 - loss: 0.0402 - val_accuracy: 0.6000 - val_loss: 6.3514 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0110 - val_accuracy: 0.6000 - val_loss: 5.1115 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0078 - val_accuracy: 0.8000 - val_loss: 2.0723 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9977 - loss: 0.0107 - val_accuracy: 0.8000 - val_loss: 1.9418 - learning_rate: 0.0100\nEpoch 14/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9954 - loss: 0.0196 - val_accuracy: 0.6000 - val_loss: 4.4229 - learning_rate: 0.0100\nEpoch 15/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9903 - loss: 0.0539 - val_accuracy: 0.8000 - val_loss: 1.6030 - learning_rate: 0.0100\nEpoch 16/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9838 - loss: 0.0498 - val_accuracy: 0.7333 - val_loss: 2.1197 - learning_rate: 0.0100\nEpoch 17/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9977 - loss: 0.0225 - val_accuracy: 0.6667 - val_loss: 3.7783 - learning_rate: 0.0100\nEpoch 18/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9815 - loss: 0.0389 - val_accuracy: 0.9333 - val_loss: 0.2081 - learning_rate: 0.0100\nEpoch 19/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9560 - loss: 0.0847 - val_accuracy: 0.8667 - val_loss: 0.3722 - learning_rate: 0.0100\nEpoch 20/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0127 - val_accuracy: 0.8667 - val_loss: 0.4019 - learning_rate: 0.0100\nEpoch 21/50\n\u001b[1m7/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0035\nEpoch 21: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0048 - val_accuracy: 0.8000 - val_loss: 0.3173 - learning_rate: 0.0100\nEpoch 22/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0051 - val_accuracy: 0.8000 - val_loss: 0.4566 - learning_rate: 1.0000e-03\nEpoch 23/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0049 - val_accuracy: 0.8000 - val_loss: 0.5684 - learning_rate: 1.0000e-03\nEpoch 23: early stopping\nRestoring model weights from the end of the best epoch: 18.\nFold 2 - Train Accuracy: 94.74%, Validation Accuracy: 93.33%\n\nTraining on Fold 3...\nEpoch 1/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 765ms/step - accuracy: 0.6695 - loss: 1.4414 - val_accuracy: 0.5333 - val_loss: 301.3988 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9007 - loss: 0.2649 - val_accuracy: 0.4667 - val_loss: 1160.6516 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9750 - loss: 0.0983 - val_accuracy: 0.5333 - val_loss: 135.2151 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9775 - loss: 0.0699 - val_accuracy: 0.5333 - val_loss: 74.2654 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9958 - loss: 0.0306 - val_accuracy: 0.5333 - val_loss: 63.1838 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9871 - loss: 0.0378 - val_accuracy: 0.6667 - val_loss: 5.2567 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9958 - loss: 0.0225 - val_accuracy: 0.5333 - val_loss: 18.2138 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9930 - loss: 0.0199 - val_accuracy: 0.5333 - val_loss: 23.8600 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m7/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9902 - loss: 0.0215\nEpoch 9: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9909 - loss: 0.0215 - val_accuracy: 0.6000 - val_loss: 11.2142 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0088 - val_accuracy: 0.5333 - val_loss: 6.4387 - learning_rate: 1.0000e-03\nEpoch 11/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0114 - val_accuracy: 0.5333 - val_loss: 3.6848 - learning_rate: 1.0000e-03\nEpoch 12/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9958 - loss: 0.0130 - val_accuracy: 0.6000 - val_loss: 2.0157 - learning_rate: 1.0000e-03\nEpoch 13/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0081 - val_accuracy: 0.6667 - val_loss: 1.0853 - learning_rate: 1.0000e-03\nEpoch 14/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0063 - val_accuracy: 0.7333 - val_loss: 0.6190 - learning_rate: 1.0000e-03\nEpoch 15/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0046 - val_accuracy: 0.8000 - val_loss: 0.3415 - learning_rate: 1.0000e-03\nEpoch 16/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0061 - val_accuracy: 0.8667 - val_loss: 0.2312 - learning_rate: 1.0000e-03\nEpoch 17/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9958 - loss: 0.0089 - val_accuracy: 0.9333 - val_loss: 0.1432 - learning_rate: 1.0000e-03\nEpoch 18/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9977 - loss: 0.0059 - val_accuracy: 1.0000 - val_loss: 0.0724 - learning_rate: 1.0000e-03\nEpoch 19/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0049 - val_accuracy: 1.0000 - val_loss: 0.0775 - learning_rate: 1.0000e-03\nEpoch 20/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0044 - val_accuracy: 0.9333 - val_loss: 0.1076 - learning_rate: 1.0000e-03\nEpoch 21/50\n\u001b[1m7/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0041\nEpoch 21: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0043 - val_accuracy: 0.9333 - val_loss: 0.1341 - learning_rate: 1.0000e-03\nEpoch 22/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0032 - val_accuracy: 0.9333 - val_loss: 0.1508 - learning_rate: 1.0000e-04\nEpoch 23/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0032 - val_accuracy: 0.9333 - val_loss: 0.1602 - learning_rate: 1.0000e-04\nEpoch 23: early stopping\nRestoring model weights from the end of the best epoch: 18.\nFold 3 - Train Accuracy: 81.95%, Validation Accuracy: 100.00%\n\nTraining on Fold 4...\nEpoch 1/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 758ms/step - accuracy: 0.6544 - loss: 0.9348 - val_accuracy: 0.5333 - val_loss: 387.9161 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9537 - loss: 0.2127 - val_accuracy: 0.4667 - val_loss: 643.5619 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9328 - loss: 0.1788 - val_accuracy: 0.4667 - val_loss: 3484.5117 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9739 - loss: 0.0805 - val_accuracy: 0.4667 - val_loss: 377.8097 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9903 - loss: 0.0458 - val_accuracy: 0.4667 - val_loss: 139.7285 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9916 - loss: 0.0230 - val_accuracy: 0.4667 - val_loss: 46.0601 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9958 - loss: 0.0214 - val_accuracy: 0.5333 - val_loss: 18.4508 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0085 - val_accuracy: 0.7333 - val_loss: 7.7101 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0034 - val_accuracy: 0.8000 - val_loss: 5.9020 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9985 - loss: 0.0100 - val_accuracy: 0.7333 - val_loss: 6.5947 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9935 - loss: 0.0162 - val_accuracy: 0.7333 - val_loss: 6.5569 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m7/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9902 - loss: 0.0346\nEpoch 12: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9909 - loss: 0.0330 - val_accuracy: 0.5333 - val_loss: 7.4810 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9854 - loss: 0.0274 - val_accuracy: 0.5333 - val_loss: 5.5711 - learning_rate: 1.0000e-03\nEpoch 14/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9945 - loss: 0.0243 - val_accuracy: 0.6000 - val_loss: 3.2783 - learning_rate: 1.0000e-03\nEpoch 15/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0095 - val_accuracy: 0.6000 - val_loss: 1.7324 - learning_rate: 1.0000e-03\nEpoch 16/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9909 - loss: 0.0201 - val_accuracy: 0.6667 - val_loss: 1.1653 - learning_rate: 1.0000e-03\nEpoch 17/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0035 - val_accuracy: 0.8000 - val_loss: 0.5294 - learning_rate: 1.0000e-03\nEpoch 18/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9878 - loss: 0.0129 - val_accuracy: 0.9333 - val_loss: 0.1498 - learning_rate: 1.0000e-03\nEpoch 19/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 1.0000 - val_loss: 0.0464 - learning_rate: 1.0000e-03\nEpoch 20/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0036 - val_accuracy: 1.0000 - val_loss: 0.0214 - learning_rate: 1.0000e-03\nEpoch 21/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 1.0000 - val_loss: 0.0483 - learning_rate: 1.0000e-03\nEpoch 22/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0044 - val_accuracy: 0.9333 - val_loss: 0.0909 - learning_rate: 1.0000e-03\nEpoch 23/50\n\u001b[1m7/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0012    \nEpoch 23: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.9333 - val_loss: 0.1089 - learning_rate: 1.0000e-03\nEpoch 24/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.9333 - val_loss: 0.1164 - learning_rate: 1.0000e-04\nEpoch 25/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.9333 - val_loss: 0.1159 - learning_rate: 1.0000e-04\nEpoch 25: early stopping\nRestoring model weights from the end of the best epoch: 20.\nFold 4 - Train Accuracy: 94.74%, Validation Accuracy: 100.00%\n\nTraining on Fold 5...\nEpoch 1/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 779ms/step - accuracy: 0.6810 - loss: 1.0574 - val_accuracy: 0.5333 - val_loss: 17272.9395 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9064 - loss: 0.2461 - val_accuracy: 0.4667 - val_loss: 354.2272 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9583 - loss: 0.1495 - val_accuracy: 0.4667 - val_loss: 189.4381 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9876 - loss: 0.0625 - val_accuracy: 0.6000 - val_loss: 29.6793 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0312 - val_accuracy: 0.4667 - val_loss: 292.3539 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9922 - loss: 0.0512 - val_accuracy: 0.4667 - val_loss: 259.6829 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m7/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9723 - loss: 0.0404\nEpoch 7: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9760 - loss: 0.0363 - val_accuracy: 0.4667 - val_loss: 59.4705 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0158 - val_accuracy: 0.4667 - val_loss: 34.3677 - learning_rate: 1.0000e-03\nEpoch 9/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9855 - loss: 0.0222 - val_accuracy: 0.4667 - val_loss: 24.2294 - learning_rate: 1.0000e-03\nEpoch 10/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0088 - val_accuracy: 0.4667 - val_loss: 17.2175 - learning_rate: 1.0000e-03\nEpoch 11/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0070 - val_accuracy: 0.5333 - val_loss: 11.6263 - learning_rate: 1.0000e-03\nEpoch 12/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0105 - val_accuracy: 0.5333 - val_loss: 7.5757 - learning_rate: 1.0000e-03\nEpoch 13/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0079 - val_accuracy: 0.5333 - val_loss: 4.6189 - learning_rate: 1.0000e-03\nEpoch 14/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0052 - val_accuracy: 0.5333 - val_loss: 2.8495 - learning_rate: 1.0000e-03\nEpoch 15/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0039 - val_accuracy: 0.6667 - val_loss: 2.0877 - learning_rate: 1.0000e-03\nEpoch 16/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0061 - val_accuracy: 0.6667 - val_loss: 1.7129 - learning_rate: 1.0000e-03\nEpoch 17/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0083 - val_accuracy: 0.6667 - val_loss: 1.6493 - learning_rate: 1.0000e-03\nEpoch 18/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0039 - val_accuracy: 0.6667 - val_loss: 1.4460 - learning_rate: 1.0000e-03\nEpoch 19/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0094 - val_accuracy: 0.7333 - val_loss: 1.2664 - learning_rate: 1.0000e-03\nEpoch 20/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0094 - val_accuracy: 0.7333 - val_loss: 0.9668 - learning_rate: 1.0000e-03\nEpoch 21/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9878 - loss: 0.0180 - val_accuracy: 0.8000 - val_loss: 0.8645 - learning_rate: 1.0000e-03\nEpoch 22/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 0.8667 - val_loss: 0.7771 - learning_rate: 1.0000e-03\nEpoch 23/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9945 - loss: 0.0122 - val_accuracy: 0.8667 - val_loss: 0.7016 - learning_rate: 1.0000e-03\nEpoch 24/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0023 - val_accuracy: 0.8667 - val_loss: 0.6534 - learning_rate: 1.0000e-03\nEpoch 25/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0050 - val_accuracy: 0.9333 - val_loss: 0.6208 - learning_rate: 1.0000e-03\nEpoch 26/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.9333 - val_loss: 0.6016 - learning_rate: 1.0000e-03\nEpoch 27/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0039 - val_accuracy: 0.9333 - val_loss: 0.5841 - learning_rate: 1.0000e-03\nEpoch 28/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.9333 - val_loss: 0.5646 - learning_rate: 1.0000e-03\nEpoch 29/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 0.9333 - val_loss: 0.5463 - learning_rate: 1.0000e-03\nEpoch 30/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0036 - val_accuracy: 0.9333 - val_loss: 0.5281 - learning_rate: 1.0000e-03\nEpoch 31/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.9333 - val_loss: 0.5151 - learning_rate: 1.0000e-03\nEpoch 32/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.9333 - val_loss: 0.5078 - learning_rate: 1.0000e-03\nEpoch 33/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.9333 - val_loss: 0.5055 - learning_rate: 1.0000e-03\nEpoch 34/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0023 - val_accuracy: 0.9333 - val_loss: 0.5016 - learning_rate: 1.0000e-03\nEpoch 35/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.9333 - val_loss: 0.5007 - learning_rate: 1.0000e-03\nEpoch 36/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.9333 - val_loss: 0.4971 - learning_rate: 1.0000e-03\nEpoch 37/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 0.9333 - val_loss: 0.4922 - learning_rate: 1.0000e-03\nEpoch 38/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.9333 - val_loss: 0.4893 - learning_rate: 1.0000e-03\nEpoch 39/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.9333 - val_loss: 0.4871 - learning_rate: 1.0000e-03\nEpoch 40/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.9333 - val_loss: 0.4864 - learning_rate: 1.0000e-03\nEpoch 41/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 9.5835e-04 - val_accuracy: 0.9333 - val_loss: 0.4850 - learning_rate: 1.0000e-03\nEpoch 42/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.9333 - val_loss: 0.4825 - learning_rate: 1.0000e-03\nEpoch 43/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.9333 - val_loss: 0.4811 - learning_rate: 1.0000e-03\nEpoch 44/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.9333 - val_loss: 0.4785 - learning_rate: 1.0000e-03\nEpoch 45/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 8.3462e-04 - val_accuracy: 0.9333 - val_loss: 0.4753 - learning_rate: 1.0000e-03\nEpoch 46/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 0.9333 - val_loss: 0.4681 - learning_rate: 1.0000e-03\nEpoch 47/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 8.4460e-04 - val_accuracy: 0.9333 - val_loss: 0.4626 - learning_rate: 1.0000e-03\nEpoch 48/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.9333 - val_loss: 0.4552 - learning_rate: 1.0000e-03\nEpoch 49/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.9333 - val_loss: 0.4494 - learning_rate: 1.0000e-03\nEpoch 50/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 9.2122e-04 - val_accuracy: 0.9333 - val_loss: 0.4498 - learning_rate: 1.0000e-03\nRestoring model weights from the end of the best epoch: 49.\nFold 5 - Train Accuracy: 100.00%, Validation Accuracy: 93.33%\n\nTraining on Fold 6...\nEpoch 1/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 762ms/step - accuracy: 0.6717 - loss: 1.1966 - val_accuracy: 0.4667 - val_loss: 3614.4275 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8561 - loss: 0.4010 - val_accuracy: 0.2667 - val_loss: 345.6579 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9098 - loss: 0.2026 - val_accuracy: 0.5333 - val_loss: 167.4444 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9624 - loss: 0.1183 - val_accuracy: 0.5333 - val_loss: 95.4086 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9668 - loss: 0.0754 - val_accuracy: 0.5333 - val_loss: 35.4747 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9842 - loss: 0.0530 - val_accuracy: 0.5333 - val_loss: 10.2827 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9777 - loss: 0.0627 - val_accuracy: 0.5333 - val_loss: 6.3157 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9977 - loss: 0.0384 - val_accuracy: 0.3333 - val_loss: 2.2337 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9977 - loss: 0.0174 - val_accuracy: 0.4000 - val_loss: 2.2173 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0141 - val_accuracy: 0.4667 - val_loss: 3.2752 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9783 - loss: 0.0352 - val_accuracy: 0.5333 - val_loss: 4.3769 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m7/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0068\nEpoch 12: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9977 - loss: 0.0120 - val_accuracy: 0.7333 - val_loss: 2.4426 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0062 - val_accuracy: 0.7333 - val_loss: 1.7223 - learning_rate: 1.0000e-03\nEpoch 14/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0058 - val_accuracy: 0.8667 - val_loss: 1.3436 - learning_rate: 1.0000e-03\nEpoch 15/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0076 - val_accuracy: 0.8667 - val_loss: 1.0805 - learning_rate: 1.0000e-03\nEpoch 16/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0067 - val_accuracy: 0.9333 - val_loss: 0.8693 - learning_rate: 1.0000e-03\nEpoch 17/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0043 - val_accuracy: 0.9333 - val_loss: 0.7113 - learning_rate: 1.0000e-03\nEpoch 18/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0046 - val_accuracy: 0.9333 - val_loss: 0.5562 - learning_rate: 1.0000e-03\nEpoch 19/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0031 - val_accuracy: 0.9333 - val_loss: 0.4615 - learning_rate: 1.0000e-03\nEpoch 20/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0043 - val_accuracy: 0.9333 - val_loss: 0.3651 - learning_rate: 1.0000e-03\nEpoch 21/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.9333 - val_loss: 0.2712 - learning_rate: 1.0000e-03\nEpoch 22/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0049 - val_accuracy: 0.9333 - val_loss: 0.2093 - learning_rate: 1.0000e-03\nEpoch 23/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.9333 - val_loss: 0.1486 - learning_rate: 1.0000e-03\nEpoch 24/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.9333 - val_loss: 0.0671 - learning_rate: 1.0000e-03\nEpoch 25/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 1.0000 - val_loss: 0.0307 - learning_rate: 1.0000e-03\nEpoch 26/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 1.0000 - val_loss: 0.0125 - learning_rate: 1.0000e-03\nEpoch 27/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 1.0000 - val_loss: 0.0056 - learning_rate: 1.0000e-03\nEpoch 28/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 1.0000 - val_loss: 0.0035 - learning_rate: 1.0000e-03\nEpoch 29/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 1.0000 - val_loss: 0.0028 - learning_rate: 1.0000e-03\nEpoch 30/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 1.0000 - val_loss: 0.0025 - learning_rate: 1.0000e-03\nEpoch 31/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 1.0000 - val_loss: 0.0022 - learning_rate: 1.0000e-03\nEpoch 32/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 1.0000 - val_loss: 0.0021 - learning_rate: 1.0000e-03\nEpoch 33/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 1.0000 - val_loss: 0.0022 - learning_rate: 1.0000e-03\nEpoch 34/50\n\u001b[1m7/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0013    \nEpoch 34: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0023 - val_accuracy: 1.0000 - val_loss: 0.0025 - learning_rate: 1.0000e-03\nEpoch 35/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 1.0000 - val_loss: 0.0030 - learning_rate: 1.0000e-04\nEpoch 36/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0035 - val_accuracy: 1.0000 - val_loss: 0.0036 - learning_rate: 1.0000e-04\nEpoch 37/50\n\u001b[1m7/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 9.4305e-04\nEpoch 37: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 1.0000 - val_loss: 0.0048 - learning_rate: 1.0000e-04\nEpoch 37: early stopping\nRestoring model weights from the end of the best epoch: 32.\nFold 6 - Train Accuracy: 97.74%, Validation Accuracy: 100.00%\n\nTraining on Fold 7...\nEpoch 1/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 767ms/step - accuracy: 0.7689 - loss: 0.9487 - val_accuracy: 0.5333 - val_loss: 3646.8135 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8375 - loss: 0.4361 - val_accuracy: 0.5333 - val_loss: 1631.9688 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9443 - loss: 0.1562 - val_accuracy: 0.5333 - val_loss: 95.2392 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9630 - loss: 0.0992 - val_accuracy: 0.4667 - val_loss: 229.8753 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9844 - loss: 0.0453 - val_accuracy: 0.4667 - val_loss: 80.3652 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0268 - val_accuracy: 0.4667 - val_loss: 56.1819 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0219 - val_accuracy: 0.4667 - val_loss: 39.8879 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0078 - val_accuracy: 0.4667 - val_loss: 32.3757 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0060 - val_accuracy: 0.5333 - val_loss: 11.9778 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0049 - val_accuracy: 0.6000 - val_loss: 4.1707 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.6000 - val_loss: 3.2083 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.7333 - val_loss: 2.0536 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9783 - loss: 0.0275 - val_accuracy: 0.6667 - val_loss: 2.4578 - learning_rate: 0.0100\nEpoch 14/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9777 - loss: 0.0407 - val_accuracy: 0.7333 - val_loss: 1.0755 - learning_rate: 0.0100\nEpoch 15/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9768 - loss: 0.0966 - val_accuracy: 0.6000 - val_loss: 5.5854 - learning_rate: 0.0100\nEpoch 16/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9379 - loss: 0.1863 - val_accuracy: 1.0000 - val_loss: 0.0299 - learning_rate: 0.0100\nEpoch 17/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9977 - loss: 0.0243 - val_accuracy: 0.6000 - val_loss: 4.1563 - learning_rate: 0.0100\nEpoch 18/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9945 - loss: 0.0270 - val_accuracy: 0.7333 - val_loss: 1.7820 - learning_rate: 0.0100\nEpoch 19/50\n\u001b[1m7/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0102\nEpoch 19: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0104 - val_accuracy: 0.8667 - val_loss: 0.6349 - learning_rate: 0.0100\nEpoch 20/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0100 - val_accuracy: 0.8667 - val_loss: 0.3338 - learning_rate: 1.0000e-03\nEpoch 21/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0086 - val_accuracy: 0.8667 - val_loss: 0.1670 - learning_rate: 1.0000e-03\nEpoch 21: early stopping\nRestoring model weights from the end of the best epoch: 16.\nFold 7 - Train Accuracy: 90.23%, Validation Accuracy: 100.00%\n\nTraining on Fold 8...\nEpoch 1/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 768ms/step - accuracy: 0.6014 - loss: 1.0826 - val_accuracy: 0.5333 - val_loss: 5205.0156 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9170 - loss: 0.2904 - val_accuracy: 0.4667 - val_loss: 3072.7756 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9564 - loss: 0.1106 - val_accuracy: 0.4667 - val_loss: 1160.0426 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9839 - loss: 0.0364 - val_accuracy: 0.4667 - val_loss: 485.4072 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9909 - loss: 0.0326 - val_accuracy: 0.4667 - val_loss: 289.2257 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9909 - loss: 0.0319 - val_accuracy: 0.4667 - val_loss: 143.5277 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9792 - loss: 0.0295 - val_accuracy: 0.4000 - val_loss: 40.3450 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0054 - val_accuracy: 0.4667 - val_loss: 27.2909 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 0.4667 - val_loss: 17.5357 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.5333 - val_loss: 7.8722 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 0.6000 - val_loss: 4.4673 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.6667 - val_loss: 2.5986 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.7333 - val_loss: 1.6147 - learning_rate: 0.0100\nEpoch 14/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 7.9640e-04 - val_accuracy: 0.8667 - val_loss: 1.2343 - learning_rate: 0.0100\nEpoch 15/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 8.4428e-04 - val_accuracy: 0.8667 - val_loss: 1.0670 - learning_rate: 0.0100\nEpoch 16/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 4.3774e-04 - val_accuracy: 0.8000 - val_loss: 1.0612 - learning_rate: 0.0100\nEpoch 17/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 0.8000 - val_loss: 0.9809 - learning_rate: 0.0100\nEpoch 18/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 4.5988e-04 - val_accuracy: 0.8000 - val_loss: 0.8816 - learning_rate: 0.0100\nEpoch 19/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 5.1100e-04 - val_accuracy: 0.8667 - val_loss: 0.8135 - learning_rate: 0.0100\nEpoch 20/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 2.2611e-04 - val_accuracy: 0.8667 - val_loss: 0.7517 - learning_rate: 0.0100\nEpoch 21/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 1.8408e-04 - val_accuracy: 0.8667 - val_loss: 0.6913 - learning_rate: 0.0100\nEpoch 22/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 4.9305e-04 - val_accuracy: 0.8667 - val_loss: 0.6622 - learning_rate: 0.0100\nEpoch 23/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 2.1483e-04 - val_accuracy: 0.8667 - val_loss: 0.6940 - learning_rate: 0.0100\nEpoch 24/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 1.8932e-04 - val_accuracy: 0.8667 - val_loss: 0.7638 - learning_rate: 0.0100\nEpoch 25/50\n\u001b[1m7/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 3.8096e-04\nEpoch 25: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 3.6251e-04 - val_accuracy: 0.8667 - val_loss: 0.7981 - learning_rate: 0.0100\nEpoch 26/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 7.2794e-04 - val_accuracy: 0.8667 - val_loss: 0.7881 - learning_rate: 1.0000e-03\nEpoch 27/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 1.9483e-04 - val_accuracy: 0.8667 - val_loss: 0.7578 - learning_rate: 1.0000e-03\nEpoch 27: early stopping\nRestoring model weights from the end of the best epoch: 22.\nFold 8 - Train Accuracy: 97.74%, Validation Accuracy: 86.67%\n\nTraining on Fold 9...\nEpoch 1/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1s/step - accuracy: 0.7010 - loss: 0.8866 - val_accuracy: 0.5000 - val_loss: 9161.7529 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8778 - loss: 0.4616 - val_accuracy: 0.5000 - val_loss: 4503.3022 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9670 - loss: 0.1262 - val_accuracy: 0.5000 - val_loss: 2504.0261 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9945 - loss: 0.0366 - val_accuracy: 0.5000 - val_loss: 951.7460 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9815 - loss: 0.0248 - val_accuracy: 0.5000 - val_loss: 435.9248 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0056 - val_accuracy: 0.5000 - val_loss: 225.2595 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0105 - val_accuracy: 0.5000 - val_loss: 124.2107 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0107 - val_accuracy: 0.5000 - val_loss: 66.5899 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0097 - val_accuracy: 0.5000 - val_loss: 40.0657 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 0.5000 - val_loss: 24.4561 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0043 - val_accuracy: 0.5714 - val_loss: 15.1804 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0123 - val_accuracy: 0.5714 - val_loss: 7.9592 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.6429 - val_loss: 3.7053 - learning_rate: 0.0100\nEpoch 14/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 9.0752e-04 - val_accuracy: 0.7143 - val_loss: 1.0451 - learning_rate: 0.0100\nEpoch 15/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0042 - val_accuracy: 0.7857 - val_loss: 0.4552 - learning_rate: 0.0100\nEpoch 16/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 8.7988e-04 - val_accuracy: 0.7143 - val_loss: 0.7438 - learning_rate: 0.0100\nEpoch 17/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 4.3384e-04 - val_accuracy: 0.7143 - val_loss: 1.0599 - learning_rate: 0.0100\nEpoch 18/50\n\u001b[1m7/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0026\nEpoch 18: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.7143 - val_loss: 0.8423 - learning_rate: 0.0100\nEpoch 19/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 2.2718e-04 - val_accuracy: 0.7143 - val_loss: 0.8245 - learning_rate: 1.0000e-03\nEpoch 20/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 2.7886e-04 - val_accuracy: 0.7857 - val_loss: 0.7708 - learning_rate: 1.0000e-03\nEpoch 20: early stopping\nRestoring model weights from the end of the best epoch: 15.\nFold 9 - Train Accuracy: 65.67%, Validation Accuracy: 78.57%\n\nTraining on Fold 10...\nEpoch 1/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 802ms/step - accuracy: 0.7340 - loss: 0.8674 - val_accuracy: 0.5000 - val_loss: 11946.4775 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8347 - loss: 0.5087 - val_accuracy: 0.5000 - val_loss: 11255.2051 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9245 - loss: 0.1939 - val_accuracy: 0.5000 - val_loss: 2254.7307 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9536 - loss: 0.0743 - val_accuracy: 0.5000 - val_loss: 364.9631 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9945 - loss: 0.0298 - val_accuracy: 0.5714 - val_loss: 23.3272 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9945 - loss: 0.0193 - val_accuracy: 0.5000 - val_loss: 57.5167 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0113 - val_accuracy: 0.5000 - val_loss: 47.2059 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0052 - val_accuracy: 0.5000 - val_loss: 20.3296 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0038 - val_accuracy: 0.5000 - val_loss: 8.7200 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0051 - val_accuracy: 0.5000 - val_loss: 3.2984 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0039 - val_accuracy: 0.5000 - val_loss: 2.2810 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 9.1255e-04 - val_accuracy: 0.6429 - val_loss: 1.4279 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.7857 - val_loss: 0.9072 - learning_rate: 0.0100\nEpoch 14/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9945 - loss: 0.0068 - val_accuracy: 0.7857 - val_loss: 0.5153 - learning_rate: 0.0100\nEpoch 15/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.8571 - val_loss: 0.4462 - learning_rate: 0.0100\nEpoch 16/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9909 - loss: 0.0110 - val_accuracy: 0.7143 - val_loss: 0.7698 - learning_rate: 0.0100\nEpoch 17/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 7.1177e-04 - val_accuracy: 0.6429 - val_loss: 1.0951 - learning_rate: 0.0100\nEpoch 18/50\n\u001b[1m7/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0043\nEpoch 18: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0043 - val_accuracy: 0.7857 - val_loss: 0.7033 - learning_rate: 0.0100\nEpoch 19/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.7857 - val_loss: 0.6231 - learning_rate: 1.0000e-03\nEpoch 20/50\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0060 - val_accuracy: 0.8571 - val_loss: 0.5632 - learning_rate: 1.0000e-03\nEpoch 20: early stopping\nRestoring model weights from the end of the best epoch: 15.\nFold 10 - Train Accuracy: 90.30%, Validation Accuracy: 85.71%\n\nAverage Training Accuracy: 87.33%\nAverage Validation Accuracy: 91.76%\n","output_type":"stream"}],"execution_count":91},{"cell_type":"markdown","source":"## 2.1 Flipping","metadata":{}},{"cell_type":"code","source":"X_train_flipped = np.flip(X_train, axis=2)\nX_test_flipped = np.flip(X_test, axis=2)\n\nX_train_augmented = np.concatenate((X_train, X_train_flipped), axis=0)\ny_train_augmented = np.concatenate((y_train, y_train), axis=0)\n\ntrain_evaluate_model_with_k_fold(\n    X_train=X_train_augmented,\n    y_train=y_train_augmented,\n    lr=0.01,\n    epochs=50,\n    batch_size=16)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T20:07:32.726250Z","iopub.execute_input":"2025-02-07T20:07:32.726603Z","iopub.status.idle":"2025-02-07T20:12:27.809953Z","shell.execute_reply.started":"2025-02-07T20:07:32.726574Z","shell.execute_reply":"2025-02-07T20:12:27.809138Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"\nTraining on Fold 1...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 587ms/step - accuracy: 0.7027 - loss: 1.3310 - val_accuracy: 0.5000 - val_loss: 16620.5059 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8934 - loss: 0.3664 - val_accuracy: 0.5000 - val_loss: 427.3303 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9478 - loss: 0.1739 - val_accuracy: 0.7667 - val_loss: 6.4587 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9412 - loss: 0.1210 - val_accuracy: 0.5000 - val_loss: 30.9617 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9833 - loss: 0.0664 - val_accuracy: 0.5333 - val_loss: 6.3170 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9857 - loss: 0.0385 - val_accuracy: 0.6333 - val_loss: 2.1121 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9832 - loss: 0.0373 - val_accuracy: 0.5667 - val_loss: 4.1205 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9958 - loss: 0.0289 - val_accuracy: 0.7667 - val_loss: 1.2864 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9813 - loss: 0.0309 - val_accuracy: 0.7333 - val_loss: 2.1451 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9751 - loss: 0.0596 - val_accuracy: 0.8000 - val_loss: 1.3798 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9888 - loss: 0.0416 - val_accuracy: 0.8000 - val_loss: 1.0002 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9821 - loss: 0.0496 - val_accuracy: 0.8000 - val_loss: 0.9705 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9828 - loss: 0.0752 - val_accuracy: 0.9000 - val_loss: 0.4471 - learning_rate: 0.0100\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9873 - loss: 0.0291 - val_accuracy: 0.8333 - val_loss: 0.5800 - learning_rate: 0.0100\nEpoch 15/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9715 - loss: 0.0484 - val_accuracy: 0.9333 - val_loss: 0.6710 - learning_rate: 0.0100\nEpoch 16/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9958 - loss: 0.0176 - val_accuracy: 0.9000 - val_loss: 0.3724 - learning_rate: 0.0100\nEpoch 17/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9915 - loss: 0.0285 - val_accuracy: 0.9333 - val_loss: 0.6232 - learning_rate: 0.0100\nEpoch 18/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9958 - loss: 0.0137 - val_accuracy: 0.9333 - val_loss: 0.4389 - learning_rate: 0.0100\nEpoch 19/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0066 - val_accuracy: 0.9667 - val_loss: 0.3089 - learning_rate: 0.0100\nEpoch 20/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 0.9333 - val_loss: 0.3173 - learning_rate: 0.0100\nEpoch 21/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 0.9333 - val_loss: 0.3239 - learning_rate: 0.0100\nEpoch 22/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.9333 - val_loss: 0.2683 - learning_rate: 0.0100\nEpoch 23/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 8.7328e-04 - val_accuracy: 0.9333 - val_loss: 0.2182 - learning_rate: 0.0100\nEpoch 24/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 8.0141e-04 - val_accuracy: 0.9333 - val_loss: 0.1689 - learning_rate: 0.0100\nEpoch 25/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 8.6493e-04 - val_accuracy: 0.9667 - val_loss: 0.1346 - learning_rate: 0.0100\nEpoch 26/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 7.8507e-04 - val_accuracy: 0.9667 - val_loss: 0.1179 - learning_rate: 0.0100\nEpoch 27/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0070 - val_accuracy: 0.9667 - val_loss: 0.4106 - learning_rate: 0.0100\nEpoch 28/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9937 - loss: 0.0173 - val_accuracy: 0.9333 - val_loss: 0.8180 - learning_rate: 0.0100\nEpoch 29/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9989 - loss: 0.0123\nEpoch 29: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9986 - loss: 0.0130 - val_accuracy: 0.9000 - val_loss: 1.2867 - learning_rate: 0.0100\nEpoch 30/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9931 - loss: 0.0312 - val_accuracy: 0.9333 - val_loss: 0.7785 - learning_rate: 1.0000e-03\nEpoch 31/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0051 - val_accuracy: 0.9333 - val_loss: 0.6175 - learning_rate: 1.0000e-03\nEpoch 31: early stopping\nRestoring model weights from the end of the best epoch: 26.\nFold 1 - Train Accuracy: 98.87%, Validation Accuracy: 96.67%\n\nTraining on Fold 2...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 419ms/step - accuracy: 0.7275 - loss: 0.9014 - val_accuracy: 0.5000 - val_loss: 1960.6597 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.9259 - loss: 0.2505 - val_accuracy: 0.5000 - val_loss: 193.4128 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9415 - loss: 0.1260 - val_accuracy: 0.5000 - val_loss: 108.3874 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9838 - loss: 0.0479 - val_accuracy: 0.8333 - val_loss: 3.5453 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9797 - loss: 0.0386 - val_accuracy: 0.8667 - val_loss: 1.4603 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9798 - loss: 0.0434 - val_accuracy: 0.6333 - val_loss: 4.1378 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9655 - loss: 0.0892 - val_accuracy: 0.9000 - val_loss: 1.3894 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9856 - loss: 0.0304 - val_accuracy: 0.6667 - val_loss: 3.2065 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9972 - loss: 0.0251 - val_accuracy: 0.6333 - val_loss: 2.4322 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9821 - loss: 0.0364\nEpoch 10: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9819 - loss: 0.0384 - val_accuracy: 0.6000 - val_loss: 4.5285 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9687 - loss: 0.1192 - val_accuracy: 0.7667 - val_loss: 1.5679 - learning_rate: 1.0000e-03\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9980 - loss: 0.0236 - val_accuracy: 0.8333 - val_loss: 0.6830 - learning_rate: 1.0000e-03\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0067 - val_accuracy: 0.8333 - val_loss: 0.3972 - learning_rate: 1.0000e-03\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0061 - val_accuracy: 0.8667 - val_loss: 0.2768 - learning_rate: 1.0000e-03\nEpoch 15/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0059 - val_accuracy: 0.9000 - val_loss: 0.2063 - learning_rate: 1.0000e-03\nEpoch 16/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 0.9000 - val_loss: 0.1504 - learning_rate: 1.0000e-03\nEpoch 17/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0039 - val_accuracy: 0.9333 - val_loss: 0.1183 - learning_rate: 1.0000e-03\nEpoch 18/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0036 - val_accuracy: 0.9333 - val_loss: 0.0973 - learning_rate: 1.0000e-03\nEpoch 19/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0031 - val_accuracy: 0.9333 - val_loss: 0.0758 - learning_rate: 1.0000e-03\nEpoch 20/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 0.9333 - val_loss: 0.0575 - learning_rate: 1.0000e-03\nEpoch 21/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 1.0000 - val_loss: 0.0472 - learning_rate: 1.0000e-03\nEpoch 22/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 1.0000 - val_loss: 0.0383 - learning_rate: 1.0000e-03\nEpoch 23/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 1.0000 - val_loss: 0.0297 - learning_rate: 1.0000e-03\nEpoch 24/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 1.0000 - val_loss: 0.0236 - learning_rate: 1.0000e-03\nEpoch 25/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0035 - val_accuracy: 1.0000 - val_loss: 0.0199 - learning_rate: 1.0000e-03\nEpoch 26/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0032 - val_accuracy: 1.0000 - val_loss: 0.0171 - learning_rate: 1.0000e-03\nEpoch 27/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 1.0000 - val_loss: 0.0164 - learning_rate: 1.0000e-03\nEpoch 28/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 1.0000 - val_loss: 0.0159 - learning_rate: 1.0000e-03\nEpoch 29/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 1.0000 - val_loss: 0.0147 - learning_rate: 1.0000e-03\nEpoch 30/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 1.0000 - val_loss: 0.0145 - learning_rate: 1.0000e-03\nEpoch 31/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 1.0000 - val_loss: 0.0150 - learning_rate: 1.0000e-03\nEpoch 32/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 1.0000 - val_loss: 0.0154 - learning_rate: 1.0000e-03\nEpoch 33/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0010    \nEpoch 33: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 1.0000 - val_loss: 0.0160 - learning_rate: 1.0000e-03\nEpoch 34/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 1.0000 - val_loss: 0.0166 - learning_rate: 1.0000e-04\nEpoch 35/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0023 - val_accuracy: 1.0000 - val_loss: 0.0168 - learning_rate: 1.0000e-04\nEpoch 35: early stopping\nRestoring model weights from the end of the best epoch: 30.\nFold 2 - Train Accuracy: 100.00%, Validation Accuracy: 100.00%\n\nTraining on Fold 3...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 416ms/step - accuracy: 0.7413 - loss: 1.0052 - val_accuracy: 0.5000 - val_loss: 321.9003 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9111 - loss: 0.2235 - val_accuracy: 0.4667 - val_loss: 53.7540 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9571 - loss: 0.1889 - val_accuracy: 0.3000 - val_loss: 11.3137 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9834 - loss: 0.0471 - val_accuracy: 0.6667 - val_loss: 3.8711 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9698 - loss: 0.0582 - val_accuracy: 0.6333 - val_loss: 4.9022 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9844 - loss: 0.0311 - val_accuracy: 0.7333 - val_loss: 1.2166 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9959 - loss: 0.0187 - val_accuracy: 0.7667 - val_loss: 1.0136 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9919 - loss: 0.0219 - val_accuracy: 0.8333 - val_loss: 0.7915 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9952 - loss: 0.0118 - val_accuracy: 0.8667 - val_loss: 0.5879 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9895 - loss: 0.0780 - val_accuracy: 0.9333 - val_loss: 0.6822 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9934 - loss: 0.0147 - val_accuracy: 1.0000 - val_loss: 0.0256 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9783 - loss: 0.0459 - val_accuracy: 0.7667 - val_loss: 1.4888 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9837 - loss: 0.0308 - val_accuracy: 0.8333 - val_loss: 0.9383 - learning_rate: 0.0100\nEpoch 14/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9718 - loss: 0.0585\nEpoch 14: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9728 - loss: 0.0568 - val_accuracy: 0.9333 - val_loss: 0.4212 - learning_rate: 0.0100\nEpoch 15/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9779 - loss: 0.0230 - val_accuracy: 0.9333 - val_loss: 0.1815 - learning_rate: 1.0000e-03\nEpoch 16/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9983 - loss: 0.0078 - val_accuracy: 0.9667 - val_loss: 0.0497 - learning_rate: 1.0000e-03\nEpoch 16: early stopping\nRestoring model weights from the end of the best epoch: 11.\nFold 3 - Train Accuracy: 83.83%, Validation Accuracy: 100.00%\n\nTraining on Fold 4...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 411ms/step - accuracy: 0.7313 - loss: 0.9982 - val_accuracy: 0.5000 - val_loss: 1036.3601 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.8500 - loss: 0.3436 - val_accuracy: 0.5000 - val_loss: 282.9016 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9068 - loss: 0.2196 - val_accuracy: 0.5000 - val_loss: 79.3200 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9374 - loss: 0.1556 - val_accuracy: 0.5000 - val_loss: 47.8281 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9532 - loss: 0.1009 - val_accuracy: 0.5000 - val_loss: 40.5223 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9639 - loss: 0.0695 - val_accuracy: 0.5333 - val_loss: 41.6773 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9593 - loss: 0.0971 - val_accuracy: 0.5333 - val_loss: 10.7694 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9830 - loss: 0.0859 - val_accuracy: 0.8333 - val_loss: 0.4875 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9609 - loss: 0.0855 - val_accuracy: 0.8000 - val_loss: 0.8538 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9747 - loss: 0.0511 - val_accuracy: 0.7667 - val_loss: 0.7994 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9943 - loss: 0.0277\nEpoch 11: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9941 - loss: 0.0275 - val_accuracy: 0.7667 - val_loss: 1.2644 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9728 - loss: 0.0605 - val_accuracy: 0.8667 - val_loss: 0.5261 - learning_rate: 1.0000e-03\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9977 - loss: 0.0144 - val_accuracy: 0.9000 - val_loss: 0.3659 - learning_rate: 1.0000e-03\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9942 - loss: 0.0165 - val_accuracy: 0.9000 - val_loss: 0.3638 - learning_rate: 1.0000e-03\nEpoch 15/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0099 - val_accuracy: 0.9000 - val_loss: 0.3791 - learning_rate: 1.0000e-03\nEpoch 16/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0102 - val_accuracy: 0.9000 - val_loss: 0.3636 - learning_rate: 1.0000e-03\nEpoch 17/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0065 - val_accuracy: 0.9000 - val_loss: 0.3450 - learning_rate: 1.0000e-03\nEpoch 18/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9977 - loss: 0.0114 - val_accuracy: 0.9000 - val_loss: 0.4096 - learning_rate: 1.0000e-03\nEpoch 19/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0069 - val_accuracy: 0.8667 - val_loss: 0.4033 - learning_rate: 1.0000e-03\nEpoch 20/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0083 - val_accuracy: 0.8667 - val_loss: 0.3299 - learning_rate: 1.0000e-03\nEpoch 21/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0076 - val_accuracy: 0.8667 - val_loss: 0.3043 - learning_rate: 1.0000e-03\nEpoch 22/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0069 - val_accuracy: 0.8667 - val_loss: 0.2867 - learning_rate: 1.0000e-03\nEpoch 23/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0037 - val_accuracy: 0.9000 - val_loss: 0.2860 - learning_rate: 1.0000e-03\nEpoch 24/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0040 - val_accuracy: 0.9000 - val_loss: 0.3214 - learning_rate: 1.0000e-03\nEpoch 25/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0071 - val_accuracy: 0.9000 - val_loss: 0.3017 - learning_rate: 1.0000e-03\nEpoch 26/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0060\nEpoch 26: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0060 - val_accuracy: 0.9000 - val_loss: 0.3307 - learning_rate: 1.0000e-03\nEpoch 27/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0041 - val_accuracy: 0.9000 - val_loss: 0.3310 - learning_rate: 1.0000e-04\nEpoch 28/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0046 - val_accuracy: 0.9000 - val_loss: 0.3431 - learning_rate: 1.0000e-04\nEpoch 28: early stopping\nRestoring model weights from the end of the best epoch: 23.\nFold 4 - Train Accuracy: 98.50%, Validation Accuracy: 90.00%\n\nTraining on Fold 5...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 414ms/step - accuracy: 0.7724 - loss: 0.7265 - val_accuracy: 0.5000 - val_loss: 852.1312 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8633 - loss: 0.2694 - val_accuracy: 0.5000 - val_loss: 538.6650 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9373 - loss: 0.1387 - val_accuracy: 0.5667 - val_loss: 43.1859 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9753 - loss: 0.0790 - val_accuracy: 0.5333 - val_loss: 18.3740 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9846 - loss: 0.0568 - val_accuracy: 0.8333 - val_loss: 1.7281 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9769 - loss: 0.0569 - val_accuracy: 0.7667 - val_loss: 1.5927 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9798 - loss: 0.0437 - val_accuracy: 0.7333 - val_loss: 1.5111 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9789 - loss: 0.0568 - val_accuracy: 0.7000 - val_loss: 1.8700 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9938 - loss: 0.0458 - val_accuracy: 0.9333 - val_loss: 0.3278 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9983 - loss: 0.0316 - val_accuracy: 0.9000 - val_loss: 0.4695 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9765 - loss: 0.0696 - val_accuracy: 0.7333 - val_loss: 1.4645 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9938 - loss: 0.0188 - val_accuracy: 0.9333 - val_loss: 0.2075 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9693 - loss: 0.1357 - val_accuracy: 0.8000 - val_loss: 1.2899 - learning_rate: 0.0100\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9728 - loss: 0.0582 - val_accuracy: 0.9333 - val_loss: 0.1870 - learning_rate: 0.0100\nEpoch 15/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9815 - loss: 0.0478 - val_accuracy: 0.9333 - val_loss: 0.1246 - learning_rate: 0.0100\nEpoch 16/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9906 - loss: 0.0189 - val_accuracy: 0.9000 - val_loss: 0.3572 - learning_rate: 0.0100\nEpoch 17/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0048 - val_accuracy: 0.9667 - val_loss: 0.1284 - learning_rate: 0.0100\nEpoch 18/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0039\nEpoch 18: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0038 - val_accuracy: 0.9667 - val_loss: 0.1486 - learning_rate: 0.0100\nEpoch 19/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.9667 - val_loss: 0.1392 - learning_rate: 1.0000e-03\nEpoch 20/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.9667 - val_loss: 0.1319 - learning_rate: 1.0000e-03\nEpoch 20: early stopping\nRestoring model weights from the end of the best epoch: 15.\nFold 5 - Train Accuracy: 95.86%, Validation Accuracy: 93.33%\n\nTraining on Fold 6...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 410ms/step - accuracy: 0.7035 - loss: 0.8208 - val_accuracy: 0.5000 - val_loss: 1159.8646 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.9384 - loss: 0.1623 - val_accuracy: 0.5000 - val_loss: 460.0631 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9614 - loss: 0.0878 - val_accuracy: 0.7333 - val_loss: 4.9971 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9890 - loss: 0.0451 - val_accuracy: 0.5000 - val_loss: 25.8830 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9459 - loss: 0.1100 - val_accuracy: 0.6000 - val_loss: 9.7861 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9743 - loss: 0.1125\nEpoch 6: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9730 - loss: 0.1152 - val_accuracy: 0.5333 - val_loss: 19.2874 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9848 - loss: 0.0422 - val_accuracy: 0.5333 - val_loss: 6.6809 - learning_rate: 1.0000e-03\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9934 - loss: 0.0291 - val_accuracy: 0.6000 - val_loss: 2.5047 - learning_rate: 1.0000e-03\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9940 - loss: 0.0237 - val_accuracy: 0.8000 - val_loss: 1.0468 - learning_rate: 1.0000e-03\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9951 - loss: 0.0211 - val_accuracy: 0.8667 - val_loss: 0.4761 - learning_rate: 1.0000e-03\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9983 - loss: 0.0149 - val_accuracy: 0.8667 - val_loss: 0.3204 - learning_rate: 1.0000e-03\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9969 - loss: 0.0126 - val_accuracy: 0.9000 - val_loss: 0.3143 - learning_rate: 1.0000e-03\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0086 - val_accuracy: 0.9000 - val_loss: 0.3760 - learning_rate: 1.0000e-03\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0075 - val_accuracy: 0.9000 - val_loss: 0.4447 - learning_rate: 1.0000e-03\nEpoch 15/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0052\nEpoch 15: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0055 - val_accuracy: 0.9000 - val_loss: 0.4761 - learning_rate: 1.0000e-03\nEpoch 16/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0072 - val_accuracy: 0.9000 - val_loss: 0.4825 - learning_rate: 1.0000e-04\nEpoch 17/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9986 - loss: 0.0088 - val_accuracy: 0.9000 - val_loss: 0.4765 - learning_rate: 1.0000e-04\nEpoch 17: early stopping\nRestoring model weights from the end of the best epoch: 12.\nFold 6 - Train Accuracy: 96.62%, Validation Accuracy: 90.00%\n\nTraining on Fold 7...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 648ms/step - accuracy: 0.6803 - loss: 1.3878 - val_accuracy: 0.4828 - val_loss: 14831.5273 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8948 - loss: 0.3442 - val_accuracy: 0.5172 - val_loss: 543.3107 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9290 - loss: 0.2448 - val_accuracy: 0.5172 - val_loss: 186.9715 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9188 - loss: 0.1818 - val_accuracy: 0.5172 - val_loss: 40.1445 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9538 - loss: 0.1089 - val_accuracy: 0.5172 - val_loss: 25.0545 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9945 - loss: 0.0501 - val_accuracy: 0.4828 - val_loss: 9.1966 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9983 - loss: 0.0276 - val_accuracy: 0.4828 - val_loss: 6.9879 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9901 - loss: 0.0321 - val_accuracy: 0.5862 - val_loss: 3.4000 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9890 - loss: 0.0354 - val_accuracy: 0.6207 - val_loss: 4.4053 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9787 - loss: 0.0649 - val_accuracy: 0.7241 - val_loss: 2.6660 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9620 - loss: 0.0997 - val_accuracy: 0.5172 - val_loss: 8.6096 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9604 - loss: 0.1355 - val_accuracy: 0.7586 - val_loss: 1.8325 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9760 - loss: 0.0591 - val_accuracy: 0.7931 - val_loss: 0.9336 - learning_rate: 0.0100\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9878 - loss: 0.0529 - val_accuracy: 0.7241 - val_loss: 2.0851 - learning_rate: 0.0100\nEpoch 15/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0252 - val_accuracy: 1.0000 - val_loss: 0.0270 - learning_rate: 0.0100\nEpoch 16/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9964 - loss: 0.0176 - val_accuracy: 0.7931 - val_loss: 1.1161 - learning_rate: 0.0100\nEpoch 17/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9914 - loss: 0.0221 - val_accuracy: 1.0000 - val_loss: 0.0236 - learning_rate: 0.0100\nEpoch 18/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9808 - loss: 0.0434 - val_accuracy: 0.8621 - val_loss: 0.6437 - learning_rate: 0.0100\nEpoch 19/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9888 - loss: 0.0280 - val_accuracy: 0.8621 - val_loss: 0.3904 - learning_rate: 0.0100\nEpoch 20/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9826 - loss: 0.0392\nEpoch 20: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9820 - loss: 0.0395 - val_accuracy: 0.8621 - val_loss: 0.3324 - learning_rate: 0.0100\nEpoch 21/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9968 - loss: 0.0078 - val_accuracy: 0.8966 - val_loss: 0.2192 - learning_rate: 1.0000e-03\nEpoch 22/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9931 - loss: 0.0118 - val_accuracy: 0.9310 - val_loss: 0.1293 - learning_rate: 1.0000e-03\nEpoch 22: early stopping\nRestoring model weights from the end of the best epoch: 17.\nFold 7 - Train Accuracy: 98.13%, Validation Accuracy: 100.00%\n\nTraining on Fold 8...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 415ms/step - accuracy: 0.7922 - loss: 0.6227 - val_accuracy: 0.4138 - val_loss: 252.6774 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.9411 - loss: 0.1330 - val_accuracy: 0.4828 - val_loss: 329.9691 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9778 - loss: 0.0476 - val_accuracy: 0.5172 - val_loss: 62.8196 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9916 - loss: 0.0287 - val_accuracy: 0.5172 - val_loss: 18.7114 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9930 - loss: 0.0268 - val_accuracy: 0.6207 - val_loss: 2.8108 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9964 - loss: 0.0113 - val_accuracy: 0.5517 - val_loss: 5.5355 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9931 - loss: 0.0154 - val_accuracy: 0.5517 - val_loss: 3.8799 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0063 - val_accuracy: 0.7931 - val_loss: 1.1057 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0041 - val_accuracy: 0.7241 - val_loss: 2.2098 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.6897 - val_loss: 2.1121 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9925 - loss: 0.0175\nEpoch 11: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9921 - loss: 0.0178 - val_accuracy: 0.8621 - val_loss: 1.9091 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9983 - loss: 0.0139 - val_accuracy: 0.8276 - val_loss: 1.8961 - learning_rate: 1.0000e-03\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9983 - loss: 0.0060 - val_accuracy: 0.8276 - val_loss: 1.8547 - learning_rate: 1.0000e-03\nEpoch 13: early stopping\nRestoring model weights from the end of the best epoch: 8.\nFold 8 - Train Accuracy: 61.80%, Validation Accuracy: 79.31%\n\nTraining on Fold 9...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 417ms/step - accuracy: 0.7600 - loss: 0.8179 - val_accuracy: 0.5172 - val_loss: 677.0947 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9319 - loss: 0.1718 - val_accuracy: 0.5172 - val_loss: 127.7192 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9569 - loss: 0.1074 - val_accuracy: 0.4828 - val_loss: 10.7426 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9724 - loss: 0.0581 - val_accuracy: 0.4828 - val_loss: 5.0490 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9883 - loss: 0.0379 - val_accuracy: 0.4828 - val_loss: 5.2252 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9973 - loss: 0.0191 - val_accuracy: 0.5517 - val_loss: 2.6785 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9854 - loss: 0.0229 - val_accuracy: 0.7931 - val_loss: 1.5825 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9881 - loss: 0.0262 - val_accuracy: 0.7931 - val_loss: 0.7501 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9881 - loss: 0.0306 - val_accuracy: 0.8276 - val_loss: 0.9315 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9932 - loss: 0.0357 - val_accuracy: 0.9310 - val_loss: 0.6435 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9845 - loss: 0.0297 - val_accuracy: 0.8276 - val_loss: 1.0861 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9973 - loss: 0.0149 - val_accuracy: 0.8966 - val_loss: 0.6240 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9960 - loss: 0.0249 - val_accuracy: 0.9310 - val_loss: 0.8474 - learning_rate: 0.0100\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9938 - loss: 0.0103 - val_accuracy: 0.9310 - val_loss: 0.2575 - learning_rate: 0.0100\nEpoch 15/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9969 - loss: 0.0142 - val_accuracy: 0.9310 - val_loss: 0.4247 - learning_rate: 0.0100\nEpoch 16/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9915 - loss: 0.0201 - val_accuracy: 0.9310 - val_loss: 0.2878 - learning_rate: 0.0100\nEpoch 17/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9961 - loss: 0.0073 \nEpoch 17: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9957 - loss: 0.0089 - val_accuracy: 0.9310 - val_loss: 0.4483 - learning_rate: 0.0100\nEpoch 18/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0051 - val_accuracy: 0.9310 - val_loss: 0.3753 - learning_rate: 1.0000e-03\nEpoch 19/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.9655 - val_loss: 0.3142 - learning_rate: 1.0000e-03\nEpoch 19: early stopping\nRestoring model weights from the end of the best epoch: 14.\nFold 9 - Train Accuracy: 98.13%, Validation Accuracy: 93.10%\n\nTraining on Fold 10...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 410ms/step - accuracy: 0.7854 - loss: 0.7082 - val_accuracy: 0.4828 - val_loss: 9705.5928 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.8391 - loss: 0.3779 - val_accuracy: 0.5172 - val_loss: 161.1179 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9239 - loss: 0.1830 - val_accuracy: 0.4828 - val_loss: 76.9329 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9700 - loss: 0.0868 - val_accuracy: 0.5172 - val_loss: 8.8986 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9783 - loss: 0.0718 - val_accuracy: 0.4828 - val_loss: 7.0644 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0244 - val_accuracy: 0.5172 - val_loss: 8.1642 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0130 - val_accuracy: 0.5517 - val_loss: 4.2839 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9898 - loss: 0.0388 - val_accuracy: 0.8621 - val_loss: 1.4607 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9732 - loss: 0.0834 - val_accuracy: 0.7241 - val_loss: 1.8758 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9670 - loss: 0.0889 - val_accuracy: 0.6897 - val_loss: 2.3471 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9859 - loss: 0.0627 - val_accuracy: 0.7586 - val_loss: 1.0156 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9822 - loss: 0.0474 - val_accuracy: 0.8621 - val_loss: 0.2683 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9894 - loss: 0.0499 - val_accuracy: 0.8966 - val_loss: 0.4822 - learning_rate: 0.0100\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9812 - loss: 0.0437 - val_accuracy: 0.9655 - val_loss: 0.4538 - learning_rate: 0.0100\nEpoch 15/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9901 - loss: 0.0343\nEpoch 15: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9899 - loss: 0.0345 - val_accuracy: 0.8966 - val_loss: 0.5675 - learning_rate: 0.0100\nEpoch 16/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9983 - loss: 0.0126 - val_accuracy: 0.9655 - val_loss: 0.1227 - learning_rate: 1.0000e-03\nEpoch 17/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0079 - val_accuracy: 0.9655 - val_loss: 0.0568 - learning_rate: 1.0000e-03\nEpoch 18/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0082 - val_accuracy: 0.9655 - val_loss: 0.0758 - learning_rate: 1.0000e-03\nEpoch 19/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0073 - val_accuracy: 0.9655 - val_loss: 0.0869 - learning_rate: 1.0000e-03\nEpoch 20/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0053\nEpoch 20: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0053 - val_accuracy: 0.9655 - val_loss: 0.0862 - learning_rate: 1.0000e-03\nEpoch 21/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0046 - val_accuracy: 0.9655 - val_loss: 0.0766 - learning_rate: 1.0000e-04\nEpoch 22/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0039 - val_accuracy: 0.9655 - val_loss: 0.0684 - learning_rate: 1.0000e-04\nEpoch 22: early stopping\nRestoring model weights from the end of the best epoch: 17.\nFold 10 - Train Accuracy: 100.00%, Validation Accuracy: 96.55%\n\nAverage Training Accuracy: 93.17%\nAverage Validation Accuracy: 93.90%\n","output_type":"stream"}],"execution_count":92},{"cell_type":"markdown","source":"## 2.2 Rotating 90 degrees","metadata":{}},{"cell_type":"code","source":"X_train_rotated = np.rot90(X_train, k=1, axes=(1,2))\nX_test_rotated = np.rot90(X_test, k=1, axes=(1,2))\n\nX_train_augmented = np.concatenate((X_train, X_train_rotated), axis=0)\ny_train_augmented = np.concatenate((y_train, y_train), axis=0)\n\ntrain_evaluate_model_with_k_fold(\n    X_train=X_train_augmented,\n    y_train=y_train_augmented,\n    lr=0.01,\n    epochs=50,\n    batch_size=16)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T20:12:27.811225Z","iopub.execute_input":"2025-02-07T20:12:27.811503Z","iopub.status.idle":"2025-02-07T20:17:38.216602Z","shell.execute_reply.started":"2025-02-07T20:12:27.811481Z","shell.execute_reply":"2025-02-07T20:17:38.215799Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"\nTraining on Fold 1...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 417ms/step - accuracy: 0.6361 - loss: 1.2447 - val_accuracy: 0.5000 - val_loss: 4839.6313 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8952 - loss: 0.2765 - val_accuracy: 0.5000 - val_loss: 1245.4366 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9409 - loss: 0.1635 - val_accuracy: 0.5000 - val_loss: 204.4291 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9410 - loss: 0.1255 - val_accuracy: 0.5000 - val_loss: 54.3854 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9684 - loss: 0.0888 - val_accuracy: 0.5000 - val_loss: 22.5367 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9722 - loss: 0.0923 - val_accuracy: 0.5333 - val_loss: 13.4147 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9915 - loss: 0.0482 - val_accuracy: 0.7333 - val_loss: 1.8227 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9838 - loss: 0.0417 - val_accuracy: 0.8000 - val_loss: 1.8836 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9828 - loss: 0.0449 - val_accuracy: 0.9667 - val_loss: 0.0355 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9757 - loss: 0.0798 - val_accuracy: 0.8000 - val_loss: 1.1263 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9653 - loss: 0.0690 - val_accuracy: 0.9000 - val_loss: 0.8889 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9856 - loss: 0.0492\nEpoch 12: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9839 - loss: 0.0527 - val_accuracy: 0.9000 - val_loss: 0.5334 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9595 - loss: 0.1061 - val_accuracy: 0.7000 - val_loss: 1.0600 - learning_rate: 1.0000e-03\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9718 - loss: 0.0459 - val_accuracy: 0.8333 - val_loss: 0.5079 - learning_rate: 1.0000e-03\nEpoch 14: early stopping\nRestoring model weights from the end of the best epoch: 9.\nFold 1 - Train Accuracy: 89.85%, Validation Accuracy: 96.67%\n\nTraining on Fold 2...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 417ms/step - accuracy: 0.7120 - loss: 0.9730 - val_accuracy: 0.5000 - val_loss: 1991.7644 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.8461 - loss: 0.3232 - val_accuracy: 0.5000 - val_loss: 292.3757 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9233 - loss: 0.2093 - val_accuracy: 0.5000 - val_loss: 157.4633 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9392 - loss: 0.1256 - val_accuracy: 0.5000 - val_loss: 41.4227 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9580 - loss: 0.0870 - val_accuracy: 0.5667 - val_loss: 11.3872 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9810 - loss: 0.0445 - val_accuracy: 0.5667 - val_loss: 14.0562 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9899 - loss: 0.0279 - val_accuracy: 0.7000 - val_loss: 1.8718 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9648 - loss: 0.0848 - val_accuracy: 0.8333 - val_loss: 1.0863 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9810 - loss: 0.0515 - val_accuracy: 0.9333 - val_loss: 0.0832 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9739 - loss: 0.1116 - val_accuracy: 0.8667 - val_loss: 0.6277 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9482 - loss: 0.1277 - val_accuracy: 0.9667 - val_loss: 0.0526 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9839 - loss: 0.0492 - val_accuracy: 0.9667 - val_loss: 0.0544 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9834 - loss: 0.0485 - val_accuracy: 1.0000 - val_loss: 0.0428 - learning_rate: 0.0100\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9810 - loss: 0.0522 - val_accuracy: 0.9667 - val_loss: 0.1681 - learning_rate: 0.0100\nEpoch 15/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9747 - loss: 0.0528 - val_accuracy: 0.9667 - val_loss: 0.6010 - learning_rate: 0.0100\nEpoch 16/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9956 - loss: 0.0235\nEpoch 16: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9952 - loss: 0.0233 - val_accuracy: 0.9667 - val_loss: 0.2127 - learning_rate: 0.0100\nEpoch 17/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0087 - val_accuracy: 0.9667 - val_loss: 0.2069 - learning_rate: 1.0000e-03\nEpoch 18/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0051 - val_accuracy: 0.9667 - val_loss: 0.2055 - learning_rate: 1.0000e-03\nEpoch 18: early stopping\nRestoring model weights from the end of the best epoch: 13.\nFold 2 - Train Accuracy: 98.12%, Validation Accuracy: 100.00%\n\nTraining on Fold 3...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 414ms/step - accuracy: 0.6849 - loss: 1.0669 - val_accuracy: 0.5000 - val_loss: 1187.1964 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8933 - loss: 0.3032 - val_accuracy: 0.5000 - val_loss: 233.9431 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9563 - loss: 0.1137 - val_accuracy: 0.5000 - val_loss: 73.1968 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9598 - loss: 0.0986 - val_accuracy: 0.5000 - val_loss: 36.9917 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9652 - loss: 0.1139 - val_accuracy: 0.5000 - val_loss: 20.9795 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9783 - loss: 0.0566 - val_accuracy: 0.7333 - val_loss: 3.4409 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9859 - loss: 0.0337 - val_accuracy: 0.6000 - val_loss: 7.8507 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9825 - loss: 0.0628 - val_accuracy: 0.6000 - val_loss: 2.8036 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9904 - loss: 0.0335 - val_accuracy: 0.6333 - val_loss: 7.5293 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9896 - loss: 0.0300 - val_accuracy: 0.7667 - val_loss: 3.1352 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9899 - loss: 0.0406\nEpoch 11: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9898 - loss: 0.0412 - val_accuracy: 0.6333 - val_loss: 4.2462 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9851 - loss: 0.0329 - val_accuracy: 0.7333 - val_loss: 2.5814 - learning_rate: 1.0000e-03\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0122 - val_accuracy: 0.8000 - val_loss: 1.3988 - learning_rate: 1.0000e-03\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9986 - loss: 0.0109 - val_accuracy: 0.8667 - val_loss: 0.8145 - learning_rate: 1.0000e-03\nEpoch 15/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0078 - val_accuracy: 0.9000 - val_loss: 0.4846 - learning_rate: 1.0000e-03\nEpoch 16/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0055 - val_accuracy: 0.9000 - val_loss: 0.2851 - learning_rate: 1.0000e-03\nEpoch 17/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0035 - val_accuracy: 0.9000 - val_loss: 0.1879 - learning_rate: 1.0000e-03\nEpoch 18/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0043 - val_accuracy: 0.9333 - val_loss: 0.1264 - learning_rate: 1.0000e-03\nEpoch 19/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0031 - val_accuracy: 0.9667 - val_loss: 0.0825 - learning_rate: 1.0000e-03\nEpoch 20/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0034 - val_accuracy: 0.9667 - val_loss: 0.0620 - learning_rate: 1.0000e-03\nEpoch 21/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 1.0000 - val_loss: 0.0437 - learning_rate: 1.0000e-03\nEpoch 22/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 1.0000 - val_loss: 0.0285 - learning_rate: 1.0000e-03\nEpoch 23/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9983 - loss: 0.0035 - val_accuracy: 1.0000 - val_loss: 0.0282 - learning_rate: 1.0000e-03\nEpoch 24/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 1.0000 - val_loss: 0.0319 - learning_rate: 1.0000e-03\nEpoch 25/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0053 - val_accuracy: 1.0000 - val_loss: 0.0326 - learning_rate: 1.0000e-03\nEpoch 26/50\n\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0019\nEpoch 26: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 1.0000 - val_loss: 0.0285 - learning_rate: 1.0000e-03\nEpoch 27/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 1.0000 - val_loss: 0.0271 - learning_rate: 1.0000e-04\nEpoch 28/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 1.0000 - val_loss: 0.0257 - learning_rate: 1.0000e-04\nEpoch 29/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 1.0000 - val_loss: 0.0239 - learning_rate: 1.0000e-04\nEpoch 30/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 1.0000 - val_loss: 0.0219 - learning_rate: 1.0000e-04\nEpoch 31/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 1.0000 - val_loss: 0.0215 - learning_rate: 1.0000e-04\nEpoch 32/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 1.0000 - val_loss: 0.0214 - learning_rate: 1.0000e-04\nEpoch 33/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 1.0000 - val_loss: 0.0212 - learning_rate: 1.0000e-04\nEpoch 34/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 1.0000 - val_loss: 0.0210 - learning_rate: 1.0000e-04\nEpoch 35/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 1.0000 - val_loss: 0.0215 - learning_rate: 1.0000e-04\nEpoch 36/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 1.0000 - val_loss: 0.0214 - learning_rate: 1.0000e-04\nEpoch 37/50\n\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0011    \nEpoch 37: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 1.0000 - val_loss: 0.0210 - learning_rate: 1.0000e-04\nEpoch 38/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 1.0000 - val_loss: 0.0209 - learning_rate: 1.0000e-05\nEpoch 39/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 1.0000 - val_loss: 0.0210 - learning_rate: 1.0000e-05\nEpoch 40/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 1.0000 - val_loss: 0.0207 - learning_rate: 1.0000e-05\nEpoch 41/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 1.0000 - val_loss: 0.0203 - learning_rate: 1.0000e-05\nEpoch 42/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 1.0000 - val_loss: 0.0208 - learning_rate: 1.0000e-05\nEpoch 43/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 1.0000 - val_loss: 0.0209 - learning_rate: 1.0000e-05\nEpoch 44/50\n\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0014  \nEpoch 44: ReduceLROnPlateau reducing learning rate to 9.99999883788405e-07.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 1.0000 - val_loss: 0.0208 - learning_rate: 1.0000e-05\nEpoch 45/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 1.0000 - val_loss: 0.0209 - learning_rate: 1.0000e-06\nEpoch 46/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 1.0000 - val_loss: 0.0209 - learning_rate: 1.0000e-06\nEpoch 46: early stopping\nRestoring model weights from the end of the best epoch: 41.\nFold 3 - Train Accuracy: 99.62%, Validation Accuracy: 100.00%\n\nTraining on Fold 4...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 414ms/step - accuracy: 0.6296 - loss: 1.4729 - val_accuracy: 0.5000 - val_loss: 1828.9956 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.8734 - loss: 0.3453 - val_accuracy: 0.5000 - val_loss: 395.3312 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9043 - loss: 0.2053 - val_accuracy: 0.4667 - val_loss: 21.4848 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9421 - loss: 0.1194 - val_accuracy: 0.4667 - val_loss: 9.5101 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9618 - loss: 0.1012 - val_accuracy: 0.5000 - val_loss: 14.7918 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9754 - loss: 0.0642 - val_accuracy: 0.5000 - val_loss: 9.0522 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9609 - loss: 0.0896 - val_accuracy: 0.5000 - val_loss: 6.7473 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9619 - loss: 0.1012 - val_accuracy: 0.5000 - val_loss: 7.4273 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9498 - loss: 0.1262 - val_accuracy: 0.5333 - val_loss: 2.8312 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9479 - loss: 0.1291 - val_accuracy: 0.5667 - val_loss: 2.3945 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9897 - loss: 0.0417 - val_accuracy: 0.6667 - val_loss: 2.7764 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9766 - loss: 0.0512 - val_accuracy: 0.8000 - val_loss: 0.5087 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9621 - loss: 0.0568 - val_accuracy: 0.8333 - val_loss: 0.6599 - learning_rate: 0.0100\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9826 - loss: 0.0531 - val_accuracy: 0.7000 - val_loss: 1.5904 - learning_rate: 0.0100\nEpoch 15/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9689 - loss: 0.0616\nEpoch 15: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9686 - loss: 0.0621 - val_accuracy: 0.8000 - val_loss: 0.8471 - learning_rate: 0.0100\nEpoch 16/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9731 - loss: 0.0648 - val_accuracy: 0.8333 - val_loss: 0.5881 - learning_rate: 1.0000e-03\nEpoch 17/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9791 - loss: 0.0609 - val_accuracy: 0.9333 - val_loss: 0.3583 - learning_rate: 1.0000e-03\nEpoch 18/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9942 - loss: 0.0182 - val_accuracy: 0.9333 - val_loss: 0.2859 - learning_rate: 1.0000e-03\nEpoch 19/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9876 - loss: 0.0258 - val_accuracy: 0.9333 - val_loss: 0.2677 - learning_rate: 1.0000e-03\nEpoch 20/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0127 - val_accuracy: 0.9333 - val_loss: 0.2502 - learning_rate: 1.0000e-03\nEpoch 21/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0133 - val_accuracy: 0.9333 - val_loss: 0.2628 - learning_rate: 1.0000e-03\nEpoch 22/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9996 - loss: 0.0094 - val_accuracy: 0.9333 - val_loss: 0.2519 - learning_rate: 1.0000e-03\nEpoch 23/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0068\nEpoch 23: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0069 - val_accuracy: 0.9333 - val_loss: 0.2771 - learning_rate: 1.0000e-03\nEpoch 24/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0052 - val_accuracy: 0.9333 - val_loss: 0.2549 - learning_rate: 1.0000e-04\nEpoch 25/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0100 - val_accuracy: 0.9333 - val_loss: 0.2358 - learning_rate: 1.0000e-04\nEpoch 26/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0105 - val_accuracy: 0.9333 - val_loss: 0.2153 - learning_rate: 1.0000e-04\nEpoch 27/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0063 - val_accuracy: 0.9333 - val_loss: 0.1977 - learning_rate: 1.0000e-04\nEpoch 28/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0133 - val_accuracy: 0.9333 - val_loss: 0.1837 - learning_rate: 1.0000e-04\nEpoch 29/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0089 - val_accuracy: 0.9333 - val_loss: 0.1695 - learning_rate: 1.0000e-04\nEpoch 30/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0066 - val_accuracy: 0.9333 - val_loss: 0.1531 - learning_rate: 1.0000e-04\nEpoch 31/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0092 - val_accuracy: 0.9333 - val_loss: 0.1401 - learning_rate: 1.0000e-04\nEpoch 32/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0080 - val_accuracy: 0.9333 - val_loss: 0.1251 - learning_rate: 1.0000e-04\nEpoch 33/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0072 - val_accuracy: 0.9333 - val_loss: 0.1170 - learning_rate: 1.0000e-04\nEpoch 34/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0133 - val_accuracy: 0.9333 - val_loss: 0.1132 - learning_rate: 1.0000e-04\nEpoch 35/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0077 - val_accuracy: 0.9333 - val_loss: 0.1072 - learning_rate: 1.0000e-04\nEpoch 36/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0101 - val_accuracy: 0.9333 - val_loss: 0.1052 - learning_rate: 1.0000e-04\nEpoch 37/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0047 - val_accuracy: 0.9667 - val_loss: 0.0985 - learning_rate: 1.0000e-04\nEpoch 38/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0076 - val_accuracy: 0.9667 - val_loss: 0.0917 - learning_rate: 1.0000e-04\nEpoch 39/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0078 - val_accuracy: 0.9667 - val_loss: 0.0854 - learning_rate: 1.0000e-04\nEpoch 40/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0054 - val_accuracy: 0.9667 - val_loss: 0.0815 - learning_rate: 1.0000e-04\nEpoch 41/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0053 - val_accuracy: 0.9667 - val_loss: 0.0798 - learning_rate: 1.0000e-04\nEpoch 42/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0067 - val_accuracy: 0.9667 - val_loss: 0.0769 - learning_rate: 1.0000e-04\nEpoch 43/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0102 - val_accuracy: 0.9667 - val_loss: 0.0745 - learning_rate: 1.0000e-04\nEpoch 44/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0058 - val_accuracy: 0.9667 - val_loss: 0.0715 - learning_rate: 1.0000e-04\nEpoch 45/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0067 - val_accuracy: 0.9667 - val_loss: 0.0689 - learning_rate: 1.0000e-04\nEpoch 46/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0056 - val_accuracy: 0.9667 - val_loss: 0.0682 - learning_rate: 1.0000e-04\nEpoch 47/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0056 - val_accuracy: 0.9667 - val_loss: 0.0676 - learning_rate: 1.0000e-04\nEpoch 48/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0054 - val_accuracy: 0.9667 - val_loss: 0.0653 - learning_rate: 1.0000e-04\nEpoch 49/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9983 - loss: 0.0089 - val_accuracy: 0.9667 - val_loss: 0.0611 - learning_rate: 1.0000e-04\nEpoch 50/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0050 - val_accuracy: 1.0000 - val_loss: 0.0577 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 50.\nFold 4 - Train Accuracy: 100.00%, Validation Accuracy: 100.00%\n\nTraining on Fold 5...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 423ms/step - accuracy: 0.6990 - loss: 1.2446 - val_accuracy: 0.5000 - val_loss: 1237.5651 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9193 - loss: 0.2319 - val_accuracy: 0.5333 - val_loss: 166.1831 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9337 - loss: 0.1625 - val_accuracy: 0.8333 - val_loss: 2.5185 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9600 - loss: 0.1153 - val_accuracy: 0.7333 - val_loss: 3.5519 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9911 - loss: 0.0593 - val_accuracy: 0.5333 - val_loss: 11.6510 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9928 - loss: 0.0556 - val_accuracy: 0.8333 - val_loss: 1.3852 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9489 - loss: 0.0982 - val_accuracy: 0.5333 - val_loss: 2.9601 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9256 - loss: 0.2129 - val_accuracy: 0.5333 - val_loss: 6.8811 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9548 - loss: 0.1226\nEpoch 9: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9560 - loss: 0.1205 - val_accuracy: 0.5333 - val_loss: 6.4764 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9865 - loss: 0.0600 - val_accuracy: 0.5333 - val_loss: 4.7822 - learning_rate: 1.0000e-03\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9964 - loss: 0.0372 - val_accuracy: 0.5667 - val_loss: 3.5388 - learning_rate: 1.0000e-03\nEpoch 11: early stopping\nRestoring model weights from the end of the best epoch: 6.\nFold 5 - Train Accuracy: 77.07%, Validation Accuracy: 83.33%\n\nTraining on Fold 6...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 413ms/step - accuracy: 0.6477 - loss: 1.1049 - val_accuracy: 0.5000 - val_loss: 860.3218 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9055 - loss: 0.2613 - val_accuracy: 0.5000 - val_loss: 438.2376 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9314 - loss: 0.1486 - val_accuracy: 0.5000 - val_loss: 37.5232 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9506 - loss: 0.1304 - val_accuracy: 0.5000 - val_loss: 20.6201 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9799 - loss: 0.0404 - val_accuracy: 0.5000 - val_loss: 14.1708 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9778 - loss: 0.0600 - val_accuracy: 0.5333 - val_loss: 10.0083 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9679 - loss: 0.0678 - val_accuracy: 0.7333 - val_loss: 1.9213 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9675 - loss: 0.1098 - val_accuracy: 0.5667 - val_loss: 4.5591 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9758 - loss: 0.0614 - val_accuracy: 0.7333 - val_loss: 1.9494 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9837 - loss: 0.0804\nEpoch 10: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9838 - loss: 0.0793 - val_accuracy: 0.5333 - val_loss: 5.3460 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9775 - loss: 0.0543 - val_accuracy: 0.5667 - val_loss: 4.1140 - learning_rate: 1.0000e-03\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9934 - loss: 0.0267 - val_accuracy: 0.5667 - val_loss: 3.2218 - learning_rate: 1.0000e-03\nEpoch 12: early stopping\nRestoring model weights from the end of the best epoch: 7.\nFold 6 - Train Accuracy: 75.56%, Validation Accuracy: 73.33%\n\nTraining on Fold 7...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 416ms/step - accuracy: 0.5898 - loss: 1.6001 - val_accuracy: 0.4828 - val_loss: 10373.5908 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8826 - loss: 0.3826 - val_accuracy: 0.4828 - val_loss: 347.1299 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.8908 - loss: 0.3242 - val_accuracy: 0.5172 - val_loss: 59.0188 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9244 - loss: 0.2437 - val_accuracy: 0.6207 - val_loss: 2.6299 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9624 - loss: 0.1577 - val_accuracy: 0.7241 - val_loss: 2.3157 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9587 - loss: 0.1400 - val_accuracy: 0.7586 - val_loss: 1.1810 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9695 - loss: 0.0926 - val_accuracy: 0.7931 - val_loss: 1.1927 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9791 - loss: 0.0606 - val_accuracy: 0.5517 - val_loss: 2.4751 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9570 - loss: 0.0854\nEpoch 9: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9564 - loss: 0.0879 - val_accuracy: 0.6897 - val_loss: 1.3100 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9579 - loss: 0.1240 - val_accuracy: 0.6897 - val_loss: 1.1538 - learning_rate: 1.0000e-03\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9649 - loss: 0.0595 - val_accuracy: 0.6552 - val_loss: 1.1769 - learning_rate: 1.0000e-03\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9968 - loss: 0.0262 - val_accuracy: 0.6552 - val_loss: 1.1874 - learning_rate: 1.0000e-03\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9928 - loss: 0.0225 - val_accuracy: 0.6552 - val_loss: 1.0847 - learning_rate: 1.0000e-03\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9945 - loss: 0.0238 - val_accuracy: 0.6897 - val_loss: 0.8498 - learning_rate: 1.0000e-03\nEpoch 15/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9968 - loss: 0.0196 - val_accuracy: 0.7586 - val_loss: 0.6946 - learning_rate: 1.0000e-03\nEpoch 16/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0189 - val_accuracy: 0.7586 - val_loss: 0.5939 - learning_rate: 1.0000e-03\nEpoch 17/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9949 - loss: 0.0214 - val_accuracy: 0.8621 - val_loss: 0.3781 - learning_rate: 1.0000e-03\nEpoch 18/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0186 - val_accuracy: 0.9310 - val_loss: 0.2531 - learning_rate: 1.0000e-03\nEpoch 19/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9968 - loss: 0.0126 - val_accuracy: 0.9310 - val_loss: 0.2332 - learning_rate: 1.0000e-03\nEpoch 20/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9968 - loss: 0.0149 - val_accuracy: 0.9310 - val_loss: 0.1606 - learning_rate: 1.0000e-03\nEpoch 21/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9977 - loss: 0.0144 - val_accuracy: 0.9655 - val_loss: 0.0758 - learning_rate: 1.0000e-03\nEpoch 22/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0150 - val_accuracy: 0.9655 - val_loss: 0.0643 - learning_rate: 1.0000e-03\nEpoch 23/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0091 - val_accuracy: 1.0000 - val_loss: 0.0451 - learning_rate: 1.0000e-03\nEpoch 24/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9968 - loss: 0.0129 - val_accuracy: 1.0000 - val_loss: 0.0384 - learning_rate: 1.0000e-03\nEpoch 25/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0089 - val_accuracy: 1.0000 - val_loss: 0.0291 - learning_rate: 1.0000e-03\nEpoch 26/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9968 - loss: 0.0128 - val_accuracy: 1.0000 - val_loss: 0.0207 - learning_rate: 1.0000e-03\nEpoch 27/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0084 - val_accuracy: 1.0000 - val_loss: 0.0151 - learning_rate: 1.0000e-03\nEpoch 28/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0111 - val_accuracy: 1.0000 - val_loss: 0.0094 - learning_rate: 1.0000e-03\nEpoch 29/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0055 - val_accuracy: 1.0000 - val_loss: 0.0073 - learning_rate: 1.0000e-03\nEpoch 30/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0076 - val_accuracy: 1.0000 - val_loss: 0.0065 - learning_rate: 1.0000e-03\nEpoch 31/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0063 - val_accuracy: 1.0000 - val_loss: 0.0053 - learning_rate: 1.0000e-03\nEpoch 32/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0082 - val_accuracy: 1.0000 - val_loss: 0.0064 - learning_rate: 1.0000e-03\nEpoch 33/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9968 - loss: 0.0115 - val_accuracy: 1.0000 - val_loss: 0.0115 - learning_rate: 1.0000e-03\nEpoch 34/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0131\nEpoch 34: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0130 - val_accuracy: 1.0000 - val_loss: 0.0053 - learning_rate: 1.0000e-03\nEpoch 35/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0053 - val_accuracy: 1.0000 - val_loss: 0.0050 - learning_rate: 1.0000e-04\nEpoch 36/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0065 - val_accuracy: 1.0000 - val_loss: 0.0050 - learning_rate: 1.0000e-04\nEpoch 37/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9968 - loss: 0.0087 - val_accuracy: 1.0000 - val_loss: 0.0052 - learning_rate: 1.0000e-04\nEpoch 38/50\n\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0052\nEpoch 38: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0055 - val_accuracy: 1.0000 - val_loss: 0.0053 - learning_rate: 1.0000e-04\nEpoch 39/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9968 - loss: 0.0106 - val_accuracy: 1.0000 - val_loss: 0.0052 - learning_rate: 1.0000e-05\nEpoch 40/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9968 - loss: 0.0080 - val_accuracy: 1.0000 - val_loss: 0.0053 - learning_rate: 1.0000e-05\nEpoch 40: early stopping\nRestoring model weights from the end of the best epoch: 35.\nFold 7 - Train Accuracy: 99.25%, Validation Accuracy: 100.00%\n\nTraining on Fold 8...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 414ms/step - accuracy: 0.7072 - loss: 0.9804 - val_accuracy: 0.4828 - val_loss: 8193.0967 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9124 - loss: 0.2735 - val_accuracy: 0.5172 - val_loss: 644.2912 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9527 - loss: 0.1119 - val_accuracy: 0.4483 - val_loss: 63.9924 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9589 - loss: 0.1060 - val_accuracy: 0.7931 - val_loss: 6.9687 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9874 - loss: 0.0366 - val_accuracy: 0.8621 - val_loss: 4.6259 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9567 - loss: 0.1358 - val_accuracy: 0.6207 - val_loss: 4.5336 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9414 - loss: 0.1406 - val_accuracy: 0.8276 - val_loss: 1.7141 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9736 - loss: 0.0643 - val_accuracy: 0.6552 - val_loss: 2.9824 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9814 - loss: 0.0546 - val_accuracy: 0.6897 - val_loss: 4.5087 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9842 - loss: 0.0657 - val_accuracy: 0.9310 - val_loss: 0.8086 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9666 - loss: 0.0834 - val_accuracy: 0.9310 - val_loss: 0.4333 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9980 - loss: 0.0084 - val_accuracy: 0.9655 - val_loss: 0.3347 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9855 - loss: 0.0205 - val_accuracy: 0.9655 - val_loss: 0.5005 - learning_rate: 0.0100\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9973 - loss: 0.0156 - val_accuracy: 0.8276 - val_loss: 1.1050 - learning_rate: 0.0100\nEpoch 15/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0056\nEpoch 15: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9996 - loss: 0.0066 - val_accuracy: 0.8621 - val_loss: 0.5412 - learning_rate: 0.0100\nEpoch 16/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 0.8966 - val_loss: 0.3990 - learning_rate: 1.0000e-03\nEpoch 17/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 0.8966 - val_loss: 0.3695 - learning_rate: 1.0000e-03\nEpoch 17: early stopping\nRestoring model weights from the end of the best epoch: 12.\nFold 8 - Train Accuracy: 92.88%, Validation Accuracy: 96.55%\n\nTraining on Fold 9...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 416ms/step - accuracy: 0.5721 - loss: 1.5033 - val_accuracy: 0.5172 - val_loss: 3025.3999 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8924 - loss: 0.3417 - val_accuracy: 0.5172 - val_loss: 161.9472 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9237 - loss: 0.1983 - val_accuracy: 0.5172 - val_loss: 38.1197 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9469 - loss: 0.1324 - val_accuracy: 0.5862 - val_loss: 12.3559 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9831 - loss: 0.0790 - val_accuracy: 0.5517 - val_loss: 8.9458 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9759 - loss: 0.0534 - val_accuracy: 0.7241 - val_loss: 3.1040 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9799 - loss: 0.0469 - val_accuracy: 0.5517 - val_loss: 8.9332 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9822 - loss: 0.0648 - val_accuracy: 0.6552 - val_loss: 6.1160 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9492 - loss: 0.1287\nEpoch 9: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9465 - loss: 0.1339 - val_accuracy: 0.7241 - val_loss: 3.9218 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9455 - loss: 0.2320 - val_accuracy: 0.8276 - val_loss: 1.0328 - learning_rate: 1.0000e-03\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9795 - loss: 0.1066 - val_accuracy: 0.9310 - val_loss: 0.7175 - learning_rate: 1.0000e-03\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9756 - loss: 0.0567 - val_accuracy: 0.8966 - val_loss: 0.6652 - learning_rate: 1.0000e-03\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9850 - loss: 0.0387 - val_accuracy: 0.8966 - val_loss: 0.6451 - learning_rate: 1.0000e-03\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9822 - loss: 0.0339 - val_accuracy: 0.8966 - val_loss: 0.6418 - learning_rate: 1.0000e-03\nEpoch 15/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9958 - loss: 0.0222 - val_accuracy: 0.9310 - val_loss: 0.5850 - learning_rate: 1.0000e-03\nEpoch 16/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0162 - val_accuracy: 0.9310 - val_loss: 0.5373 - learning_rate: 1.0000e-03\nEpoch 17/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0170 - val_accuracy: 0.9310 - val_loss: 0.5231 - learning_rate: 1.0000e-03\nEpoch 18/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9958 - loss: 0.0150 - val_accuracy: 0.9310 - val_loss: 0.5020 - learning_rate: 1.0000e-03\nEpoch 19/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9958 - loss: 0.0135 - val_accuracy: 0.9310 - val_loss: 0.4708 - learning_rate: 1.0000e-03\nEpoch 20/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9958 - loss: 0.0183 - val_accuracy: 0.9310 - val_loss: 0.4544 - learning_rate: 1.0000e-03\nEpoch 21/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0104 - val_accuracy: 0.9310 - val_loss: 0.4566 - learning_rate: 1.0000e-03\nEpoch 22/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9973 - loss: 0.0100 - val_accuracy: 0.9310 - val_loss: 0.4545 - learning_rate: 1.0000e-03\nEpoch 23/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0079 - val_accuracy: 0.9310 - val_loss: 0.4300 - learning_rate: 1.0000e-03\nEpoch 24/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0100 - val_accuracy: 0.9310 - val_loss: 0.4238 - learning_rate: 1.0000e-03\nEpoch 25/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0105 - val_accuracy: 0.9310 - val_loss: 0.3762 - learning_rate: 1.0000e-03\nEpoch 26/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0115 - val_accuracy: 0.9310 - val_loss: 0.3618 - learning_rate: 1.0000e-03\nEpoch 27/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0073 - val_accuracy: 0.9310 - val_loss: 0.3403 - learning_rate: 1.0000e-03\nEpoch 28/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0071 - val_accuracy: 0.9655 - val_loss: 0.3309 - learning_rate: 1.0000e-03\nEpoch 29/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0074 - val_accuracy: 0.9655 - val_loss: 0.3258 - learning_rate: 1.0000e-03\nEpoch 30/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0077 - val_accuracy: 0.9655 - val_loss: 0.3347 - learning_rate: 1.0000e-03\nEpoch 31/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0097 - val_accuracy: 0.9655 - val_loss: 0.3370 - learning_rate: 1.0000e-03\nEpoch 32/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0054 \nEpoch 32: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0056 - val_accuracy: 0.9655 - val_loss: 0.3326 - learning_rate: 1.0000e-03\nEpoch 33/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0061 - val_accuracy: 0.9655 - val_loss: 0.3273 - learning_rate: 1.0000e-04\nEpoch 34/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0044 - val_accuracy: 0.9655 - val_loss: 0.3234 - learning_rate: 1.0000e-04\nEpoch 35/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0042 - val_accuracy: 0.9655 - val_loss: 0.3207 - learning_rate: 1.0000e-04\nEpoch 36/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0075 - val_accuracy: 0.9655 - val_loss: 0.3196 - learning_rate: 1.0000e-04\nEpoch 37/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0055 - val_accuracy: 0.9655 - val_loss: 0.3169 - learning_rate: 1.0000e-04\nEpoch 38/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0045 - val_accuracy: 0.9655 - val_loss: 0.3138 - learning_rate: 1.0000e-04\nEpoch 39/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0045 - val_accuracy: 0.9655 - val_loss: 0.3130 - learning_rate: 1.0000e-04\nEpoch 40/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0072 - val_accuracy: 0.9655 - val_loss: 0.3127 - learning_rate: 1.0000e-04\nEpoch 41/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0032 - val_accuracy: 0.9655 - val_loss: 0.3125 - learning_rate: 1.0000e-04\nEpoch 42/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0062 - val_accuracy: 0.9655 - val_loss: 0.3144 - learning_rate: 1.0000e-04\nEpoch 43/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0055 - val_accuracy: 0.9655 - val_loss: 0.3157 - learning_rate: 1.0000e-04\nEpoch 44/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0053\nEpoch 44: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0056 - val_accuracy: 0.9655 - val_loss: 0.3131 - learning_rate: 1.0000e-04\nEpoch 45/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0041 - val_accuracy: 0.9655 - val_loss: 0.3120 - learning_rate: 1.0000e-05\nEpoch 46/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0042 - val_accuracy: 0.9655 - val_loss: 0.3123 - learning_rate: 1.0000e-05\nEpoch 47/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0060 - val_accuracy: 0.9655 - val_loss: 0.3108 - learning_rate: 1.0000e-05\nEpoch 48/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0041 - val_accuracy: 0.9655 - val_loss: 0.3117 - learning_rate: 1.0000e-05\nEpoch 49/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0054 - val_accuracy: 0.9655 - val_loss: 0.3113 - learning_rate: 1.0000e-05\nEpoch 50/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0027 \nEpoch 50: ReduceLROnPlateau reducing learning rate to 9.99999883788405e-07.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0030 - val_accuracy: 0.9655 - val_loss: 0.3111 - learning_rate: 1.0000e-05\nRestoring model weights from the end of the best epoch: 47.\nFold 9 - Train Accuracy: 100.00%, Validation Accuracy: 96.55%\n\nTraining on Fold 10...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 413ms/step - accuracy: 0.6130 - loss: 1.4028 - val_accuracy: 0.7241 - val_loss: 95.1961 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.8083 - loss: 0.4206 - val_accuracy: 0.4828 - val_loss: 1321.4591 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.8511 - loss: 0.3517 - val_accuracy: 0.4828 - val_loss: 90.4384 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9239 - loss: 0.1801 - val_accuracy: 0.5517 - val_loss: 7.5313 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9887 - loss: 0.0725 - val_accuracy: 0.4828 - val_loss: 8.6257 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9699 - loss: 0.0923 - val_accuracy: 0.4828 - val_loss: 5.7382 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9813 - loss: 0.0677 - val_accuracy: 0.6897 - val_loss: 2.3627 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9643 - loss: 0.0556 - val_accuracy: 0.5517 - val_loss: 3.4337 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9759 - loss: 0.0595 - val_accuracy: 0.7931 - val_loss: 1.7641 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9903 - loss: 0.0384 - val_accuracy: 0.8276 - val_loss: 1.0378 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9854 - loss: 0.0462 - val_accuracy: 0.8621 - val_loss: 0.5456 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0152 - val_accuracy: 0.8966 - val_loss: 0.4788 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0102 - val_accuracy: 0.8621 - val_loss: 0.5906 - learning_rate: 0.0100\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9973 - loss: 0.0098 - val_accuracy: 0.8966 - val_loss: 0.7417 - learning_rate: 0.0100\nEpoch 15/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0056\nEpoch 15: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0059 - val_accuracy: 0.7931 - val_loss: 1.4301 - learning_rate: 0.0100\nEpoch 16/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9986 - loss: 0.0072 - val_accuracy: 0.7931 - val_loss: 1.5227 - learning_rate: 1.0000e-03\nEpoch 17/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0053 - val_accuracy: 0.7931 - val_loss: 1.3540 - learning_rate: 1.0000e-03\nEpoch 17: early stopping\nRestoring model weights from the end of the best epoch: 12.\nFold 10 - Train Accuracy: 93.26%, Validation Accuracy: 89.66%\n\nAverage Training Accuracy: 92.56%\nAverage Validation Accuracy: 93.61%\n","output_type":"stream"}],"execution_count":93},{"cell_type":"markdown","source":"## 2.3 Rotating 180 degrees","metadata":{}},{"cell_type":"code","source":"X_train_rotated = np.rot180(X_train, k=2, axes=(1,2))\nX_test_rotated = np.rot180(X_test, k=2, axes=(1,2))\n\nX_train_augmented = np.concatenate((X_train, X_train_rotated), axis=0)\ny_train_augmented = np.concatenate((y_train, y_train), axis=0)\n\ntrain_evaluate_model_with_k_fold(\n    X_train=X_train_augmented,\n    y_train=y_train_augmented,\n    lr=0.01,\n    epochs=50,\n    batch_size=16)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T20:17:38.218503Z","iopub.execute_input":"2025-02-07T20:17:38.218730Z","iopub.status.idle":"2025-02-07T20:22:13.503580Z","shell.execute_reply.started":"2025-02-07T20:17:38.218711Z","shell.execute_reply":"2025-02-07T20:22:13.502774Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"\nTraining on Fold 1...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 417ms/step - accuracy: 0.7017 - loss: 1.0316 - val_accuracy: 0.5000 - val_loss: 5975.9946 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8575 - loss: 0.3144 - val_accuracy: 0.5000 - val_loss: 455.1063 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9435 - loss: 0.1664 - val_accuracy: 0.4333 - val_loss: 28.0014 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9273 - loss: 0.1367 - val_accuracy: 0.5000 - val_loss: 33.0817 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9306 - loss: 0.1428 - val_accuracy: 0.5000 - val_loss: 5.3856 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9832 - loss: 0.0499 - val_accuracy: 0.5333 - val_loss: 5.0419 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9804 - loss: 0.0385 - val_accuracy: 0.6000 - val_loss: 2.5874 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9908 - loss: 0.0273 - val_accuracy: 0.6333 - val_loss: 2.2090 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9973 - loss: 0.0205 - val_accuracy: 0.5333 - val_loss: 5.4682 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9903 - loss: 0.0513 - val_accuracy: 0.9000 - val_loss: 0.4326 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9742 - loss: 0.0478 - val_accuracy: 0.8667 - val_loss: 0.5168 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9863 - loss: 0.0452 - val_accuracy: 0.8667 - val_loss: 0.4239 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9888 - loss: 0.0562 - val_accuracy: 0.7667 - val_loss: 1.4342 - learning_rate: 0.0100\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9931 - loss: 0.0382 - val_accuracy: 0.5333 - val_loss: 9.0806 - learning_rate: 0.0100\nEpoch 15/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9916 - loss: 0.0320\nEpoch 15: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9917 - loss: 0.0331 - val_accuracy: 0.8333 - val_loss: 0.9574 - learning_rate: 0.0100\nEpoch 16/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9836 - loss: 0.0916 - val_accuracy: 0.8667 - val_loss: 0.2261 - learning_rate: 1.0000e-03\nEpoch 17/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9921 - loss: 0.0177 - val_accuracy: 0.9333 - val_loss: 0.1592 - learning_rate: 1.0000e-03\nEpoch 18/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0061 - val_accuracy: 0.9333 - val_loss: 0.1928 - learning_rate: 1.0000e-03\nEpoch 19/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0056 - val_accuracy: 0.9333 - val_loss: 0.2137 - learning_rate: 1.0000e-03\nEpoch 20/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0072\nEpoch 20: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0071 - val_accuracy: 0.9333 - val_loss: 0.2270 - learning_rate: 1.0000e-03\nEpoch 21/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0050 - val_accuracy: 0.9333 - val_loss: 0.2305 - learning_rate: 1.0000e-04\nEpoch 22/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0046 - val_accuracy: 0.9333 - val_loss: 0.2319 - learning_rate: 1.0000e-04\nEpoch 22: early stopping\nRestoring model weights from the end of the best epoch: 17.\nFold 1 - Train Accuracy: 96.99%, Validation Accuracy: 93.33%\n\nTraining on Fold 2...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 418ms/step - accuracy: 0.7745 - loss: 0.9139 - val_accuracy: 0.5000 - val_loss: 4913.1577 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.8492 - loss: 0.4177 - val_accuracy: 0.5000 - val_loss: 338.0827 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9464 - loss: 0.1657 - val_accuracy: 0.5000 - val_loss: 64.9230 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9775 - loss: 0.0927 - val_accuracy: 0.5000 - val_loss: 23.5754 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9717 - loss: 0.1017 - val_accuracy: 0.5000 - val_loss: 8.9480 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9865 - loss: 0.0536 - val_accuracy: 0.5333 - val_loss: 3.2759 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9916 - loss: 0.0325 - val_accuracy: 0.5000 - val_loss: 2.9125 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9902 - loss: 0.0299 - val_accuracy: 0.6333 - val_loss: 1.7526 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9964 - loss: 0.0155 - val_accuracy: 0.7000 - val_loss: 0.9210 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9919 - loss: 0.0208 - val_accuracy: 0.8000 - val_loss: 0.7837 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9824 - loss: 0.0395 - val_accuracy: 0.8667 - val_loss: 0.5440 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9738 - loss: 0.0673 - val_accuracy: 0.9333 - val_loss: 0.2188 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9858 - loss: 0.0407 - val_accuracy: 0.9667 - val_loss: 0.0528 - learning_rate: 0.0100\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9951 - loss: 0.0144 - val_accuracy: 1.0000 - val_loss: 0.0184 - learning_rate: 0.0100\nEpoch 15/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9975 - loss: 0.0092 - val_accuracy: 0.8667 - val_loss: 0.9539 - learning_rate: 0.0100\nEpoch 16/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9884 - loss: 0.0339 - val_accuracy: 0.8333 - val_loss: 0.6116 - learning_rate: 0.0100\nEpoch 17/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9686 - loss: 0.0941\nEpoch 17: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9675 - loss: 0.0972 - val_accuracy: 0.9333 - val_loss: 0.1411 - learning_rate: 0.0100\nEpoch 18/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9973 - loss: 0.0092 - val_accuracy: 0.9333 - val_loss: 0.0907 - learning_rate: 1.0000e-03\nEpoch 19/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9989 - loss: 0.0111 - val_accuracy: 0.9667 - val_loss: 0.0657 - learning_rate: 1.0000e-03\nEpoch 19: early stopping\nRestoring model weights from the end of the best epoch: 14.\nFold 2 - Train Accuracy: 90.98%, Validation Accuracy: 100.00%\n\nTraining on Fold 3...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 418ms/step - accuracy: 0.6891 - loss: 1.2126 - val_accuracy: 0.5000 - val_loss: 1655.2473 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8898 - loss: 0.2520 - val_accuracy: 0.5000 - val_loss: 239.2184 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9374 - loss: 0.1527 - val_accuracy: 0.5000 - val_loss: 59.6500 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9541 - loss: 0.1097 - val_accuracy: 0.5000 - val_loss: 26.0393 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9825 - loss: 0.0588 - val_accuracy: 0.5000 - val_loss: 17.2025 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9650 - loss: 0.0672 - val_accuracy: 0.5000 - val_loss: 8.5182 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9883 - loss: 0.0326 - val_accuracy: 0.8667 - val_loss: 1.0574 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9931 - loss: 0.0200 - val_accuracy: 0.9000 - val_loss: 1.3575 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9989 - loss: 0.0139 - val_accuracy: 0.7333 - val_loss: 1.8257 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9931 - loss: 0.0206 - val_accuracy: 0.9333 - val_loss: 0.8123 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9931 - loss: 0.0127 - val_accuracy: 0.8667 - val_loss: 1.1304 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9926 - loss: 0.0142 - val_accuracy: 0.7667 - val_loss: 2.1009 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9628 - loss: 0.0786 - val_accuracy: 1.0000 - val_loss: 0.0690 - learning_rate: 0.0100\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9335 - loss: 0.2664 - val_accuracy: 0.8333 - val_loss: 1.0223 - learning_rate: 0.0100\nEpoch 15/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9027 - loss: 0.2044 - val_accuracy: 0.9000 - val_loss: 0.8098 - learning_rate: 0.0100\nEpoch 16/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9458 - loss: 0.1195\nEpoch 16: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9472 - loss: 0.1167 - val_accuracy: 0.8667 - val_loss: 0.5661 - learning_rate: 0.0100\nEpoch 17/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9823 - loss: 0.0547 - val_accuracy: 0.9667 - val_loss: 0.2243 - learning_rate: 1.0000e-03\nEpoch 18/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9956 - loss: 0.0246 - val_accuracy: 0.9667 - val_loss: 0.1395 - learning_rate: 1.0000e-03\nEpoch 18: early stopping\nRestoring model weights from the end of the best epoch: 13.\nFold 3 - Train Accuracy: 86.09%, Validation Accuracy: 100.00%\n\nTraining on Fold 4...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 430ms/step - accuracy: 0.6960 - loss: 1.0019 - val_accuracy: 0.5000 - val_loss: 4317.1206 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.8996 - loss: 0.2990 - val_accuracy: 0.5000 - val_loss: 254.5440 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9215 - loss: 0.1582 - val_accuracy: 0.5000 - val_loss: 85.3654 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9441 - loss: 0.1239 - val_accuracy: 0.5000 - val_loss: 26.6385 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9584 - loss: 0.1286 - val_accuracy: 0.4667 - val_loss: 5.1537 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9745 - loss: 0.0950 - val_accuracy: 0.5000 - val_loss: 2.9723 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9878 - loss: 0.0515 - val_accuracy: 0.6667 - val_loss: 2.4927 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9972 - loss: 0.0428 - val_accuracy: 0.7000 - val_loss: 2.5103 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9711 - loss: 0.0701 - val_accuracy: 0.5000 - val_loss: 11.0729 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9394 - loss: 0.1779\nEpoch 10: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9413 - loss: 0.1710 - val_accuracy: 0.5000 - val_loss: 11.6218 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9675 - loss: 0.0797 - val_accuracy: 0.5333 - val_loss: 5.1762 - learning_rate: 1.0000e-03\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9855 - loss: 0.0562 - val_accuracy: 0.6333 - val_loss: 2.7255 - learning_rate: 1.0000e-03\nEpoch 12: early stopping\nRestoring model weights from the end of the best epoch: 7.\nFold 4 - Train Accuracy: 80.83%, Validation Accuracy: 66.67%\n\nTraining on Fold 5...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 419ms/step - accuracy: 0.7561 - loss: 0.9836 - val_accuracy: 0.5000 - val_loss: 8473.5664 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.8749 - loss: 0.3450 - val_accuracy: 0.5000 - val_loss: 491.8939 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9264 - loss: 0.1714 - val_accuracy: 0.5000 - val_loss: 281.4154 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9383 - loss: 0.1451 - val_accuracy: 0.5333 - val_loss: 52.4922 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9656 - loss: 0.0777 - val_accuracy: 0.4667 - val_loss: 10.5211 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9603 - loss: 0.0904 - val_accuracy: 0.5333 - val_loss: 17.2013 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9734 - loss: 0.0786 - val_accuracy: 0.5333 - val_loss: 2.3541 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9661 - loss: 0.0890 - val_accuracy: 0.5333 - val_loss: 13.0870 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9598 - loss: 0.0858 - val_accuracy: 0.6000 - val_loss: 6.7072 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9854 - loss: 0.0803 - val_accuracy: 0.8333 - val_loss: 0.7276 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9746 - loss: 0.0723 - val_accuracy: 0.8333 - val_loss: 1.2553 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9859 - loss: 0.0354 - val_accuracy: 1.0000 - val_loss: 0.0193 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9884 - loss: 0.0219 - val_accuracy: 1.0000 - val_loss: 0.0205 - learning_rate: 0.0100\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9994 - loss: 0.0164 - val_accuracy: 1.0000 - val_loss: 0.0045 - learning_rate: 0.0100\nEpoch 15/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9867 - loss: 0.0176 - val_accuracy: 0.9333 - val_loss: 0.4204 - learning_rate: 0.0100\nEpoch 16/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9696 - loss: 0.0725 - val_accuracy: 0.9667 - val_loss: 0.1100 - learning_rate: 0.0100\nEpoch 17/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9821 - loss: 0.0422\nEpoch 17: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9828 - loss: 0.0440 - val_accuracy: 0.9000 - val_loss: 0.3681 - learning_rate: 0.0100\nEpoch 18/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9888 - loss: 0.0254 - val_accuracy: 0.9333 - val_loss: 0.2652 - learning_rate: 1.0000e-03\nEpoch 19/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0039 - val_accuracy: 0.9333 - val_loss: 0.2003 - learning_rate: 1.0000e-03\nEpoch 19: early stopping\nRestoring model weights from the end of the best epoch: 14.\nFold 5 - Train Accuracy: 99.62%, Validation Accuracy: 100.00%\n\nTraining on Fold 6...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 413ms/step - accuracy: 0.7141 - loss: 0.8669 - val_accuracy: 0.5000 - val_loss: 3943.4517 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9002 - loss: 0.2789 - val_accuracy: 0.5000 - val_loss: 463.0600 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9200 - loss: 0.1524 - val_accuracy: 0.5000 - val_loss: 78.2061 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9669 - loss: 0.0886 - val_accuracy: 0.5000 - val_loss: 26.8919 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9850 - loss: 0.0573 - val_accuracy: 0.5333 - val_loss: 13.8055 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9811 - loss: 0.0620 - val_accuracy: 0.5000 - val_loss: 11.0175 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9458 - loss: 0.1246 - val_accuracy: 0.4667 - val_loss: 3.5129 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9656 - loss: 0.0952 - val_accuracy: 0.6667 - val_loss: 1.8429 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9830 - loss: 0.0702 - val_accuracy: 0.7000 - val_loss: 1.0742 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9941 - loss: 0.0260 - val_accuracy: 0.6667 - val_loss: 1.8015 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9862 - loss: 0.0206 - val_accuracy: 0.5667 - val_loss: 3.8432 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9828 - loss: 0.0613\nEpoch 12: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9830 - loss: 0.0595 - val_accuracy: 0.7000 - val_loss: 1.6844 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9839 - loss: 0.0192 - val_accuracy: 0.7000 - val_loss: 1.6471 - learning_rate: 1.0000e-03\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9983 - loss: 0.0057 - val_accuracy: 0.7000 - val_loss: 1.5585 - learning_rate: 1.0000e-03\nEpoch 14: early stopping\nRestoring model weights from the end of the best epoch: 9.\nFold 6 - Train Accuracy: 78.95%, Validation Accuracy: 70.00%\n\nTraining on Fold 7...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 418ms/step - accuracy: 0.6302 - loss: 1.4685 - val_accuracy: 0.4828 - val_loss: 5349.1885 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.8932 - loss: 0.3364 - val_accuracy: 0.5172 - val_loss: 348.2767 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9180 - loss: 0.2161 - val_accuracy: 0.5172 - val_loss: 65.4382 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9565 - loss: 0.1370 - val_accuracy: 0.5172 - val_loss: 38.4636 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9627 - loss: 0.0840 - val_accuracy: 0.5172 - val_loss: 3.8232 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9860 - loss: 0.0491 - val_accuracy: 0.5862 - val_loss: 1.5536 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9863 - loss: 0.0497 - val_accuracy: 0.5172 - val_loss: 1.3828 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9772 - loss: 0.0435 - val_accuracy: 0.5172 - val_loss: 4.9311 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9608 - loss: 0.1404 - val_accuracy: 0.6897 - val_loss: 1.6888 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9821 - loss: 0.0536 - val_accuracy: 0.8966 - val_loss: 0.7962 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9912 - loss: 0.0355 - val_accuracy: 0.6552 - val_loss: 2.2326 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9696 - loss: 0.0904 - val_accuracy: 0.8621 - val_loss: 0.7121 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9945 - loss: 0.0232 - val_accuracy: 0.7931 - val_loss: 1.2963 - learning_rate: 0.0100\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9994 - loss: 0.0201 - val_accuracy: 0.8966 - val_loss: 0.3900 - learning_rate: 0.0100\nEpoch 15/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0063 - val_accuracy: 0.8966 - val_loss: 0.3009 - learning_rate: 0.0100\nEpoch 16/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9930 - loss: 0.0171 - val_accuracy: 0.9655 - val_loss: 0.2858 - learning_rate: 0.0100\nEpoch 17/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9898 - loss: 0.0548 - val_accuracy: 0.9310 - val_loss: 0.1752 - learning_rate: 0.0100\nEpoch 18/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9800 - loss: 0.0743 - val_accuracy: 0.7931 - val_loss: 0.5794 - learning_rate: 0.0100\nEpoch 19/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9655 - loss: 0.0800 - val_accuracy: 0.9655 - val_loss: 0.1482 - learning_rate: 0.0100\nEpoch 20/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9721 - loss: 0.0635 - val_accuracy: 0.8621 - val_loss: 0.3304 - learning_rate: 0.0100\nEpoch 21/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9949 - loss: 0.0341 - val_accuracy: 0.9655 - val_loss: 0.1621 - learning_rate: 0.0100\nEpoch 22/50\n\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9964 - loss: 0.0167\nEpoch 22: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9964 - loss: 0.0172 - val_accuracy: 0.9310 - val_loss: 0.3409 - learning_rate: 0.0100\nEpoch 23/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9937 - loss: 0.0128 - val_accuracy: 0.9310 - val_loss: 0.2348 - learning_rate: 1.0000e-03\nEpoch 24/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9968 - loss: 0.0070 - val_accuracy: 0.8966 - val_loss: 0.1663 - learning_rate: 1.0000e-03\nEpoch 24: early stopping\nRestoring model weights from the end of the best epoch: 19.\nFold 7 - Train Accuracy: 96.63%, Validation Accuracy: 96.55%\n\nTraining on Fold 8...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 418ms/step - accuracy: 0.7429 - loss: 0.8838 - val_accuracy: 0.5172 - val_loss: 5825.9980 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.8936 - loss: 0.2312 - val_accuracy: 0.5172 - val_loss: 832.8497 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9421 - loss: 0.1480 - val_accuracy: 0.5172 - val_loss: 187.0098 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9684 - loss: 0.0676 - val_accuracy: 0.5172 - val_loss: 43.6305 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9915 - loss: 0.0326 - val_accuracy: 0.5172 - val_loss: 24.1279 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9950 - loss: 0.0273 - val_accuracy: 0.5517 - val_loss: 3.4707 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9882 - loss: 0.0333 - val_accuracy: 0.7241 - val_loss: 1.4773 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9845 - loss: 0.0453 - val_accuracy: 0.8276 - val_loss: 0.8537 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9820 - loss: 0.0596 - val_accuracy: 0.8621 - val_loss: 0.6129 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9819 - loss: 0.0572 - val_accuracy: 0.9310 - val_loss: 0.2385 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9749 - loss: 0.0796 - val_accuracy: 0.9310 - val_loss: 0.2174 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9977 - loss: 0.0159 - val_accuracy: 0.9655 - val_loss: 0.2459 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0187 - val_accuracy: 0.9655 - val_loss: 0.1548 - learning_rate: 0.0100\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0055 - val_accuracy: 0.9655 - val_loss: 0.1671 - learning_rate: 0.0100\nEpoch 15/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.9655 - val_loss: 0.2178 - learning_rate: 0.0100\nEpoch 16/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0015\nEpoch 16: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.9655 - val_loss: 0.2625 - learning_rate: 0.0100\nEpoch 17/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 6.8367e-04 - val_accuracy: 0.9655 - val_loss: 0.2706 - learning_rate: 1.0000e-03\nEpoch 18/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 8.6171e-04 - val_accuracy: 0.9655 - val_loss: 0.2703 - learning_rate: 1.0000e-03\nEpoch 18: early stopping\nRestoring model weights from the end of the best epoch: 13.\nFold 8 - Train Accuracy: 98.50%, Validation Accuracy: 96.55%\n\nTraining on Fold 9...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 409ms/step - accuracy: 0.6063 - loss: 1.3037 - val_accuracy: 0.5172 - val_loss: 4996.6655 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.8051 - loss: 0.3553 - val_accuracy: 0.4828 - val_loss: 163.2422 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9247 - loss: 0.1704 - val_accuracy: 0.4138 - val_loss: 40.9846 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9419 - loss: 0.1074 - val_accuracy: 0.6552 - val_loss: 9.7892 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9707 - loss: 0.0686 - val_accuracy: 0.4828 - val_loss: 27.5898 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9632 - loss: 0.1230 - val_accuracy: 0.6552 - val_loss: 1.8125 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9677 - loss: 0.0734 - val_accuracy: 0.6552 - val_loss: 5.7218 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9779 - loss: 0.0756 - val_accuracy: 0.7931 - val_loss: 1.4274 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9899 - loss: 0.0324 - val_accuracy: 0.8276 - val_loss: 1.4482 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9899 - loss: 0.0564 - val_accuracy: 0.9655 - val_loss: 0.4591 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9918 - loss: 0.0233 - val_accuracy: 0.9655 - val_loss: 0.7949 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9912 - loss: 0.0509 - val_accuracy: 0.8621 - val_loss: 0.8275 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9998 - loss: 0.0206\nEpoch 13: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9990 - loss: 0.0242 - val_accuracy: 0.9655 - val_loss: 0.6080 - learning_rate: 0.0100\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0137 - val_accuracy: 0.9655 - val_loss: 0.5542 - learning_rate: 1.0000e-03\nEpoch 15/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0085 - val_accuracy: 0.9655 - val_loss: 0.5096 - learning_rate: 1.0000e-03\nEpoch 15: early stopping\nRestoring model weights from the end of the best epoch: 10.\nFold 9 - Train Accuracy: 88.39%, Validation Accuracy: 96.55%\n\nTraining on Fold 10...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 419ms/step - accuracy: 0.6692 - loss: 0.9942 - val_accuracy: 0.5172 - val_loss: 2904.0464 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8662 - loss: 0.3959 - val_accuracy: 0.4828 - val_loss: 1011.5618 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9209 - loss: 0.2046 - val_accuracy: 0.4483 - val_loss: 16.3471 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9213 - loss: 0.1679 - val_accuracy: 0.3448 - val_loss: 15.2019 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9644 - loss: 0.0967 - val_accuracy: 0.4828 - val_loss: 7.3115 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9662 - loss: 0.0684 - val_accuracy: 0.6897 - val_loss: 4.4162 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9775 - loss: 0.0509 - val_accuracy: 0.7931 - val_loss: 1.5238 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9724 - loss: 0.0864 - val_accuracy: 0.7931 - val_loss: 2.0232 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9793 - loss: 0.0695 - val_accuracy: 0.8621 - val_loss: 1.8078 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9811 - loss: 0.0546\nEpoch 10: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9792 - loss: 0.0568 - val_accuracy: 0.8621 - val_loss: 1.6269 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0145 - val_accuracy: 0.8966 - val_loss: 1.2092 - learning_rate: 1.0000e-03\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0160 - val_accuracy: 0.8966 - val_loss: 1.0179 - learning_rate: 1.0000e-03\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9809 - loss: 0.0263 - val_accuracy: 0.8966 - val_loss: 0.8760 - learning_rate: 1.0000e-03\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9994 - loss: 0.0109 - val_accuracy: 0.8621 - val_loss: 0.7786 - learning_rate: 1.0000e-03\nEpoch 15/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0111 - val_accuracy: 0.8621 - val_loss: 0.7188 - learning_rate: 1.0000e-03\nEpoch 16/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9973 - loss: 0.0121 - val_accuracy: 0.8966 - val_loss: 0.6476 - learning_rate: 1.0000e-03\nEpoch 17/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0093 - val_accuracy: 0.8966 - val_loss: 0.6301 - learning_rate: 1.0000e-03\nEpoch 18/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0088 - val_accuracy: 0.8966 - val_loss: 0.6158 - learning_rate: 1.0000e-03\nEpoch 19/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0071 - val_accuracy: 0.8621 - val_loss: 0.5958 - learning_rate: 1.0000e-03\nEpoch 20/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0092 - val_accuracy: 0.8621 - val_loss: 0.5453 - learning_rate: 1.0000e-03\nEpoch 21/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0061 - val_accuracy: 0.8621 - val_loss: 0.4788 - learning_rate: 1.0000e-03\nEpoch 22/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0061 - val_accuracy: 0.8621 - val_loss: 0.4491 - learning_rate: 1.0000e-03\nEpoch 23/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0044 - val_accuracy: 0.8621 - val_loss: 0.4373 - learning_rate: 1.0000e-03\nEpoch 24/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0072 - val_accuracy: 0.8966 - val_loss: 0.4147 - learning_rate: 1.0000e-03\nEpoch 25/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0046 - val_accuracy: 0.8966 - val_loss: 0.4058 - learning_rate: 1.0000e-03\nEpoch 26/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0038 - val_accuracy: 0.8621 - val_loss: 0.4067 - learning_rate: 1.0000e-03\nEpoch 27/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0056 - val_accuracy: 0.8966 - val_loss: 0.3939 - learning_rate: 1.0000e-03\nEpoch 28/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0036 - val_accuracy: 0.8966 - val_loss: 0.3840 - learning_rate: 1.0000e-03\nEpoch 29/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0053 - val_accuracy: 0.8966 - val_loss: 0.3617 - learning_rate: 1.0000e-03\nEpoch 30/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0043 - val_accuracy: 0.8966 - val_loss: 0.3397 - learning_rate: 1.0000e-03\nEpoch 31/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0051 - val_accuracy: 0.9310 - val_loss: 0.3346 - learning_rate: 1.0000e-03\nEpoch 32/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.9310 - val_loss: 0.3313 - learning_rate: 1.0000e-03\nEpoch 33/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 0.9310 - val_loss: 0.3338 - learning_rate: 1.0000e-03\nEpoch 34/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 0.9310 - val_loss: 0.3431 - learning_rate: 1.0000e-03\nEpoch 35/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9998 - loss: 0.0033\nEpoch 35: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9994 - loss: 0.0039 - val_accuracy: 0.9310 - val_loss: 0.3466 - learning_rate: 1.0000e-03\nEpoch 36/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0023 - val_accuracy: 0.9310 - val_loss: 0.3444 - learning_rate: 1.0000e-04\nEpoch 37/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.9310 - val_loss: 0.3418 - learning_rate: 1.0000e-04\nEpoch 37: early stopping\nRestoring model weights from the end of the best epoch: 32.\nFold 10 - Train Accuracy: 98.50%, Validation Accuracy: 93.10%\n\nAverage Training Accuracy: 91.55%\nAverage Validation Accuracy: 91.28%\n","output_type":"stream"}],"execution_count":94},{"cell_type":"markdown","source":"## 2.4 Rotating 270 degrees","metadata":{}},{"cell_type":"code","source":"X_train_rotated = np.rot270(X_train, k=3, axes=(1,2))\nX_test_rotated = np.rot270(X_test, k=3, axes=(1,2))\n\nX_train_augmented = np.concatenate((X_train, X_train_rotated), axis=0)\ny_train_augmented = np.concatenate((y_train, y_train), axis=0)\n\ntrain_evaluate_model_with_k_fold(\n    X_train=X_train_augmented,\n    y_train=y_train_augmented,\n    lr=0.01,\n    epochs=50,\n    batch_size=16)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T20:22:13.504699Z","iopub.execute_input":"2025-02-07T20:22:13.504960Z","iopub.status.idle":"2025-02-07T20:26:48.252769Z","shell.execute_reply.started":"2025-02-07T20:22:13.504939Z","shell.execute_reply":"2025-02-07T20:26:48.251876Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"\nTraining on Fold 1...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 418ms/step - accuracy: 0.6981 - loss: 1.2505 - val_accuracy: 0.5000 - val_loss: 1607.7814 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.8862 - loss: 0.2480 - val_accuracy: 0.5000 - val_loss: 394.4673 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9394 - loss: 0.1392 - val_accuracy: 0.5000 - val_loss: 295.5130 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9551 - loss: 0.1141 - val_accuracy: 0.5000 - val_loss: 103.0436 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9614 - loss: 0.1062 - val_accuracy: 0.5333 - val_loss: 15.5523 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9463 - loss: 0.1305 - val_accuracy: 0.5333 - val_loss: 4.8851 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9949 - loss: 0.0614 - val_accuracy: 0.5667 - val_loss: 5.5517 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9921 - loss: 0.0364 - val_accuracy: 0.6667 - val_loss: 1.1213 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9716 - loss: 0.0636 - val_accuracy: 0.8667 - val_loss: 0.3657 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9796 - loss: 0.0567 - val_accuracy: 0.8667 - val_loss: 0.9205 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9958 - loss: 0.0421 - val_accuracy: 1.0000 - val_loss: 0.0221 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9740 - loss: 0.0734 - val_accuracy: 0.8000 - val_loss: 0.9972 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9668 - loss: 0.1015 - val_accuracy: 0.8333 - val_loss: 0.6611 - learning_rate: 0.0100\nEpoch 14/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9826 - loss: 0.0515\nEpoch 14: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9828 - loss: 0.0504 - val_accuracy: 0.9333 - val_loss: 0.0804 - learning_rate: 0.0100\nEpoch 15/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9888 - loss: 0.0265 - val_accuracy: 0.9667 - val_loss: 0.0486 - learning_rate: 1.0000e-03\nEpoch 16/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0099 - val_accuracy: 0.9667 - val_loss: 0.0579 - learning_rate: 1.0000e-03\nEpoch 16: early stopping\nRestoring model weights from the end of the best epoch: 11.\nFold 1 - Train Accuracy: 94.36%, Validation Accuracy: 100.00%\n\nTraining on Fold 2...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 423ms/step - accuracy: 0.6011 - loss: 1.5730 - val_accuracy: 0.5000 - val_loss: 1110.5763 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.7743 - loss: 0.4531 - val_accuracy: 0.5000 - val_loss: 332.4502 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9186 - loss: 0.2578 - val_accuracy: 0.5000 - val_loss: 207.2202 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9128 - loss: 0.2264 - val_accuracy: 0.5000 - val_loss: 79.8109 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9555 - loss: 0.1266 - val_accuracy: 0.5000 - val_loss: 37.6913 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9699 - loss: 0.0825 - val_accuracy: 0.5333 - val_loss: 17.5848 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9760 - loss: 0.0521 - val_accuracy: 0.5667 - val_loss: 10.7115 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9952 - loss: 0.0222 - val_accuracy: 0.5667 - val_loss: 4.4777 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0163 - val_accuracy: 0.5667 - val_loss: 4.1745 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9927 - loss: 0.0175 - val_accuracy: 0.7667 - val_loss: 1.2084 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9922 - loss: 0.0250 - val_accuracy: 0.6000 - val_loss: 3.7155 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9654 - loss: 0.1364 - val_accuracy: 0.5667 - val_loss: 5.3585 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9733 - loss: 0.0819\nEpoch 13: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9746 - loss: 0.0788 - val_accuracy: 0.7000 - val_loss: 2.6380 - learning_rate: 0.0100\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9893 - loss: 0.0385 - val_accuracy: 0.8333 - val_loss: 1.0495 - learning_rate: 1.0000e-03\nEpoch 15/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9951 - loss: 0.0292 - val_accuracy: 0.8667 - val_loss: 0.4811 - learning_rate: 1.0000e-03\nEpoch 16/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9893 - loss: 0.0318 - val_accuracy: 0.9000 - val_loss: 0.2367 - learning_rate: 1.0000e-03\nEpoch 17/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0174 - val_accuracy: 0.9333 - val_loss: 0.1616 - learning_rate: 1.0000e-03\nEpoch 18/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0165 - val_accuracy: 0.9333 - val_loss: 0.1470 - learning_rate: 1.0000e-03\nEpoch 19/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0128 - val_accuracy: 0.9333 - val_loss: 0.1270 - learning_rate: 1.0000e-03\nEpoch 20/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0072 - val_accuracy: 0.9333 - val_loss: 0.1001 - learning_rate: 1.0000e-03\nEpoch 21/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0079 - val_accuracy: 0.9667 - val_loss: 0.0971 - learning_rate: 1.0000e-03\nEpoch 22/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0075 - val_accuracy: 0.9667 - val_loss: 0.0941 - learning_rate: 1.0000e-03\nEpoch 23/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0067 - val_accuracy: 0.9667 - val_loss: 0.0819 - learning_rate: 1.0000e-03\nEpoch 24/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9964 - loss: 0.0102 - val_accuracy: 0.9667 - val_loss: 0.0858 - learning_rate: 1.0000e-03\nEpoch 25/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0062 - val_accuracy: 0.9667 - val_loss: 0.0880 - learning_rate: 1.0000e-03\nEpoch 26/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0066\nEpoch 26: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0070 - val_accuracy: 0.9667 - val_loss: 0.0890 - learning_rate: 1.0000e-03\nEpoch 27/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0087 - val_accuracy: 0.9667 - val_loss: 0.0710 - learning_rate: 1.0000e-04\nEpoch 28/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0053 - val_accuracy: 0.9667 - val_loss: 0.0558 - learning_rate: 1.0000e-04\nEpoch 29/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0047 - val_accuracy: 0.9667 - val_loss: 0.0452 - learning_rate: 1.0000e-04\nEpoch 30/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0073 - val_accuracy: 0.9667 - val_loss: 0.0376 - learning_rate: 1.0000e-04\nEpoch 31/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0067 - val_accuracy: 0.9667 - val_loss: 0.0305 - learning_rate: 1.0000e-04\nEpoch 32/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0061 - val_accuracy: 1.0000 - val_loss: 0.0256 - learning_rate: 1.0000e-04\nEpoch 33/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0043 - val_accuracy: 1.0000 - val_loss: 0.0226 - learning_rate: 1.0000e-04\nEpoch 34/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0060 - val_accuracy: 1.0000 - val_loss: 0.0212 - learning_rate: 1.0000e-04\nEpoch 35/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0041 - val_accuracy: 1.0000 - val_loss: 0.0201 - learning_rate: 1.0000e-04\nEpoch 36/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0047 - val_accuracy: 1.0000 - val_loss: 0.0205 - learning_rate: 1.0000e-04\nEpoch 37/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0051 - val_accuracy: 1.0000 - val_loss: 0.0213 - learning_rate: 1.0000e-04\nEpoch 38/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0046\nEpoch 38: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0047 - val_accuracy: 1.0000 - val_loss: 0.0229 - learning_rate: 1.0000e-04\nEpoch 39/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0053 - val_accuracy: 1.0000 - val_loss: 0.0246 - learning_rate: 1.0000e-05\nEpoch 40/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0051 - val_accuracy: 1.0000 - val_loss: 0.0271 - learning_rate: 1.0000e-05\nEpoch 40: early stopping\nRestoring model weights from the end of the best epoch: 35.\nFold 2 - Train Accuracy: 96.62%, Validation Accuracy: 100.00%\n\nTraining on Fold 3...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 412ms/step - accuracy: 0.6425 - loss: 1.2031 - val_accuracy: 0.5000 - val_loss: 694.2881 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.8560 - loss: 0.3356 - val_accuracy: 0.5000 - val_loss: 337.0931 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9321 - loss: 0.1507 - val_accuracy: 0.5000 - val_loss: 47.6345 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9599 - loss: 0.0628 - val_accuracy: 0.5000 - val_loss: 28.6129 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9914 - loss: 0.0387 - val_accuracy: 0.5000 - val_loss: 11.1439 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9690 - loss: 0.0484 - val_accuracy: 0.5000 - val_loss: 11.2283 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9816 - loss: 0.0390 - val_accuracy: 0.5000 - val_loss: 10.0405 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9727 - loss: 0.0583 - val_accuracy: 0.6333 - val_loss: 2.7623 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9889 - loss: 0.0373 - val_accuracy: 0.5000 - val_loss: 3.4841 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9880 - loss: 0.0476 - val_accuracy: 0.5000 - val_loss: 8.1388 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9947 - loss: 0.0258 - val_accuracy: 0.8000 - val_loss: 1.4421 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9820 - loss: 0.0558 - val_accuracy: 0.9000 - val_loss: 0.7105 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9834 - loss: 0.0423 - val_accuracy: 0.8667 - val_loss: 0.7354 - learning_rate: 0.0100\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9938 - loss: 0.0251 - val_accuracy: 0.6333 - val_loss: 2.0846 - learning_rate: 0.0100\nEpoch 15/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9919 - loss: 0.0180 - val_accuracy: 0.9333 - val_loss: 0.4055 - learning_rate: 0.0100\nEpoch 16/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9927 - loss: 0.0231 - val_accuracy: 0.9333 - val_loss: 0.1398 - learning_rate: 0.0100\nEpoch 17/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9989 - loss: 0.0057 - val_accuracy: 0.9333 - val_loss: 0.4577 - learning_rate: 0.0100\nEpoch 18/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9977 - loss: 0.0066 - val_accuracy: 0.8667 - val_loss: 0.6618 - learning_rate: 0.0100\nEpoch 19/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0035\nEpoch 19: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0035 - val_accuracy: 0.9000 - val_loss: 0.5838 - learning_rate: 0.0100\nEpoch 20/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.9000 - val_loss: 0.4478 - learning_rate: 1.0000e-03\nEpoch 21/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 9.7771e-04 - val_accuracy: 0.9333 - val_loss: 0.3185 - learning_rate: 1.0000e-03\nEpoch 21: early stopping\nRestoring model weights from the end of the best epoch: 16.\nFold 3 - Train Accuracy: 93.23%, Validation Accuracy: 93.33%\n\nTraining on Fold 4...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 433ms/step - accuracy: 0.6825 - loss: 1.3245 - val_accuracy: 0.5000 - val_loss: 1705.3313 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8954 - loss: 0.2588 - val_accuracy: 0.5000 - val_loss: 378.6555 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9290 - loss: 0.1495 - val_accuracy: 0.5000 - val_loss: 64.0954 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9482 - loss: 0.1147 - val_accuracy: 0.5000 - val_loss: 31.9703 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9752 - loss: 0.0813 - val_accuracy: 0.5333 - val_loss: 9.0170 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9802 - loss: 0.0608 - val_accuracy: 0.5667 - val_loss: 3.6397 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9902 - loss: 0.0383 - val_accuracy: 0.8667 - val_loss: 0.6848 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9996 - loss: 0.0301 - val_accuracy: 0.6000 - val_loss: 3.8618 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9861 - loss: 0.0320 - val_accuracy: 0.6667 - val_loss: 2.3868 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9737 - loss: 0.0982\nEpoch 10: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9745 - loss: 0.0958 - val_accuracy: 0.8000 - val_loss: 1.2716 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9848 - loss: 0.0508 - val_accuracy: 0.8667 - val_loss: 0.9117 - learning_rate: 1.0000e-03\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9977 - loss: 0.0196 - val_accuracy: 0.8333 - val_loss: 0.8873 - learning_rate: 1.0000e-03\nEpoch 12: early stopping\nRestoring model weights from the end of the best epoch: 7.\nFold 4 - Train Accuracy: 84.59%, Validation Accuracy: 86.67%\n\nTraining on Fold 5...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 416ms/step - accuracy: 0.7229 - loss: 0.8717 - val_accuracy: 0.5000 - val_loss: 3012.1289 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.8734 - loss: 0.3264 - val_accuracy: 0.5333 - val_loss: 197.7631 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9225 - loss: 0.2217 - val_accuracy: 0.7333 - val_loss: 25.7146 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9591 - loss: 0.1641 - val_accuracy: 0.5000 - val_loss: 46.0752 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9439 - loss: 0.1723 - val_accuracy: 0.6000 - val_loss: 4.9387 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9377 - loss: 0.1862 - val_accuracy: 0.5667 - val_loss: 2.6449 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9615 - loss: 0.1006 - val_accuracy: 0.8667 - val_loss: 0.4068 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9899 - loss: 0.0617 - val_accuracy: 0.7667 - val_loss: 1.1983 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9922 - loss: 0.0233 - val_accuracy: 0.7667 - val_loss: 0.9655 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9995 - loss: 0.0158\nEpoch 10: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9991 - loss: 0.0155 - val_accuracy: 0.8667 - val_loss: 0.5536 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0095 - val_accuracy: 0.9000 - val_loss: 0.4203 - learning_rate: 1.0000e-03\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9991 - loss: 0.0077 - val_accuracy: 0.9333 - val_loss: 0.3215 - learning_rate: 1.0000e-03\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0077 - val_accuracy: 0.9667 - val_loss: 0.2331 - learning_rate: 1.0000e-03\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9942 - loss: 0.0141 - val_accuracy: 0.9667 - val_loss: 0.1192 - learning_rate: 1.0000e-03\nEpoch 15/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0051 - val_accuracy: 0.9667 - val_loss: 0.0595 - learning_rate: 1.0000e-03\nEpoch 16/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0060 - val_accuracy: 0.9667 - val_loss: 0.0373 - learning_rate: 1.0000e-03\nEpoch 17/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0060 - val_accuracy: 1.0000 - val_loss: 0.0166 - learning_rate: 1.0000e-03\nEpoch 18/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0118 - val_accuracy: 1.0000 - val_loss: 0.0140 - learning_rate: 1.0000e-03\nEpoch 19/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0045 - val_accuracy: 1.0000 - val_loss: 0.0095 - learning_rate: 1.0000e-03\nEpoch 20/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0045 - val_accuracy: 1.0000 - val_loss: 0.0085 - learning_rate: 1.0000e-03\nEpoch 21/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0054 - val_accuracy: 1.0000 - val_loss: 0.0088 - learning_rate: 1.0000e-03\nEpoch 22/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0032 - val_accuracy: 1.0000 - val_loss: 0.0081 - learning_rate: 1.0000e-03\nEpoch 23/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 1.0000 - val_loss: 0.0083 - learning_rate: 1.0000e-03\nEpoch 24/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 1.0000 - val_loss: 0.0087 - learning_rate: 1.0000e-03\nEpoch 25/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0043\nEpoch 25: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0042 - val_accuracy: 1.0000 - val_loss: 0.0108 - learning_rate: 1.0000e-03\nEpoch 26/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0030 - val_accuracy: 1.0000 - val_loss: 0.0103 - learning_rate: 1.0000e-04\nEpoch 27/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0036 - val_accuracy: 1.0000 - val_loss: 0.0088 - learning_rate: 1.0000e-04\nEpoch 27: early stopping\nRestoring model weights from the end of the best epoch: 22.\nFold 5 - Train Accuracy: 96.62%, Validation Accuracy: 100.00%\n\nTraining on Fold 6...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 413ms/step - accuracy: 0.7139 - loss: 1.1981 - val_accuracy: 0.5000 - val_loss: 4125.4961 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8791 - loss: 0.2579 - val_accuracy: 0.5000 - val_loss: 1974.9471 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9413 - loss: 0.1494 - val_accuracy: 0.5000 - val_loss: 266.8892 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9461 - loss: 0.0966 - val_accuracy: 0.5000 - val_loss: 63.3284 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9900 - loss: 0.0508 - val_accuracy: 0.5000 - val_loss: 32.3055 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9842 - loss: 0.0409 - val_accuracy: 0.5333 - val_loss: 10.4338 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9701 - loss: 0.0573 - val_accuracy: 0.5000 - val_loss: 12.4102 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9814 - loss: 0.0565 - val_accuracy: 0.6000 - val_loss: 2.2547 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9842 - loss: 0.0425 - val_accuracy: 0.6667 - val_loss: 2.4281 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9955 - loss: 0.0193 - val_accuracy: 0.5667 - val_loss: 3.2786 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9964 - loss: 0.0127\nEpoch 11: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9964 - loss: 0.0128 - val_accuracy: 0.5667 - val_loss: 6.5748 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9878 - loss: 0.0319 - val_accuracy: 0.6000 - val_loss: 5.2052 - learning_rate: 1.0000e-03\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0089 - val_accuracy: 0.6333 - val_loss: 3.9770 - learning_rate: 1.0000e-03\nEpoch 13: early stopping\nRestoring model weights from the end of the best epoch: 8.\nFold 6 - Train Accuracy: 76.32%, Validation Accuracy: 60.00%\n\nTraining on Fold 7...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 416ms/step - accuracy: 0.6477 - loss: 1.3924 - val_accuracy: 0.5172 - val_loss: 3542.1450 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8597 - loss: 0.3562 - val_accuracy: 0.5172 - val_loss: 93.0478 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9029 - loss: 0.2885 - val_accuracy: 0.4828 - val_loss: 29.3248 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9031 - loss: 0.2610 - val_accuracy: 0.5172 - val_loss: 31.1105 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9258 - loss: 0.2901 - val_accuracy: 0.5172 - val_loss: 18.8935 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9350 - loss: 0.2433 - val_accuracy: 0.5172 - val_loss: 5.8304 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9656 - loss: 0.1492 - val_accuracy: 0.4828 - val_loss: 4.2173 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9577 - loss: 0.1214 - val_accuracy: 0.7586 - val_loss: 0.7264 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9886 - loss: 0.0560 - val_accuracy: 0.8276 - val_loss: 0.2833 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9798 - loss: 0.0756 - val_accuracy: 0.8276 - val_loss: 0.6233 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9192 - loss: 0.1994 - val_accuracy: 0.8621 - val_loss: 0.2611 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9827 - loss: 0.1144 - val_accuracy: 0.7586 - val_loss: 0.7053 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9804 - loss: 0.0775 - val_accuracy: 0.8621 - val_loss: 0.5064 - learning_rate: 0.0100\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9823 - loss: 0.0495 - val_accuracy: 0.9310 - val_loss: 0.0792 - learning_rate: 0.0100\nEpoch 15/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9672 - loss: 0.0634 - val_accuracy: 0.8276 - val_loss: 0.4928 - learning_rate: 0.0100\nEpoch 16/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9642 - loss: 0.1249 - val_accuracy: 0.7931 - val_loss: 0.4194 - learning_rate: 0.0100\nEpoch 17/50\n\u001b[1m16/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9748 - loss: 0.0481\nEpoch 17: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9756 - loss: 0.0473 - val_accuracy: 0.8276 - val_loss: 0.5563 - learning_rate: 0.0100\nEpoch 18/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9627 - loss: 0.0698 - val_accuracy: 0.8966 - val_loss: 0.4490 - learning_rate: 1.0000e-03\nEpoch 19/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9885 - loss: 0.0337 - val_accuracy: 0.8966 - val_loss: 0.3631 - learning_rate: 1.0000e-03\nEpoch 19: early stopping\nRestoring model weights from the end of the best epoch: 14.\nFold 7 - Train Accuracy: 96.25%, Validation Accuracy: 93.10%\n\nTraining on Fold 8...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 418ms/step - accuracy: 0.6973 - loss: 1.0603 - val_accuracy: 0.5172 - val_loss: 4163.1133 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.9244 - loss: 0.1771 - val_accuracy: 0.5172 - val_loss: 186.4009 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9575 - loss: 0.0950 - val_accuracy: 0.5172 - val_loss: 44.9895 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9729 - loss: 0.0633 - val_accuracy: 0.5172 - val_loss: 30.4228 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9983 - loss: 0.0203 - val_accuracy: 0.4828 - val_loss: 12.4293 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9914 - loss: 0.0265 - val_accuracy: 0.6552 - val_loss: 4.4827 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9816 - loss: 0.0584 - val_accuracy: 0.7931 - val_loss: 2.2414 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9795 - loss: 0.0728 - val_accuracy: 0.8621 - val_loss: 0.6880 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9621 - loss: 0.0723 - val_accuracy: 0.9655 - val_loss: 0.3013 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9936 - loss: 0.0252 - val_accuracy: 0.9310 - val_loss: 0.5482 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9980 - loss: 0.0128 - val_accuracy: 0.9310 - val_loss: 0.4954 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9964 - loss: 0.0100\nEpoch 12: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9964 - loss: 0.0102 - val_accuracy: 0.8966 - val_loss: 0.7211 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0055 - val_accuracy: 0.9310 - val_loss: 0.5810 - learning_rate: 1.0000e-03\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0073 - val_accuracy: 0.9310 - val_loss: 0.5368 - learning_rate: 1.0000e-03\nEpoch 14: early stopping\nRestoring model weights from the end of the best epoch: 9.\nFold 8 - Train Accuracy: 89.51%, Validation Accuracy: 96.55%\n\nTraining on Fold 9...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 414ms/step - accuracy: 0.7174 - loss: 1.3490 - val_accuracy: 0.4828 - val_loss: 1876.8817 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9287 - loss: 0.2070 - val_accuracy: 0.4828 - val_loss: 488.2412 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9511 - loss: 0.1647 - val_accuracy: 0.4828 - val_loss: 96.0055 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9573 - loss: 0.1189 - val_accuracy: 0.4828 - val_loss: 36.9367 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9730 - loss: 0.0796 - val_accuracy: 0.4828 - val_loss: 21.3071 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9827 - loss: 0.0489 - val_accuracy: 0.5517 - val_loss: 10.6873 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9914 - loss: 0.0314 - val_accuracy: 0.5862 - val_loss: 5.4800 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9866 - loss: 0.0393 - val_accuracy: 0.4828 - val_loss: 7.6419 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9605 - loss: 0.0844 - val_accuracy: 0.8276 - val_loss: 1.3974 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9837 - loss: 0.0328 - val_accuracy: 0.6897 - val_loss: 2.1386 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9716 - loss: 0.0658 - val_accuracy: 0.5862 - val_loss: 1.5871 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9852 - loss: 0.0390 - val_accuracy: 0.8621 - val_loss: 0.4886 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9831 - loss: 0.0438 - val_accuracy: 0.9655 - val_loss: 0.5529 - learning_rate: 0.0100\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0116 - val_accuracy: 0.8276 - val_loss: 0.9912 - learning_rate: 0.0100\nEpoch 15/50\n\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0056\nEpoch 15: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9994 - loss: 0.0068 - val_accuracy: 0.8966 - val_loss: 0.8267 - learning_rate: 0.0100\nEpoch 16/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 0.8966 - val_loss: 0.7150 - learning_rate: 1.0000e-03\nEpoch 17/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.8966 - val_loss: 0.6302 - learning_rate: 1.0000e-03\nEpoch 17: early stopping\nRestoring model weights from the end of the best epoch: 12.\nFold 9 - Train Accuracy: 82.02%, Validation Accuracy: 86.21%\n\nTraining on Fold 10...\nEpoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 424ms/step - accuracy: 0.6254 - loss: 1.7405 - val_accuracy: 0.5172 - val_loss: 2932.0447 - learning_rate: 0.0100\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.8466 - loss: 0.4071 - val_accuracy: 0.4828 - val_loss: 1634.8331 - learning_rate: 0.0100\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8646 - loss: 0.3808 - val_accuracy: 0.4828 - val_loss: 261.8527 - learning_rate: 0.0100\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9054 - loss: 0.2054 - val_accuracy: 0.4828 - val_loss: 35.9489 - learning_rate: 0.0100\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9285 - loss: 0.1551 - val_accuracy: 0.4828 - val_loss: 18.1290 - learning_rate: 0.0100\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9528 - loss: 0.0930 - val_accuracy: 0.5517 - val_loss: 11.5473 - learning_rate: 0.0100\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9638 - loss: 0.0891 - val_accuracy: 0.5517 - val_loss: 7.9227 - learning_rate: 0.0100\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9845 - loss: 0.0514 - val_accuracy: 0.5862 - val_loss: 4.6441 - learning_rate: 0.0100\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9646 - loss: 0.0884 - val_accuracy: 0.8966 - val_loss: 1.2115 - learning_rate: 0.0100\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9677 - loss: 0.0918 - val_accuracy: 0.8621 - val_loss: 0.4132 - learning_rate: 0.0100\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9670 - loss: 0.1039 - val_accuracy: 0.8966 - val_loss: 0.7937 - learning_rate: 0.0100\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9769 - loss: 0.0742 - val_accuracy: 0.9310 - val_loss: 0.3315 - learning_rate: 0.0100\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9848 - loss: 0.0479 - val_accuracy: 0.8966 - val_loss: 0.5449 - learning_rate: 0.0100\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9781 - loss: 0.0613 - val_accuracy: 0.8621 - val_loss: 1.0021 - learning_rate: 0.0100\nEpoch 15/50\n\u001b[1m15/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9952 - loss: 0.0277\nEpoch 15: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9934 - loss: 0.0307 - val_accuracy: 0.9310 - val_loss: 0.4817 - learning_rate: 0.0100\nEpoch 16/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9915 - loss: 0.0325 - val_accuracy: 0.9310 - val_loss: 0.4130 - learning_rate: 1.0000e-03\nEpoch 17/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0156 - val_accuracy: 0.9310 - val_loss: 0.3575 - learning_rate: 1.0000e-03\nEpoch 17: early stopping\nRestoring model weights from the end of the best epoch: 12.\nFold 10 - Train Accuracy: 96.63%, Validation Accuracy: 93.10%\n\nAverage Training Accuracy: 90.61%\nAverage Validation Accuracy: 90.90%\n","output_type":"stream"}],"execution_count":95},{"cell_type":"markdown","source":"# 3 Network Training","metadata":{}},{"cell_type":"markdown","source":"## 3.1 Data Preparation","metadata":{}},{"cell_type":"code","source":"X_train, y_train, X_test, y_test = load_dataset()\n\nX_train_flipped = np.flip(X_train, axis=2)\nX_train_rotated_90 = np.rot90(X_train, k=1, axes=(1,2))\nX_train_rotated_180 = np.rot90(X_train, k=2, axes=(1,2))\nX_train_rotated_270 = np.rot90(X_train, k=3, axes=(1,2))\n\nX_train_augmented = np.concatenate((X_train, X_train_flipped, X_train_rotated_90, X_train_rotated_180, X_train_rotated_270), axis=0)\ny_train_augmented = np.concatenate((y_train, y_train, y_train, y_train, y_train), axis=0)\n\nindices = np.arange(X_train_augmented.shape[0])\nnp.random.shuffle(indices)\nX_train_augmented = X_train_augmented[indices]\ny_train_augmented = y_train_augmented[indices]\n\n# Split the data into training (80%) and validation (20%) sets\nX_train_final, X_val_final, y_train_final, y_val_final = train_test_split(X_train_augmented, y_train_augmented, test_size=0.3, random_state=33)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T21:58:40.853540Z","iopub.execute_input":"2025-02-07T21:58:40.853826Z","iopub.status.idle":"2025-02-07T21:58:48.942555Z","shell.execute_reply.started":"2025-02-07T21:58:40.853802Z","shell.execute_reply":"2025-02-07T21:58:48.941837Z"}},"outputs":[],"execution_count":144},{"cell_type":"code","source":"X_test.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T21:58:51.414028Z","iopub.execute_input":"2025-02-07T21:58:51.414333Z","iopub.status.idle":"2025-02-07T21:58:51.419139Z","shell.execute_reply.started":"2025-02-07T21:58:51.414309Z","shell.execute_reply":"2025-02-07T21:58:51.418495Z"}},"outputs":[{"execution_count":145,"output_type":"execute_result","data":{"text/plain":"(40, 150, 150, 3)"},"metadata":{}}],"execution_count":145},{"cell_type":"markdown","source":"## 3.2 Training","metadata":{}},{"cell_type":"code","source":"model = define_model(\n    input_shape=(150,150,3),\n    lr=0.04\n)\n\nhistory = model.fit(\n    X_train_final, y_train_final,\n    validation_data=(X_val_final, y_val_final),\n    epochs=50,\n    batch_size=32,\n    callbacks=[\n        EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True, verbose=1),\n        ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, verbose=1)\n    ],\n    verbose=1,\n    shuffle=True\n)\n\n# Extract loss & accuracy\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nval_loss = np.log(val_loss)\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\n# Plot Loss\nplt.figure(figsize=(12, 5))\nplt.subplot(1, 2, 1)\nplt.plot(loss, label=\"Train Loss\")\nplt.plot(val_loss, label=\"Validation Loss\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Log Loss\")\nplt.legend()\nplt.title(\"Log Loss over epochs\")\n\n# Plot Accuracy\nplt.subplot(1, 2, 2)\nplt.plot(acc, label=\"Train Accuracy\")\nplt.plot(val_acc, label=\"Validation Accuracy\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Accuracy\")\nplt.legend()\nplt.title(\"Accuracy over epochs\")\n\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T21:52:27.725464Z","iopub.execute_input":"2025-02-07T21:52:27.725746Z","iopub.status.idle":"2025-02-07T21:53:01.634472Z","shell.execute_reply.started":"2025-02-07T21:52:27.725724Z","shell.execute_reply":"2025-02-07T21:53:01.633580Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 468ms/step - accuracy: 0.6341 - loss: 1.3445 - val_accuracy: 0.5135 - val_loss: 137674.0781 - learning_rate: 0.0400\nEpoch 2/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.8316 - loss: 0.3957 - val_accuracy: 0.5135 - val_loss: 9951.5518 - learning_rate: 0.0400\nEpoch 3/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.9179 - loss: 0.2064 - val_accuracy: 0.5135 - val_loss: 1353.2944 - learning_rate: 0.0400\nEpoch 4/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.9539 - loss: 0.1507 - val_accuracy: 0.5135 - val_loss: 280.6783 - learning_rate: 0.0400\nEpoch 5/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.9808 - loss: 0.0689 - val_accuracy: 0.5135 - val_loss: 157.3855 - learning_rate: 0.0400\nEpoch 6/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.9702 - loss: 0.0805 - val_accuracy: 0.5135 - val_loss: 106.0295 - learning_rate: 0.0400\nEpoch 7/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.9907 - loss: 0.0402 - val_accuracy: 0.5135 - val_loss: 53.5714 - learning_rate: 0.0400\nEpoch 8/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.9821 - loss: 0.0443 - val_accuracy: 0.5135 - val_loss: 47.6132 - learning_rate: 0.0400\nEpoch 9/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.9851 - loss: 0.0427 - val_accuracy: 0.5270 - val_loss: 13.8134 - learning_rate: 0.0400\nEpoch 10/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.9617 - loss: 0.0995 - val_accuracy: 0.5180 - val_loss: 10.5764 - learning_rate: 0.0400\nEpoch 11/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.9792 - loss: 0.0854 - val_accuracy: 0.6171 - val_loss: 3.5516 - learning_rate: 0.0400\nEpoch 12/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.9819 - loss: 0.0593 - val_accuracy: 0.7883 - val_loss: 0.8526 - learning_rate: 0.0400\nEpoch 13/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.9968 - loss: 0.0213 - val_accuracy: 0.9099 - val_loss: 0.2882 - learning_rate: 0.0400\nEpoch 14/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.9918 - loss: 0.0186 - val_accuracy: 0.9324 - val_loss: 0.1866 - learning_rate: 0.0400\nEpoch 15/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.9971 - loss: 0.0122 - val_accuracy: 0.9730 - val_loss: 0.1875 - learning_rate: 0.0400\nEpoch 16/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.9931 - loss: 0.0202 - val_accuracy: 0.9144 - val_loss: 0.3707 - learning_rate: 0.0400\nEpoch 17/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9885 - loss: 0.0314\nEpoch 17: ReduceLROnPlateau reducing learning rate to 0.007999999821186066.\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.9885 - loss: 0.0315 - val_accuracy: 0.7523 - val_loss: 2.9711 - learning_rate: 0.0400\nEpoch 18/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.9986 - loss: 0.0093 - val_accuracy: 0.8243 - val_loss: 1.5020 - learning_rate: 0.0080\nEpoch 19/50\n\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 0.8874 - val_loss: 0.6418 - learning_rate: 0.0080\nEpoch 19: early stopping\nRestoring model weights from the end of the best epoch: 14.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1200x500 with 2 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":135},{"cell_type":"markdown","source":"# 4 Network Evaluation","metadata":{}},{"cell_type":"markdown","source":"## 4.1 Evaluation Metrics","metadata":{}},{"cell_type":"code","source":"y_pred = model.predict(X_test)\ny_pred_classes = np.argmax(y_pred, axis=1)  # If using categorical cross-entropy (for classification)\n\n# Report the evaluation metrics\naccuracy = accuracy_score(y_test, y_pred_classes)\nprecision = precision_score(y_test, y_pred_classes, average='weighted')  # Use 'macro' for unbalanced classes\nsensitivity = recall_score(y_test, y_pred_classes, average='weighted')  # Sensitivity = Recall\nspecificity = recall_score(y_test, y_pred_classes, average='weighted')  # Specificity is 1 - False Positive Rate, can use 1 - recall for binary case\nf1 = f1_score(y_test, y_pred_classes, average='weighted')\n\n# Print the classification report (for precision, recall, F1)\nprint(\"Classification Report:\")\nprint(classification_report(y_test, y_pred_classes))\n\n# Print the evaluation metrics\nprint(f\"Accuracy: {accuracy:.4f}\")\nprint(f\"Precision: {precision:.4f}\")\nprint(f\"Sensitivity: {sensitivity:.4f}\")\nprint(f\"Specificity: {specificity:.4f}\")\nprint(f\"F1 Score: {f1:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T21:58:25.439926Z","iopub.execute_input":"2025-02-07T21:58:25.440205Z","iopub.status.idle":"2025-02-07T21:58:25.547641Z","shell.execute_reply.started":"2025-02-07T21:58:25.440183Z","shell.execute_reply":"2025-02-07T21:58:25.546865Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.50      1.00      0.67        20\n           1       0.00      0.00      0.00        20\n\n    accuracy                           0.50        40\n   macro avg       0.25      0.50      0.33        40\nweighted avg       0.25      0.50      0.33        40\n\nAccuracy: 0.5000\nPrecision: 0.2500\nSensitivity: 0.5000\nSpecificity: 0.5000\nF1 Score: 0.3333\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}],"execution_count":142},{"cell_type":"code","source":"X_test.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T21:58:33.462625Z","iopub.execute_input":"2025-02-07T21:58:33.462907Z","iopub.status.idle":"2025-02-07T21:58:33.467890Z","shell.execute_reply.started":"2025-02-07T21:58:33.462885Z","shell.execute_reply":"2025-02-07T21:58:33.467094Z"}},"outputs":[{"execution_count":143,"output_type":"execute_result","data":{"text/plain":"(40, 150, 150, 3)"},"metadata":{}}],"execution_count":143},{"cell_type":"code","source":"y_pred = model.predict(X_test)\ny_pred_classes = np.argmax(y_pred, axis=1)  # If using categorical cross-entropy (for classification)\n\n# Report the evaluation metrics\naccuracy = accuracy_score(y_test, y_pred_classes)\nprecision = precision_score(y_test, y_pred_classes, average='weighted')  # Use 'macro' for unbalanced classes\nsensitivity = recall_score(y_test, y_pred_classes, average='weighted')  # Sensitivity = Recall\nspecificity = recall_score(y_test, y_pred_classes, average='weighted')  # Specificity is 1 - False Positive Rate, can use 1 - recall for binary case\nf1 = f1_score(y_test, y_pred_classes, average='weighted')\n\n# Print the classification report (for precision, recall, F1)\nprint(\"Classification Report:\")\nprint(classification_report(y_test, y_pred_classes))\n\n# Print the evaluation metrics\nprint(f\"Accuracy: {accuracy:.4f}\")\nprint(f\"Precision: {precision:.4f}\")\nprint(f\"Sensitivity: {sensitivity:.4f}\")\nprint(f\"Specificity: {specificity:.4f}\")\nprint(f\"F1 Score: {f1:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T21:53:54.136421Z","iopub.execute_input":"2025-02-07T21:53:54.136745Z","iopub.status.idle":"2025-02-07T21:53:55.240181Z","shell.execute_reply.started":"2025-02-07T21:53:54.136717Z","shell.execute_reply":"2025-02-07T21:53:55.239530Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 503ms/step\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.50      1.00      0.67        20\n           1       0.00      0.00      0.00        20\n\n    accuracy                           0.50        40\n   macro avg       0.25      0.50      0.33        40\nweighted avg       0.25      0.50      0.33        40\n\nAccuracy: 0.5000\nPrecision: 0.2500\nSensitivity: 0.5000\nSpecificity: 0.5000\nF1 Score: 0.3333\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}],"execution_count":136},{"cell_type":"code","source":"# Evaluate the model on the fold's training and validation sets\ntrain_loss, train_acc = model.evaluate(X_train_final, y_train_final, verbose=0)\ntest_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\nprint(\"Training Accuracy: {:.2f}%\".format(train_acc*100))\nprint(\"Test Accuracy: {:.2f}%\".format(test_acc*100))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T21:56:36.366205Z","iopub.execute_input":"2025-02-07T21:56:36.366535Z","iopub.status.idle":"2025-02-07T21:56:38.013254Z","shell.execute_reply.started":"2025-02-07T21:56:36.366509Z","shell.execute_reply":"2025-02-07T21:56:38.012481Z"}},"outputs":[{"name":"stdout","text":"Training Accuracy: 99.03%\nTest Accuracy: 85.00%\n","output_type":"stream"}],"execution_count":137},{"cell_type":"markdown","source":"## 4.2 Confusion Matrix","metadata":{}},{"cell_type":"code","source":"# Confusion Matrix\ncm = confusion_matrix(y_test, y_pred_classes)\n\n# Plot the confusion matrix\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=np.unique(y_test), yticklabels=np.unique(y_test))\nplt.title(\"Confusion Matrix\")\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T21:45:12.494018Z","iopub.execute_input":"2025-02-07T21:45:12.494302Z","iopub.status.idle":"2025-02-07T21:45:12.692667Z","shell.execute_reply.started":"2025-02-07T21:45:12.494280Z","shell.execute_reply":"2025-02-07T21:45:12.691875Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 800x600 with 2 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAo0AAAIjCAYAAABmuyHTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABEZElEQVR4nO3de1yUdf7//+eAMpgKKCKHUjyfUtG0SM3TSqKViVYeqhXNQ7XaWmSZlSJWy34952q6HRRXczW3tNLWMk3NFc9S2pareKBS8AgGKhBcvz/6OZ9GwItBxhmZx31v1+3mvOc6vGb2Zr16vt/XNRbDMAwBAAAA1+Dl6gIAAADg/mgaAQAAYIqmEQAAAKZoGgEAAGCKphEAAACmaBoBAABgiqYRAAAApmgaAQAAYIqmEQAAAKZoGgFc06FDh9SzZ0/5+/vLYrFo9erV5Xr+Y8eOyWKxKCkpqVzPezPr1q2bunXr5uoyAMAOTSNwE0hNTdWTTz6pBg0ayNfXV35+furUqZPefPNNXbp0yanXjo2N1f79+/XGG29oyZIlat++vVOvdyMNHTpUFotFfn5+xX6Phw4dksVikcVi0fTp0x0+/4kTJzR58mSlpKSUQ7UA4FqVXF0AgGtbu3atHnnkEVmtVg0ZMkQtW7ZUXl6etm7dqhdeeEHfffed3n77badc+9KlS0pOTtYrr7yiMWPGOOUa4eHhunTpkipXruyU85upVKmSLl68qE8//VQDBgywe+/999+Xr6+vLl++XKZznzhxQgkJCapXr57atGlT6uO++OKLMl0PAJyJphFwY0ePHtWgQYMUHh6ujRs3KjQ01Pbe6NGjdfjwYa1du9Zp1z99+rQkKSAgwGnXsFgs8vX1ddr5zVitVnXq1En//Oc/izSNy5Yt0/33368PP/zwhtRy8eJF3XLLLfLx8bkh1wMARzA9DbixqVOnKjs7W++9955dw3hFo0aNNHbsWNvrX3/9Va+99poaNmwoq9WqevXq6eWXX1Zubq7dcfXq1dMDDzygrVu36q677pKvr68aNGigf/zjH7Z9Jk+erPDwcEnSCy+8IIvFonr16kn6bVr3yp9/b/LkybJYLHZj69ev1z333KOAgABVq1ZNTZs21csvv2x7v6Q1jRs3blTnzp1VtWpVBQQEqG/fvvr++++Lvd7hw4c1dOhQBQQEyN/fX8OGDdPFixdL/mKv8uijj+rf//63MjMzbWO7du3SoUOH9OijjxbZ/9y5cxo3bpxatWqlatWqyc/PT71799Y333xj22fTpk268847JUnDhg2zTXNf+ZzdunVTy5YttWfPHnXp0kW33HKL7Xu5ek1jbGysfH19i3z+6Oho1ahRQydOnCj1ZwWAsqJpBNzYp59+qgYNGqhjx46l2n/EiBGaNGmS7rjjDs2aNUtdu3ZVYmKiBg0aVGTfw4cP6+GHH9a9996rGTNmqEaNGho6dKi+++47SVL//v01a9YsSdLgwYO1ZMkSzZ4926H6v/vuOz3wwAPKzc3VlClTNGPGDD344IP6z3/+c83jvvzyS0VHR+vUqVOaPHmy4uLitG3bNnXq1EnHjh0rsv+AAQP0yy+/KDExUQMGDFBSUpISEhJKXWf//v1lsVj00Ucf2caWLVumZs2a6Y477iiy/5EjR7R69Wo98MADmjlzpl544QXt379fXbt2tTVwzZs315QpUyRJo0aN0pIlS7RkyRJ16dLFdp6zZ8+qd+/eatOmjWbPnq3u3bsXW9+bb76poKAgxcbGqqCgQJL097//XV988YX+9re/KSwsrNSfFQDKzADglrKysgxJRt++fUu1f0pKiiHJGDFihN34uHHjDEnGxo0bbWPh4eGGJGPLli22sVOnThlWq9V4/vnnbWNHjx41JBnTpk2zO2dsbKwRHh5epIb4+Hjj9/9YmTVrliHJOH36dIl1X7nGokWLbGNt2rQxateubZw9e9Y29s033xheXl7GkCFDilzviSeesDtnv379jMDAwBKv+fvPUbVqVcMwDOPhhx82evToYRiGYRQUFBghISFGQkJCsd/B5cuXjYKCgiKfw2q1GlOmTLGN7dq1q8hnu6Jr166GJGPBggXFvte1a1e7sc8//9yQZLz++uvGkSNHjGrVqhkxMTGmnxEAygtJI+CmLly4IEmqXr16qfb/7LPPJElxcXF2488//7wkFVn72KJFC3Xu3Nn2OigoSE2bNtWRI0fKXPPVrqyF/Pjjj1VYWFiqY06ePKmUlBQNHTpUNWvWtI23bt1a9957r+1z/t5TTz1l97pz5846e/as7TssjUcffVSbNm1Senq6Nm7cqPT09GKnpqXf1kF6ef32j8+CggKdPXvWNvW+d+/eUl/TarVq2LBhpdq3Z8+eevLJJzVlyhT1799fvr6++vvf/17qawHA9aJpBNyUn5+fJOmXX34p1f7Hjx+Xl5eXGjVqZDceEhKigIAAHT9+3G68bt26Rc5Ro0YNnT9/vowVFzVw4EB16tRJI0aMUHBwsAYNGqQPPvjgmg3klTqbNm1a5L3mzZvrzJkzysnJsRu/+rPUqFFDkhz6LPfdd5+qV6+uFStW6P3339edd95Z5Lu8orCwULNmzVLjxo1ltVpVq1YtBQUF6dtvv1VWVlapr3nrrbc6dNPL9OnTVbNmTaWkpGjOnDmqXbt2qY8FgOtF0wi4KT8/P4WFhenAgQMOHXf1jSgl8fb2LnbcMIwyX+PKersrqlSpoi1btujLL7/UH//4R3377bcaOHCg7r333iL7Xo/r+SxXWK1W9e/fX4sXL9aqVatKTBkl6S9/+Yvi4uLUpUsXLV26VJ9//rnWr1+v22+/vdSJqvTb9+OIffv26dSpU5Kk/fv3O3QsAFwvmkbAjT3wwANKTU1VcnKy6b7h4eEqLCzUoUOH7MYzMjKUmZlpuxO6PNSoUcPuTuMrrk4zJcnLy0s9evTQzJkz9d///ldvvPGGNm7cqK+++qrYc1+p8+DBg0Xe++GHH1SrVi1VrVr1+j5ACR599FHt27dPv/zyS7E3D13xr3/9S927d9d7772nQYMGqWfPnoqKiirynZS2gS+NnJwcDRs2TC1atNCoUaM0depU7dq1q9zODwBmaBoBN/biiy+qatWqGjFihDIyMoq8n5qaqjfffFPSb9Orkorc4Txz5kxJ0v33319udTVs2FBZWVn69ttvbWMnT57UqlWr7PY7d+5ckWOvPOT66scAXREaGqo2bdpo8eLFdk3YgQMH9MUXX9g+pzN0795dr732mubOnauQkJAS9/P29i6SYq5cuVI///yz3diV5ra4BttR48ePV1pamhYvXqyZM2eqXr16io2NLfF7BIDyxsO9ATfWsGFDLVu2TAMHDlTz5s3tfhFm27ZtWrlypYYOHSpJioiIUGxsrN5++21lZmaqa9eu2rlzpxYvXqyYmJgSH+dSFoMGDdL48ePVr18//fnPf9bFixc1f/58NWnSxO5GkClTpmjLli26//77FR4erlOnTumtt97SbbfdpnvuuafE80+bNk29e/dWhw4dNHz4cF26dEl/+9vf5O/vr8mTJ5fb57ial5eXXn31VdP9HnjgAU2ZMkXDhg1Tx44dtX//fr3//vtq0KCB3X4NGzZUQECAFixYoOrVq6tq1aqKjIxU/fr1Hapr48aNeuuttxQfH297BNCiRYvUrVs3TZw4UVOnTnXofABQFiSNgJt78MEH9e233+rhhx/Wxx9/rNGjR+ull17SsWPHNGPGDM2ZM8e277vvvquEhATt2rVLzz77rDZu3KgJEyZo+fLl5VpTYGCgVq1apVtuuUUvvviiFi9erMTERPXp06dI7XXr1tXChQs1evRozZs3T126dNHGjRvl7+9f4vmjoqK0bt06BQYGatKkSZo+fbruvvtu/ec//3G44XKGl19+Wc8//7w+//xzjR07Vnv37tXatWtVp04du/0qV66sxYsXy9vbW0899ZQGDx6szZs3O3StX375RU888YTatm2rV155xTbeuXNnjR07VjNmzND27dvL5XMBwLVYDEdWigMAAMAjkTQCAADAFE0jAAAATNE0AgAAwBRNIwAAgJtITEzUnXfeqerVq6t27dqKiYkp8tzay5cva/To0QoMDFS1atX00EMPFftYtt8zDEOTJk1SaGioqlSpoqioqCLP9TVD0wgAAOAmNm/erNGjR2v79u1av3698vPz1bNnT7ufT33uuef06aefauXKldq8ebNOnDih/v37X/O8U6dO1Zw5c7RgwQLt2LFDVatWVXR0tC5fvlzq2rh7GgAAwE2dPn1atWvX1ubNm9WlSxdlZWUpKChIy5Yt08MPPyzpt1/Lat68uZKTk3X33XcXOYdhGAoLC9Pzzz+vcePGSZKysrIUHByspKSka/4C1u+RNAIAADhRbm6uLly4YLeV9tecsrKyJEk1a9aUJO3Zs0f5+fmKioqy7dOsWTPVrVu3xJ+cPXr0qNLT0+2O8ff3V2RkZKl+pvaKCvmLMFXajnF1CQCc5Pyuua4uAYCT+LqwK3Fm7zC+by0lJCTYjcXHx5v+wlVhYaGeffZZderUSS1btpQkpaeny8fHRwEBAXb7BgcHKz09vdjzXBkPDg4u9THFqZBNIwAAgLuYMGGC4uLi7MasVqvpcaNHj9aBAwe0detWZ5XmEJpGAAAAi/NW7Fmt1lI1ib83ZswYrVmzRlu2bNFtt91mGw8JCVFeXp4yMzPt0saMjAyFhIQUe64r4xkZGQoNDbU7pk2bNqWuiTWNAAAAFovzNgcYhqExY8Zo1apV2rhxo+rXr2/3frt27VS5cmVt2LDBNnbw4EGlpaWpQ4cOxZ6zfv36CgkJsTvmwoUL2rFjR4nHFIemEQAAwE2MHj1aS5cu1bJly1S9enWlp6crPT1dly5dkvTbDSzDhw9XXFycvvrqK+3Zs0fDhg1Thw4d7O6cbtasmVatWiVJslgsevbZZ/X666/rk08+0f79+zVkyBCFhYUpJiam1LUxPQ0AAODE6WlHzJ8/X5LUrVs3u/FFixZp6NChkqRZs2bJy8tLDz30kHJzcxUdHa233nrLbv+DBw/a7ryWpBdffFE5OTkaNWqUMjMzdc8992jdunXy9fUtdW0V8jmN3D0NVFzcPQ1UXC69e7r9c04796Xds5x27huJpBEAAMDBtYeeyD2yWAAAALg1kkYAAAA3WdPozviGAAAAYIqkEQAAgDWNpmgaAQAAmJ42xTcEAAAAUySNAAAATE+bImkEAACAKZJGAAAA1jSa4hsCAACAKZJGAAAA1jSaImkEAACAKZJGAAAA1jSaomkEAABgetoUbTUAAABMkTQCAAAwPW2KbwgAAACmSBoBAABIGk3xDQEAAMAUSSMAAIAXd0+bIWkEAACAKZJGAAAA1jSaomkEAADg4d6maKsBAABgiqQRAACA6WlTfEMAAAAwRdIIAADAmkZTJI0AAAAwRdIIAADAmkZTfEMAAAAwRdIIAADAmkZTNI0AAABMT5viGwIAAIApkkYAAACmp02RNAIAAMAUSSMAAABrGk3xDQEAAMAUSSMAAABrGk2RNAIAAMAUSSMAAABrGk3RNAIAANA0muIbAgAAgCmSRgAAAG6EMUXSCAAAAFMkjQAAAKxpNMU3BAAAAFM0jQAAABaL8zYHbdmyRX369FFYWJgsFotWr159VamWYrdp06aVeM7JkycX2b9Zs2YO1UXTCAAA4EZycnIUERGhefPmFfv+yZMn7baFCxfKYrHooYceuuZ5b7/9drvjtm7d6lBdrGkEAABw4prG3Nxc5ebm2o1ZrVZZrdZi9+/du7d69+5d4vlCQkLsXn/88cfq3r27GjRocM06KlWqVORYR5A0AgAAOHF6OjExUf7+/nZbYmJiuZSdkZGhtWvXavjw4ab7Hjp0SGFhYWrQoIEee+wxpaWlOXQtkkYAAAAnmjBhguLi4uzGSkoZHbV48WJVr15d/fv3v+Z+kZGRSkpKUtOmTXXy5EklJCSoc+fOOnDggKpXr16qa9E0AgAAj2dx4sO9rzUVfb0WLlyoxx57TL6+vtfc7/fT3a1bt1ZkZKTCw8P1wQcflCqllGgaAQAAbkpff/21Dh48qBUrVjh8bEBAgJo0aaLDhw+X+hjWNAIAAI9X0mNsymNzlvfee0/t2rVTRESEw8dmZ2crNTVVoaGhpT6GphEAAMCNZGdnKyUlRSkpKZKko0ePKiUlxe7GlQsXLmjlypUaMWJEsefo0aOH5s6da3s9btw4bd68WceOHdO2bdvUr18/eXt7a/DgwaWui+lpAAAA5wWCDtu9e7e6d+9ue33lJprY2FglJSVJkpYvXy7DMEps+lJTU3XmzBnb659++kmDBw/W2bNnFRQUpHvuuUfbt29XUFBQqeuyGIZhlOHzuLUqbce4ugQATnJ+11zznQDclHxdGGVVfWSR086ds3KY0859I5E0AgAAj+fMtYcVBU0jAADweDSN5rgRBgAAAKZIGgEAgMcjaTRH0ggAAABTJI0AAMDjkTSaI2kEAACAKZJGAAAAgkZTJI0AAAAwRdIIAAA8HmsazZE0AgAAwBRJIwAA8HgkjeZoGgEAgMejaTTH9DQAAABMkTQCAACPR9JojqQRAAAApkgaAQAACBpNkTQCAADAFEkjAADweKxpNEfSCAAAAFMkjQAAwOORNJqjaQQAAB6PptEc09MAAAAwRdIIAABA0GiKpBEAAACmSBoBAIDHY02jOZJGAAAAmCJpBAAAHo+k0RxJIwAAAEyRNAIAAI9H0miOphEAAHg8mkZzTE8DAADAFEkjAAAAQaMpkkYAAACYImkEAAAejzWN5kgaAQAAYIqkEQAAeDySRnMkjQAAADBF0ggAADweSaM5mkYAAAB6RlNMTwMAAMAUSSMAAPB4TE+bI2kEAACAKZJGAADg8UgazZE0AgAAwBRJI24K457oqZg/RKhJvWBdys3Xjm+O6JU3P9ah46ds+1h9Kumvcf31SHQ7WX0q6cvk7zX2Lyt06twvLqwcQFktX/a+Fi96T2fOnFaTps300ssT1ap1a1eXhQqKpNEcSSNuCp3vaKQFK7ao65DpeuDpuapUyVtr5o/RLb4+tn2mjntI93dpqcdefE89R8xWaJC/ls8Y4cKqAZTVun9/pulTE/Xkn0Zr+cpVatq0mZ5+crjOnj3r6tIAp9uyZYv69OmjsLAwWSwWrV692u79oUOHymKx2G29evUyPe+8efNUr149+fr6KjIyUjt37nSoLppG3BT6jnlLSz/doe+PpGv//37WqPilqhtaU21b1JEk+VXz1dCYDho/8yNt3vU/7fv+R42KX6oObRrqrlb1XFs8AIctWbxI/R8eoJh+D6lho0Z6NT5Bvr6+Wv3Rh64uDRXU1U1YeW6OysnJUUREhObNm1fiPr169dLJkydt2z//+c9rnnPFihWKi4tTfHy89u7dq4iICEVHR+vUqVPXPO73XDo9febMGS1cuFDJyclKT0+XJIWEhKhjx44aOnSogoKCXFke3JhfNV9J0vmsi5Kkts3ryqdyJW3cftC2z/+OZSjt5DlFtq6vnfuPuaJMAGWQn5en7//7nYaPfNI25uXlpbvv7qhvv9nnwspQobnR7HTv3r3Vu3fva+5jtVoVEhJS6nPOnDlTI0eO1LBhwyRJCxYs0Nq1a7Vw4UK99NJLpTqHy5LGXbt2qUmTJpozZ478/f3VpUsXdenSRf7+/pozZ46aNWum3bt3m54nNzdXFy5csNuMwoIb8AngKhaLRdPGPaxt+1L139STkqSQQD/l5uUrK/uS3b6nzl5QcKCfK8oEUEbnM8+roKBAgYGBduOBgYE6c+aMi6oCyq64XiU3N/e6zrlp0ybVrl1bTZs21dNPP33NpRt5eXnas2ePoqKibGNeXl6KiopScnJyqa/psqTxmWee0SOPPKIFCxYUiW4Nw9BTTz2lZ555xvTDJCYmKiEhwW7MO/hOVQ69q9xrhnuYPWGAbm8Uqh7DZrm6FABABeHMG2GK61Xi4+M1efLkMp2vV69e6t+/v+rXr6/U1FS9/PLL6t27t5KTk+Xt7V1k/zNnzqigoEDBwcF248HBwfrhhx9KfV2XNY3ffPONkpKSiv0/yWKx6LnnnlPbtm1NzzNhwgTFxcXZjdXuPL7c6oR7mTX+Ed3XuaWihs/Wz6cybePpZy/I6lNZ/tWq2KWNtQP9lHH2ggsqBVBWNQJqyNvbu0hycvbsWdWqVctFVQFlV1yvYrVay3y+QYMG2f7cqlUrtW7dWg0bNtSmTZvUo0ePMp/XjMump0NCQq55187OnTuLdMTFsVqt8vPzs9ssXkW7bNz8Zo1/RA/+IUK9npyj4yfs/2Wy7/s05eX/qu6RTW1jjcNrq25oTe349uiNLhXAdajs46PmLW7Xju3/N9NUWFioHTuS1TrCPEwAysKZN8IU16tcT9N4tQYNGqhWrVo6fPhwse/XqlVL3t7eysjIsBvPyMhwaF2ky5LGcePGadSoUdqzZ4969OhhaxAzMjK0YcMGvfPOO5o+fbqryoObmT1hgAb2bq9Hnntb2TmXFRxYXZKUlX1Zl3PzdSH7spJWJ+v/Pd9f57Jy9EvOZc0c/4i2f3OEm2CAm9AfY4dp4svjdfvtLdWyVWstXbJYly5dUky//q4uDXA7P/30k86ePavQ0NBi3/fx8VG7du20YcMGxcTESPrtP8Q2bNigMWPGlPo6LmsaR48erVq1amnWrFl66623VFDw280r3t7eateunZKSkjRgwABXlQc38+SALpKk9e8+azc+ctISLf10hyTpxekfqrDQ0D+nj/jt4d7bvtfYxBU3ulQA5aBX7/t0/tw5vTV3js6cOa2mzZrrrb+/q0Cmp+Ek7vRs7+zsbLvU8OjRo0pJSVHNmjVVs2ZNJSQk6KGHHlJISIhSU1P14osvqlGjRoqOjrYd06NHD/Xr18/WFMbFxSk2Nlbt27fXXXfdpdmzZysnJ8d2N3VpWAzDMMrvY5ZNfn6+7Y64WrVqqXLlytd1viptS981A7i5nN8119UlAHASXxc+CLDRuH877dyHp1/78TlX27Rpk7p3715kPDY2VvPnz1dMTIz27dunzMxMhYWFqWfPnnrttdfslvXVq1dPQ4cOtbvZZu7cuZo2bZrS09PVpk0bzZkzR5GRkaWuyy2axvJG0whUXDSNQMXlyqax8QvrnHbuQ9PMf63lZsBvTwMAAI/nTtPT7oqfEQQAAIApkkYAAODxnPlw74qCpBEAAACmSBoBAIDHI2g0R9IIAAAAUySNAADA43l5ETWaIWkEAACAKZJGAADg8VjTaI6mEQAAeDweuWOO6WkAAACYImkEAAAej6DRHEkjAAAATJE0AgAAj8eaRnMkjQAAADBF0ggAADweSaM5kkYAAACYImkEAAAej6DRHE0jAADweExPm2N6GgAAAKZIGgEAgMcjaDRH0ggAAABTJI0AAMDjsabRHEkjAAAATJE0AgAAj0fQaI6kEQAAAKZIGgEAgMdjTaM5kkYAAACYImkEAAAej6DRHE0jAADweExPm2N6GgAAAKZIGgEAgMcjaDRH0ggAAABTJI0AAMDjsabRHEkjAAAATJE0AgAAj0fQaI6kEQAAAKZIGgEAgMdjTaM5mkYAAODx6BnNMT0NAAAAUySNAADA4zE9bY6kEQAAAKZIGgEAgMcjaTRH0ggAAABTJI0AAMDjETSaI2kEAACAKZJGAADg8VjTaI6kEQAAeDyLxXmbo7Zs2aI+ffooLCxMFotFq1evtr2Xn5+v8ePHq1WrVqpatarCwsI0ZMgQnThx4prnnDx5siwWi93WrFkzh+qiaQQAAHAjOTk5ioiI0Lx584q8d/HiRe3du1cTJ07U3r179dFHH+ngwYN68MEHTc97++236+TJk7Zt69atDtXF9DQAAPB47jQ93bt3b/Xu3bvY9/z9/bV+/Xq7sblz5+quu+5SWlqa6tatW+J5K1WqpJCQkDLXRdIIAADgRLm5ubpw4YLdlpubW27nz8rKksViUUBAwDX3O3TokMLCwtSgQQM99thjSktLc+g6NI0AAMDjOXNNY2Jiovz9/e22xMTEcqn78uXLGj9+vAYPHiw/P78S94uMjFRSUpLWrVun+fPn6+jRo+rcubN++eWXUl+L6WkAAAAnmjBhguLi4uzGrFbrdZ83Pz9fAwYMkGEYmj9//jX3/f10d+vWrRUZGanw8HB98MEHGj58eKmuR9MIAAA8npcT1zRardZyaRJ/70rDePz4cW3cuPGaKWNxAgIC1KRJEx0+fLjUxzA9DQAAcBO50jAeOnRIX375pQIDAx0+R3Z2tlJTUxUaGlrqY2gaAQCAx3On5zRmZ2crJSVFKSkpkqSjR48qJSVFaWlpys/P18MPP6zdu3fr/fffV0FBgdLT05Wenq68vDzbOXr06KG5c+faXo8bN06bN2/WsWPHtG3bNvXr10/e3t4aPHhwqetiehoAAHg8d3rkzu7du9W9e3fb6yvrIWNjYzV58mR98sknkqQ2bdrYHffVV1+pW7dukqTU1FSdOXPG9t5PP/2kwYMH6+zZswoKCtI999yj7du3KygoqNR10TQCAAC4kW7duskwjBLfv9Z7Vxw7dszu9fLly6+3LJpGAAAAL/cJGt0WaxoBAABgiqQRAAB4PHda0+iuSBoBAABgiqQRAAB4PIJGcySNAAAAMEXSCAAAPJ5FRI1maBoBAIDH45E75pieBgAAgCmSRgAA4PF45I45kkYAAACYImkEAAAej6DRHEkjAAAATJE0AgAAj+dF1GiKpBEAAACmSBoBAIDHI2g0R9MIAAA8Ho/cMVeqpvHbb78t9Qlbt25d5mIAAADgnkrVNLZp00YWi0WGYRT7/pX3LBaLCgoKyrVAAAAAZyNoNFeqpvHo0aPOrgMAAABurFRNY3h4uLPrAAAAcBkeuWOuTI/cWbJkiTp16qSwsDAdP35ckjR79mx9/PHH5VocAAAA3IPDTeP8+fMVFxen++67T5mZmbY1jAEBAZo9e3Z51wcAAOB0FiduFYXDTePf/vY3vfPOO3rllVfk7e1tG2/fvr32799frsUBAADAPTj8nMajR4+qbdu2RcatVqtycnLKpSgAAIAbiec0mnM4aaxfv75SUlKKjK9bt07Nmzcvj5oAAABuKC+L87aKwuGkMS4uTqNHj9bly5dlGIZ27typf/7zn0pMTNS7777rjBoBAADgYg43jSNGjFCVKlX06quv6uLFi3r00UcVFhamN998U4MGDXJGjQAAAE7F9LS5Mv329GOPPabHHntMFy9eVHZ2tmrXrl3edQEAAMCNlKlplKRTp07p4MGDkn7rzoOCgsqtKAAAgBuJoNGcwzfC/PLLL/rjH/+osLAwde3aVV27dlVYWJgef/xxZWVlOaNGAAAAuJjDTeOIESO0Y8cOrV27VpmZmcrMzNSaNWu0e/duPfnkk86oEQAAwKksFovTtorC4enpNWvW6PPPP9c999xjG4uOjtY777yjXr16lWtxAAAAcA8ON42BgYHy9/cvMu7v768aNWqUS1EAAAA3UkV6nqKzODw9/eqrryouLk7p6em2sfT0dL3wwguaOHFiuRYHAABwIzA9ba5USWPbtm3tPvShQ4dUt25d1a1bV5KUlpYmq9Wq06dPs64RAACgAipV0xgTE+PkMgAAAFyn4uSBzlOqpjE+Pt7ZdQAAAMCNlfnh3gAAABWFVwVae+gsDjeNBQUFmjVrlj744AOlpaUpLy/P7v1z586VW3EAAABwDw7fPZ2QkKCZM2dq4MCBysrKUlxcnPr37y8vLy9NnjzZCSUCAAA4l8XivK2icLhpfP/99/XOO+/o+eefV6VKlTR48GC9++67mjRpkrZv3+6MGgEAAOBiDjeN6enpatWqlSSpWrVqtt+bfuCBB7R27dryrQ4AAOAG4DmN5hxuGm+77TadPHlSktSwYUN98cUXkqRdu3bJarWWb3UAAABwCw43jf369dOGDRskSc8884wmTpyoxo0ba8iQIXriiSfKvUAAAABnY02jOYfvnv7rX/9q+/PAgQMVHh6ubdu2qXHjxurTp0+5FgcAAHAj8Mgdcw4njVe7++67FRcXp8jISP3lL38pj5oAAADgZq67abzi5MmTmjhxYnmdDgAA4IZxp+npLVu2qE+fPgoLC5PFYtHq1avt3jcMQ5MmTVJoaKiqVKmiqKgoHTp0yPS88+bNU7169eTr66vIyEjt3LnTobrKrWkEAADA9cvJyVFERITmzZtX7PtTp07VnDlztGDBAu3YsUNVq1ZVdHS0Ll++XOI5V6xYobi4OMXHx2vv3r2KiIhQdHS0Tp06Veq6aBoBAIDHc6dH7vTu3Vuvv/66+vXrV+Q9wzA0e/Zsvfrqq+rbt69at26tf/zjHzpx4kSRRPL3Zs6cqZEjR2rYsGFq0aKFFixYoFtuuUULFy4sdV00jQAAAE6Um5urCxcu2G25ubllOtfRo0eVnp6uqKgo25i/v78iIyOVnJxc7DF5eXnas2eP3TFeXl6Kiooq8ZjilPru6bi4uGu+f/r06VJfFAAAwJ04M0VLTExUQkKC3Vh8fHyZfn45PT1dkhQcHGw3HhwcbHvvamfOnFFBQUGxx/zwww+lvnapm8Z9+/aZ7tOlS5dSXxgAAMATTJgwoUj4djP+IEqpm8avvvrKmXUAAAC4jDN/7s9qtZZbkxgSEiJJysjIUGhoqG08IyNDbdq0KfaYWrVqydvbWxkZGXbjGRkZtvOVBmsaAQCAx/OyOG8rT/Xr11dISIjt1/kk6cKFC9qxY4c6dOhQ7DE+Pj5q166d3TGFhYXasGFDiccUx+FfhAEAAIDzZGdn6/Dhw7bXR48eVUpKimrWrKm6devq2Wef1euvv67GjRurfv36mjhxosLCwhQTE2M7pkePHurXr5/GjBkj6bd7U2JjY9W+fXvdddddmj17tnJycjRs2LBS10XTCAAAPF55J4LXY/fu3erevbvt9ZX1kLGxsUpKStKLL76onJwcjRo1SpmZmbrnnnu0bt06+fr62o5JTU3VmTNnbK8HDhyo06dPa9KkSUpPT1ebNm20bt26IjfHXIvFMAyjHD6fW6nSdoyrSwDgJOd3zXV1CQCcxNeFUVbcJ6W/i9hRMx9s5rRz30gkjQAAwOM580aYiqJMN8J8/fXXevzxx9WhQwf9/PPPkqQlS5Zo69at5VocAAAA3IPDTeOHH36o6OhoValSRfv27bM90TwrK0t/+ctfyr1AAAAAZ7tZ7p52JYebxtdff10LFizQO++8o8qVK9vGO3XqpL1795ZrcQAAAHAPDq9pPHjwYLG//OLv76/MzMzyqAkAAOCGYkmjOYeTxpCQELtnB12xdetWNWjQoFyKAgAAuJG8LBanbRWFw03jyJEjNXbsWO3YsUMWi0UnTpzQ+++/r3Hjxunpp592Ro0AAABwMYenp1966SUVFhaqR48eunjxorp06SKr1apx48bpmWeecUaNAAAATsXvKptzuGm0WCx65ZVX9MILL+jw4cPKzs5WixYtVK1aNWfUBwAAADdQ5od7+/j4qEWLFuVZCwAAgEtUoKWHTuNw09i9e/drPjV948aN11UQAAAA3I/DTWObNm3sXufn5yslJUUHDhxQbGxsedUFAABww1Sku5ydxeGmcdasWcWOT548WdnZ2dddEAAAANxPud0s9Pjjj2vhwoXldToAAIAbxmJx3lZRlPlGmKslJyfL19e3vE4HAABww1Sk34h2Foebxv79+9u9NgxDJ0+e1O7duzVx4sRyKwwAAADuw+Gm0d/f3+61l5eXmjZtqilTpqhnz57lVhgAAMCNwo0w5hxqGgsKCjRs2DC1atVKNWrUcFZNAAAAcDMO3Qjj7e2tnj17KjMz00nlAAAA3HjcCGPO4bunW7ZsqSNHjjijFgAAALgph5vG119/XePGjdOaNWt08uRJXbhwwW4DAAC42XhZnLdVFKVe0zhlyhQ9//zzuu+++yRJDz74oN3PCRqGIYvFooKCgvKvEgAAAC5V6qYxISFBTz31lL766itn1gMAAHDDWVSBIkEnKXXTaBiGJKlr165OKwYAAMAVKtI0srM4tKbRUpFuAQIAAECpOfScxiZNmpg2jufOnbuuggAAAG40kkZzDjWNCQkJRX4RBgAAABWfQ03joEGDVLt2bWfVAgAA4BIswTNX6jWNfJkAAACey+G7pwEAACoa1jSaK3XTWFhY6Mw6AAAA4MYcWtMIAABQEbEKzxxNIwAA8HhedI2mHHq4NwAAADwTSSMAAPB43AhjjqQRAAAApkgaAQCAx2NJozmSRgAAAJgiaQQAAB7PS0SNZkgaAQAAYIqkEQAAeDzWNJqjaQQAAB6PR+6YY3oaAAAApkgaAQCAx+NnBM2RNAIAAMAUSSMAAPB4BI3mSBoBAABgiqYRAAB4PC+LxWmbI+rVqyeLxVJkGz16dLH7JyUlFdnX19e3PL6SIpieBgAAcBO7du1SQUGB7fWBAwd077336pFHHinxGD8/Px08eND22uKkuXaaRgAA4PGcuaYxNzdXubm5dmNWq1VWq7XIvkFBQXav//rXv6phw4bq2rVriee3WCwKCQkpn2KvgelpAADg8bycuCUmJsrf399uS0xMNK0pLy9PS5cu1RNPPHHN9DA7O1vh4eGqU6eO+vbtq++++65M34EZkkYAAAAnmjBhguLi4uzGiksZr7Z69WplZmZq6NChJe7TtGlTLVy4UK1bt1ZWVpamT5+ujh076rvvvtNtt912vaXbsRiGYZTrGd1AlbZjXF0CACc5v2uuq0sA4CS+LoyyFu/+0Wnnjm1fp0zHRUdHy8fHR59++mmpj8nPz1fz5s01ePBgvfbaa2W6bklIGgEAANzM8ePH9eWXX+qjjz5y6LjKlSurbdu2Onz4cLnXxJpGAADg8SxO3Mpi0aJFql27tu6//36HjisoKND+/fsVGhpaxiuXjKYRAADAjRQWFmrRokWKjY1VpUr2k8JDhgzRhAkTbK+nTJmiL774QkeOHNHevXv1+OOP6/jx4xoxYkS518X0NAAA8HiOPoTbmb788kulpaXpiSeeKPJeWlqavLz+L/M7f/68Ro4cqfT0dNWoUUPt2rXTtm3b1KJFi3KvixthANxUuBEGqLhceSPM0j0/Oe3cj7cr37uYXYWkEQAAeDz3yRndF00jAADweG40O+22uBEGAAAApkgaAQCAx7vWz/ThNySNAAAAMEXSCAAAPB4pmjm+IwAAAJgiaQQAAB6PNY3mSBoBAABgiqQRAAB4PHJGcySNAAAAMEXSCAAAPB5rGs3RNAIAAI/H1Ks5viMAAACYImkEAAAej+lpcySNAAAAMEXSCAAAPB45ozmSRgAAAJgiaQQAAB6PJY3mSBoBAABgiqQRAAB4PC9WNZqiaQQAAB6P6WlzTE8DAADAFEkjAADweBamp02RNAIAAMAUSSMAAPB4rGk0R9IIAAAAUySNAADA4/HIHXMkjQAAADBF0ggAADweaxrN0TQCAACPR9NojulpAAAAmCJpBAAAHo+He5sjaQQAAIApkkYAAODxvAgaTZE0AgAAwBRJIwAA8HisaTRH0ggAAABTJI0AAMDj8ZxGczSNAADA4zE9bY7paQAAAJgiaQQAAB6PR+6YI2kEAACAKZJGAADg8VjTaI6kEQAAAKZIGnFTGPdET8X8IUJN6gXrUm6+dnxzRK+8+bEOHT9l28fqU0l/jeuvR6LbyepTSV8mf6+xf1mhU+d+cWHlAMpq+bL3tXjRezpz5rSaNG2ml16eqFatW7u6LFRQPHLHHEkjbgqd72ikBSu2qOuQ6Xrg6bmqVMlba+aP0S2+PrZ9po57SPd3aanHXnxPPUfMVmiQv5bPGOHCqgGU1bp/f6bpUxP15J9Ga/nKVWratJmefnK4zp496+rSAKeaPHmyLBaL3dasWbNrHrNy5Uo1a9ZMvr6+atWqlT777DOn1EbTiJtC3zFvaemnO/T9kXTt/9/PGhW/VHVDa6ptizqSJL9qvhoa00HjZ36kzbv+p33f/6hR8UvVoU1D3dWqnmuLB+CwJYsXqf/DAxTT7yE1bNRIr8YnyNfXV6s/+tDVpaGCsjhxc9Ttt9+ukydP2ratW7eWuO+2bds0ePBgDR8+XPv27VNMTIxiYmJ04MCBMlz52mgacVPyq+YrSTqfdVGS1LZ5XflUrqSN2w/a9vnfsQylnTynyNb1XVIjgLLJz8vT9//9Tnd36Ggb8/Ly0t13d9S33+xzYWWoyLwsFqdtjqpUqZJCQkJsW61atUrc980331SvXr30wgsvqHnz5nrttdd0xx13aO7cudfzdRTLrZvGH3/8UU888cQ198nNzdWFCxfsNqOw4AZVCFewWCyaNu5hbduXqv+mnpQkhQT6KTcvX1nZl+z2PXX2goID/VxRJoAyOp95XgUFBQoMDLQbDwwM1JkzZ1xUFVB2xfUqubm5Je5/6NAhhYWFqUGDBnrssceUlpZW4r7JycmKioqyG4uOjlZycnK51X+FWzeN586d0+LFi6+5T2Jiovz9/e22XzP23KAK4QqzJwzQ7Y1CNeSlRa4uBQBQQThzerq4XiUxMbHYOiIjI5WUlKR169Zp/vz5Onr0qDp37qxffin+ps709HQFBwfbjQUHBys9Pb3sX0YJXHr39CeffHLN948cOWJ6jgkTJiguLs5urHbn8ddVF9zXrPGP6L7OLRU1fLZ+PpVpG08/e0FWn8ryr1bFLm2sHeinjLMXXFApgLKqEVBD3t7eRW56OXv27DWn6QB3VVyvYrVai923d+/etj+3bt1akZGRCg8P1wcffKDhw4c7tU4zLm0aY2JiZLFYZBhGiftYTNYCWK3WIl+8xcu7XOqDe5k1/hE9+IcI9Rz5po6fsP+Xyb7v05SX/6u6RzbV6g0pkqTG4bVVN7Smdnx71AXVAiiryj4+at7idu3Ynqw/9Pht2q2wsFA7diRr0ODHXVwdKiwnPnKnuF6ltAICAtSkSRMdPny42PdDQkKUkZFhN5aRkaGQkJAyXe9aXDo9HRoaqo8++kiFhYXFbnv37nVleXAjsycM0KD771Tsy0nKzrms4MDqCg6sLl9rZUnShezLSlqdrP/3fH91ad9YbZvX0dsJj2v7N0e0c/8x1xYPwGF/jB2mj/71gT5ZvUpHUlP1+pTJunTpkmL69Xd1acANlZ2drdTUVIWGhhb7focOHbRhwwa7sfXr16tDhw7lXotLk8Z27dppz5496tu3b7Hvm6WQ8BxPDugiSVr/7rN24yMnLdHST3dIkl6c/qEKCw39c/qI3x7uve17jU1ccaNLBVAOevW+T+fPndNbc+fozJnTatqsud76+7sKZHoaTuIuPyM4btw49enTR+Hh4Tpx4oTi4+Pl7e2twYMHS5KGDBmiW2+91bYmcuzYseratatmzJih+++/X8uXL9fu3bv19ttvl3ttFsOFXdnXX3+tnJwc9erVq9j3c3JytHv3bnXt2tWh81ZpO6Y8ygPghs7vKv/HSABwD74ujLJ2pGY57dyRDf1Lve+gQYO0ZcsWnT17VkFBQbrnnnv0xhtvqGHDhpKkbt26qV69ekpKSrIds3LlSr366qs6duyYGjdurKlTp+q+++4r74/h2qbRWWgagYqLphGouFzZNO484rym8a4GpW8a3Rm/PQ0AADyee0xOuze3fk4jAAAA3ANJIwAAAFGjKZJGAAAAmCJpBAAAHs9dHrnjzkgaAQAAYIqkEQAAeDyTXy2GSBoBAABQCiSNAADA4xE0mqNpBAAAoGs0xfQ0AAAATJE0AgAAj8cjd8yRNAIAAMAUSSMAAPB4PHLHHEkjAAAATJE0AgAAj0fQaI6kEQAAAKZIGgEAAIgaTdE0AgAAj8cjd8wxPQ0AAABTJI0AAMDj8cgdcySNAAAAMEXSCAAAPB5BozmSRgAAAJgiaQQAACBqNEXSCAAAAFMkjQAAwOPxnEZzJI0AAAAwRdIIAAA8Hs9pNEfTCAAAPB49ozmmpwEAAGCKpBEAAICo0RRJIwAAAEyRNAIAAI/HI3fMkTQCAADAFEkjAADweDxyxxxJIwAAAEyRNAIAAI9H0GiOphEAAICu0RTT0wAAADBF0ggAADwej9wxR9IIAAAAUySNAADA4/HIHXMkjQAAADBF0ggAADweQaM5kkYAAACYImkEAAAgajRF0ggAADyexYn/c0RiYqLuvPNOVa9eXbVr11ZMTIwOHjx4zWOSkpJksVjsNl9f3+v5OopF0wgAAOAmNm/erNGjR2v79u1av3698vPz1bNnT+Xk5FzzOD8/P508edK2HT9+vNxrY3oaAAB4PHd55M66devsXiclJal27dras2ePunTpUuJxFotFISEhTq2NpBEAAMCJcnNzdeHCBbstNze3VMdmZWVJkmrWrHnN/bKzsxUeHq46deqob9+++u6776677qvRNAIAAI9nceKWmJgof39/uy0xMdG0psLCQj377LPq1KmTWrZsWeJ+TZs21cKFC/Xxxx9r6dKlKiwsVMeOHfXTTz+V6bsoicUwDKNcz+gGqrQd4+oSADjJ+V1zXV0CACfxdeGiuWNnLjvt3KHVLUWSRavVKqvVes3jnn76af373//W1q1bddttt5X6evn5+WrevLkGDx6s1157rUw1F4c1jQAAAE5c01iaBvFqY8aM0Zo1a7RlyxaHGkZJqly5stq2bavDhw87dJwZpqcBAADchGEYGjNmjFatWqWNGzeqfv36Dp+joKBA+/fvV2hoaLnWRtIIAAA8nqPPU3SW0aNHa9myZfr4449VvXp1paenS5L8/f1VpUoVSdKQIUN066232tZFTpkyRXfffbcaNWqkzMxMTZs2TcePH9eIESPKtTaaRgAA4PHc5ZE78+fPlyR169bNbnzRokUaOnSoJCktLU1eXv83WXz+/HmNHDlS6enpqlGjhtq1a6dt27apRYsW5VobN8IAuKlwIwxQcbnyRpi0c6V7BE5Z1K3p2HpGd0XSCAAAPJ6bBI1ujRthAAAAYIqkEQAAeDx3WdPozkgaAQAAYIqkEQAAgFWNpkgaAQAAYIqkEQAAeDzWNJqjaQQAAB6PntEc09MAAAAwRdIIAAA8HtPT5kgaAQAAYIqkEQAAeDwLqxpNkTQCAADAFEkjAAAAQaMpkkYAAACYImkEAAAej6DRHE0jAADweDxyxxzT0wAAADBF0ggAADwej9wxR9IIAAAAUySNAAAABI2mSBoBAABgiqQRAAB4PIJGcySNAAAAMEXSCAAAPB7PaTRH0wgAADwej9wxx/Q0AAAATJE0AgAAj8f0tDmSRgAAAJiiaQQAAIApmkYAAACYYk0jAADweKxpNEfSCAAAAFMkjQAAwOPxnEZzNI0AAMDjMT1tjulpAAAAmCJpBAAAHo+g0RxJIwAAAEyRNAIAABA1miJpBAAAgCmSRgAA4PF45I45kkYAAACYImkEAAAej+c0miNpBAAAgCmSRgAA4PEIGs3RNAIAANA1mmJ6GgAAAKZoGgEAgMezOPF/ZTFv3jzVq1dPvr6+ioyM1M6dO6+5/8qVK9WsWTP5+vqqVatW+uyzz8p03WuhaQQAAHAjK1asUFxcnOLj47V3715FREQoOjpap06dKnb/bdu2afDgwRo+fLj27dunmJgYxcTE6MCBA+Val8UwDKNcz+gGqrQd4+oSADjJ+V1zXV0CACfxdeGdFpd/dd65Hf1ckZGRuvPOOzV37m//vCssLFSdOnX0zDPP6KWXXiqy/8CBA5WTk6M1a9bYxu6++261adNGCxYsuK7af4+kEQAAwIlyc3N14cIFuy03N7fYffPy8rRnzx5FRUXZxry8vBQVFaXk5ORij0lOTrbbX5Kio6NL3L+sKuTd05f2kUR4itzcXCUmJmrChAmyWq2uLgdAOeLvN24kZ6ack19PVEJCgt1YfHy8Jk+eXGTfM2fOqKCgQMHBwXbjwcHB+uGHH4o9f3p6erH7p6enX1/hVyFpxE0tNzdXCQkJJf4XG4CbF3+/UVFMmDBBWVlZdtuECRNcXZbDKmTSCAAA4C6sVmup0/JatWrJ29tbGRkZduMZGRkKCQkp9piQkBCH9i8rkkYAAAA34ePjo3bt2mnDhg22scLCQm3YsEEdOnQo9pgOHTrY7S9J69evL3H/siJpBAAAcCNxcXGKjY1V+/btddddd2n27NnKycnRsGHDJElDhgzRrbfeqsTEREnS2LFj1bVrV82YMUP333+/li9frt27d+vtt98u17poGnFTs1qtio+PZ5E8UAHx9xueauDAgTp9+rQmTZqk9PR0tWnTRuvWrbPd7JKWliYvr/+bLO7YsaOWLVumV199VS+//LIaN26s1atXq2XLluVaV4V8TiMAAADKF2saAQAAYIqmEQAAAKZoGgEAAGCKphEAAACmaBpxU5s3b57q1asnX19fRUZGaufOna4uCcB12rJli/r06aOwsDBZLBatXr3a1SUBEE0jbmIrVqxQXFyc4uPjtXfvXkVERCg6OlqnTp1ydWkArkNOTo4iIiI0b948V5cC4Hd45A5uWpGRkbrzzjs1d+5cSb89Mb9OnTp65pln9NJLL7m4OgDlwWKxaNWqVYqJiXF1KYDHI2nETSkvL0979uxRVFSUbczLy0tRUVFKTk52YWUAAFRMNI24KZ05c0YFBQW2p+NfERwcrPT0dBdVBQBAxUXTCAAAAFM0jbgp1apVS97e3srIyLAbz8jIUEhIiIuqAgCg4qJpxE3Jx8dH7dq104YNG2xjhYWF2rBhgzp06ODCygAAqJgquboAoKzi4uIUGxur9u3b66677tLs2bOVk5OjYcOGubo0ANchOztbhw8ftr0+evSoUlJSVLNmTdWtW9eFlQGejUfu4KY2d+5cTZs2Tenp6WrTpo3mzJmjyMhIV5cF4Dps2rRJ3bt3LzIeGxurpKSkG18QAEk0jQAAACgF1jQCAADAFE0jAAAATNE0AgAAwBRNIwAAAEzRNAIAAMAUTSMAAABM0TQCAADAFE0jAAAATNE0Aig3Q4cOVUxMjO11t27d9Oyzz97wOjZt2iSLxaLMzEynXePqz1oWN6JOACgvNI1ABTd06FBZLBZZLBb5+PioUaNGmjJlin799VenX/ujjz7Sa6+9Vqp9b3QDVa9ePc2ePfuGXAsAKoJKri4AgPP16tVLixYtUm5urj777DONHj1alStX1oQJE4rsm5eXJx8fn3K5bs2aNcvlPAAA1yNpBDyA1WpVSEiIwsPD9fTTTysqKkqffPKJpP+bZn3jjTcUFhampk2bSpJ+/PFHDRgwQAEBAapZs6b69u2rY8eO2c5ZUFCguLg4BQQEKDAwUC+++KKu/in7q6enc3NzNX78eNWpU0dWq1WNGjXSe++9p2PHjql79+6SpBo1ashisWjo0KGSpMLCQiUmJqp+/fqqUqWKIiIi9K9//cvuOp999pmaNGmiKlWqqHv37nZ1lkVBQYGGDx9uu2bTpk315ptvFrtvQkKCgoKC5Ofnp6eeekp5eXm290pTOwDcLEgaAQ9UpUoVnT171vZ6w4YN8vPz0/r16yVJ+fn5io6OVocOHfT111+rUqVKev3119WrVy99++238vHx0YwZM5SUlKSFCxeqefPmmjFjhlatWqU//OEPJV53yJAhSk5O1pw5cxQREaGjR4/qzJkzqlOnjj788EM99NBDOnjwoPz8/FSlShVJUmJiopYuXaoFCxaocePG2rJlix5//HEFBQWpa9eu+vHHH9W/f3+NHj1ao0aN0u7du/X8889f1/dTWFio2267TStXrlRgYKC2bdumUaNGKTQ0VAMGDLD73nx9fbVp0yYdO3ZMw4YNU2BgoN54441S1Q4ANxUDQIUWGxtr9O3b1zAMwygsLDTWr19vWK1WY9y4cbb3g4ODjdzcXNsxS5YsMZo2bWoUFhbaxnJzc40qVaoYn3/+uWEYhhEaGmpMnTrV9n5+fr5x22232a5lGIbRtWtXY+zYsYZhGMbBgwcNScb69euLrfOrr74yJBnnz5+3jV2+fNm45ZZbjG3bttntO3z4cGPw4MGGYRjGhAkTjBYtWti9P378+CLnulp4eLgxa9asEt+/2ujRo42HHnrI9jo2NtaoWbOmkZOTYxubP3++Ua1aNaOgoKBUtRf3mQHAXZE0Ah5gzZo1qlatmvLz81VYWKhHH31UkydPtr3fqlUru3WM33zzjQ4fPqzq1avbnefy5ctKTU1VVlaWTp48qcjISNt7lSpVUvv27YtMUV+RkpIib29vhxK2w4cP6+LFi7r33nvtxvPy8tS2bVtJ0vfff29XhyR16NCh1Ncoybx587Rw4UKlpaXp0qVLysvLU5s2bez2iYiI0C233GJ33ezsbP3444/Kzs42rR0AbiY0jYAH6N69u+bPny8fHx+FhYWpUiX7v/pVq1a1e52dna127drp/fffL3KuoKCgMtVwZbrZEdnZ2ZKktWvX6tZbb7V7z2q1lqmO0li+fLnGjRunGTNmqEOHDqpevbqmTZumHTt2lPocrqodAJyFphHwAFWrVlWjRo1Kvf8dd9yhFStWqHbt2vLz8yt2n9DQUO3YsUNdunSRJP3666/as2eP7rjjjmL3b9WqlQoLC7V582ZFRUUVef9K0llQUGAba9GihaxWq9LS0kpMKJs3b267qeeK7du3m3/Ia/jPf/6jjh076k9/+pNtLDU1tch+33zzjS5dumRriLdv365q1aqpTp06qlmzpmntAHAz4e5pAEU89thjqlWrlvr27auvv/5aR48e1aZNm/TnP/9ZP/30kyRp7Nix+utf/6rVq1frhx9+0J/+9KdrPmOxXr16io2N1RNPPKHVq1fbzvnBBx9IksLDw2WxWLRmzRqdPn1a2dnZql69usaNG6fnnntOixcvVmpqqvbu3au//e1vWrx4sSTpqaee0qFDh/TCCy/o4MGDWrZsmZKSkkr1OX/++WelpKTYbefPn1fjxo21e/duff755/rf//6niRMnateuXUWOz8vL0/Dhw/Xf//5Xn332meLj4zVmzBh5eXmVqnYAuKm4elElAOf6/Y0wjrx/8uRJY8iQIUatWrUMq9VqNGjQwBg5cqSRlZVlGMZvN76MHTvW8PPzMwICAoy4uDhjyJAhJd4IYxiGcenSJeO5554zQkNDDR8fH6NRo0bGwoULbe9PmTLFCAkJMSwWixEbG2sYxm8378yePdto2rSpUblyZSMoKMiIjo42Nm/ebDvu008/NRo1amRYrVajc+fOxsKFC0t1I4ykItuSJUuMy5cvG0OHDjX8/f2NgIAA4+mnnzZeeuklIyIiosj3NmnSJCMwMNCoVq2aMXLkSOPy5cu2fcxq50YYADcTi2GUsGodAAAA+P8xPQ0AAABTNI0AAAAwRdMIAAAAUzSNAAAAMEXTCAAAAFM0jQAAADBF0wgAAABTNI0AAAAwRdMIAAAAUzSNAAAAMEXTCAAAAFP/H4j5qZf+FJqVAAAAAElFTkSuQmCC\n"},"metadata":{}}],"execution_count":130},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}